0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        9B:9E:55:A9:86:D9:50:0B:6D:2D:9F:BA:A7:E6:45:39:D4:DD:5F:C6
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sat Sep 17 07:58:55 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   22C    P0    32W / 250W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.358472704

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2afb1d13e8e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m38.343s
user	0m3.689s
sys	0m3.131s
[07:59:35] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 0.2451],
        [ 0.3861],
        [-1.5635],
        ...,
        [ 1.1367],
        [-1.3202],
        [ 0.5389]], device='cuda:0', requires_grad=True) 
node features sum: tensor(245.3040, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 3.5222e-03,  4.7750e-02,  7.0008e-02, -1.2623e-01,  7.6544e-02,
          2.5779e-02, -1.2022e-01,  3.6439e-02,  8.2804e-02,  6.3673e-02,
         -1.3628e-01,  2.6464e-02,  1.2395e-01,  1.8213e-02, -6.5033e-02,
         -1.3455e-01,  3.6155e-02,  1.2934e-01, -8.5648e-02, -8.5553e-02,
          2.2466e-02, -6.2332e-02,  6.6531e-02, -6.9368e-02,  5.8684e-02,
         -1.2841e-01, -8.3193e-02,  6.5184e-02, -1.4041e-01, -8.9149e-02,
         -1.3238e-01,  1.1091e-01,  6.8717e-02, -8.9128e-02,  1.4997e-01,
          1.2498e-01,  1.1680e-01, -4.3998e-02, -8.6173e-03, -2.2304e-02,
          1.6252e-03, -1.4267e-01,  5.4326e-02, -2.9458e-02, -1.4333e-01,
          1.1677e-02,  5.0698e-02, -3.2091e-02,  1.2746e-01,  7.0451e-02,
          7.5621e-02,  3.2511e-02,  1.4482e-01, -4.5320e-02, -1.1694e-01,
         -1.2340e-01, -2.3360e-02, -1.0261e-02, -7.7144e-02, -8.7997e-02,
          1.9815e-02, -8.2327e-02, -7.7879e-02, -3.9578e-02, -8.5581e-02,
         -1.2786e-01, -1.3946e-01,  9.7679e-02, -4.9680e-03, -3.6838e-02,
          1.4607e-01, -1.2438e-01,  9.5907e-02, -3.5942e-02,  2.1427e-02,
         -1.3886e-03,  9.5041e-02, -2.0786e-02, -3.1392e-02,  1.0722e-01,
         -3.3602e-02, -2.4448e-02, -4.3369e-05, -1.4946e-01, -8.5654e-02,
         -3.2232e-02, -7.5164e-02, -1.0818e-01,  3.3142e-02,  1.2921e-01,
          2.4401e-02,  4.9307e-02,  1.3383e-02, -7.0519e-02,  1.4852e-02,
         -1.1954e-01,  1.4753e-02,  1.3820e-01, -1.2456e-01, -3.9684e-02,
         -1.1346e-01,  6.5437e-02,  1.3250e-01, -4.5560e-02,  1.2548e-02,
          1.3357e-03,  3.3258e-02, -5.0447e-02,  4.9077e-02, -1.3198e-01,
          1.3879e-01,  6.3749e-02,  1.2372e-01,  1.2175e-01,  1.2118e-01,
          7.3368e-02,  1.1255e-01, -8.9667e-02,  3.5793e-02,  7.4896e-02,
         -1.4324e-01, -3.3772e-03,  8.4200e-02, -1.1922e-01,  1.0721e-01,
          4.1462e-02,  8.6438e-02, -3.8317e-02, -8.5170e-02,  1.1073e-01,
         -5.8915e-02,  4.5319e-02, -1.4132e-01,  8.3718e-02, -1.4657e-01,
          5.4408e-02, -7.0854e-02, -1.1839e-01,  2.3311e-02,  1.5639e-02,
          1.4693e-01,  1.1356e-01, -1.4154e-01,  1.1765e-01,  8.5928e-03,
          1.0854e-01,  5.1484e-02,  1.2033e-01, -1.0484e-01,  7.9820e-02,
         -1.3055e-01,  3.4190e-02, -2.6564e-03, -4.6809e-02,  1.5026e-01,
          9.5580e-02, -1.0870e-01,  5.6153e-02,  1.2194e-01,  6.5119e-02,
         -5.3325e-02,  1.3098e-01,  1.0151e-01,  1.2048e-01, -1.0476e-01,
          6.5430e-02,  7.3080e-02, -4.6354e-03,  1.1382e-01,  5.4558e-02,
         -1.2776e-01,  7.0996e-02,  1.2389e-01,  2.3083e-02, -1.5069e-02,
         -8.6339e-02, -1.0723e-01, -9.3518e-02, -1.1425e-01, -1.0545e-01,
         -1.0045e-01, -1.3965e-01, -3.1668e-02, -1.1878e-01, -4.4600e-02,
          2.5438e-02,  3.0477e-02, -8.0283e-02, -6.2315e-02, -2.4569e-02,
         -6.0256e-02, -8.7556e-04, -8.5550e-02,  6.6268e-02,  9.8122e-02,
          3.1928e-02,  1.1004e-01,  1.2486e-01,  1.5056e-01,  3.0147e-02,
         -2.0999e-02,  9.8500e-02,  6.2136e-02, -1.1251e-01, -5.8338e-02,
         -2.6933e-02, -1.0387e-01, -7.4614e-02, -1.2236e-01,  1.4359e-01,
          1.1208e-01,  1.4180e-01,  1.4881e-01,  4.0311e-03, -9.5926e-02,
         -9.0798e-02, -1.3910e-01, -1.1012e-01,  1.1952e-01,  1.2688e-01,
          1.1458e-01, -7.8169e-02,  3.6743e-02,  4.9104e-02, -7.1458e-02,
          1.0944e-01, -1.1876e-01,  1.0351e-01, -1.3240e-01,  5.8060e-02,
          1.2313e-01,  1.2218e-01,  1.8688e-02,  4.5727e-02, -9.9055e-02,
         -4.6323e-02,  1.5098e-01, -1.0809e-01,  9.3782e-03, -1.4080e-02,
          4.7778e-02,  9.2754e-02, -7.1945e-02,  1.0742e-01,  1.1221e-01,
         -8.9802e-02, -8.3419e-02,  1.3524e-01,  5.5420e-02, -1.0249e-02,
          1.1600e-01, -1.0932e-01, -1.1213e-01,  1.3731e-01, -7.3122e-02,
          9.2201e-02]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 3.5222e-03,  4.7750e-02,  7.0008e-02, -1.2623e-01,  7.6544e-02,
          2.5779e-02, -1.2022e-01,  3.6439e-02,  8.2804e-02,  6.3673e-02,
         -1.3628e-01,  2.6464e-02,  1.2395e-01,  1.8213e-02, -6.5033e-02,
         -1.3455e-01,  3.6155e-02,  1.2934e-01, -8.5648e-02, -8.5553e-02,
          2.2466e-02, -6.2332e-02,  6.6531e-02, -6.9368e-02,  5.8684e-02,
         -1.2841e-01, -8.3193e-02,  6.5184e-02, -1.4041e-01, -8.9149e-02,
         -1.3238e-01,  1.1091e-01,  6.8717e-02, -8.9128e-02,  1.4997e-01,
          1.2498e-01,  1.1680e-01, -4.3998e-02, -8.6173e-03, -2.2304e-02,
          1.6252e-03, -1.4267e-01,  5.4326e-02, -2.9458e-02, -1.4333e-01,
          1.1677e-02,  5.0698e-02, -3.2091e-02,  1.2746e-01,  7.0451e-02,
          7.5621e-02,  3.2511e-02,  1.4482e-01, -4.5320e-02, -1.1694e-01,
         -1.2340e-01, -2.3360e-02, -1.0261e-02, -7.7144e-02, -8.7997e-02,
          1.9815e-02, -8.2327e-02, -7.7879e-02, -3.9578e-02, -8.5581e-02,
         -1.2786e-01, -1.3946e-01,  9.7679e-02, -4.9680e-03, -3.6838e-02,
          1.4607e-01, -1.2438e-01,  9.5907e-02, -3.5942e-02,  2.1427e-02,
         -1.3886e-03,  9.5041e-02, -2.0786e-02, -3.1392e-02,  1.0722e-01,
         -3.3602e-02, -2.4448e-02, -4.3369e-05, -1.4946e-01, -8.5654e-02,
         -3.2232e-02, -7.5164e-02, -1.0818e-01,  3.3142e-02,  1.2921e-01,
          2.4401e-02,  4.9307e-02,  1.3383e-02, -7.0519e-02,  1.4852e-02,
         -1.1954e-01,  1.4753e-02,  1.3820e-01, -1.2456e-01, -3.9684e-02,
         -1.1346e-01,  6.5437e-02,  1.3250e-01, -4.5560e-02,  1.2548e-02,
          1.3357e-03,  3.3258e-02, -5.0447e-02,  4.9077e-02, -1.3198e-01,
          1.3879e-01,  6.3749e-02,  1.2372e-01,  1.2175e-01,  1.2118e-01,
          7.3368e-02,  1.1255e-01, -8.9667e-02,  3.5793e-02,  7.4896e-02,
         -1.4324e-01, -3.3772e-03,  8.4200e-02, -1.1922e-01,  1.0721e-01,
          4.1462e-02,  8.6438e-02, -3.8317e-02, -8.5170e-02,  1.1073e-01,
         -5.8915e-02,  4.5319e-02, -1.4132e-01,  8.3718e-02, -1.4657e-01,
          5.4408e-02, -7.0854e-02, -1.1839e-01,  2.3311e-02,  1.5639e-02,
          1.4693e-01,  1.1356e-01, -1.4154e-01,  1.1765e-01,  8.5928e-03,
          1.0854e-01,  5.1484e-02,  1.2033e-01, -1.0484e-01,  7.9820e-02,
         -1.3055e-01,  3.4190e-02, -2.6564e-03, -4.6809e-02,  1.5026e-01,
          9.5580e-02, -1.0870e-01,  5.6153e-02,  1.2194e-01,  6.5119e-02,
         -5.3325e-02,  1.3098e-01,  1.0151e-01,  1.2048e-01, -1.0476e-01,
          6.5430e-02,  7.3080e-02, -4.6354e-03,  1.1382e-01,  5.4558e-02,
         -1.2776e-01,  7.0996e-02,  1.2389e-01,  2.3083e-02, -1.5069e-02,
         -8.6339e-02, -1.0723e-01, -9.3518e-02, -1.1425e-01, -1.0545e-01,
         -1.0045e-01, -1.3965e-01, -3.1668e-02, -1.1878e-01, -4.4600e-02,
          2.5438e-02,  3.0477e-02, -8.0283e-02, -6.2315e-02, -2.4569e-02,
         -6.0256e-02, -8.7556e-04, -8.5550e-02,  6.6268e-02,  9.8122e-02,
          3.1928e-02,  1.1004e-01,  1.2486e-01,  1.5056e-01,  3.0147e-02,
         -2.0999e-02,  9.8500e-02,  6.2136e-02, -1.1251e-01, -5.8338e-02,
         -2.6933e-02, -1.0387e-01, -7.4614e-02, -1.2236e-01,  1.4359e-01,
          1.1208e-01,  1.4180e-01,  1.4881e-01,  4.0311e-03, -9.5926e-02,
         -9.0798e-02, -1.3910e-01, -1.1012e-01,  1.1952e-01,  1.2688e-01,
          1.1458e-01, -7.8169e-02,  3.6743e-02,  4.9104e-02, -7.1458e-02,
          1.0944e-01, -1.1876e-01,  1.0351e-01, -1.3240e-01,  5.8060e-02,
          1.2313e-01,  1.2218e-01,  1.8688e-02,  4.5727e-02, -9.9055e-02,
         -4.6323e-02,  1.5098e-01, -1.0809e-01,  9.3782e-03, -1.4080e-02,
          4.7778e-02,  9.2754e-02, -7.1945e-02,  1.0742e-01,  1.1221e-01,
         -8.9802e-02, -8.3419e-02,  1.3524e-01,  5.5420e-02, -1.0249e-02,
          1.1600e-01, -1.0932e-01, -1.1213e-01,  1.3731e-01, -7.3122e-02,
          9.2201e-02]], device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.0772,  0.1154,  0.0975,  ...,  0.1094,  0.0044, -0.0800],
        [ 0.0700, -0.0178, -0.0855,  ...,  0.0867,  0.1031, -0.0457],
        [-0.0957, -0.0517, -0.1062,  ..., -0.0212,  0.1057,  0.1156],
        ...,
        [-0.0995, -0.0862, -0.0530,  ...,  0.0588, -0.0895,  0.1136],
        [-0.0828,  0.0419,  0.0311,  ...,  0.0397, -0.0876,  0.0399],
        [ 0.0139,  0.0247,  0.0737,  ..., -0.0534,  0.0662,  0.0805]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0772,  0.1154,  0.0975,  ...,  0.1094,  0.0044, -0.0800],
        [ 0.0700, -0.0178, -0.0855,  ...,  0.0867,  0.1031, -0.0457],
        [-0.0957, -0.0517, -0.1062,  ..., -0.0212,  0.1057,  0.1156],
        ...,
        [-0.0995, -0.0862, -0.0530,  ...,  0.0588, -0.0895,  0.1136],
        [-0.0828,  0.0419,  0.0311,  ...,  0.0397, -0.0876,  0.0399],
        [ 0.0139,  0.0247,  0.0737,  ..., -0.0534,  0.0662,  0.0805]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0636,  0.1650,  0.1348,  ..., -0.0092,  0.0040,  0.0289],
        [-0.1356,  0.1227,  0.0824,  ...,  0.1089, -0.0990, -0.1359],
        [ 0.0764,  0.0314, -0.0182,  ...,  0.1157,  0.0115,  0.1141],
        ...,
        [ 0.0139,  0.1331,  0.0512,  ..., -0.1002, -0.1356,  0.1652],
        [-0.1405, -0.1757,  0.1615,  ...,  0.1647, -0.0908, -0.0844],
        [-0.1712, -0.0278, -0.0730,  ..., -0.0740, -0.0677,  0.1466]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0636,  0.1650,  0.1348,  ..., -0.0092,  0.0040,  0.0289],
        [-0.1356,  0.1227,  0.0824,  ...,  0.1089, -0.0990, -0.1359],
        [ 0.0764,  0.0314, -0.0182,  ...,  0.1157,  0.0115,  0.1141],
        ...,
        [ 0.0139,  0.1331,  0.0512,  ..., -0.1002, -0.1356,  0.1652],
        [-0.1405, -0.1757,  0.1615,  ...,  0.1647, -0.0908, -0.0844],
        [-0.1712, -0.0278, -0.0730,  ..., -0.0740, -0.0677,  0.1466]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.1131,  0.1733, -0.0428,  ..., -0.1668, -0.1395,  0.2493],
        [-0.0532, -0.2463,  0.1839,  ..., -0.1421, -0.0476, -0.1456],
        [ 0.2105, -0.2150,  0.0367,  ...,  0.0198, -0.1202,  0.0621],
        ...,
        [ 0.0118,  0.1879,  0.1418,  ...,  0.1153,  0.1608,  0.0745],
        [ 0.0505, -0.1249, -0.0856,  ..., -0.2078, -0.0450,  0.1612],
        [ 0.0233, -0.0508, -0.0315,  ..., -0.1676, -0.0852,  0.0027]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1131,  0.1733, -0.0428,  ..., -0.1668, -0.1395,  0.2493],
        [-0.0532, -0.2463,  0.1839,  ..., -0.1421, -0.0476, -0.1456],
        [ 0.2105, -0.2150,  0.0367,  ...,  0.0198, -0.1202,  0.0621],
        ...,
        [ 0.0118,  0.1879,  0.1418,  ...,  0.1153,  0.1608,  0.0745],
        [ 0.0505, -0.1249, -0.0856,  ..., -0.2078, -0.0450,  0.1612],
        [ 0.0233, -0.0508, -0.0315,  ..., -0.1676, -0.0852,  0.0027]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.3551],
        [ 0.0649],
        [ 0.2544],
        [-0.1619],
        [ 0.1417],
        [ 0.1192],
        [-0.1382],
        [-0.1573],
        [ 0.3480],
        [-0.3433],
        [-0.1277],
        [ 0.4004],
        [-0.1555],
        [-0.2323],
        [-0.3064],
        [-0.3407],
        [-0.4052],
        [ 0.4191],
        [-0.3211],
        [ 0.3431],
        [-0.3751],
        [ 0.3236],
        [-0.2770],
        [ 0.2546],
        [-0.1362],
        [ 0.3571],
        [ 0.3218],
        [-0.2942],
        [ 0.0451],
        [-0.3516],
        [ 0.0491],
        [-0.3602]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.3551],
        [ 0.0649],
        [ 0.2544],
        [-0.1619],
        [ 0.1417],
        [ 0.1192],
        [-0.1382],
        [-0.1573],
        [ 0.3480],
        [-0.3433],
        [-0.1277],
        [ 0.4004],
        [-0.1555],
        [-0.2323],
        [-0.3064],
        [-0.3407],
        [-0.4052],
        [ 0.4191],
        [-0.3211],
        [ 0.3431],
        [-0.3751],
        [ 0.3236],
        [-0.2770],
        [ 0.2546],
        [-0.1362],
        [ 0.3571],
        [ 0.3218],
        [-0.2942],
        [ 0.0451],
        [-0.3516],
        [ 0.0491],
        [-0.3602]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)

net when the batchsize is 2 GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network when the batchsize is 2:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-0.1066, -0.0986, -0.0225, -0.0297, -0.1429, -0.0916, -0.0370, -0.1464,
         -0.0362, -0.1266, -0.0547, -0.0268, -0.0738,  0.0616,  0.1168, -0.1455,
          0.0593, -0.0772,  0.0776,  0.0885,  0.0805, -0.0074, -0.0343,  0.0071,
          0.1472,  0.0702,  0.0629,  0.0403,  0.0594, -0.0722,  0.1457,  0.0753,
         -0.0821,  0.1365,  0.0060,  0.1323, -0.0674, -0.0201, -0.0224,  0.1261,
         -0.0707,  0.0850, -0.0275,  0.1093, -0.0716,  0.0898,  0.0948,  0.1221,
          0.0176,  0.1344, -0.1081,  0.0399,  0.0841,  0.0487,  0.1385, -0.0678,
         -0.1364, -0.0799, -0.0841,  0.1143, -0.0293, -0.0744,  0.0597,  0.0450,
         -0.0176,  0.1081, -0.0112,  0.1014, -0.0730,  0.1168, -0.1082,  0.0640,
         -0.0809, -0.0170,  0.0247,  0.1451,  0.0308,  0.0977,  0.0619,  0.0343,
         -0.0023, -0.0610, -0.0024, -0.0611, -0.0473, -0.1174,  0.0539, -0.1427,
          0.1370,  0.1518,  0.0009, -0.0297,  0.0961,  0.0896,  0.0094,  0.0560,
          0.0233,  0.0138, -0.0599, -0.0512,  0.0147,  0.0501,  0.1386, -0.0779,
          0.1200, -0.1444, -0.1255, -0.0961, -0.1341, -0.0895, -0.0985,  0.1415,
          0.0206, -0.1392, -0.0409, -0.0483, -0.0174,  0.0633,  0.1178,  0.0310,
          0.1056,  0.1339, -0.1312,  0.0573, -0.0012,  0.0507, -0.0796, -0.0747,
          0.0596,  0.0200,  0.0065, -0.0734, -0.0178, -0.1490,  0.1006,  0.0569,
          0.0781, -0.0496,  0.0174,  0.0164,  0.0676,  0.0866, -0.1153,  0.0010,
         -0.1317, -0.0021, -0.1364, -0.0056,  0.1513,  0.1297,  0.1252, -0.0068,
          0.0727,  0.1175,  0.1281,  0.1145,  0.0984, -0.0464,  0.0825, -0.1008,
          0.0921,  0.0868,  0.0687, -0.1392, -0.0080, -0.0791,  0.1275, -0.0696,
         -0.0526,  0.0735, -0.0249,  0.1288, -0.0610,  0.0891, -0.1191, -0.1463,
         -0.0223, -0.0041,  0.0416,  0.0572,  0.0071,  0.1040,  0.0661, -0.0447,
          0.0583,  0.0611,  0.0029, -0.0372,  0.0201,  0.1226,  0.0538, -0.0433,
         -0.0366,  0.1234, -0.0344,  0.1161,  0.0069,  0.0330, -0.1349, -0.1517,
         -0.0526,  0.0364,  0.0912, -0.0386, -0.0959, -0.1217,  0.0043,  0.1045,
          0.1244,  0.1122, -0.0130,  0.0595, -0.0176, -0.1136,  0.0753, -0.1373,
          0.0283, -0.0451,  0.0125, -0.1357,  0.0763,  0.0823, -0.1337,  0.0261,
          0.0455, -0.0226,  0.1321,  0.1199,  0.1244, -0.0187, -0.0531, -0.1010,
         -0.0834,  0.1312,  0.1074,  0.0896,  0.0215,  0.1488, -0.0005,  0.1489,
         -0.0762, -0.0351,  0.0362,  0.0182,  0.0546, -0.0397,  0.0122, -0.1147,
          0.1175, -0.0621, -0.0190,  0.0012, -0.0761, -0.1007,  0.0555, -0.0337]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1066, -0.0986, -0.0225, -0.0297, -0.1429, -0.0916, -0.0370, -0.1464,
         -0.0362, -0.1266, -0.0547, -0.0268, -0.0738,  0.0616,  0.1168, -0.1455,
          0.0593, -0.0772,  0.0776,  0.0885,  0.0805, -0.0074, -0.0343,  0.0071,
          0.1472,  0.0702,  0.0629,  0.0403,  0.0594, -0.0722,  0.1457,  0.0753,
         -0.0821,  0.1365,  0.0060,  0.1323, -0.0674, -0.0201, -0.0224,  0.1261,
         -0.0707,  0.0850, -0.0275,  0.1093, -0.0716,  0.0898,  0.0948,  0.1221,
          0.0176,  0.1344, -0.1081,  0.0399,  0.0841,  0.0487,  0.1385, -0.0678,
         -0.1364, -0.0799, -0.0841,  0.1143, -0.0293, -0.0744,  0.0597,  0.0450,
         -0.0176,  0.1081, -0.0112,  0.1014, -0.0730,  0.1168, -0.1082,  0.0640,
         -0.0809, -0.0170,  0.0247,  0.1451,  0.0308,  0.0977,  0.0619,  0.0343,
         -0.0023, -0.0610, -0.0024, -0.0611, -0.0473, -0.1174,  0.0539, -0.1427,
          0.1370,  0.1518,  0.0009, -0.0297,  0.0961,  0.0896,  0.0094,  0.0560,
          0.0233,  0.0138, -0.0599, -0.0512,  0.0147,  0.0501,  0.1386, -0.0779,
          0.1200, -0.1444, -0.1255, -0.0961, -0.1341, -0.0895, -0.0985,  0.1415,
          0.0206, -0.1392, -0.0409, -0.0483, -0.0174,  0.0633,  0.1178,  0.0310,
          0.1056,  0.1339, -0.1312,  0.0573, -0.0012,  0.0507, -0.0796, -0.0747,
          0.0596,  0.0200,  0.0065, -0.0734, -0.0178, -0.1490,  0.1006,  0.0569,
          0.0781, -0.0496,  0.0174,  0.0164,  0.0676,  0.0866, -0.1153,  0.0010,
         -0.1317, -0.0021, -0.1364, -0.0056,  0.1513,  0.1297,  0.1252, -0.0068,
          0.0727,  0.1175,  0.1281,  0.1145,  0.0984, -0.0464,  0.0825, -0.1008,
          0.0921,  0.0868,  0.0687, -0.1392, -0.0080, -0.0791,  0.1275, -0.0696,
         -0.0526,  0.0735, -0.0249,  0.1288, -0.0610,  0.0891, -0.1191, -0.1463,
         -0.0223, -0.0041,  0.0416,  0.0572,  0.0071,  0.1040,  0.0661, -0.0447,
          0.0583,  0.0611,  0.0029, -0.0372,  0.0201,  0.1226,  0.0538, -0.0433,
         -0.0366,  0.1234, -0.0344,  0.1161,  0.0069,  0.0330, -0.1349, -0.1517,
         -0.0526,  0.0364,  0.0912, -0.0386, -0.0959, -0.1217,  0.0043,  0.1045,
          0.1244,  0.1122, -0.0130,  0.0595, -0.0176, -0.1136,  0.0753, -0.1373,
          0.0283, -0.0451,  0.0125, -0.1357,  0.0763,  0.0823, -0.1337,  0.0261,
          0.0455, -0.0226,  0.1321,  0.1199,  0.1244, -0.0187, -0.0531, -0.1010,
         -0.0834,  0.1312,  0.1074,  0.0896,  0.0215,  0.1488, -0.0005,  0.1489,
         -0.0762, -0.0351,  0.0362,  0.0182,  0.0546, -0.0397,  0.0122, -0.1147,
          0.1175, -0.0621, -0.0190,  0.0012, -0.0761, -0.1007,  0.0555, -0.0337]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.0895, -0.1229,  0.0305,  ..., -0.0537,  0.0927,  0.0540],
        [-0.0148,  0.1142, -0.0312,  ...,  0.0673,  0.0141,  0.0742],
        [-0.0359, -0.0461, -0.0722,  ...,  0.0137, -0.0416,  0.0930],
        ...,
        [ 0.0020,  0.1088,  0.0085,  ..., -0.1155,  0.0272, -0.0344],
        [ 0.0826, -0.1049, -0.0808,  ..., -0.1045, -0.0845, -0.1006],
        [-0.0880, -0.0426,  0.0282,  ...,  0.0565, -0.0350,  0.0947]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0895, -0.1229,  0.0305,  ..., -0.0537,  0.0927,  0.0540],
        [-0.0148,  0.1142, -0.0312,  ...,  0.0673,  0.0141,  0.0742],
        [-0.0359, -0.0461, -0.0722,  ...,  0.0137, -0.0416,  0.0930],
        ...,
        [ 0.0020,  0.1088,  0.0085,  ..., -0.1155,  0.0272, -0.0344],
        [ 0.0826, -0.1049, -0.0808,  ..., -0.1045, -0.0845, -0.1006],
        [-0.0880, -0.0426,  0.0282,  ...,  0.0565, -0.0350,  0.0947]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0340,  0.0863, -0.1309,  ...,  0.1220, -0.0831, -0.1730],
        [ 0.0829,  0.1076, -0.1459,  ..., -0.0417, -0.0251, -0.0801],
        [ 0.0318, -0.1544, -0.1467,  ..., -0.0958,  0.1574,  0.0274],
        ...,
        [ 0.1640, -0.1252, -0.0116,  ...,  0.1743, -0.0352, -0.1626],
        [-0.0415, -0.0314,  0.1020,  ...,  0.1157,  0.1344, -0.0987],
        [-0.0635,  0.0367, -0.0311,  ..., -0.0822, -0.0651,  0.0361]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0340,  0.0863, -0.1309,  ...,  0.1220, -0.0831, -0.1730],
        [ 0.0829,  0.1076, -0.1459,  ..., -0.0417, -0.0251, -0.0801],
        [ 0.0318, -0.1544, -0.1467,  ..., -0.0958,  0.1574,  0.0274],
        ...,
        [ 0.1640, -0.1252, -0.0116,  ...,  0.1743, -0.0352, -0.1626],
        [-0.0415, -0.0314,  0.1020,  ...,  0.1157,  0.1344, -0.0987],
        [-0.0635,  0.0367, -0.0311,  ..., -0.0822, -0.0651,  0.0361]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.2318,  0.1006,  0.0791,  ..., -0.0392, -0.1439, -0.0045],
        [ 0.0907, -0.2254,  0.2017,  ...,  0.2057,  0.0917,  0.1814],
        [-0.1808,  0.2328, -0.0861,  ..., -0.1324, -0.1002, -0.2271],
        ...,
        [ 0.1762, -0.0607,  0.0675,  ..., -0.0579,  0.0164,  0.1267],
        [-0.2045,  0.1668,  0.2169,  ...,  0.0350, -0.1920,  0.1118],
        [ 0.2397, -0.0241,  0.0131,  ...,  0.1241, -0.0842, -0.1409]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.2318,  0.1006,  0.0791,  ..., -0.0392, -0.1439, -0.0045],
        [ 0.0907, -0.2254,  0.2017,  ...,  0.2057,  0.0917,  0.1814],
        [-0.1808,  0.2328, -0.0861,  ..., -0.1324, -0.1002, -0.2271],
        ...,
        [ 0.1762, -0.0607,  0.0675,  ..., -0.0579,  0.0164,  0.1267],
        [-0.2045,  0.1668,  0.2169,  ...,  0.0350, -0.1920,  0.1118],
        [ 0.2397, -0.0241,  0.0131,  ...,  0.1241, -0.0842, -0.1409]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[ 0.2356],
        [-0.0813],
        [-0.0954],
        [-0.4062],
        [ 0.4184],
        [ 0.0722],
        [-0.2303],
        [-0.0530],
        [ 0.0382],
        [-0.0409],
        [-0.0029],
        [ 0.2419],
        [-0.1415],
        [ 0.2866],
        [-0.0094],
        [ 0.1722],
        [-0.0178],
        [-0.3430],
        [ 0.0940],
        [ 0.1798],
        [ 0.3199],
        [ 0.2206],
        [-0.2750],
        [-0.0348],
        [ 0.4080],
        [-0.2992],
        [-0.3581],
        [ 0.1197],
        [ 0.3815],
        [ 0.2750],
        [-0.0570],
        [ 0.2294]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.2356],
        [-0.0813],
        [-0.0954],
        [-0.4062],
        [ 0.4184],
        [ 0.0722],
        [-0.2303],
        [-0.0530],
        [ 0.0382],
        [-0.0409],
        [-0.0029],
        [ 0.2419],
        [-0.1415],
        [ 0.2866],
        [-0.0094],
        [ 0.1722],
        [-0.0178],
        [-0.3430],
        [ 0.0940],
        [ 0.1798],
        [ 0.3199],
        [ 0.2206],
        [-0.2750],
        [-0.0348],
        [ 0.4080],
        [-0.2992],
        [-0.3581],
        [ 0.1197],
        [ 0.3815],
        [ 0.2750],
        [-0.0570],
        [ 0.2294]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(103.8686, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-7.9421, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-8.1199, device='cuda:0')



h[100].sum tensor(9.3513, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(9.5606, device='cuda:0')



h[200].sum tensor(11.5826, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(11.8419, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(11131.6016, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(63985.9766, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-113.3930, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-28.7667, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-182.1703, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.0742],
        [-0.0523],
        [-0.0352],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-3435.3652, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[-0.0742],
        [-0.0523],
        [-0.0352],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/./ModelBha.py", line 174, in <module>
    net = GCN(1, 1, BATCH_SIZEs).to(device)
NameError: name 'BATCH_SIZEs' is not defined

real	0m58.414s
user	0m17.066s
sys	0m10.246s
