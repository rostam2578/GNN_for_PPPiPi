0: gpu032.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-161765e2-e3f6-cb58-9a0c-52038bd3a4b7)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        F3:11:5D:1F:E1:F9:00:68:9F:33:A6:7D:A7:17:9D:64:43:00:25:7B
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sun Sep 25 20:45:44 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:16:00.0 Off |                    0 |
| N/A   41C    P0    45W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b9aad2248e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m13.078s
user	0m2.953s
sys	0m2.118s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 79982

node features (random input): tensor([[-1.9362],
        [ 0.1330],
        [ 0.1220],
        ...,
        [-1.5198],
        [ 0.2567],
        [ 0.0157]], device='cuda:0', requires_grad=True) 
node features sum: tensor(115.1299, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
edges features sum: tensor(79982., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 15

In degrees of node 234: 15





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-0.0232,  0.0665,  0.1466,  0.0606, -0.0030, -0.0551, -0.0416, -0.1321,
         -0.0501,  0.0304, -0.1026,  0.1309, -0.0457, -0.1179,  0.0161,  0.0186,
         -0.1203,  0.1438,  0.0081,  0.1024, -0.1411,  0.0740,  0.1018, -0.0555,
         -0.1224,  0.1214, -0.0197, -0.0546,  0.0729, -0.0848, -0.1068, -0.1059,
          0.0630, -0.0736, -0.0472, -0.0864, -0.0654,  0.1076, -0.1509,  0.0524,
          0.0964, -0.0338, -0.1056,  0.0911, -0.1430,  0.1324,  0.0820,  0.1154,
          0.0167, -0.1514,  0.0259,  0.0431, -0.0638, -0.0786,  0.0939, -0.1323,
         -0.0573, -0.1108,  0.0429, -0.1208, -0.0552,  0.0067, -0.1030,  0.1301,
         -0.0481,  0.1045,  0.0635, -0.1516,  0.1129,  0.0112, -0.1465, -0.1039,
          0.1437,  0.1112, -0.1440,  0.0936, -0.1189, -0.0944, -0.1160, -0.1145,
         -0.0076,  0.1305,  0.0792, -0.1374, -0.0867,  0.0525,  0.1166, -0.0784,
          0.0137,  0.0427,  0.1118, -0.1246, -0.0899, -0.0514, -0.0792, -0.1397,
          0.0543,  0.1071, -0.1401, -0.1513,  0.1359, -0.0526,  0.1222,  0.1206,
         -0.1360,  0.1503, -0.0608,  0.0715,  0.0719,  0.0938, -0.0372,  0.0630,
         -0.1104,  0.0831,  0.1225, -0.0501, -0.1310,  0.0241, -0.0734, -0.0028,
         -0.1254, -0.0227,  0.1352,  0.1095, -0.0263, -0.1229,  0.0367, -0.0294,
          0.0338, -0.0062, -0.0410, -0.0645, -0.1505,  0.0943,  0.1216, -0.0437,
         -0.0622,  0.0165,  0.0750, -0.0009, -0.0722, -0.0713,  0.0754,  0.0405,
         -0.1504,  0.1300, -0.0904, -0.1054,  0.1300, -0.0015, -0.0918,  0.0537,
         -0.0399,  0.0524, -0.0616,  0.1367,  0.1316,  0.1514, -0.1241,  0.1354,
          0.0561,  0.0282, -0.0831, -0.1336, -0.1360,  0.0105,  0.0275, -0.0404,
         -0.0009, -0.0034, -0.0780, -0.0321,  0.0119,  0.0447,  0.1265,  0.0598,
         -0.0593, -0.0951,  0.0143, -0.0774, -0.1251,  0.0795, -0.0241, -0.0591,
         -0.0273,  0.0089,  0.1188,  0.0078, -0.1308, -0.0393,  0.0777,  0.0518,
          0.1119, -0.0895,  0.1171, -0.1220,  0.0402, -0.0007, -0.0665,  0.0997,
         -0.1183,  0.1039,  0.1384,  0.1054, -0.1091,  0.0878,  0.0007, -0.0593,
         -0.0742, -0.0489,  0.0700, -0.1217, -0.0037, -0.0673,  0.0951, -0.0173,
         -0.0823,  0.0618, -0.0683, -0.1182,  0.0818, -0.0669, -0.0902,  0.0611,
          0.0986, -0.1356, -0.0685, -0.0826,  0.1225, -0.0934, -0.0043,  0.1525,
          0.0414, -0.1417,  0.0582,  0.0918,  0.1445, -0.1420, -0.1484, -0.0074,
         -0.1276, -0.0843,  0.0648, -0.1030,  0.1513, -0.1370,  0.1273, -0.0629,
         -0.1137, -0.0628,  0.1523,  0.1259, -0.0924,  0.0528, -0.0359,  0.0362]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0232,  0.0665,  0.1466,  0.0606, -0.0030, -0.0551, -0.0416, -0.1321,
         -0.0501,  0.0304, -0.1026,  0.1309, -0.0457, -0.1179,  0.0161,  0.0186,
         -0.1203,  0.1438,  0.0081,  0.1024, -0.1411,  0.0740,  0.1018, -0.0555,
         -0.1224,  0.1214, -0.0197, -0.0546,  0.0729, -0.0848, -0.1068, -0.1059,
          0.0630, -0.0736, -0.0472, -0.0864, -0.0654,  0.1076, -0.1509,  0.0524,
          0.0964, -0.0338, -0.1056,  0.0911, -0.1430,  0.1324,  0.0820,  0.1154,
          0.0167, -0.1514,  0.0259,  0.0431, -0.0638, -0.0786,  0.0939, -0.1323,
         -0.0573, -0.1108,  0.0429, -0.1208, -0.0552,  0.0067, -0.1030,  0.1301,
         -0.0481,  0.1045,  0.0635, -0.1516,  0.1129,  0.0112, -0.1465, -0.1039,
          0.1437,  0.1112, -0.1440,  0.0936, -0.1189, -0.0944, -0.1160, -0.1145,
         -0.0076,  0.1305,  0.0792, -0.1374, -0.0867,  0.0525,  0.1166, -0.0784,
          0.0137,  0.0427,  0.1118, -0.1246, -0.0899, -0.0514, -0.0792, -0.1397,
          0.0543,  0.1071, -0.1401, -0.1513,  0.1359, -0.0526,  0.1222,  0.1206,
         -0.1360,  0.1503, -0.0608,  0.0715,  0.0719,  0.0938, -0.0372,  0.0630,
         -0.1104,  0.0831,  0.1225, -0.0501, -0.1310,  0.0241, -0.0734, -0.0028,
         -0.1254, -0.0227,  0.1352,  0.1095, -0.0263, -0.1229,  0.0367, -0.0294,
          0.0338, -0.0062, -0.0410, -0.0645, -0.1505,  0.0943,  0.1216, -0.0437,
         -0.0622,  0.0165,  0.0750, -0.0009, -0.0722, -0.0713,  0.0754,  0.0405,
         -0.1504,  0.1300, -0.0904, -0.1054,  0.1300, -0.0015, -0.0918,  0.0537,
         -0.0399,  0.0524, -0.0616,  0.1367,  0.1316,  0.1514, -0.1241,  0.1354,
          0.0561,  0.0282, -0.0831, -0.1336, -0.1360,  0.0105,  0.0275, -0.0404,
         -0.0009, -0.0034, -0.0780, -0.0321,  0.0119,  0.0447,  0.1265,  0.0598,
         -0.0593, -0.0951,  0.0143, -0.0774, -0.1251,  0.0795, -0.0241, -0.0591,
         -0.0273,  0.0089,  0.1188,  0.0078, -0.1308, -0.0393,  0.0777,  0.0518,
          0.1119, -0.0895,  0.1171, -0.1220,  0.0402, -0.0007, -0.0665,  0.0997,
         -0.1183,  0.1039,  0.1384,  0.1054, -0.1091,  0.0878,  0.0007, -0.0593,
         -0.0742, -0.0489,  0.0700, -0.1217, -0.0037, -0.0673,  0.0951, -0.0173,
         -0.0823,  0.0618, -0.0683, -0.1182,  0.0818, -0.0669, -0.0902,  0.0611,
          0.0986, -0.1356, -0.0685, -0.0826,  0.1225, -0.0934, -0.0043,  0.1525,
          0.0414, -0.1417,  0.0582,  0.0918,  0.1445, -0.1420, -0.1484, -0.0074,
         -0.1276, -0.0843,  0.0648, -0.1030,  0.1513, -0.1370,  0.1273, -0.0629,
         -0.1137, -0.0628,  0.1523,  0.1259, -0.0924,  0.0528, -0.0359,  0.0362]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0519, -0.0516, -0.1046,  ..., -0.0369,  0.0380,  0.0371],
        [ 0.1173,  0.1034,  0.1083,  ..., -0.0348, -0.0503, -0.0865],
        [-0.1010, -0.0111, -0.0850,  ...,  0.1001, -0.0087,  0.0306],
        ...,
        [ 0.0222,  0.0254, -0.0276,  ...,  0.0397, -0.1139, -0.0702],
        [-0.0921,  0.0827,  0.0295,  ..., -0.0682,  0.1094,  0.0553],
        [-0.1243, -0.0664,  0.0423,  ...,  0.0736, -0.0540, -0.0131]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0519, -0.0516, -0.1046,  ..., -0.0369,  0.0380,  0.0371],
        [ 0.1173,  0.1034,  0.1083,  ..., -0.0348, -0.0503, -0.0865],
        [-0.1010, -0.0111, -0.0850,  ...,  0.1001, -0.0087,  0.0306],
        ...,
        [ 0.0222,  0.0254, -0.0276,  ...,  0.0397, -0.1139, -0.0702],
        [-0.0921,  0.0827,  0.0295,  ..., -0.0682,  0.1094,  0.0553],
        [-0.1243, -0.0664,  0.0423,  ...,  0.0736, -0.0540, -0.0131]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0600, -0.1372, -0.1609,  ..., -0.0833, -0.1239,  0.1043],
        [-0.0802,  0.0147,  0.0246,  ..., -0.0780, -0.0954,  0.1626],
        [-0.0490, -0.1724, -0.1657,  ..., -0.1042, -0.0526, -0.1482],
        ...,
        [-0.0294, -0.1148,  0.1327,  ..., -0.1139,  0.1230,  0.0992],
        [ 0.0914, -0.0644,  0.0006,  ..., -0.0200, -0.1314, -0.0289],
        [ 0.0944,  0.1646, -0.0212,  ..., -0.1440, -0.1710,  0.0618]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0600, -0.1372, -0.1609,  ..., -0.0833, -0.1239,  0.1043],
        [-0.0802,  0.0147,  0.0246,  ..., -0.0780, -0.0954,  0.1626],
        [-0.0490, -0.1724, -0.1657,  ..., -0.1042, -0.0526, -0.1482],
        ...,
        [-0.0294, -0.1148,  0.1327,  ..., -0.1139,  0.1230,  0.0992],
        [ 0.0914, -0.0644,  0.0006,  ..., -0.0200, -0.1314, -0.0289],
        [ 0.0944,  0.1646, -0.0212,  ..., -0.1440, -0.1710,  0.0618]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.1414,  0.1927, -0.0500,  ..., -0.0979,  0.2032, -0.1007],
        [-0.1105, -0.1244,  0.2460,  ...,  0.1480, -0.1870,  0.0215],
        [ 0.0680,  0.2241,  0.1207,  ..., -0.1272, -0.1709,  0.2376],
        ...,
        [ 0.1141, -0.2475,  0.0927,  ...,  0.1055, -0.1950, -0.0637],
        [ 0.0363, -0.2025,  0.0645,  ...,  0.2358,  0.2373, -0.2451],
        [ 0.1635, -0.2283,  0.0287,  ..., -0.2323,  0.2078, -0.1634]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1414,  0.1927, -0.0500,  ..., -0.0979,  0.2032, -0.1007],
        [-0.1105, -0.1244,  0.2460,  ...,  0.1480, -0.1870,  0.0215],
        [ 0.0680,  0.2241,  0.1207,  ..., -0.1272, -0.1709,  0.2376],
        ...,
        [ 0.1141, -0.2475,  0.0927,  ...,  0.1055, -0.1950, -0.0637],
        [ 0.0363, -0.2025,  0.0645,  ...,  0.2358,  0.2373, -0.2451],
        [ 0.1635, -0.2283,  0.0287,  ..., -0.2323,  0.2078, -0.1634]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.3085],
        [ 0.1917],
        [ 0.1965],
        [ 0.2938],
        [-0.1966],
        [ 0.2637],
        [-0.3227],
        [-0.3491],
        [ 0.3129],
        [-0.3292],
        [ 0.2517],
        [-0.0851],
        [ 0.0066],
        [-0.0905],
        [ 0.0013],
        [ 0.1887],
        [-0.2538],
        [-0.3265],
        [-0.1311],
        [-0.1008],
        [ 0.0962],
        [ 0.0305],
        [ 0.1763],
        [ 0.1567],
        [-0.1512],
        [ 0.1678],
        [-0.2609],
        [ 0.2914],
        [ 0.2838],
        [-0.2397],
        [ 0.3934],
        [-0.2841]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.3085],
        [ 0.1917],
        [ 0.1965],
        [ 0.2938],
        [-0.1966],
        [ 0.2637],
        [-0.3227],
        [-0.3491],
        [ 0.3129],
        [-0.3292],
        [ 0.2517],
        [-0.0851],
        [ 0.0066],
        [-0.0905],
        [ 0.0013],
        [ 0.1887],
        [-0.2538],
        [-0.3265],
        [-0.1311],
        [-0.1008],
        [ 0.0962],
        [ 0.0305],
        [ 0.1763],
        [ 0.1567],
        [-0.1512],
        [ 0.1678],
        [-0.2609],
        [ 0.2914],
        [ 0.2838],
        [-0.2397],
        [ 0.3934],
        [-0.2841]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=79982,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([79982, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(79982., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(55.2692, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(1.8563, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(1.8891, device='cuda:0')



h[100].sum tensor(10.9436, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(11.1368, device='cuda:0')



h[200].sum tensor(-7.6224, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-7.7569, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(10974.6924, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000e+00, 1.4543e-02, 0.0000e+00,  ..., 7.5112e-04, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 3.7307e-03, 0.0000e+00,  ..., 1.9268e-04, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 1.1539e-03, 0.0000e+00,  ..., 5.9595e-05, 0.0000e+00,
         0.0000e+00],
        ...,
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00]], device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(62027.6172, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-52.1362, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(1324.8093, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(80.3607, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-14.5357, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=79982,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.5918],
        [0.3912],
        [0.2509],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(28103.7617, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([79982, 1]) 
g.edata[efet].sum tensor(79982., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[0.5918],
        [0.3912],
        [0.2509],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=1599640,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([1599640, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(1599640., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0076,  0.0095, -0.0159,  ..., -0.0132, -0.0111,  0.0130],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(-492.8239, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-63.2024, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-64.3548, device='cuda:0')



h[100].sum tensor(-81.3180, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-82.8007, device='cuda:0')



h[200].sum tensor(58.3660, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(59.4302, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0566, 0.0000,  ..., 0.0000, 0.0000, 0.0774],
        [0.0000, 0.0310, 0.0000,  ..., 0.0000, 0.0000, 0.0424],
        [0.0000, 0.0074, 0.0000,  ..., 0.0000, 0.0000, 0.0101],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(109492.3125, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0712, 0.2483, 0.0000,  ..., 0.0000, 0.2754, 0.0000],
        [0.0536, 0.1869, 0.0000,  ..., 0.0000, 0.2073, 0.0000],
        [0.0380, 0.1325, 0.0000,  ..., 0.0000, 0.1470, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(565914.3750, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(2741.9182, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(183.5011, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-627.4685, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(8650.1328, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(578.9045, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=1599640,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[2.0924e+00],
        [2.1833e+00],
        [2.3451e+00],
        ...,
        [1.0887e-05],
        [1.8091e-05],
        [2.5839e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(129095.2969, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([1599640, 1]) 
g.edata[efet].sum tensor(1599640., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[0.5918],
        [0.3912],
        [0.2509],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/checkpoint_dir/90016284saved_checkpoint.tar



load_model True 
TraEvN 9001 
BatchSize 30 
EpochNum 80 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 
startmesh 284 
endmesh 285 






optimizer.param_groups
 [{'params': [Parameter containing:
tensor([[ 1.0076e-40, -4.7452e-13,  8.5099e-02,  9.7981e-02,  1.8748e-01,
          1.7174e-01, -3.7681e-12, -6.4529e-12,  1.1833e-01,  1.5747e-01,
          1.9213e-01,  1.1904e-01,  1.2590e-01, -3.3106e-13,  4.4109e-02,
         -1.7796e-17, -2.7480e-03,  1.1192e-01,  8.6889e-02,  1.3959e-01,
         -4.0209e-11, -1.7586e-33,  6.2472e-02,  1.3035e-01, -7.4809e-34,
         -7.2355e-04, -6.9009e-19,  6.3752e-02, -2.3849e-03,  1.0285e-01,
         -5.6311e-13,  7.3909e-02, -8.3398e-21, -5.3455e-23,  1.8028e-01,
          2.0822e-01, -1.2992e-10,  2.2170e-19,  1.0582e-01,  1.7794e-01,
          1.4241e-01,  1.5546e-01,  2.7655e-03,  1.6161e-01, -4.2103e-03,
          7.6704e-41,  9.7278e-02, -1.0763e-40,  1.3845e-01, -2.5767e-13,
         -3.2189e-30, -3.8767e-41,  1.1937e-05,  7.4505e-02, -2.8187e-41,
         -1.9561e-03, -2.5500e-05,  1.0375e-01, -1.2188e-09, -5.0265e-13,
          9.3991e-41,  1.7898e-01, -1.0861e-02, -8.3738e-23,  9.5822e-02,
          1.7488e-01,  2.5739e-01,  1.3917e-01,  3.3075e-41,  8.0075e-02,
         -3.0651e-12, -9.3809e-10,  1.0931e-01, -1.2632e-06,  8.2083e-02,
          8.7719e-02, -8.6903e-06,  7.2083e-02, -3.8073e-12, -3.7840e-29,
         -2.1479e-02, -5.4808e-41, -2.4659e-03, -6.5027e-12,  1.0087e-35,
          5.7344e-04, -3.9924e-13, -1.6431e-03,  1.9390e-40,  1.2487e-01,
         -8.8806e-41, -3.7880e-10,  1.4563e-01,  5.1986e-02, -9.1071e-02,
          4.8800e-14, -2.7304e+00,  7.5317e-02,  1.7143e-01, -5.6215e-12,
          2.7830e-03,  1.8333e-01,  1.0798e-01, -3.5132e-41, -7.7982e-42,
         -1.5986e-15, -2.3301e-03, -2.7785e-21, -1.6885e-09,  1.2168e-01,
         -1.2117e-12, -9.3940e-10,  1.0729e-01,  6.2461e-02,  5.7822e-02,
          1.0425e-01, -5.6811e-41,  1.1143e-01, -5.6213e-10, -4.6760e-13,
          2.1131e-16, -2.4723e-03, -3.1646e-03,  2.3806e-01, -2.1715e-03,
         -7.5765e-10,  1.4553e-01, -5.2708e-14,  8.4413e-03,  3.8607e-41,
          8.8876e-02,  1.2897e-01, -3.2161e-12, -4.0855e-03,  2.4055e-09,
          5.1016e-02,  2.1028e-01,  1.9203e-01,  1.6598e-01,  2.0248e-01,
          1.4678e-01,  7.8349e-04,  1.9454e-01, -3.2202e-03, -1.5898e-03,
         -6.4877e-41, -5.0396e-02,  3.2932e-41,  1.3742e-01, -1.3744e-02,
         -1.5774e-03,  1.0404e-01,  1.4925e-01, -2.3755e-15,  1.1806e-03,
         -4.2991e-13,  1.7377e-01,  5.1399e-02, -7.5344e-30, -3.8368e-12,
         -3.3036e-12,  1.7028e-01, -1.0773e-10,  2.2634e-01, -3.8273e-12,
         -5.3807e-13, -2.4105e-17,  1.9463e-01,  7.8645e-02,  2.0077e-01,
         -1.5703e-14,  1.3155e-40,  1.3898e-01,  9.2085e-04,  8.9895e-02,
         -5.5980e-12,  1.4376e-01, -4.9409e-12,  6.5518e-02, -2.6928e-02,
          1.3006e-01,  1.6913e-01,  1.9898e-01,  1.5325e-01,  1.5412e-01,
          1.9705e-01, -1.0609e-10,  1.2143e-01,  1.2357e-01,  9.5935e-02,
          1.6458e-01,  1.9604e-01,  9.4026e-02,  8.6880e-02, -3.3936e-03,
          1.0404e-01, -3.1436e-12, -2.2484e-21,  1.0961e-01, -1.7790e-13,
         -2.1130e-02, -3.5353e-03,  9.1966e-02, -4.0469e-12,  8.0849e-02,
          4.7105e-41, -2.1600e-02,  1.2787e-01, -1.9811e-04,  1.6660e-01,
          8.3242e-02,  6.0632e-02, -3.1735e-12, -6.4173e-12, -7.4182e-41,
         -2.0316e-28, -1.5908e-02,  9.6841e-11, -5.6313e-03, -4.4687e-12,
          1.7767e-01, -1.4026e-20, -3.1723e-12,  3.1621e-03,  1.4207e-40,
          1.1499e-01,  9.2266e-02, -3.4287e-16, -8.1983e-04,  1.5851e-01,
          6.4657e-02, -2.6482e-03,  2.0335e-01, -6.7958e-06, -2.6435e-03,
         -4.3234e-02,  1.1632e-01, -1.7353e-03,  1.7324e-40,  8.2986e-02,
          1.5746e-01, -2.3766e-03, -1.1877e-09, -5.3763e-10,  5.5299e-03,
         -2.6275e-03,  2.3566e-01, -1.0962e-09, -6.4193e-12, -2.4130e-27,
         -1.3185e-08,  1.2546e-01, -4.0478e-12,  8.9223e-02, -5.7288e-03,
         -2.3289e-21]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-4.0970e-27, -4.6670e-04, -6.2237e-05, -1.1598e-03, -2.7719e-03,
         7.6853e-05, -4.8550e-04, -4.7713e-04, -2.1069e-03, -8.5922e-05,
        -3.5546e-02, -9.6324e-04,  5.6761e-05, -4.7675e-04, -2.9204e-03,
        -3.3829e-04, -3.1080e-03, -6.7404e-03, -6.2335e-03,  9.5737e-05,
        -3.1175e-03, -1.4791e-03, -7.0601e-03, -5.7334e-03, -2.9433e-06,
        -3.0594e-03, -3.2186e-04, -6.3575e-03, -3.1855e-03, -1.2895e-04,
        -4.7780e-04, -7.3646e-03, -1.6757e-04, -2.3207e-04, -6.4764e-05,
        -2.9000e-03, -3.4198e-04, -9.2444e-05, -1.1563e-02, -2.4294e-03,
        -2.1517e-03,  4.6985e-03, -2.8580e-03, -2.4926e-03, -2.6077e-03,
        -1.9990e-05, -3.9400e-05, -2.0805e-06, -1.2535e-02, -4.7664e-04,
        -2.1589e-04, -1.5572e-05, -3.5219e-03, -1.8704e-04, -4.8822e-10,
        -3.9412e-03, -3.0762e-03, -1.2169e-03, -8.0378e-05, -4.6975e-04,
        -2.0236e-32,  5.4889e-05,  5.3119e-03, -2.1030e-04, -6.0694e-03,
         4.5732e-05, -4.4752e-03,  6.6859e-05, -4.4238e-27,  1.1315e-04,
        -5.0877e-04, -8.2313e-05, -5.9483e-03, -2.2141e-03, -2.3535e-03,
        -3.5667e-03, -3.1738e-03, -2.0396e-03, -4.8371e-04, -2.1792e-04,
         1.6381e-02, -3.3856e-05, -2.8341e-03, -4.7636e-04, -1.5217e-35,
        -3.0909e-03, -4.7690e-04, -7.5494e-04, -1.9833e-35, -5.5674e-05,
        -5.0159e-07, -3.0645e-03, -2.6573e-03, -5.4994e-03,  1.2745e-02,
        -1.5831e-03,  3.0621e-02, -4.5264e-04,  2.7211e-04, -4.9092e-04,
        -3.1516e-03, -3.3847e-03, -4.8200e-03, -1.0286e-33, -1.4010e-04,
        -5.7633e-04, -2.8477e-03, -2.5995e-04, -1.3537e-04, -8.2447e-05,
        -4.6740e-04, -8.1097e-05, -1.6410e-04,  1.9210e-02,  9.9016e-03,
        -9.0509e-03, -1.9406e-05, -1.4196e-03, -9.7979e-05, -4.7004e-04,
        -6.4701e-15, -3.4989e-03, -3.1763e-03, -6.7712e-03, -2.7294e-03,
        -7.2318e-05,  6.5509e-03, -4.7171e-04,  7.5435e-03, -1.9049e-04,
        -1.4186e-02, -1.8458e-04, -5.0348e-04, -3.7528e-03, -1.9872e-03,
         1.7165e-03,  1.6097e-04, -3.2210e-04, -2.1457e-03, -3.3318e-05,
         9.9298e-05, -5.4099e-03, -1.1175e-04, -3.0269e-03, -3.2087e-03,
        -3.1555e-05,  1.6110e-02, -3.2061e-12, -3.6950e-04,  9.8527e-03,
        -3.9356e-03, -2.6388e-02, -1.1434e-04, -4.7969e-04, -3.1762e-03,
        -4.6852e-04, -1.8794e-02, -6.0725e-03, -1.7742e-04, -4.8207e-04,
        -5.0066e-04,  1.1799e-04, -3.4676e-04,  9.4854e-04, -4.8234e-04,
        -4.7751e-04, -3.8839e-04, -9.3605e-03,  4.8658e-03,  3.0029e-04,
        -4.6055e-04, -5.7309e-12, -1.7947e-03, -3.2558e-03, -5.6730e-03,
        -4.9134e-04,  2.8115e-03, -5.0413e-04, -1.6648e-03,  8.4502e-03,
        -4.2433e-03,  8.7693e-05,  1.9806e-03,  5.1977e-05, -7.8430e-03,
        -5.2866e-03, -3.4751e-04, -7.1738e-03, -1.5401e-03, -1.3761e-03,
        -1.4972e-02, -4.9674e-05, -8.9552e-04, -1.0467e-03, -3.5624e-03,
        -5.6799e-05, -5.0591e-04, -1.8794e-04, -3.1208e-03, -4.7640e-04,
         3.6855e-03, -3.0937e-03, -1.4555e-02, -4.6554e-04,  1.5073e-02,
        -7.6132e-06,  1.0062e-02,  9.9715e-04, -8.5160e-05,  8.9093e-05,
         7.0559e-03, -1.6324e-02, -5.0489e-04, -4.7767e-04, -1.8995e-04,
        -2.9255e-04,  1.4859e-02, -1.7602e-05,  8.0499e-03, -5.1466e-04,
         4.5473e-04, -2.8963e-04, -5.0493e-04, -3.1623e-03, -1.8079e-26,
        -5.9618e-05,  3.2258e-05, -3.7061e-04, -1.3062e-03, -2.9027e-03,
         5.8721e-03, -2.6838e-03,  2.8622e-05, -2.9678e-03, -3.4241e-03,
         8.2101e-03, -1.4102e-04, -3.2503e-03, -2.2129e-10, -3.5589e-03,
         5.4069e-03, -2.9055e-03, -7.7519e-05, -2.0380e-03, -5.4663e-03,
        -4.0726e-03, -2.6797e-03, -7.4450e-05, -4.7764e-04, -2.2492e-04,
        -1.3554e-04, -1.6017e-03, -4.7709e-04, -9.4620e-04, -4.2668e-03,
        -2.0677e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-1.1535e-40,  3.7978e-41, -1.6032e-40,  ...,  1.2296e-40,
         -7.1522e-42, -1.7370e-40],
        [-1.2442e-40, -6.6534e-41, -2.1963e-23,  ..., -1.5558e-40,
          2.8617e-07, -3.0932e-09],
        [-2.2950e-04,  1.0051e-40, -4.6974e-02,  ...,  8.0645e-42,
         -1.0101e-01, -1.4687e-03],
        ...,
        [-1.9803e-04, -6.4310e-41, -8.0334e-02,  ...,  1.0305e-40,
          8.8672e-02,  5.4892e-02],
        [-6.8367e-41,  6.0899e-41, -5.7258e-04,  ...,  1.8142e-40,
          5.3009e-04, -7.0033e-04],
        [ 1.2070e-40, -2.0071e-40, -4.0788e-37,  ...,  2.7823e-41,
         -8.4646e-11, -6.7265e-19]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-3.0593e-03, -4.6836e-07,  5.2427e-02,  1.4727e-02,  2.9469e-02,
         1.9121e-02,  8.1748e-03,  1.4238e-01,  1.9708e-01,  8.9397e-02,
        -2.3764e-03, -1.1579e-03, -3.7575e-03,  1.1831e-01, -3.3481e-04,
        -2.4162e-08,  2.2032e-02,  1.2948e-01, -1.4263e-02, -7.4856e-09,
        -1.5522e-02,  1.1004e-01, -2.9805e-30, -1.4338e-02,  1.2109e-01,
         2.9334e-02,  1.8958e-02,  6.7604e-02, -9.8335e-03,  1.5636e-01,
         1.0623e-01,  6.3771e-02,  7.7482e-03,  6.5942e-02, -4.3590e-04,
        -2.9529e-03,  1.0599e-01, -4.0316e-03, -2.1062e-02, -3.7802e-02,
        -9.4286e-02, -3.0936e-03, -3.8688e-03,  1.1176e-01,  1.2382e-01,
        -4.1302e-02,  1.9920e-01, -4.1849e-06, -3.0638e-03, -3.7121e-03,
         1.0870e-02, -3.7012e-03,  9.3570e-02,  7.2967e-02,  2.1057e-02,
        -3.6404e-02,  1.5247e-02,  1.5220e-02,  7.7266e-02, -2.4349e-11,
         9.8994e-02,  1.5281e-02,  7.7790e-02, -4.5749e-03, -2.9225e-03,
         4.9633e-02,  5.7546e-02, -4.6389e-03,  5.6994e-02,  4.1217e-02,
        -7.2509e-18, -1.3337e-03,  1.9703e-01, -1.9044e-03, -2.2977e-02,
         9.4437e-02,  1.4711e-02,  7.5851e-02, -2.1134e-03,  7.4420e-02,
        -4.4075e-02,  1.7227e-01, -2.9456e-03,  3.4963e-02, -4.3526e-03,
         1.5553e-01, -5.7740e-06,  5.5662e-02, -8.0279e-07, -1.0274e-02,
        -2.2904e-19, -3.3350e-03,  2.4884e-02, -5.4770e-06, -8.5508e-03,
         2.5205e-02, -2.5545e-05,  1.6238e-02,  1.0975e-01,  1.5459e-02,
        -4.1836e-06, -1.5096e-06,  4.0276e-02, -5.7221e-28,  7.3796e-02,
        -4.1599e-06,  2.8426e-02,  1.8025e-02,  2.1303e-02, -2.1740e-03,
         5.4848e-02,  2.9835e-02, -9.4852e-05, -2.5634e-02, -5.9871e-03,
        -3.1261e-03,  9.9833e-02,  1.1814e-01,  1.0885e-01, -1.2015e-02,
         2.0164e-03,  8.6022e-02, -3.2582e-03,  7.4467e-02, -2.5858e-03,
        -6.1815e-07, -2.5535e-03,  8.3091e-03], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[ 6.6477e-04,  1.3075e-03,  2.2982e-03,  ...,  1.1541e-40,
         -1.1725e-03,  6.4443e-04],
        [-1.1076e-14,  5.5210e-09,  3.2529e-10,  ..., -1.1499e-40,
         -5.3909e-32,  1.2864e-28],
        [ 1.5442e-01, -8.7943e-02,  8.2164e-02,  ..., -1.6282e-08,
          6.8936e-02,  2.4873e-02],
        ...,
        [-1.1485e-14,  5.4268e-09,  2.9419e-10,  ..., -8.0736e-41,
         -1.1528e-30,  2.2491e-29],
        [ 1.7418e-02,  9.0034e-02,  1.9307e-02,  ..., -2.4034e-03,
          5.7133e-02,  8.1395e-02],
        [ 3.0718e-02,  1.5153e-01, -1.1221e-01,  ..., -2.5011e-03,
          1.4741e-01, -1.4788e-01]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 5.0386e-02,  8.0924e-02,  1.9932e-02,  4.0687e-02, -1.2189e-01,
         2.0797e-01,  3.6408e-03, -6.5747e-02, -3.5210e-02,  1.2937e-01,
        -2.6029e-03,  7.4614e-02, -3.1932e-02,  9.2721e-02, -3.0023e-03,
        -2.6529e-03,  5.6282e-03,  1.5434e-01,  1.9262e-02, -3.9509e-02,
        -3.9298e-03,  4.2272e-41, -8.9533e-02, -1.8858e-08,  2.3813e-02,
         2.2635e-02, -6.5586e-02, -1.0886e-14, -4.2543e-03, -8.4905e-02,
         9.9519e-02,  4.2990e-02,  1.7715e-02,  5.1336e-01,  2.8310e-02,
         5.9292e-01, -1.2059e-02, -3.3644e-41, -1.0261e-01,  5.8166e-01,
         6.0275e-01,  1.7001e-01,  3.5869e-01,  7.3710e-02, -2.4171e-02,
         7.5741e-02, -6.0251e-02, -7.2692e-02,  5.3216e-01, -2.9029e-02,
        -4.3077e-02,  4.3459e-01,  4.8081e-02, -2.1208e-02, -6.5748e-02,
        -1.2977e-01,  3.6575e-02,  1.1258e-01,  2.0047e-01,  3.2170e-02,
         6.8401e-02, -2.1159e-03, -1.4777e-02,  3.5003e-01], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[ 4.5361e-02, -2.5416e-01,  1.7201e-01,  ..., -4.3167e-02,
         -2.3020e-01, -1.5807e-02],
        [ 1.8317e-01,  5.0939e-03, -6.8991e-02,  ..., -2.0485e-01,
          6.8011e-03,  2.3558e-02],
        [-3.0885e-02,  1.8940e-01, -3.8720e-02,  ...,  2.4586e-02,
         -1.6983e-01,  3.4412e-02],
        ...,
        [-8.8702e-41,  3.3552e-39, -1.9257e-29,  ...,  1.8260e-41,
          3.1571e-42,  2.0025e-41],
        [ 1.2266e-02, -1.5358e-01,  2.0889e-01,  ..., -1.1895e-02,
         -1.4659e-01, -6.5047e-02],
        [-8.5310e-01, -3.3321e-01, -7.8892e-01,  ...,  2.7579e-01,
         -5.2910e-01, -6.6384e-01]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-3.5677e-01,  3.6482e-01, -1.8174e-01,  7.2786e-01, -2.3176e-01,
         6.5816e-01,  4.3364e-01,  9.1823e-03, -9.3887e-01,  8.6179e-01,
        -3.3974e-01,  8.1999e-01,  2.3528e-01,  4.3968e-01, -6.7660e-01,
         1.0309e-01,  5.4861e-01,  1.4907e+00,  1.0564e+00, -3.1145e-02,
         6.4272e-01, -1.7427e-01, -6.8055e-01, -3.8571e-01,  6.7339e-01,
         2.4329e-01,  6.5753e-01, -2.6564e-01, -9.2828e-04,  8.3973e-01,
        -2.2654e-01,  4.9546e-01], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 2.6161e-01],
        [-6.0314e-01],
        [-8.8726e-01],
        [ 3.3087e-01],
        [-6.9164e-01],
        [ 3.0222e-01],
        [-2.6353e-01],
        [-7.9615e-01],
        [-4.3549e-01],
        [ 1.3947e-01],
        [-1.1361e+00],
        [ 7.8202e-02],
        [ 3.3502e-01],
        [-3.0313e-01],
        [-4.1468e-01],
        [ 6.4982e-01],
        [-2.4421e+00],
        [-7.3053e+00],
        [-3.5008e+00],
        [-1.2678e+00],
        [ 5.2290e-01],
        [-2.4659e-01],
        [-2.6996e-01],
        [-8.7084e-01],
        [ 4.2985e-01],
        [-3.1791e-01],
        [ 1.1974e-01],
        [-7.7330e-01],
        [ 2.6228e-03],
        [ 3.1968e-01],
        [-8.2516e-01],
        [ 3.6124e+00]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0561], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/./TrainingBhaself.py", line 65, in <module>
    optimizer.add_param_group({'params': dglgraph.edata['efet']})
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/optim/optimizer.py", line 258, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor

real	0m36.892s
user	0m18.742s
sys	0m8.505s
