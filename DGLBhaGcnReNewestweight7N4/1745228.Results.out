0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        9B:9E:55:A9:86:D9:50:0B:6D:2D:9F:BA:A7:E6:45:39:D4:DD:5F:C6
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sat Sep 17 08:04:25 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   25C    P0    33W / 250W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.358472704

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2ba5f19488e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m5.227s
user	0m2.696s
sys	0m1.180s
[08:04:33] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[-0.0600],
        [ 1.7083],
        [ 1.1423],
        ...,
        [-1.1751],
        [ 1.1670],
        [-0.1397]], device='cuda:0', requires_grad=True) 
node features sum: tensor(110.9092, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 1.6779e-03,  1.0232e-01, -1.3869e-01,  7.5061e-02, -9.7608e-02,
          4.6993e-02,  1.3247e-01, -2.4455e-02,  1.3614e-01, -5.4873e-02,
         -9.7179e-02, -4.8619e-02, -7.2232e-02, -8.8021e-02,  1.0824e-02,
         -7.6114e-02, -8.8099e-03,  7.3524e-02, -1.1197e-01, -1.2394e-01,
         -6.3036e-02, -6.9532e-02, -9.4794e-03, -2.7559e-05, -5.2590e-02,
          8.8466e-02, -1.0196e-01,  2.6119e-02,  1.0382e-02,  4.1149e-02,
         -8.4965e-02, -1.5289e-02,  2.5967e-02,  6.1441e-02,  9.4931e-02,
          5.9011e-02, -1.3079e-01,  6.4998e-02,  5.0346e-02,  7.0584e-02,
          2.0091e-02,  1.8914e-02,  9.5002e-02, -1.1205e-01, -3.4882e-02,
         -4.9865e-02, -1.1711e-01, -1.1194e-01, -1.1632e-01,  1.5060e-01,
         -1.4344e-01,  1.5169e-01,  9.5329e-02, -7.2316e-02, -9.0733e-02,
          4.8899e-02,  8.0433e-02, -1.2610e-01,  1.0736e-01, -7.0344e-02,
         -3.8580e-02,  5.9050e-02,  6.8814e-02,  8.0950e-02, -5.2505e-02,
         -5.9524e-02, -1.2331e-01,  4.7950e-02, -1.2266e-01,  3.5812e-02,
          1.1588e-01,  5.9660e-02,  7.1585e-02, -1.2247e-01,  5.2603e-02,
          1.0363e-01,  9.4175e-02, -7.9552e-02, -1.8733e-02,  2.7739e-02,
         -5.2408e-02, -3.8984e-02,  1.3816e-01,  1.1255e-01,  6.5505e-02,
          1.0660e-03,  5.0977e-02,  1.1011e-01, -1.3549e-02,  5.1581e-02,
         -6.4272e-02,  9.6737e-02,  1.1153e-01,  9.5959e-02,  1.4405e-01,
          4.1269e-03,  7.5699e-03, -1.1076e-02,  1.5115e-01, -5.0778e-02,
          8.6223e-02,  5.3717e-02, -5.4476e-02, -4.8254e-02, -1.4318e-01,
         -3.3653e-02,  1.6502e-02,  1.4933e-01,  6.6975e-02, -1.2457e-01,
          1.1474e-01,  1.2653e-02, -7.9678e-02, -7.7201e-02, -4.2491e-02,
         -7.0504e-02,  1.9161e-02, -6.7044e-02, -1.1843e-01, -9.7062e-02,
          8.1879e-02, -1.9208e-02,  1.8710e-02, -2.2243e-02, -1.1035e-01,
         -7.3481e-02,  1.4427e-01, -8.5792e-02, -4.6503e-02, -6.4588e-03,
         -1.0231e-02,  7.7576e-02,  4.1092e-03,  3.1029e-02,  7.7560e-02,
         -5.8520e-02,  4.0539e-02, -2.4623e-03,  1.0430e-01,  2.2876e-02,
          3.9433e-02,  2.8457e-02,  1.4068e-01, -8.7206e-02, -2.0576e-02,
          2.3789e-02, -5.5298e-02, -1.1563e-01,  2.4503e-02, -1.3696e-01,
          4.3324e-02, -9.8449e-02,  9.6543e-02, -7.4082e-02, -2.4449e-02,
         -3.8290e-02,  3.5866e-02, -3.4120e-03, -1.3649e-01, -7.2253e-02,
         -5.7753e-02, -1.1918e-01,  1.7821e-02, -1.1699e-01,  6.8678e-02,
          8.0847e-02, -9.6730e-02, -1.1189e-01, -2.1885e-02, -1.4820e-01,
          1.1834e-01, -1.1235e-01,  1.3536e-01,  4.9293e-02,  9.5485e-02,
          9.3159e-02,  6.5124e-02,  9.9573e-02,  1.3612e-01, -3.3365e-02,
         -3.3464e-02, -1.5772e-02,  1.1379e-01, -4.2026e-02,  1.4072e-01,
          7.3616e-02,  9.9196e-02,  1.1512e-01, -1.1554e-01, -4.4247e-02,
          1.3514e-01, -9.4465e-02,  5.4056e-02,  7.8852e-02,  1.1897e-01,
          9.6835e-02,  4.0162e-02, -6.7232e-02, -9.8557e-02, -1.2874e-01,
          7.9639e-02, -1.9853e-02, -7.5827e-02,  7.3326e-03,  7.9803e-02,
          9.5847e-02,  1.0779e-01, -5.5566e-02, -1.2206e-01, -7.3349e-02,
         -6.6728e-02, -1.3875e-01, -5.3680e-02,  1.3558e-02,  1.0533e-01,
         -2.5712e-02,  6.0278e-02, -4.9499e-02, -1.8748e-03, -5.4628e-02,
         -4.6744e-02,  9.5958e-02, -1.0944e-01,  5.9821e-02, -9.1105e-03,
         -4.5783e-02,  8.4869e-02,  1.0534e-02, -1.1134e-01,  1.4691e-01,
         -1.3563e-02, -8.8541e-02, -4.2181e-02,  3.9216e-02, -3.5932e-03,
          6.2010e-02, -4.3774e-02, -1.0969e-01, -4.4127e-02,  2.9317e-02,
         -1.0609e-01, -2.3998e-02, -3.5109e-02, -1.3035e-01, -1.2399e-01,
          1.4880e-01, -5.1845e-02, -1.3513e-01, -3.3956e-02,  1.6152e-02,
         -4.0754e-02,  5.0383e-02, -7.5452e-02,  9.4885e-02,  1.0553e-01,
         -1.1288e-01]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 1.6779e-03,  1.0232e-01, -1.3869e-01,  7.5061e-02, -9.7608e-02,
          4.6993e-02,  1.3247e-01, -2.4455e-02,  1.3614e-01, -5.4873e-02,
         -9.7179e-02, -4.8619e-02, -7.2232e-02, -8.8021e-02,  1.0824e-02,
         -7.6114e-02, -8.8099e-03,  7.3524e-02, -1.1197e-01, -1.2394e-01,
         -6.3036e-02, -6.9532e-02, -9.4794e-03, -2.7559e-05, -5.2590e-02,
          8.8466e-02, -1.0196e-01,  2.6119e-02,  1.0382e-02,  4.1149e-02,
         -8.4965e-02, -1.5289e-02,  2.5967e-02,  6.1441e-02,  9.4931e-02,
          5.9011e-02, -1.3079e-01,  6.4998e-02,  5.0346e-02,  7.0584e-02,
          2.0091e-02,  1.8914e-02,  9.5002e-02, -1.1205e-01, -3.4882e-02,
         -4.9865e-02, -1.1711e-01, -1.1194e-01, -1.1632e-01,  1.5060e-01,
         -1.4344e-01,  1.5169e-01,  9.5329e-02, -7.2316e-02, -9.0733e-02,
          4.8899e-02,  8.0433e-02, -1.2610e-01,  1.0736e-01, -7.0344e-02,
         -3.8580e-02,  5.9050e-02,  6.8814e-02,  8.0950e-02, -5.2505e-02,
         -5.9524e-02, -1.2331e-01,  4.7950e-02, -1.2266e-01,  3.5812e-02,
          1.1588e-01,  5.9660e-02,  7.1585e-02, -1.2247e-01,  5.2603e-02,
          1.0363e-01,  9.4175e-02, -7.9552e-02, -1.8733e-02,  2.7739e-02,
         -5.2408e-02, -3.8984e-02,  1.3816e-01,  1.1255e-01,  6.5505e-02,
          1.0660e-03,  5.0977e-02,  1.1011e-01, -1.3549e-02,  5.1581e-02,
         -6.4272e-02,  9.6737e-02,  1.1153e-01,  9.5959e-02,  1.4405e-01,
          4.1269e-03,  7.5699e-03, -1.1076e-02,  1.5115e-01, -5.0778e-02,
          8.6223e-02,  5.3717e-02, -5.4476e-02, -4.8254e-02, -1.4318e-01,
         -3.3653e-02,  1.6502e-02,  1.4933e-01,  6.6975e-02, -1.2457e-01,
          1.1474e-01,  1.2653e-02, -7.9678e-02, -7.7201e-02, -4.2491e-02,
         -7.0504e-02,  1.9161e-02, -6.7044e-02, -1.1843e-01, -9.7062e-02,
          8.1879e-02, -1.9208e-02,  1.8710e-02, -2.2243e-02, -1.1035e-01,
         -7.3481e-02,  1.4427e-01, -8.5792e-02, -4.6503e-02, -6.4588e-03,
         -1.0231e-02,  7.7576e-02,  4.1092e-03,  3.1029e-02,  7.7560e-02,
         -5.8520e-02,  4.0539e-02, -2.4623e-03,  1.0430e-01,  2.2876e-02,
          3.9433e-02,  2.8457e-02,  1.4068e-01, -8.7206e-02, -2.0576e-02,
          2.3789e-02, -5.5298e-02, -1.1563e-01,  2.4503e-02, -1.3696e-01,
          4.3324e-02, -9.8449e-02,  9.6543e-02, -7.4082e-02, -2.4449e-02,
         -3.8290e-02,  3.5866e-02, -3.4120e-03, -1.3649e-01, -7.2253e-02,
         -5.7753e-02, -1.1918e-01,  1.7821e-02, -1.1699e-01,  6.8678e-02,
          8.0847e-02, -9.6730e-02, -1.1189e-01, -2.1885e-02, -1.4820e-01,
          1.1834e-01, -1.1235e-01,  1.3536e-01,  4.9293e-02,  9.5485e-02,
          9.3159e-02,  6.5124e-02,  9.9573e-02,  1.3612e-01, -3.3365e-02,
         -3.3464e-02, -1.5772e-02,  1.1379e-01, -4.2026e-02,  1.4072e-01,
          7.3616e-02,  9.9196e-02,  1.1512e-01, -1.1554e-01, -4.4247e-02,
          1.3514e-01, -9.4465e-02,  5.4056e-02,  7.8852e-02,  1.1897e-01,
          9.6835e-02,  4.0162e-02, -6.7232e-02, -9.8557e-02, -1.2874e-01,
          7.9639e-02, -1.9853e-02, -7.5827e-02,  7.3326e-03,  7.9803e-02,
          9.5847e-02,  1.0779e-01, -5.5566e-02, -1.2206e-01, -7.3349e-02,
         -6.6728e-02, -1.3875e-01, -5.3680e-02,  1.3558e-02,  1.0533e-01,
         -2.5712e-02,  6.0278e-02, -4.9499e-02, -1.8748e-03, -5.4628e-02,
         -4.6744e-02,  9.5958e-02, -1.0944e-01,  5.9821e-02, -9.1105e-03,
         -4.5783e-02,  8.4869e-02,  1.0534e-02, -1.1134e-01,  1.4691e-01,
         -1.3563e-02, -8.8541e-02, -4.2181e-02,  3.9216e-02, -3.5932e-03,
          6.2010e-02, -4.3774e-02, -1.0969e-01, -4.4127e-02,  2.9317e-02,
         -1.0609e-01, -2.3998e-02, -3.5109e-02, -1.3035e-01, -1.2399e-01,
          1.4880e-01, -5.1845e-02, -1.3513e-01, -3.3956e-02,  1.6152e-02,
         -4.0754e-02,  5.0383e-02, -7.5452e-02,  9.4885e-02,  1.0553e-01,
         -1.1288e-01]], device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.1172,  0.0264, -0.0669,  ..., -0.1191, -0.0596, -0.0760],
        [ 0.0751, -0.0294,  0.0681,  ...,  0.0245, -0.0760,  0.0799],
        [ 0.0721,  0.0047,  0.0121,  ..., -0.1091,  0.0007, -0.0341],
        ...,
        [-0.0877, -0.0049,  0.0376,  ..., -0.0417, -0.0229,  0.1035],
        [-0.0497,  0.0479,  0.0128,  ...,  0.1205,  0.1115,  0.0356],
        [ 0.0088, -0.0681,  0.0950,  ..., -0.0430, -0.0033, -0.0297]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1172,  0.0264, -0.0669,  ..., -0.1191, -0.0596, -0.0760],
        [ 0.0751, -0.0294,  0.0681,  ...,  0.0245, -0.0760,  0.0799],
        [ 0.0721,  0.0047,  0.0121,  ..., -0.1091,  0.0007, -0.0341],
        ...,
        [-0.0877, -0.0049,  0.0376,  ..., -0.0417, -0.0229,  0.1035],
        [-0.0497,  0.0479,  0.0128,  ...,  0.1205,  0.1115,  0.0356],
        [ 0.0088, -0.0681,  0.0950,  ..., -0.0430, -0.0033, -0.0297]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.1500,  0.0384,  0.0009,  ...,  0.0333, -0.0811,  0.1207],
        [-0.0566,  0.0699,  0.0791,  ..., -0.0632, -0.1020, -0.1671],
        [-0.0694, -0.0129, -0.1670,  ...,  0.1153, -0.1224, -0.0872],
        ...,
        [ 0.1120,  0.1520,  0.1747,  ...,  0.1198, -0.1631, -0.0542],
        [ 0.1574, -0.0047,  0.0364,  ..., -0.1427,  0.1181,  0.0504],
        [-0.0731, -0.0309,  0.1230,  ..., -0.1267,  0.0734,  0.0304]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1500,  0.0384,  0.0009,  ...,  0.0333, -0.0811,  0.1207],
        [-0.0566,  0.0699,  0.0791,  ..., -0.0632, -0.1020, -0.1671],
        [-0.0694, -0.0129, -0.1670,  ...,  0.1153, -0.1224, -0.0872],
        ...,
        [ 0.1120,  0.1520,  0.1747,  ...,  0.1198, -0.1631, -0.0542],
        [ 0.1574, -0.0047,  0.0364,  ..., -0.1427,  0.1181,  0.0504],
        [-0.0731, -0.0309,  0.1230,  ..., -0.1267,  0.0734,  0.0304]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-0.1905, -0.2324,  0.2470,  ..., -0.1642, -0.1693, -0.2375],
        [-0.0487,  0.1647, -0.1842,  ..., -0.2324, -0.0588,  0.2422],
        [ 0.0162, -0.1286,  0.1257,  ...,  0.0396, -0.2327,  0.1498],
        ...,
        [ 0.2021,  0.1467,  0.2356,  ..., -0.0015,  0.1076, -0.2411],
        [ 0.0005,  0.0178,  0.1011,  ...,  0.2264, -0.1146, -0.2067],
        [ 0.1037,  0.2131,  0.2121,  ..., -0.0448, -0.0445, -0.0742]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1905, -0.2324,  0.2470,  ..., -0.1642, -0.1693, -0.2375],
        [-0.0487,  0.1647, -0.1842,  ..., -0.2324, -0.0588,  0.2422],
        [ 0.0162, -0.1286,  0.1257,  ...,  0.0396, -0.2327,  0.1498],
        ...,
        [ 0.2021,  0.1467,  0.2356,  ..., -0.0015,  0.1076, -0.2411],
        [ 0.0005,  0.0178,  0.1011,  ...,  0.2264, -0.1146, -0.2067],
        [ 0.1037,  0.2131,  0.2121,  ..., -0.0448, -0.0445, -0.0742]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[ 0.3176],
        [ 0.1380],
        [-0.0120],
        [-0.1798],
        [ 0.1912],
        [ 0.1158],
        [-0.3458],
        [ 0.3321],
        [ 0.2306],
        [ 0.2239],
        [ 0.4094],
        [ 0.3992],
        [-0.1010],
        [-0.2620],
        [-0.4091],
        [-0.3793],
        [-0.3303],
        [-0.0745],
        [ 0.2998],
        [-0.4143],
        [ 0.0353],
        [ 0.2998],
        [-0.2637],
        [-0.4012],
        [-0.1187],
        [-0.3078],
        [ 0.0305],
        [ 0.2262],
        [-0.4087],
        [ 0.2061],
        [-0.3740],
        [-0.4262]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.3176],
        [ 0.1380],
        [-0.0120],
        [-0.1798],
        [ 0.1912],
        [ 0.1158],
        [-0.3458],
        [ 0.3321],
        [ 0.2306],
        [ 0.2239],
        [ 0.4094],
        [ 0.3992],
        [-0.1010],
        [-0.2620],
        [-0.4091],
        [-0.3793],
        [-0.3303],
        [-0.0745],
        [ 0.2998],
        [-0.4143],
        [ 0.0353],
        [ 0.2998],
        [-0.2637],
        [-0.4012],
        [-0.1187],
        [-0.3078],
        [ 0.0305],
        [ 0.2262],
        [-0.4087],
        [ 0.2061],
        [-0.3740],
        [-0.4262]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)

net when the batchsize is 2 GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network when the batchsize is 2:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-0.0824, -0.1243, -0.0054,  0.1066,  0.1156, -0.1205, -0.0404,  0.0048,
          0.0607,  0.0888, -0.0797, -0.0473,  0.1210,  0.0099,  0.0329,  0.1208,
         -0.0708, -0.0279, -0.0754, -0.1477,  0.1106, -0.0618, -0.0854, -0.0329,
         -0.1258, -0.0540,  0.0553,  0.1217,  0.0159,  0.1500,  0.1371,  0.0675,
          0.1432, -0.0761,  0.0067,  0.0645,  0.0561,  0.0018,  0.1522, -0.0114,
         -0.0447, -0.0607, -0.0179,  0.0849, -0.0731, -0.1242, -0.0750,  0.0928,
          0.0826, -0.0333, -0.0892, -0.0621, -0.0623, -0.1085,  0.0504, -0.1051,
         -0.1183, -0.1007, -0.0302, -0.0219, -0.0025, -0.0613, -0.0695, -0.0769,
          0.0347,  0.0917,  0.0582,  0.0183, -0.1486, -0.1499, -0.1138, -0.1327,
         -0.0691, -0.0954,  0.0984, -0.0435, -0.0496,  0.1177,  0.1466,  0.0577,
         -0.0170,  0.0858, -0.0175, -0.1445, -0.1124, -0.0088,  0.1361, -0.0156,
         -0.0935, -0.0254,  0.0087, -0.0454,  0.0049,  0.0133,  0.1232, -0.0223,
          0.1268, -0.0209, -0.1492,  0.1238,  0.1364, -0.0494,  0.1506,  0.1507,
          0.0835, -0.0808,  0.1423,  0.0112, -0.0952, -0.1088,  0.0617,  0.0301,
         -0.1402,  0.0276, -0.0258,  0.0359, -0.0616, -0.1059,  0.1350, -0.0008,
          0.0762,  0.1439,  0.0387,  0.0969,  0.0783,  0.0231, -0.1345, -0.0669,
          0.1304,  0.1185,  0.1416,  0.0744, -0.0034,  0.0096,  0.0446,  0.1183,
          0.0770, -0.0758, -0.1395, -0.1218,  0.0349,  0.0500, -0.0183,  0.0711,
         -0.0347,  0.0934,  0.0670, -0.0038,  0.0200, -0.0276, -0.0364, -0.0272,
         -0.1283, -0.1051,  0.0405, -0.0498,  0.0711, -0.0184, -0.0232,  0.0090,
          0.0129, -0.0531,  0.0743, -0.0128,  0.1336, -0.0849, -0.0733,  0.1475,
         -0.1420,  0.0784, -0.1480, -0.0125, -0.0034, -0.1391,  0.1416, -0.0904,
         -0.0818, -0.0425,  0.1410,  0.0522,  0.0425,  0.1468,  0.1386, -0.1375,
          0.1292, -0.0469,  0.0878, -0.0481, -0.0219,  0.0223, -0.0273,  0.0728,
          0.1402,  0.0045,  0.0249,  0.0106, -0.0835,  0.0469, -0.0574, -0.0758,
          0.0743, -0.1426, -0.1342,  0.0574, -0.0107, -0.1063,  0.0519, -0.0702,
         -0.0056,  0.1312,  0.1320,  0.1328,  0.0625,  0.0867, -0.0876, -0.1189,
          0.0700, -0.0457, -0.0243,  0.1065, -0.0323,  0.0297,  0.0616, -0.0520,
         -0.0578,  0.1052,  0.1212, -0.0435, -0.0046, -0.0702,  0.0405, -0.1468,
         -0.1350,  0.0947, -0.1272, -0.0618,  0.1010,  0.1131,  0.1168,  0.1081,
         -0.0380,  0.1249, -0.0765,  0.0304,  0.0336, -0.1272, -0.1101, -0.1217,
          0.0886, -0.0488,  0.0025, -0.0683, -0.0232, -0.0983, -0.0978,  0.0507]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0824, -0.1243, -0.0054,  0.1066,  0.1156, -0.1205, -0.0404,  0.0048,
          0.0607,  0.0888, -0.0797, -0.0473,  0.1210,  0.0099,  0.0329,  0.1208,
         -0.0708, -0.0279, -0.0754, -0.1477,  0.1106, -0.0618, -0.0854, -0.0329,
         -0.1258, -0.0540,  0.0553,  0.1217,  0.0159,  0.1500,  0.1371,  0.0675,
          0.1432, -0.0761,  0.0067,  0.0645,  0.0561,  0.0018,  0.1522, -0.0114,
         -0.0447, -0.0607, -0.0179,  0.0849, -0.0731, -0.1242, -0.0750,  0.0928,
          0.0826, -0.0333, -0.0892, -0.0621, -0.0623, -0.1085,  0.0504, -0.1051,
         -0.1183, -0.1007, -0.0302, -0.0219, -0.0025, -0.0613, -0.0695, -0.0769,
          0.0347,  0.0917,  0.0582,  0.0183, -0.1486, -0.1499, -0.1138, -0.1327,
         -0.0691, -0.0954,  0.0984, -0.0435, -0.0496,  0.1177,  0.1466,  0.0577,
         -0.0170,  0.0858, -0.0175, -0.1445, -0.1124, -0.0088,  0.1361, -0.0156,
         -0.0935, -0.0254,  0.0087, -0.0454,  0.0049,  0.0133,  0.1232, -0.0223,
          0.1268, -0.0209, -0.1492,  0.1238,  0.1364, -0.0494,  0.1506,  0.1507,
          0.0835, -0.0808,  0.1423,  0.0112, -0.0952, -0.1088,  0.0617,  0.0301,
         -0.1402,  0.0276, -0.0258,  0.0359, -0.0616, -0.1059,  0.1350, -0.0008,
          0.0762,  0.1439,  0.0387,  0.0969,  0.0783,  0.0231, -0.1345, -0.0669,
          0.1304,  0.1185,  0.1416,  0.0744, -0.0034,  0.0096,  0.0446,  0.1183,
          0.0770, -0.0758, -0.1395, -0.1218,  0.0349,  0.0500, -0.0183,  0.0711,
         -0.0347,  0.0934,  0.0670, -0.0038,  0.0200, -0.0276, -0.0364, -0.0272,
         -0.1283, -0.1051,  0.0405, -0.0498,  0.0711, -0.0184, -0.0232,  0.0090,
          0.0129, -0.0531,  0.0743, -0.0128,  0.1336, -0.0849, -0.0733,  0.1475,
         -0.1420,  0.0784, -0.1480, -0.0125, -0.0034, -0.1391,  0.1416, -0.0904,
         -0.0818, -0.0425,  0.1410,  0.0522,  0.0425,  0.1468,  0.1386, -0.1375,
          0.1292, -0.0469,  0.0878, -0.0481, -0.0219,  0.0223, -0.0273,  0.0728,
          0.1402,  0.0045,  0.0249,  0.0106, -0.0835,  0.0469, -0.0574, -0.0758,
          0.0743, -0.1426, -0.1342,  0.0574, -0.0107, -0.1063,  0.0519, -0.0702,
         -0.0056,  0.1312,  0.1320,  0.1328,  0.0625,  0.0867, -0.0876, -0.1189,
          0.0700, -0.0457, -0.0243,  0.1065, -0.0323,  0.0297,  0.0616, -0.0520,
         -0.0578,  0.1052,  0.1212, -0.0435, -0.0046, -0.0702,  0.0405, -0.1468,
         -0.1350,  0.0947, -0.1272, -0.0618,  0.1010,  0.1131,  0.1168,  0.1081,
         -0.0380,  0.1249, -0.0765,  0.0304,  0.0336, -0.1272, -0.1101, -0.1217,
          0.0886, -0.0488,  0.0025, -0.0683, -0.0232, -0.0983, -0.0978,  0.0507]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0576,  0.0838,  0.0181,  ..., -0.0048, -0.0883, -0.0303],
        [ 0.1075, -0.0231, -0.0989,  ...,  0.0500, -0.0106,  0.1239],
        [-0.0377, -0.0168, -0.0997,  ..., -0.1118,  0.1206, -0.0193],
        ...,
        [ 0.0818, -0.0439, -0.0284,  ...,  0.0074,  0.0284, -0.0981],
        [-0.0674, -0.0937,  0.0048,  ...,  0.0516,  0.0740,  0.0137],
        [-0.0690,  0.0329, -0.0314,  ...,  0.0053, -0.0874, -0.0133]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0576,  0.0838,  0.0181,  ..., -0.0048, -0.0883, -0.0303],
        [ 0.1075, -0.0231, -0.0989,  ...,  0.0500, -0.0106,  0.1239],
        [-0.0377, -0.0168, -0.0997,  ..., -0.1118,  0.1206, -0.0193],
        ...,
        [ 0.0818, -0.0439, -0.0284,  ...,  0.0074,  0.0284, -0.0981],
        [-0.0674, -0.0937,  0.0048,  ...,  0.0516,  0.0740,  0.0137],
        [-0.0690,  0.0329, -0.0314,  ...,  0.0053, -0.0874, -0.0133]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0610,  0.1029, -0.1528,  ..., -0.1356,  0.0074,  0.0955],
        [-0.1697,  0.1416,  0.1183,  ...,  0.0019, -0.1046,  0.1614],
        [ 0.0484, -0.0277,  0.0153,  ..., -0.0449, -0.1120, -0.1370],
        ...,
        [ 0.0831,  0.1033,  0.0346,  ...,  0.0600, -0.0740,  0.1541],
        [-0.1523, -0.1022,  0.0907,  ..., -0.0440,  0.0362, -0.1613],
        [-0.1439,  0.0123, -0.1625,  ...,  0.1118,  0.0875, -0.1059]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0610,  0.1029, -0.1528,  ..., -0.1356,  0.0074,  0.0955],
        [-0.1697,  0.1416,  0.1183,  ...,  0.0019, -0.1046,  0.1614],
        [ 0.0484, -0.0277,  0.0153,  ..., -0.0449, -0.1120, -0.1370],
        ...,
        [ 0.0831,  0.1033,  0.0346,  ...,  0.0600, -0.0740,  0.1541],
        [-0.1523, -0.1022,  0.0907,  ..., -0.0440,  0.0362, -0.1613],
        [-0.1439,  0.0123, -0.1625,  ...,  0.1118,  0.0875, -0.1059]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.1216,  0.2279,  0.0688,  ..., -0.1406, -0.1743, -0.0907],
        [ 0.2496, -0.1470,  0.0415,  ...,  0.0769, -0.1166,  0.0033],
        [-0.1459, -0.1891, -0.1882,  ..., -0.0272,  0.2065, -0.0453],
        ...,
        [ 0.1384,  0.2293, -0.2154,  ...,  0.0117,  0.1127, -0.1369],
        [ 0.1870,  0.2202, -0.0448,  ...,  0.2451, -0.1388,  0.1060],
        [ 0.0882, -0.1449,  0.0059,  ...,  0.0919, -0.1433,  0.0572]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1216,  0.2279,  0.0688,  ..., -0.1406, -0.1743, -0.0907],
        [ 0.2496, -0.1470,  0.0415,  ...,  0.0769, -0.1166,  0.0033],
        [-0.1459, -0.1891, -0.1882,  ..., -0.0272,  0.2065, -0.0453],
        ...,
        [ 0.1384,  0.2293, -0.2154,  ...,  0.0117,  0.1127, -0.1369],
        [ 0.1870,  0.2202, -0.0448,  ...,  0.2451, -0.1388,  0.1060],
        [ 0.0882, -0.1449,  0.0059,  ...,  0.0919, -0.1433,  0.0572]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.2098],
        [ 0.4107],
        [ 0.3120],
        [-0.0467],
        [-0.1859],
        [-0.2587],
        [-0.3667],
        [-0.3388],
        [ 0.3081],
        [ 0.2764],
        [ 0.1426],
        [-0.1179],
        [ 0.1299],
        [-0.3637],
        [-0.0405],
        [-0.0408],
        [-0.0055],
        [ 0.1534],
        [-0.2909],
        [-0.1735],
        [-0.0117],
        [-0.0017],
        [-0.0255],
        [ 0.0070],
        [ 0.3444],
        [-0.2653],
        [-0.0008],
        [ 0.2607],
        [-0.0944],
        [-0.2005],
        [-0.3528],
        [-0.1952]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.2098],
        [ 0.4107],
        [ 0.3120],
        [-0.0467],
        [-0.1859],
        [-0.2587],
        [-0.3667],
        [-0.3388],
        [ 0.3081],
        [ 0.2764],
        [ 0.1426],
        [-0.1179],
        [ 0.1299],
        [-0.3637],
        [-0.0405],
        [-0.0408],
        [-0.0055],
        [ 0.1534],
        [-0.2909],
        [-0.1735],
        [-0.0117],
        [-0.0017],
        [-0.0255],
        [ 0.0070],
        [ 0.3444],
        [-0.2653],
        [-0.0008],
        [ 0.2607],
        [-0.0944],
        [-0.2005],
        [-0.3528],
        [-0.1952]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-11.4884, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(11.3784, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(11.6330, device='cuda:0')



h[100].sum tensor(7.6124, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(7.7828, device='cuda:0')



h[200].sum tensor(-5.6855, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-5.8128, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(9304.8486, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0078, 0.0058, 0.0000,  ..., 0.0000, 0.0229, 0.0027],
        [0.0036, 0.0027, 0.0000,  ..., 0.0000, 0.0107, 0.0013],
        [0.0010, 0.0008, 0.0000,  ..., 0.0000, 0.0030, 0.0004],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(65904.8594, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(783.7382, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(49.8408, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(1095.8210, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(69.6645, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-42.7081, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.9159],
        [-0.6451],
        [-0.4342],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-42369.2617, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[-0.9159],
        [-0.6451],
        [-0.4342],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=1463720,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([1463720, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(1463720., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[ 0.0028,  0.0021, -0.0030,  ..., -0.0196, -0.0209,  0.0076],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(1296.6996, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(18.1900, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(18.6466, device='cuda:0')



h[100].sum tensor(83.1109, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(85.1973, device='cuda:0')



h[200].sum tensor(-55.7512, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-57.1508, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0105, 0.0080, 0.0000,  ..., 0.0000, 0.0000, 0.0287],
        [0.0086, 0.0066, 0.0000,  ..., 0.0000, 0.0000, 0.0236],
        [0.0020, 0.0015, 0.0000,  ..., 0.0000, 0.0000, 0.0055],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(109361.4531, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.1041,  ..., 0.0000, 0.3391, 0.3863],
        [0.0000, 0.0000, 0.0892,  ..., 0.0000, 0.2906, 0.3310],
        [0.0000, 0.0000, 0.0716,  ..., 0.0000, 0.2333, 0.2658],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(480554.1250, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-527.2504, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-370.0767, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-642.9949, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=1463720,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-2.4174e+00],
        [-2.6158e+00],
        [-2.8864e+00],
        ...,
        [-3.1503e-05],
        [-5.2372e-05],
        [-7.4855e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(-167809.2812, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([1463720, 1]) 
g.edata[efet].sum tensor(1463720., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-0.9159],
        [-0.6451],
        [-0.4342],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')

real	0m25.724s
user	0m18.246s
sys	0m5.051s
