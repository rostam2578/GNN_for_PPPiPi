0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        9B:9E:55:A9:86:D9:50:0B:6D:2D:9F:BA:A7:E6:45:39:D4:DD:5F:C6
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sat Sep 17 06:13:21 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   22C    P0    32W / 250W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.358472704

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2ac0343c78e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m5.294s
user	0m2.637s
sys	0m1.098s
[06:13:29] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 0.3494],
        [ 1.8575],
        [ 1.6025],
        ...,
        [-0.9858],
        [ 1.1361],
        [ 1.1202]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-72.3613, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-1.1566e-01, -8.3641e-02, -8.3028e-04,  3.5524e-02, -7.1274e-02,
         -1.3512e-01, -6.2875e-02,  1.2644e-01,  1.1810e-01,  3.4072e-02,
         -6.1449e-02,  7.5516e-02, -1.0145e-01, -8.0005e-02, -8.8015e-02,
          9.7540e-02,  7.0337e-02,  5.4413e-02, -1.1927e-01,  1.2039e-01,
          1.3923e-01,  8.8527e-02, -1.3709e-01,  1.4610e-01,  6.1594e-02,
         -7.6110e-02, -9.9778e-02, -1.4080e-02,  1.4105e-01,  1.3051e-01,
          3.4776e-02, -7.4375e-02, -1.1205e-02, -1.4685e-01,  5.6811e-02,
          7.1043e-02,  2.1394e-02,  1.0895e-02, -5.9261e-02, -7.4482e-02,
          6.4506e-02, -3.7674e-02, -5.2336e-02,  3.4638e-02, -1.1217e-01,
         -1.3520e-01,  1.2779e-01, -5.9438e-02, -1.9322e-02, -1.2885e-01,
          1.0150e-01,  2.9595e-02,  7.0985e-02, -1.0993e-01,  1.3994e-01,
          1.1859e-01, -1.3498e-01,  5.7241e-02, -1.0951e-01,  1.4706e-01,
          1.0748e-01,  1.2790e-01,  7.0505e-02, -6.0725e-02,  6.7968e-02,
         -7.6745e-02, -5.6748e-02, -3.3628e-02, -2.9915e-02,  1.3735e-02,
          5.0763e-02,  1.0152e-01,  1.2252e-01, -4.3466e-02, -1.4167e-01,
         -1.4821e-01,  1.9924e-02,  5.4367e-02, -3.2683e-02, -1.0639e-01,
         -1.4505e-01,  6.6367e-03, -5.0831e-02,  1.0886e-01,  6.4180e-02,
         -9.6386e-02, -9.8841e-02, -8.6987e-02, -1.7261e-03,  9.9808e-02,
         -3.4047e-02,  1.4645e-01,  1.4473e-01,  1.4354e-01,  3.5479e-02,
          5.3828e-02, -6.1969e-02,  1.4642e-02, -3.5488e-02, -1.7948e-02,
         -5.2460e-02, -7.5270e-02, -4.6192e-02,  1.0265e-02, -1.3567e-02,
         -3.4954e-02, -1.8977e-02,  1.3338e-01, -5.1229e-02, -1.3860e-01,
          8.4569e-02, -1.2613e-01, -1.5841e-02, -1.2928e-01, -5.6466e-02,
          1.3822e-01,  7.1331e-03,  1.0699e-01,  2.9092e-02,  1.0484e-02,
         -1.2369e-01,  1.1036e-01,  1.2201e-01, -5.8938e-02,  1.6181e-02,
          1.2778e-02, -1.3930e-01,  4.4865e-02, -8.1346e-03,  9.5588e-02,
         -1.1894e-01, -1.4346e-01,  1.4643e-01,  1.5236e-01,  7.8666e-02,
          1.3820e-01, -2.6350e-02, -5.0247e-02,  1.0789e-01, -1.4643e-02,
          2.0020e-02, -1.7540e-03, -1.4979e-01, -1.4386e-01, -1.0669e-01,
          4.8120e-02, -1.7521e-02,  1.1923e-01,  2.4258e-02,  8.3896e-02,
          1.2373e-02, -1.5066e-01,  1.0549e-01,  2.0010e-02,  3.3847e-02,
          4.1457e-02,  1.1285e-01, -1.3643e-01,  1.0545e-01,  1.2555e-01,
         -3.2036e-02,  1.2084e-01, -1.3862e-01,  4.5221e-02,  9.8186e-02,
         -1.2781e-02, -3.2508e-02,  5.3352e-02,  1.0006e-01,  1.5200e-01,
          1.0903e-01,  1.1276e-01, -2.6156e-03,  8.5372e-05, -1.1308e-01,
         -2.4325e-02, -1.3598e-01,  8.7822e-02,  1.0741e-01,  5.6119e-04,
         -3.3218e-02,  3.8749e-02,  1.4470e-01, -1.1521e-01, -2.2053e-02,
         -9.6311e-02,  1.4616e-02, -1.4376e-01, -1.2837e-01, -1.4499e-01,
          4.1201e-02,  1.1356e-01, -4.9810e-02, -1.5430e-02, -1.1257e-01,
         -1.3838e-01,  1.4842e-01, -6.0879e-02,  1.2975e-02, -9.3141e-02,
         -7.7832e-02, -1.2961e-01, -1.2057e-01,  6.3567e-02,  1.0890e-01,
          1.4414e-01,  3.3838e-02, -1.3371e-01,  1.4971e-01,  8.9697e-02,
         -3.8169e-03,  7.4818e-02,  1.3870e-01, -9.7058e-02,  9.3302e-02,
         -1.0647e-01,  5.7279e-02, -1.2078e-01, -2.9588e-02,  1.5062e-01,
         -4.2625e-02,  8.7177e-02, -8.6818e-02, -9.1406e-02,  3.3045e-02,
          8.0168e-02, -1.2019e-01, -1.0072e-01,  7.9744e-02, -9.8805e-02,
         -1.0321e-01, -3.3077e-02,  6.0185e-02,  5.0657e-03,  5.2440e-02,
          1.5035e-01,  5.7506e-02, -1.1534e-01, -1.2439e-01,  1.1848e-02,
         -7.9882e-02,  5.2763e-02,  7.4591e-02, -1.4897e-02, -1.3502e-01,
         -1.4745e-01, -7.3103e-03,  1.0171e-01, -3.7376e-02,  1.6933e-02,
         -1.4189e-01, -7.3755e-03,  1.0062e-01,  3.2712e-02,  8.0522e-02,
         -1.1530e-01]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-1.1566e-01, -8.3641e-02, -8.3028e-04,  3.5524e-02, -7.1274e-02,
         -1.3512e-01, -6.2875e-02,  1.2644e-01,  1.1810e-01,  3.4072e-02,
         -6.1449e-02,  7.5516e-02, -1.0145e-01, -8.0005e-02, -8.8015e-02,
          9.7540e-02,  7.0337e-02,  5.4413e-02, -1.1927e-01,  1.2039e-01,
          1.3923e-01,  8.8527e-02, -1.3709e-01,  1.4610e-01,  6.1594e-02,
         -7.6110e-02, -9.9778e-02, -1.4080e-02,  1.4105e-01,  1.3051e-01,
          3.4776e-02, -7.4375e-02, -1.1205e-02, -1.4685e-01,  5.6811e-02,
          7.1043e-02,  2.1394e-02,  1.0895e-02, -5.9261e-02, -7.4482e-02,
          6.4506e-02, -3.7674e-02, -5.2336e-02,  3.4638e-02, -1.1217e-01,
         -1.3520e-01,  1.2779e-01, -5.9438e-02, -1.9322e-02, -1.2885e-01,
          1.0150e-01,  2.9595e-02,  7.0985e-02, -1.0993e-01,  1.3994e-01,
          1.1859e-01, -1.3498e-01,  5.7241e-02, -1.0951e-01,  1.4706e-01,
          1.0748e-01,  1.2790e-01,  7.0505e-02, -6.0725e-02,  6.7968e-02,
         -7.6745e-02, -5.6748e-02, -3.3628e-02, -2.9915e-02,  1.3735e-02,
          5.0763e-02,  1.0152e-01,  1.2252e-01, -4.3466e-02, -1.4167e-01,
         -1.4821e-01,  1.9924e-02,  5.4367e-02, -3.2683e-02, -1.0639e-01,
         -1.4505e-01,  6.6367e-03, -5.0831e-02,  1.0886e-01,  6.4180e-02,
         -9.6386e-02, -9.8841e-02, -8.6987e-02, -1.7261e-03,  9.9808e-02,
         -3.4047e-02,  1.4645e-01,  1.4473e-01,  1.4354e-01,  3.5479e-02,
          5.3828e-02, -6.1969e-02,  1.4642e-02, -3.5488e-02, -1.7948e-02,
         -5.2460e-02, -7.5270e-02, -4.6192e-02,  1.0265e-02, -1.3567e-02,
         -3.4954e-02, -1.8977e-02,  1.3338e-01, -5.1229e-02, -1.3860e-01,
          8.4569e-02, -1.2613e-01, -1.5841e-02, -1.2928e-01, -5.6466e-02,
          1.3822e-01,  7.1331e-03,  1.0699e-01,  2.9092e-02,  1.0484e-02,
         -1.2369e-01,  1.1036e-01,  1.2201e-01, -5.8938e-02,  1.6181e-02,
          1.2778e-02, -1.3930e-01,  4.4865e-02, -8.1346e-03,  9.5588e-02,
         -1.1894e-01, -1.4346e-01,  1.4643e-01,  1.5236e-01,  7.8666e-02,
          1.3820e-01, -2.6350e-02, -5.0247e-02,  1.0789e-01, -1.4643e-02,
          2.0020e-02, -1.7540e-03, -1.4979e-01, -1.4386e-01, -1.0669e-01,
          4.8120e-02, -1.7521e-02,  1.1923e-01,  2.4258e-02,  8.3896e-02,
          1.2373e-02, -1.5066e-01,  1.0549e-01,  2.0010e-02,  3.3847e-02,
          4.1457e-02,  1.1285e-01, -1.3643e-01,  1.0545e-01,  1.2555e-01,
         -3.2036e-02,  1.2084e-01, -1.3862e-01,  4.5221e-02,  9.8186e-02,
         -1.2781e-02, -3.2508e-02,  5.3352e-02,  1.0006e-01,  1.5200e-01,
          1.0903e-01,  1.1276e-01, -2.6156e-03,  8.5372e-05, -1.1308e-01,
         -2.4325e-02, -1.3598e-01,  8.7822e-02,  1.0741e-01,  5.6119e-04,
         -3.3218e-02,  3.8749e-02,  1.4470e-01, -1.1521e-01, -2.2053e-02,
         -9.6311e-02,  1.4616e-02, -1.4376e-01, -1.2837e-01, -1.4499e-01,
          4.1201e-02,  1.1356e-01, -4.9810e-02, -1.5430e-02, -1.1257e-01,
         -1.3838e-01,  1.4842e-01, -6.0879e-02,  1.2975e-02, -9.3141e-02,
         -7.7832e-02, -1.2961e-01, -1.2057e-01,  6.3567e-02,  1.0890e-01,
          1.4414e-01,  3.3838e-02, -1.3371e-01,  1.4971e-01,  8.9697e-02,
         -3.8169e-03,  7.4818e-02,  1.3870e-01, -9.7058e-02,  9.3302e-02,
         -1.0647e-01,  5.7279e-02, -1.2078e-01, -2.9588e-02,  1.5062e-01,
         -4.2625e-02,  8.7177e-02, -8.6818e-02, -9.1406e-02,  3.3045e-02,
          8.0168e-02, -1.2019e-01, -1.0072e-01,  7.9744e-02, -9.8805e-02,
         -1.0321e-01, -3.3077e-02,  6.0185e-02,  5.0657e-03,  5.2440e-02,
          1.5035e-01,  5.7506e-02, -1.1534e-01, -1.2439e-01,  1.1848e-02,
         -7.9882e-02,  5.2763e-02,  7.4591e-02, -1.4897e-02, -1.3502e-01,
         -1.4745e-01, -7.3103e-03,  1.0171e-01, -3.7376e-02,  1.6933e-02,
         -1.4189e-01, -7.3755e-03,  1.0062e-01,  3.2712e-02,  8.0522e-02,
         -1.1530e-01]], device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0606,  0.0508, -0.1210,  ...,  0.0849,  0.0244,  0.0495],
        [ 0.0353,  0.0838,  0.0346,  ...,  0.1032,  0.0248,  0.0378],
        [ 0.0688, -0.0575,  0.0989,  ..., -0.0995, -0.0323, -0.0781],
        ...,
        [-0.0778, -0.0780,  0.1184,  ..., -0.0326,  0.0365,  0.0092],
        [-0.1063,  0.0848,  0.0218,  ...,  0.0336, -0.0528,  0.0417],
        [-0.0788, -0.1031,  0.0592,  ..., -0.1122,  0.0446,  0.1243]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0606,  0.0508, -0.1210,  ...,  0.0849,  0.0244,  0.0495],
        [ 0.0353,  0.0838,  0.0346,  ...,  0.1032,  0.0248,  0.0378],
        [ 0.0688, -0.0575,  0.0989,  ..., -0.0995, -0.0323, -0.0781],
        ...,
        [-0.0778, -0.0780,  0.1184,  ..., -0.0326,  0.0365,  0.0092],
        [-0.1063,  0.0848,  0.0218,  ...,  0.0336, -0.0528,  0.0417],
        [-0.0788, -0.1031,  0.0592,  ..., -0.1122,  0.0446,  0.1243]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0692, -0.0867, -0.0019,  ...,  0.0107, -0.0460, -0.1472],
        [ 0.0968, -0.0553, -0.1387,  ...,  0.0382, -0.0156,  0.1115],
        [ 0.1674, -0.0348,  0.0485,  ..., -0.1468, -0.0955,  0.0700],
        ...,
        [-0.0135,  0.1188, -0.1725,  ..., -0.1038, -0.0500, -0.0273],
        [ 0.1201,  0.0335, -0.1411,  ...,  0.0994,  0.1572, -0.0542],
        [-0.0153, -0.0641,  0.0922,  ..., -0.1025, -0.0432, -0.0778]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0692, -0.0867, -0.0019,  ...,  0.0107, -0.0460, -0.1472],
        [ 0.0968, -0.0553, -0.1387,  ...,  0.0382, -0.0156,  0.1115],
        [ 0.1674, -0.0348,  0.0485,  ..., -0.1468, -0.0955,  0.0700],
        ...,
        [-0.0135,  0.1188, -0.1725,  ..., -0.1038, -0.0500, -0.0273],
        [ 0.1201,  0.0335, -0.1411,  ...,  0.0994,  0.1572, -0.0542],
        [-0.0153, -0.0641,  0.0922,  ..., -0.1025, -0.0432, -0.0778]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-0.1400, -0.1399, -0.1733,  ...,  0.0869, -0.0335,  0.0625],
        [-0.2125,  0.2096,  0.1219,  ..., -0.2000,  0.1765, -0.0691],
        [ 0.2233, -0.0930,  0.2080,  ..., -0.0816,  0.0507, -0.1796],
        ...,
        [ 0.2260,  0.1027, -0.0458,  ...,  0.2161,  0.1350, -0.0975],
        [-0.1283,  0.1124, -0.0764,  ...,  0.0587, -0.0655,  0.2364],
        [-0.0595,  0.1296,  0.1247,  ...,  0.0936, -0.1827,  0.1019]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1400, -0.1399, -0.1733,  ...,  0.0869, -0.0335,  0.0625],
        [-0.2125,  0.2096,  0.1219,  ..., -0.2000,  0.1765, -0.0691],
        [ 0.2233, -0.0930,  0.2080,  ..., -0.0816,  0.0507, -0.1796],
        ...,
        [ 0.2260,  0.1027, -0.0458,  ...,  0.2161,  0.1350, -0.0975],
        [-0.1283,  0.1124, -0.0764,  ...,  0.0587, -0.0655,  0.2364],
        [-0.0595,  0.1296,  0.1247,  ...,  0.0936, -0.1827,  0.1019]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[ 0.2267],
        [-0.2419],
        [-0.3112],
        [ 0.0613],
        [ 0.1995],
        [ 0.3206],
        [-0.1952],
        [ 0.0627],
        [ 0.1850],
        [-0.0933],
        [ 0.1913],
        [-0.4077],
        [ 0.4059],
        [-0.0065],
        [-0.2403],
        [ 0.1079],
        [ 0.2490],
        [ 0.0791],
        [ 0.1588],
        [-0.3492],
        [ 0.2917],
        [ 0.3235],
        [ 0.2368],
        [-0.3636],
        [-0.1532],
        [-0.0016],
        [ 0.2565],
        [ 0.2119],
        [ 0.2559],
        [-0.1539],
        [ 0.2678],
        [ 0.1146]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.2267],
        [-0.2419],
        [-0.3112],
        [ 0.0613],
        [ 0.1995],
        [ 0.3206],
        [-0.1952],
        [ 0.0627],
        [ 0.1850],
        [-0.0933],
        [ 0.1913],
        [-0.4077],
        [ 0.4059],
        [-0.0065],
        [-0.2403],
        [ 0.1079],
        [ 0.2490],
        [ 0.0791],
        [ 0.1588],
        [-0.3492],
        [ 0.2917],
        [ 0.3235],
        [ 0.2368],
        [-0.3636],
        [-0.1532],
        [-0.0016],
        [ 0.2565],
        [ 0.2119],
        [ 0.2559],
        [-0.1539],
        [ 0.2678],
        [ 0.1146]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)

net when the batchsize is 2 GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network when the batchsize is 2:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-3.1017e-03,  3.4707e-02,  7.2239e-02, -9.6760e-02, -8.9264e-02,
         -1.1325e-02, -2.4496e-02, -1.1478e-01,  9.7155e-02,  1.0014e-02,
          8.3237e-03, -5.6485e-02, -3.8202e-02, -7.4364e-02,  2.4300e-02,
         -1.2139e-01, -3.1168e-02,  7.6010e-03, -3.4055e-02, -1.2964e-01,
          1.1212e-01,  1.3910e-01,  4.7883e-02, -5.3194e-02,  2.6049e-02,
          4.3300e-02,  1.3507e-01,  9.5599e-04,  1.2682e-01,  7.8375e-02,
         -1.4247e-01, -9.4383e-02,  6.5209e-02,  5.3381e-02, -1.3815e-01,
          1.3919e-02, -9.9777e-02,  5.8847e-02,  8.0582e-02,  1.0738e-01,
          9.1523e-02, -1.5012e-01, -1.0788e-01, -1.1680e-01, -4.3210e-02,
          1.0137e-01,  7.3970e-02,  4.0873e-02, -1.5221e-01, -1.0040e-01,
          8.1494e-02, -2.7680e-02, -1.4825e-01,  9.5200e-02, -1.4960e-01,
         -1.0861e-01,  1.4379e-01, -7.8127e-02, -6.0065e-02, -1.0133e-01,
          5.1002e-02, -6.3280e-02, -2.4274e-02, -1.3355e-01,  8.0129e-02,
         -4.4117e-03, -4.6648e-05, -9.4850e-02, -8.9407e-02,  8.4624e-02,
         -8.8606e-02,  8.4219e-03, -1.0289e-01,  1.9544e-02, -2.5907e-02,
         -1.4843e-01, -7.4011e-02, -5.8478e-02, -3.3427e-02, -1.3120e-01,
         -1.1741e-01,  6.2228e-02, -7.6856e-02, -1.0244e-01,  1.5038e-02,
          4.0462e-02, -1.6233e-02,  7.7039e-02,  3.0326e-02,  4.8307e-02,
          1.2265e-01, -3.8583e-02, -1.4719e-01, -6.8285e-02,  1.3725e-01,
         -5.3069e-02,  8.1985e-02, -5.8624e-02,  9.2297e-02,  1.4914e-01,
          9.8561e-02, -1.2795e-01,  1.2814e-01,  3.9161e-02, -1.1578e-02,
          9.2607e-02,  6.2276e-02, -6.9254e-02,  1.9799e-02, -1.2919e-01,
         -5.3572e-02, -1.4070e-01, -8.8625e-02, -5.0992e-02,  3.1006e-03,
          4.8462e-02, -1.8266e-02,  1.2625e-01,  1.0074e-01, -1.1610e-01,
         -8.3224e-02,  3.6973e-02, -8.1549e-03,  1.1512e-01,  1.1851e-01,
         -2.1080e-02, -1.1644e-01, -1.1540e-02, -1.0386e-01,  4.8085e-02,
         -9.2563e-02, -9.2935e-02, -3.9643e-03,  9.8577e-02, -5.6047e-02,
         -8.2376e-02, -1.4175e-01, -4.4240e-02,  1.1246e-01, -1.4847e-01,
          1.5135e-01,  1.3547e-02,  1.2143e-01, -1.0173e-01,  1.5225e-02,
          7.2749e-02, -2.5812e-02,  1.6178e-02,  3.2308e-02,  4.6552e-02,
          5.5485e-02, -7.2123e-02, -1.3346e-01, -5.8750e-02,  2.1447e-02,
          1.1423e-02, -1.0446e-01,  1.4837e-01,  1.1772e-01,  9.4737e-02,
         -6.9764e-02, -1.5236e-01,  1.4876e-01, -1.7874e-02, -1.2237e-01,
          1.1790e-01,  9.7803e-02, -5.8295e-02, -4.9158e-02,  1.2769e-01,
         -1.4471e-01,  6.2421e-02,  6.9272e-02, -5.8748e-02,  3.5321e-02,
          6.2023e-02,  1.1882e-01,  1.2889e-01, -1.3076e-02,  2.9363e-02,
          8.7858e-02, -4.8241e-02, -9.2318e-02, -3.1827e-02, -1.2071e-01,
          1.3097e-01, -3.3217e-02, -1.3515e-01,  1.4760e-01,  6.6963e-03,
          4.0650e-02, -1.0206e-01,  7.4886e-02, -4.0159e-02,  5.0222e-02,
          1.1501e-01, -6.1142e-03, -5.0465e-02, -1.1033e-01,  2.6225e-02,
         -7.4587e-02,  8.3168e-03, -1.3552e-02,  1.3847e-01, -8.4775e-02,
         -1.2479e-01, -1.2496e-01, -5.1928e-02,  6.1068e-02,  2.5222e-02,
          8.1139e-02, -7.5875e-03, -1.4700e-01, -8.1728e-02, -1.0957e-01,
          5.1780e-02,  1.0580e-01, -1.4177e-01,  1.3564e-01,  5.6131e-02,
          6.0231e-02,  8.8373e-02, -1.1280e-01,  1.1890e-01,  9.8166e-02,
          7.1548e-02, -1.1861e-01,  1.3741e-01, -9.7323e-02,  9.0848e-02,
          5.9344e-02, -1.0935e-01, -9.7506e-02, -7.4206e-03, -1.3812e-01,
          1.1249e-02, -1.2248e-01,  8.3897e-02, -1.8273e-02,  1.3407e-01,
         -1.4828e-01,  2.2692e-02, -6.1146e-02, -3.8244e-02,  6.4465e-02,
         -2.6448e-02,  5.4994e-02, -2.9399e-02,  9.6949e-02, -1.0061e-01,
          8.4087e-02, -6.5262e-02, -9.4511e-02, -3.4417e-02, -6.5695e-02,
         -1.3070e-01]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-3.1017e-03,  3.4707e-02,  7.2239e-02, -9.6760e-02, -8.9264e-02,
         -1.1325e-02, -2.4496e-02, -1.1478e-01,  9.7155e-02,  1.0014e-02,
          8.3237e-03, -5.6485e-02, -3.8202e-02, -7.4364e-02,  2.4300e-02,
         -1.2139e-01, -3.1168e-02,  7.6010e-03, -3.4055e-02, -1.2964e-01,
          1.1212e-01,  1.3910e-01,  4.7883e-02, -5.3194e-02,  2.6049e-02,
          4.3300e-02,  1.3507e-01,  9.5599e-04,  1.2682e-01,  7.8375e-02,
         -1.4247e-01, -9.4383e-02,  6.5209e-02,  5.3381e-02, -1.3815e-01,
          1.3919e-02, -9.9777e-02,  5.8847e-02,  8.0582e-02,  1.0738e-01,
          9.1523e-02, -1.5012e-01, -1.0788e-01, -1.1680e-01, -4.3210e-02,
          1.0137e-01,  7.3970e-02,  4.0873e-02, -1.5221e-01, -1.0040e-01,
          8.1494e-02, -2.7680e-02, -1.4825e-01,  9.5200e-02, -1.4960e-01,
         -1.0861e-01,  1.4379e-01, -7.8127e-02, -6.0065e-02, -1.0133e-01,
          5.1002e-02, -6.3280e-02, -2.4274e-02, -1.3355e-01,  8.0129e-02,
         -4.4117e-03, -4.6648e-05, -9.4850e-02, -8.9407e-02,  8.4624e-02,
         -8.8606e-02,  8.4219e-03, -1.0289e-01,  1.9544e-02, -2.5907e-02,
         -1.4843e-01, -7.4011e-02, -5.8478e-02, -3.3427e-02, -1.3120e-01,
         -1.1741e-01,  6.2228e-02, -7.6856e-02, -1.0244e-01,  1.5038e-02,
          4.0462e-02, -1.6233e-02,  7.7039e-02,  3.0326e-02,  4.8307e-02,
          1.2265e-01, -3.8583e-02, -1.4719e-01, -6.8285e-02,  1.3725e-01,
         -5.3069e-02,  8.1985e-02, -5.8624e-02,  9.2297e-02,  1.4914e-01,
          9.8561e-02, -1.2795e-01,  1.2814e-01,  3.9161e-02, -1.1578e-02,
          9.2607e-02,  6.2276e-02, -6.9254e-02,  1.9799e-02, -1.2919e-01,
         -5.3572e-02, -1.4070e-01, -8.8625e-02, -5.0992e-02,  3.1006e-03,
          4.8462e-02, -1.8266e-02,  1.2625e-01,  1.0074e-01, -1.1610e-01,
         -8.3224e-02,  3.6973e-02, -8.1549e-03,  1.1512e-01,  1.1851e-01,
         -2.1080e-02, -1.1644e-01, -1.1540e-02, -1.0386e-01,  4.8085e-02,
         -9.2563e-02, -9.2935e-02, -3.9643e-03,  9.8577e-02, -5.6047e-02,
         -8.2376e-02, -1.4175e-01, -4.4240e-02,  1.1246e-01, -1.4847e-01,
          1.5135e-01,  1.3547e-02,  1.2143e-01, -1.0173e-01,  1.5225e-02,
          7.2749e-02, -2.5812e-02,  1.6178e-02,  3.2308e-02,  4.6552e-02,
          5.5485e-02, -7.2123e-02, -1.3346e-01, -5.8750e-02,  2.1447e-02,
          1.1423e-02, -1.0446e-01,  1.4837e-01,  1.1772e-01,  9.4737e-02,
         -6.9764e-02, -1.5236e-01,  1.4876e-01, -1.7874e-02, -1.2237e-01,
          1.1790e-01,  9.7803e-02, -5.8295e-02, -4.9158e-02,  1.2769e-01,
         -1.4471e-01,  6.2421e-02,  6.9272e-02, -5.8748e-02,  3.5321e-02,
          6.2023e-02,  1.1882e-01,  1.2889e-01, -1.3076e-02,  2.9363e-02,
          8.7858e-02, -4.8241e-02, -9.2318e-02, -3.1827e-02, -1.2071e-01,
          1.3097e-01, -3.3217e-02, -1.3515e-01,  1.4760e-01,  6.6963e-03,
          4.0650e-02, -1.0206e-01,  7.4886e-02, -4.0159e-02,  5.0222e-02,
          1.1501e-01, -6.1142e-03, -5.0465e-02, -1.1033e-01,  2.6225e-02,
         -7.4587e-02,  8.3168e-03, -1.3552e-02,  1.3847e-01, -8.4775e-02,
         -1.2479e-01, -1.2496e-01, -5.1928e-02,  6.1068e-02,  2.5222e-02,
          8.1139e-02, -7.5875e-03, -1.4700e-01, -8.1728e-02, -1.0957e-01,
          5.1780e-02,  1.0580e-01, -1.4177e-01,  1.3564e-01,  5.6131e-02,
          6.0231e-02,  8.8373e-02, -1.1280e-01,  1.1890e-01,  9.8166e-02,
          7.1548e-02, -1.1861e-01,  1.3741e-01, -9.7323e-02,  9.0848e-02,
          5.9344e-02, -1.0935e-01, -9.7506e-02, -7.4206e-03, -1.3812e-01,
          1.1249e-02, -1.2248e-01,  8.3897e-02, -1.8273e-02,  1.3407e-01,
         -1.4828e-01,  2.2692e-02, -6.1146e-02, -3.8244e-02,  6.4465e-02,
         -2.6448e-02,  5.4994e-02, -2.9399e-02,  9.6949e-02, -1.0061e-01,
          8.4087e-02, -6.5262e-02, -9.4511e-02, -3.4417e-02, -6.5695e-02,
         -1.3070e-01]], device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0523,  0.0875, -0.0374,  ...,  0.0595, -0.1136,  0.1246],
        [-0.0271,  0.0706,  0.0322,  ...,  0.0901, -0.0062,  0.1140],
        [ 0.0716, -0.0890, -0.0255,  ...,  0.0461,  0.0154, -0.0606],
        ...,
        [ 0.1200, -0.1040,  0.0052,  ...,  0.0682, -0.0514,  0.0566],
        [ 0.0678,  0.1096,  0.0459,  ...,  0.0282, -0.0480, -0.0972],
        [ 0.0949, -0.0112, -0.0171,  ...,  0.0425, -0.0801,  0.0029]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0523,  0.0875, -0.0374,  ...,  0.0595, -0.1136,  0.1246],
        [-0.0271,  0.0706,  0.0322,  ...,  0.0901, -0.0062,  0.1140],
        [ 0.0716, -0.0890, -0.0255,  ...,  0.0461,  0.0154, -0.0606],
        ...,
        [ 0.1200, -0.1040,  0.0052,  ...,  0.0682, -0.0514,  0.0566],
        [ 0.0678,  0.1096,  0.0459,  ...,  0.0282, -0.0480, -0.0972],
        [ 0.0949, -0.0112, -0.0171,  ...,  0.0425, -0.0801,  0.0029]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0115, -0.1214,  0.0738,  ...,  0.0665,  0.1394, -0.1691],
        [-0.1447, -0.0911,  0.1517,  ...,  0.1016,  0.1350, -0.0141],
        [-0.1601,  0.0404,  0.0936,  ...,  0.1591,  0.0239,  0.0491],
        ...,
        [-0.1708, -0.0080, -0.1235,  ..., -0.0325, -0.0991, -0.0619],
        [-0.0245, -0.0451,  0.0323,  ..., -0.0247,  0.1437, -0.0566],
        [ 0.0827,  0.0892, -0.1291,  ..., -0.1183, -0.1095, -0.0447]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0115, -0.1214,  0.0738,  ...,  0.0665,  0.1394, -0.1691],
        [-0.1447, -0.0911,  0.1517,  ...,  0.1016,  0.1350, -0.0141],
        [-0.1601,  0.0404,  0.0936,  ...,  0.1591,  0.0239,  0.0491],
        ...,
        [-0.1708, -0.0080, -0.1235,  ..., -0.0325, -0.0991, -0.0619],
        [-0.0245, -0.0451,  0.0323,  ..., -0.0247,  0.1437, -0.0566],
        [ 0.0827,  0.0892, -0.1291,  ..., -0.1183, -0.1095, -0.0447]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.0647,  0.0409, -0.1371,  ..., -0.1153, -0.1863, -0.2129],
        [ 0.0613, -0.0520,  0.0339,  ...,  0.2119, -0.1067, -0.1224],
        [-0.1763, -0.2313, -0.2117,  ...,  0.2219, -0.0724,  0.1242],
        ...,
        [ 0.2216,  0.0862,  0.0720,  ..., -0.0160,  0.2146,  0.0834],
        [ 0.0134,  0.0016, -0.1059,  ...,  0.1821,  0.2421,  0.1033],
        [-0.0727,  0.1007, -0.0409,  ..., -0.2325, -0.0597,  0.0042]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0647,  0.0409, -0.1371,  ..., -0.1153, -0.1863, -0.2129],
        [ 0.0613, -0.0520,  0.0339,  ...,  0.2119, -0.1067, -0.1224],
        [-0.1763, -0.2313, -0.2117,  ...,  0.2219, -0.0724,  0.1242],
        ...,
        [ 0.2216,  0.0862,  0.0720,  ..., -0.0160,  0.2146,  0.0834],
        [ 0.0134,  0.0016, -0.1059,  ...,  0.1821,  0.2421,  0.1033],
        [-0.0727,  0.1007, -0.0409,  ..., -0.2325, -0.0597,  0.0042]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-2.2914e-01],
        [ 3.1062e-01],
        [-1.8154e-01],
        [-3.4957e-02],
        [-2.5074e-01],
        [ 1.9655e-01],
        [-1.0163e-01],
        [ 1.0615e-01],
        [ 3.2227e-05],
        [-1.1735e-02],
        [-3.2941e-01],
        [-2.2777e-01],
        [ 8.4687e-02],
        [ 4.1737e-01],
        [-3.9643e-01],
        [-3.7456e-03],
        [-1.1646e-01],
        [ 3.7629e-01],
        [-2.2415e-02],
        [-1.6147e-01],
        [-3.7260e-01],
        [-3.0134e-01],
        [ 2.4358e-01],
        [ 1.8320e-01],
        [-4.1350e-01],
        [ 2.7792e-01],
        [-7.1607e-02],
        [ 7.1174e-02],
        [-2.9572e-01],
        [ 4.3436e-02],
        [-2.5262e-01],
        [ 4.6364e-02]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-2.2914e-01],
        [ 3.1062e-01],
        [-1.8154e-01],
        [-3.4957e-02],
        [-2.5074e-01],
        [ 1.9655e-01],
        [-1.0163e-01],
        [ 1.0615e-01],
        [ 3.2227e-05],
        [-1.1735e-02],
        [-3.2941e-01],
        [-2.2777e-01],
        [ 8.4687e-02],
        [ 4.1737e-01],
        [-3.9643e-01],
        [-3.7456e-03],
        [-1.1646e-01],
        [ 3.7629e-01],
        [-2.2415e-02],
        [-1.6147e-01],
        [-3.7260e-01],
        [-3.0134e-01],
        [ 2.4358e-01],
        [ 1.8320e-01],
        [-4.1350e-01],
        [ 2.7792e-01],
        [-7.1607e-02],
        [ 7.1174e-02],
        [-2.9572e-01],
        [ 4.3436e-02],
        [-2.5262e-01],
        [ 4.6364e-02]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-244.7840, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-3.4797, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-3.5576, device='cuda:0')



h[100].sum tensor(2.1668, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(2.2153, device='cuda:0')



h[200].sum tensor(-8.1703, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-8.3532, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(8174.2437, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0128, 0.0116, 0.0000,  ..., 0.0142, 0.0000, 0.0000],
        [0.0060, 0.0054, 0.0000,  ..., 0.0066, 0.0000, 0.0000],
        [0.0017, 0.0015, 0.0000,  ..., 0.0019, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(52610.4531, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(1292.5837, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(82.2130, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-34.1250, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-30.1830, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.2079],
        [-0.1464],
        [-0.0986],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-9620.0986, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/./ModelBha.py", line 138, in <module>
    fig.colorbar(ax1.matshow(sitonsquare(traingnn80[EvBTr]), aspect=2, vmin=0, vmax=1, extent=[0, 288, 0, 43], origin='lower')\
NameError: name 'traingnn80' is not defined

real	0m27.111s
user	0m15.933s
sys	0m5.825s
