0: gpu035.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-80252116-953a-7f59-a9fa-e04fa0e5ce51)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        70:B2:A7:DF:ED:82:78:26:9F:D8:28:A0:1D:52:CD:B5:3B:DF:C3:17
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sun Sep 25 20:43:11 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   41C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b58864368e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m10.231s
user	0m1.836s
sys	0m1.059s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 79982

node features (random input): tensor([[ 0.1066],
        [ 0.4353],
        [-1.7351],
        ...,
        [-1.2451],
        [-0.2482],
        [ 1.2943]], device='cuda:0', requires_grad=True) 
node features sum: tensor(68.9450, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
edges features sum: tensor(79982., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 15

In degrees of node 234: 15





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-0.0672,  0.0275, -0.0700, -0.0914, -0.1275,  0.1008, -0.0745,  0.0117,
          0.1441,  0.1184,  0.1133,  0.0334,  0.1339,  0.0918, -0.0276,  0.1414,
          0.0875, -0.0025, -0.0862, -0.0486, -0.0468, -0.0679, -0.0525,  0.1500,
          0.0834, -0.0256,  0.0759, -0.0771, -0.0038,  0.1386, -0.0364,  0.1146,
          0.1262,  0.1311,  0.0817,  0.0694, -0.1183, -0.0914,  0.0823,  0.0227,
          0.0491, -0.0339,  0.0989,  0.0490,  0.1352,  0.0110, -0.0917,  0.0710,
         -0.0229, -0.1153, -0.0667, -0.1351,  0.0524,  0.1382,  0.1367,  0.0083,
         -0.0113, -0.1014,  0.1512,  0.0530,  0.1435,  0.0247,  0.0281,  0.1229,
          0.1286, -0.1409,  0.1508,  0.0972, -0.0889,  0.1166,  0.0752,  0.1332,
         -0.0713,  0.0275,  0.0471, -0.0610,  0.0509,  0.0189,  0.0123,  0.0701,
         -0.0436, -0.0490,  0.0975,  0.0582, -0.0092,  0.0560,  0.1408,  0.1303,
          0.0303, -0.0967,  0.0045, -0.0221, -0.1089,  0.1479, -0.1246,  0.1406,
         -0.0429,  0.0429, -0.0342, -0.1424,  0.1084,  0.0830, -0.1342,  0.0631,
         -0.0292, -0.0703,  0.1087,  0.0468, -0.1265,  0.1273,  0.1212, -0.1015,
          0.1159,  0.0894,  0.0859, -0.0260,  0.1041, -0.0156,  0.1474, -0.1116,
          0.1351,  0.0916,  0.0581, -0.0046,  0.0530,  0.1481, -0.0076, -0.1101,
          0.0688, -0.0494,  0.0332, -0.1068, -0.1152, -0.0880, -0.0290, -0.0541,
         -0.0183, -0.0195, -0.1396,  0.0195,  0.0436, -0.0939, -0.0444,  0.1114,
         -0.1426,  0.1273,  0.0597, -0.0804, -0.0841,  0.1287,  0.0381, -0.0368,
         -0.1218,  0.1298,  0.0070, -0.1273, -0.1490, -0.1377, -0.1358,  0.1276,
          0.0071,  0.0589, -0.0880,  0.0714,  0.1410, -0.0164,  0.0304,  0.0266,
          0.0124,  0.1181,  0.0704,  0.1384,  0.1331,  0.0130, -0.0476,  0.0630,
         -0.1277,  0.0484, -0.1174,  0.0858, -0.1245,  0.1517, -0.1373, -0.0150,
          0.1397, -0.1528,  0.1044, -0.0236,  0.0113,  0.0392, -0.1006,  0.0625,
          0.0596,  0.1139, -0.1393,  0.0930,  0.0604, -0.0034, -0.1483,  0.0547,
          0.0754, -0.1460, -0.0103,  0.0489,  0.0142, -0.0860, -0.0753, -0.1119,
         -0.0817,  0.0255,  0.0981, -0.0944, -0.0781,  0.1217,  0.0325, -0.0320,
          0.1403,  0.1483,  0.0051, -0.0877, -0.0276,  0.0138, -0.0876,  0.0552,
         -0.0865,  0.1077,  0.1166, -0.0103,  0.0373,  0.0859, -0.0704,  0.0125,
          0.1413, -0.1442, -0.1108, -0.1432, -0.0884, -0.0245, -0.1145,  0.0057,
          0.1350, -0.0467,  0.1466,  0.1113, -0.0123,  0.0168, -0.0093,  0.1162,
         -0.1526, -0.1494, -0.0907,  0.0277,  0.0109, -0.1107,  0.0137,  0.0226]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0672,  0.0275, -0.0700, -0.0914, -0.1275,  0.1008, -0.0745,  0.0117,
          0.1441,  0.1184,  0.1133,  0.0334,  0.1339,  0.0918, -0.0276,  0.1414,
          0.0875, -0.0025, -0.0862, -0.0486, -0.0468, -0.0679, -0.0525,  0.1500,
          0.0834, -0.0256,  0.0759, -0.0771, -0.0038,  0.1386, -0.0364,  0.1146,
          0.1262,  0.1311,  0.0817,  0.0694, -0.1183, -0.0914,  0.0823,  0.0227,
          0.0491, -0.0339,  0.0989,  0.0490,  0.1352,  0.0110, -0.0917,  0.0710,
         -0.0229, -0.1153, -0.0667, -0.1351,  0.0524,  0.1382,  0.1367,  0.0083,
         -0.0113, -0.1014,  0.1512,  0.0530,  0.1435,  0.0247,  0.0281,  0.1229,
          0.1286, -0.1409,  0.1508,  0.0972, -0.0889,  0.1166,  0.0752,  0.1332,
         -0.0713,  0.0275,  0.0471, -0.0610,  0.0509,  0.0189,  0.0123,  0.0701,
         -0.0436, -0.0490,  0.0975,  0.0582, -0.0092,  0.0560,  0.1408,  0.1303,
          0.0303, -0.0967,  0.0045, -0.0221, -0.1089,  0.1479, -0.1246,  0.1406,
         -0.0429,  0.0429, -0.0342, -0.1424,  0.1084,  0.0830, -0.1342,  0.0631,
         -0.0292, -0.0703,  0.1087,  0.0468, -0.1265,  0.1273,  0.1212, -0.1015,
          0.1159,  0.0894,  0.0859, -0.0260,  0.1041, -0.0156,  0.1474, -0.1116,
          0.1351,  0.0916,  0.0581, -0.0046,  0.0530,  0.1481, -0.0076, -0.1101,
          0.0688, -0.0494,  0.0332, -0.1068, -0.1152, -0.0880, -0.0290, -0.0541,
         -0.0183, -0.0195, -0.1396,  0.0195,  0.0436, -0.0939, -0.0444,  0.1114,
         -0.1426,  0.1273,  0.0597, -0.0804, -0.0841,  0.1287,  0.0381, -0.0368,
         -0.1218,  0.1298,  0.0070, -0.1273, -0.1490, -0.1377, -0.1358,  0.1276,
          0.0071,  0.0589, -0.0880,  0.0714,  0.1410, -0.0164,  0.0304,  0.0266,
          0.0124,  0.1181,  0.0704,  0.1384,  0.1331,  0.0130, -0.0476,  0.0630,
         -0.1277,  0.0484, -0.1174,  0.0858, -0.1245,  0.1517, -0.1373, -0.0150,
          0.1397, -0.1528,  0.1044, -0.0236,  0.0113,  0.0392, -0.1006,  0.0625,
          0.0596,  0.1139, -0.1393,  0.0930,  0.0604, -0.0034, -0.1483,  0.0547,
          0.0754, -0.1460, -0.0103,  0.0489,  0.0142, -0.0860, -0.0753, -0.1119,
         -0.0817,  0.0255,  0.0981, -0.0944, -0.0781,  0.1217,  0.0325, -0.0320,
          0.1403,  0.1483,  0.0051, -0.0877, -0.0276,  0.0138, -0.0876,  0.0552,
         -0.0865,  0.1077,  0.1166, -0.0103,  0.0373,  0.0859, -0.0704,  0.0125,
          0.1413, -0.1442, -0.1108, -0.1432, -0.0884, -0.0245, -0.1145,  0.0057,
          0.1350, -0.0467,  0.1466,  0.1113, -0.0123,  0.0168, -0.0093,  0.1162,
         -0.1526, -0.1494, -0.0907,  0.0277,  0.0109, -0.1107,  0.0137,  0.0226]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.1215, -0.1074, -0.0773,  ..., -0.1144,  0.1160, -0.0519],
        [ 0.0490, -0.0575, -0.1017,  ...,  0.0898,  0.0819,  0.0054],
        [ 0.0307,  0.0844,  0.0775,  ...,  0.1081,  0.0092,  0.0448],
        ...,
        [ 0.0456, -0.0325, -0.0986,  ...,  0.0514, -0.0796,  0.0884],
        [-0.0368, -0.0142,  0.0797,  ..., -0.0622, -0.0161,  0.1235],
        [ 0.0181, -0.0401,  0.1136,  ..., -0.1019, -0.0110, -0.1230]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1215, -0.1074, -0.0773,  ..., -0.1144,  0.1160, -0.0519],
        [ 0.0490, -0.0575, -0.1017,  ...,  0.0898,  0.0819,  0.0054],
        [ 0.0307,  0.0844,  0.0775,  ...,  0.1081,  0.0092,  0.0448],
        ...,
        [ 0.0456, -0.0325, -0.0986,  ...,  0.0514, -0.0796,  0.0884],
        [-0.0368, -0.0142,  0.0797,  ..., -0.0622, -0.0161,  0.1235],
        [ 0.0181, -0.0401,  0.1136,  ..., -0.1019, -0.0110, -0.1230]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0004, -0.0123, -0.1150,  ...,  0.1716, -0.0682, -0.0830],
        [-0.0872,  0.0487, -0.0597,  ..., -0.0642,  0.0918, -0.1683],
        [ 0.0972,  0.0644,  0.1151,  ...,  0.0289, -0.0511, -0.1225],
        ...,
        [-0.1298,  0.0156, -0.0024,  ...,  0.1077,  0.0349, -0.1052],
        [ 0.1164,  0.0615, -0.0387,  ..., -0.0256,  0.1358, -0.1444],
        [-0.1335,  0.1674,  0.0018,  ..., -0.0951,  0.0531,  0.1531]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0004, -0.0123, -0.1150,  ...,  0.1716, -0.0682, -0.0830],
        [-0.0872,  0.0487, -0.0597,  ..., -0.0642,  0.0918, -0.1683],
        [ 0.0972,  0.0644,  0.1151,  ...,  0.0289, -0.0511, -0.1225],
        ...,
        [-0.1298,  0.0156, -0.0024,  ...,  0.1077,  0.0349, -0.1052],
        [ 0.1164,  0.0615, -0.0387,  ..., -0.0256,  0.1358, -0.1444],
        [-0.1335,  0.1674,  0.0018,  ..., -0.0951,  0.0531,  0.1531]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-0.0666, -0.2093, -0.0808,  ..., -0.1367, -0.1218,  0.0713],
        [-0.1504, -0.0417,  0.0605,  ...,  0.0874, -0.2084, -0.0593],
        [-0.1833, -0.2275, -0.0408,  ...,  0.0361, -0.2029,  0.0934],
        ...,
        [ 0.0936, -0.0059,  0.2153,  ...,  0.1511,  0.0287, -0.0929],
        [-0.0762, -0.1706, -0.1372,  ..., -0.2252,  0.2143,  0.0772],
        [-0.0615,  0.0528, -0.0542,  ...,  0.0262,  0.1950,  0.0946]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0666, -0.2093, -0.0808,  ..., -0.1367, -0.1218,  0.0713],
        [-0.1504, -0.0417,  0.0605,  ...,  0.0874, -0.2084, -0.0593],
        [-0.1833, -0.2275, -0.0408,  ...,  0.0361, -0.2029,  0.0934],
        ...,
        [ 0.0936, -0.0059,  0.2153,  ...,  0.1511,  0.0287, -0.0929],
        [-0.0762, -0.1706, -0.1372,  ..., -0.2252,  0.2143,  0.0772],
        [-0.0615,  0.0528, -0.0542,  ...,  0.0262,  0.1950,  0.0946]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.0442],
        [ 0.4050],
        [ 0.1386],
        [ 0.0938],
        [-0.2106],
        [ 0.3091],
        [-0.3886],
        [-0.1221],
        [-0.0896],
        [ 0.2024],
        [-0.3932],
        [ 0.0024],
        [-0.2130],
        [ 0.1352],
        [ 0.3704],
        [ 0.4189],
        [-0.0095],
        [-0.1838],
        [ 0.1905],
        [-0.3230],
        [ 0.0070],
        [-0.3726],
        [ 0.3995],
        [-0.0741],
        [ 0.0237],
        [ 0.1837],
        [ 0.3070],
        [-0.3136],
        [-0.1859],
        [-0.1248],
        [ 0.1045],
        [ 0.0688]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0442],
        [ 0.4050],
        [ 0.1386],
        [ 0.0938],
        [-0.2106],
        [ 0.3091],
        [-0.3886],
        [-0.1221],
        [-0.0896],
        [ 0.2024],
        [-0.3932],
        [ 0.0024],
        [-0.2130],
        [ 0.1352],
        [ 0.3704],
        [ 0.4189],
        [-0.0095],
        [-0.1838],
        [ 0.1905],
        [-0.3230],
        [ 0.0070],
        [-0.3726],
        [ 0.3995],
        [-0.0741],
        [ 0.0237],
        [ 0.1837],
        [ 0.3070],
        [-0.3136],
        [-0.1859],
        [-0.1248],
        [ 0.1045],
        [ 0.0688]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=79982,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([79982, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(79982., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-36.0582, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(1.2563, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(1.2785, device='cuda:0')



h[100].sum tensor(-7.2184, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-7.3458, device='cuda:0')



h[200].sum tensor(-3.9877, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-4.0581, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(10286.8340, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0065, 0.0000,  ..., 0.0000, 0.0044, 0.0000],
        [0.0000, 0.0017, 0.0000,  ..., 0.0000, 0.0011, 0.0000],
        [0.0000, 0.0005, 0.0000,  ..., 0.0000, 0.0003, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(54303.1133, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-59.8507, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-5.0145, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(1460.7767, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(88.6083, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=79982,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.0683],
        [-0.0452],
        [-0.0290],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-3245.0486, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([79982, 1]) 
g.edata[efet].sum tensor(79982., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[-0.0683],
        [-0.0452],
        [-0.0290],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=1599640,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([1599640, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(1599640., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[ 0.0054, -0.0052,  0.0083,  ...,  0.0053,  0.0148,  0.0106],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(-470.7130, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(44.5890, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(45.4020, device='cuda:0')



h[100].sum tensor(129.1418, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(131.4965, device='cuda:0')



h[200].sum tensor(60.1108, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(61.2068, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0322, 0.0000, 0.0497,  ..., 0.0317, 0.0884, 0.0633],
        [0.0176, 0.0000, 0.0272,  ..., 0.0173, 0.0484, 0.0346],
        [0.0042, 0.0000, 0.0065,  ..., 0.0041, 0.0115, 0.0083],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(102022.5078, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.2522, 0.1325, 0.0000,  ..., 0.0000, 0.0000, 0.3074],
        [0.1898, 0.0997, 0.0000,  ..., 0.0000, 0.0000, 0.2314],
        [0.1346, 0.0707, 0.0000,  ..., 0.0000, 0.0000, 0.1640],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(471653.4375, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(9710.3350, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(649.8578, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-1093.0045, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-2.5576, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=1599640,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-2.1207e+00],
        [-2.2127e+00],
        [-2.3768e+00],
        ...,
        [-1.1034e-05],
        [-1.8336e-05],
        [-2.6188e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(-130836.5703, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([1599640, 1]) 
g.edata[efet].sum tensor(1599640., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-0.0683],
        [-0.0452],
        [-0.0290],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/checkpoint_dir/90016284saved_checkpoint.tar



load_model True 
TraEvN 9001 
BatchSize 30 
EpochNum 80 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 
startmesh 284 
endmesh 285 






optimizer.param_groups
 [{'params': [Parameter containing:
tensor([[ 1.0076e-40, -4.7452e-13,  8.5099e-02,  9.7981e-02,  1.8748e-01,
          1.7174e-01, -3.7681e-12, -6.4529e-12,  1.1833e-01,  1.5747e-01,
          1.9213e-01,  1.1904e-01,  1.2590e-01, -3.3106e-13,  4.4109e-02,
         -1.7796e-17, -2.7480e-03,  1.1192e-01,  8.6889e-02,  1.3959e-01,
         -4.0209e-11, -1.7586e-33,  6.2472e-02,  1.3035e-01, -7.4809e-34,
         -7.2355e-04, -6.9009e-19,  6.3752e-02, -2.3849e-03,  1.0285e-01,
         -5.6311e-13,  7.3909e-02, -8.3398e-21, -5.3455e-23,  1.8028e-01,
          2.0822e-01, -1.2992e-10,  2.2170e-19,  1.0582e-01,  1.7794e-01,
          1.4241e-01,  1.5546e-01,  2.7655e-03,  1.6161e-01, -4.2103e-03,
          7.6704e-41,  9.7278e-02, -1.0763e-40,  1.3845e-01, -2.5767e-13,
         -3.2189e-30, -3.8767e-41,  1.1937e-05,  7.4505e-02, -2.8187e-41,
         -1.9561e-03, -2.5500e-05,  1.0375e-01, -1.2188e-09, -5.0265e-13,
          9.3991e-41,  1.7898e-01, -1.0861e-02, -8.3738e-23,  9.5822e-02,
          1.7488e-01,  2.5739e-01,  1.3917e-01,  3.3075e-41,  8.0075e-02,
         -3.0651e-12, -9.3809e-10,  1.0931e-01, -1.2632e-06,  8.2083e-02,
          8.7719e-02, -8.6903e-06,  7.2083e-02, -3.8073e-12, -3.7840e-29,
         -2.1479e-02, -5.4808e-41, -2.4659e-03, -6.5027e-12,  1.0087e-35,
          5.7344e-04, -3.9924e-13, -1.6431e-03,  1.9390e-40,  1.2487e-01,
         -8.8806e-41, -3.7880e-10,  1.4563e-01,  5.1986e-02, -9.1071e-02,
          4.8800e-14, -2.7304e+00,  7.5317e-02,  1.7143e-01, -5.6215e-12,
          2.7830e-03,  1.8333e-01,  1.0798e-01, -3.5132e-41, -7.7982e-42,
         -1.5986e-15, -2.3301e-03, -2.7785e-21, -1.6885e-09,  1.2168e-01,
         -1.2117e-12, -9.3940e-10,  1.0729e-01,  6.2461e-02,  5.7822e-02,
          1.0425e-01, -5.6811e-41,  1.1143e-01, -5.6213e-10, -4.6760e-13,
          2.1131e-16, -2.4723e-03, -3.1646e-03,  2.3806e-01, -2.1715e-03,
         -7.5765e-10,  1.4553e-01, -5.2708e-14,  8.4413e-03,  3.8607e-41,
          8.8876e-02,  1.2897e-01, -3.2161e-12, -4.0855e-03,  2.4055e-09,
          5.1016e-02,  2.1028e-01,  1.9203e-01,  1.6598e-01,  2.0248e-01,
          1.4678e-01,  7.8349e-04,  1.9454e-01, -3.2202e-03, -1.5898e-03,
         -6.4877e-41, -5.0396e-02,  3.2932e-41,  1.3742e-01, -1.3744e-02,
         -1.5774e-03,  1.0404e-01,  1.4925e-01, -2.3755e-15,  1.1806e-03,
         -4.2991e-13,  1.7377e-01,  5.1399e-02, -7.5344e-30, -3.8368e-12,
         -3.3036e-12,  1.7028e-01, -1.0773e-10,  2.2634e-01, -3.8273e-12,
         -5.3807e-13, -2.4105e-17,  1.9463e-01,  7.8645e-02,  2.0077e-01,
         -1.5703e-14,  1.3155e-40,  1.3898e-01,  9.2085e-04,  8.9895e-02,
         -5.5980e-12,  1.4376e-01, -4.9409e-12,  6.5518e-02, -2.6928e-02,
          1.3006e-01,  1.6913e-01,  1.9898e-01,  1.5325e-01,  1.5412e-01,
          1.9705e-01, -1.0609e-10,  1.2143e-01,  1.2357e-01,  9.5935e-02,
          1.6458e-01,  1.9604e-01,  9.4026e-02,  8.6880e-02, -3.3936e-03,
          1.0404e-01, -3.1436e-12, -2.2484e-21,  1.0961e-01, -1.7790e-13,
         -2.1130e-02, -3.5353e-03,  9.1966e-02, -4.0469e-12,  8.0849e-02,
          4.7105e-41, -2.1600e-02,  1.2787e-01, -1.9811e-04,  1.6660e-01,
          8.3242e-02,  6.0632e-02, -3.1735e-12, -6.4173e-12, -7.4182e-41,
         -2.0316e-28, -1.5908e-02,  9.6841e-11, -5.6313e-03, -4.4687e-12,
          1.7767e-01, -1.4026e-20, -3.1723e-12,  3.1621e-03,  1.4207e-40,
          1.1499e-01,  9.2266e-02, -3.4287e-16, -8.1983e-04,  1.5851e-01,
          6.4657e-02, -2.6482e-03,  2.0335e-01, -6.7958e-06, -2.6435e-03,
         -4.3234e-02,  1.1632e-01, -1.7353e-03,  1.7324e-40,  8.2986e-02,
          1.5746e-01, -2.3766e-03, -1.1877e-09, -5.3763e-10,  5.5299e-03,
         -2.6275e-03,  2.3566e-01, -1.0962e-09, -6.4193e-12, -2.4130e-27,
         -1.3185e-08,  1.2546e-01, -4.0478e-12,  8.9223e-02, -5.7288e-03,
         -2.3289e-21]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-4.0970e-27, -4.6670e-04, -6.2237e-05, -1.1598e-03, -2.7719e-03,
         7.6853e-05, -4.8550e-04, -4.7713e-04, -2.1069e-03, -8.5922e-05,
        -3.5546e-02, -9.6324e-04,  5.6761e-05, -4.7675e-04, -2.9204e-03,
        -3.3829e-04, -3.1080e-03, -6.7404e-03, -6.2335e-03,  9.5737e-05,
        -3.1175e-03, -1.4791e-03, -7.0601e-03, -5.7334e-03, -2.9433e-06,
        -3.0594e-03, -3.2186e-04, -6.3575e-03, -3.1855e-03, -1.2895e-04,
        -4.7780e-04, -7.3646e-03, -1.6757e-04, -2.3207e-04, -6.4764e-05,
        -2.9000e-03, -3.4198e-04, -9.2444e-05, -1.1563e-02, -2.4294e-03,
        -2.1517e-03,  4.6985e-03, -2.8580e-03, -2.4926e-03, -2.6077e-03,
        -1.9990e-05, -3.9400e-05, -2.0805e-06, -1.2535e-02, -4.7664e-04,
        -2.1589e-04, -1.5572e-05, -3.5219e-03, -1.8704e-04, -4.8822e-10,
        -3.9412e-03, -3.0762e-03, -1.2169e-03, -8.0378e-05, -4.6975e-04,
        -2.0236e-32,  5.4889e-05,  5.3119e-03, -2.1030e-04, -6.0694e-03,
         4.5732e-05, -4.4752e-03,  6.6859e-05, -4.4238e-27,  1.1315e-04,
        -5.0877e-04, -8.2313e-05, -5.9483e-03, -2.2141e-03, -2.3535e-03,
        -3.5667e-03, -3.1738e-03, -2.0396e-03, -4.8371e-04, -2.1792e-04,
         1.6381e-02, -3.3856e-05, -2.8341e-03, -4.7636e-04, -1.5217e-35,
        -3.0909e-03, -4.7690e-04, -7.5494e-04, -1.9833e-35, -5.5674e-05,
        -5.0159e-07, -3.0645e-03, -2.6573e-03, -5.4994e-03,  1.2745e-02,
        -1.5831e-03,  3.0621e-02, -4.5264e-04,  2.7211e-04, -4.9092e-04,
        -3.1516e-03, -3.3847e-03, -4.8200e-03, -1.0286e-33, -1.4010e-04,
        -5.7633e-04, -2.8477e-03, -2.5995e-04, -1.3537e-04, -8.2447e-05,
        -4.6740e-04, -8.1097e-05, -1.6410e-04,  1.9210e-02,  9.9016e-03,
        -9.0509e-03, -1.9406e-05, -1.4196e-03, -9.7979e-05, -4.7004e-04,
        -6.4701e-15, -3.4989e-03, -3.1763e-03, -6.7712e-03, -2.7294e-03,
        -7.2318e-05,  6.5509e-03, -4.7171e-04,  7.5435e-03, -1.9049e-04,
        -1.4186e-02, -1.8458e-04, -5.0348e-04, -3.7528e-03, -1.9872e-03,
         1.7165e-03,  1.6097e-04, -3.2210e-04, -2.1457e-03, -3.3318e-05,
         9.9298e-05, -5.4099e-03, -1.1175e-04, -3.0269e-03, -3.2087e-03,
        -3.1555e-05,  1.6110e-02, -3.2061e-12, -3.6950e-04,  9.8527e-03,
        -3.9356e-03, -2.6388e-02, -1.1434e-04, -4.7969e-04, -3.1762e-03,
        -4.6852e-04, -1.8794e-02, -6.0725e-03, -1.7742e-04, -4.8207e-04,
        -5.0066e-04,  1.1799e-04, -3.4676e-04,  9.4854e-04, -4.8234e-04,
        -4.7751e-04, -3.8839e-04, -9.3605e-03,  4.8658e-03,  3.0029e-04,
        -4.6055e-04, -5.7309e-12, -1.7947e-03, -3.2558e-03, -5.6730e-03,
        -4.9134e-04,  2.8115e-03, -5.0413e-04, -1.6648e-03,  8.4502e-03,
        -4.2433e-03,  8.7693e-05,  1.9806e-03,  5.1977e-05, -7.8430e-03,
        -5.2866e-03, -3.4751e-04, -7.1738e-03, -1.5401e-03, -1.3761e-03,
        -1.4972e-02, -4.9674e-05, -8.9552e-04, -1.0467e-03, -3.5624e-03,
        -5.6799e-05, -5.0591e-04, -1.8794e-04, -3.1208e-03, -4.7640e-04,
         3.6855e-03, -3.0937e-03, -1.4555e-02, -4.6554e-04,  1.5073e-02,
        -7.6132e-06,  1.0062e-02,  9.9715e-04, -8.5160e-05,  8.9093e-05,
         7.0559e-03, -1.6324e-02, -5.0489e-04, -4.7767e-04, -1.8995e-04,
        -2.9255e-04,  1.4859e-02, -1.7602e-05,  8.0499e-03, -5.1466e-04,
         4.5473e-04, -2.8963e-04, -5.0493e-04, -3.1623e-03, -1.8079e-26,
        -5.9618e-05,  3.2258e-05, -3.7061e-04, -1.3062e-03, -2.9027e-03,
         5.8721e-03, -2.6838e-03,  2.8622e-05, -2.9678e-03, -3.4241e-03,
         8.2101e-03, -1.4102e-04, -3.2503e-03, -2.2129e-10, -3.5589e-03,
         5.4069e-03, -2.9055e-03, -7.7519e-05, -2.0380e-03, -5.4663e-03,
        -4.0726e-03, -2.6797e-03, -7.4450e-05, -4.7764e-04, -2.2492e-04,
        -1.3554e-04, -1.6017e-03, -4.7709e-04, -9.4620e-04, -4.2668e-03,
        -2.0677e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-1.1535e-40,  3.7978e-41, -1.6032e-40,  ...,  1.2296e-40,
         -7.1522e-42, -1.7370e-40],
        [-1.2442e-40, -6.6534e-41, -2.1963e-23,  ..., -1.5558e-40,
          2.8617e-07, -3.0932e-09],
        [-2.2950e-04,  1.0051e-40, -4.6974e-02,  ...,  8.0645e-42,
         -1.0101e-01, -1.4687e-03],
        ...,
        [-1.9803e-04, -6.4310e-41, -8.0334e-02,  ...,  1.0305e-40,
          8.8672e-02,  5.4892e-02],
        [-6.8367e-41,  6.0899e-41, -5.7258e-04,  ...,  1.8142e-40,
          5.3009e-04, -7.0033e-04],
        [ 1.2070e-40, -2.0071e-40, -4.0788e-37,  ...,  2.7823e-41,
         -8.4646e-11, -6.7265e-19]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-3.0593e-03, -4.6836e-07,  5.2427e-02,  1.4727e-02,  2.9469e-02,
         1.9121e-02,  8.1748e-03,  1.4238e-01,  1.9708e-01,  8.9397e-02,
        -2.3764e-03, -1.1579e-03, -3.7575e-03,  1.1831e-01, -3.3481e-04,
        -2.4162e-08,  2.2032e-02,  1.2948e-01, -1.4263e-02, -7.4856e-09,
        -1.5522e-02,  1.1004e-01, -2.9805e-30, -1.4338e-02,  1.2109e-01,
         2.9334e-02,  1.8958e-02,  6.7604e-02, -9.8335e-03,  1.5636e-01,
         1.0623e-01,  6.3771e-02,  7.7482e-03,  6.5942e-02, -4.3590e-04,
        -2.9529e-03,  1.0599e-01, -4.0316e-03, -2.1062e-02, -3.7802e-02,
        -9.4286e-02, -3.0936e-03, -3.8688e-03,  1.1176e-01,  1.2382e-01,
        -4.1302e-02,  1.9920e-01, -4.1849e-06, -3.0638e-03, -3.7121e-03,
         1.0870e-02, -3.7012e-03,  9.3570e-02,  7.2967e-02,  2.1057e-02,
        -3.6404e-02,  1.5247e-02,  1.5220e-02,  7.7266e-02, -2.4349e-11,
         9.8994e-02,  1.5281e-02,  7.7790e-02, -4.5749e-03, -2.9225e-03,
         4.9633e-02,  5.7546e-02, -4.6389e-03,  5.6994e-02,  4.1217e-02,
        -7.2509e-18, -1.3337e-03,  1.9703e-01, -1.9044e-03, -2.2977e-02,
         9.4437e-02,  1.4711e-02,  7.5851e-02, -2.1134e-03,  7.4420e-02,
        -4.4075e-02,  1.7227e-01, -2.9456e-03,  3.4963e-02, -4.3526e-03,
         1.5553e-01, -5.7740e-06,  5.5662e-02, -8.0279e-07, -1.0274e-02,
        -2.2904e-19, -3.3350e-03,  2.4884e-02, -5.4770e-06, -8.5508e-03,
         2.5205e-02, -2.5545e-05,  1.6238e-02,  1.0975e-01,  1.5459e-02,
        -4.1836e-06, -1.5096e-06,  4.0276e-02, -5.7221e-28,  7.3796e-02,
        -4.1599e-06,  2.8426e-02,  1.8025e-02,  2.1303e-02, -2.1740e-03,
         5.4848e-02,  2.9835e-02, -9.4852e-05, -2.5634e-02, -5.9871e-03,
        -3.1261e-03,  9.9833e-02,  1.1814e-01,  1.0885e-01, -1.2015e-02,
         2.0164e-03,  8.6022e-02, -3.2582e-03,  7.4467e-02, -2.5858e-03,
        -6.1815e-07, -2.5535e-03,  8.3091e-03], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[ 6.6477e-04,  1.3075e-03,  2.2982e-03,  ...,  1.1541e-40,
         -1.1725e-03,  6.4443e-04],
        [-1.1076e-14,  5.5210e-09,  3.2529e-10,  ..., -1.1499e-40,
         -5.3909e-32,  1.2864e-28],
        [ 1.5442e-01, -8.7943e-02,  8.2164e-02,  ..., -1.6282e-08,
          6.8936e-02,  2.4873e-02],
        ...,
        [-1.1485e-14,  5.4268e-09,  2.9419e-10,  ..., -8.0736e-41,
         -1.1528e-30,  2.2491e-29],
        [ 1.7418e-02,  9.0034e-02,  1.9307e-02,  ..., -2.4034e-03,
          5.7133e-02,  8.1395e-02],
        [ 3.0718e-02,  1.5153e-01, -1.1221e-01,  ..., -2.5011e-03,
          1.4741e-01, -1.4788e-01]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 5.0386e-02,  8.0924e-02,  1.9932e-02,  4.0687e-02, -1.2189e-01,
         2.0797e-01,  3.6408e-03, -6.5747e-02, -3.5210e-02,  1.2937e-01,
        -2.6029e-03,  7.4614e-02, -3.1932e-02,  9.2721e-02, -3.0023e-03,
        -2.6529e-03,  5.6282e-03,  1.5434e-01,  1.9262e-02, -3.9509e-02,
        -3.9298e-03,  4.2272e-41, -8.9533e-02, -1.8858e-08,  2.3813e-02,
         2.2635e-02, -6.5586e-02, -1.0886e-14, -4.2543e-03, -8.4905e-02,
         9.9519e-02,  4.2990e-02,  1.7715e-02,  5.1336e-01,  2.8310e-02,
         5.9292e-01, -1.2059e-02, -3.3644e-41, -1.0261e-01,  5.8166e-01,
         6.0275e-01,  1.7001e-01,  3.5869e-01,  7.3710e-02, -2.4171e-02,
         7.5741e-02, -6.0251e-02, -7.2692e-02,  5.3216e-01, -2.9029e-02,
        -4.3077e-02,  4.3459e-01,  4.8081e-02, -2.1208e-02, -6.5748e-02,
        -1.2977e-01,  3.6575e-02,  1.1258e-01,  2.0047e-01,  3.2170e-02,
         6.8401e-02, -2.1159e-03, -1.4777e-02,  3.5003e-01], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[ 4.5361e-02, -2.5416e-01,  1.7201e-01,  ..., -4.3167e-02,
         -2.3020e-01, -1.5807e-02],
        [ 1.8317e-01,  5.0939e-03, -6.8991e-02,  ..., -2.0485e-01,
          6.8011e-03,  2.3558e-02],
        [-3.0885e-02,  1.8940e-01, -3.8720e-02,  ...,  2.4586e-02,
         -1.6983e-01,  3.4412e-02],
        ...,
        [-8.8702e-41,  3.3552e-39, -1.9257e-29,  ...,  1.8260e-41,
          3.1571e-42,  2.0025e-41],
        [ 1.2266e-02, -1.5358e-01,  2.0889e-01,  ..., -1.1895e-02,
         -1.4659e-01, -6.5047e-02],
        [-8.5310e-01, -3.3321e-01, -7.8892e-01,  ...,  2.7579e-01,
         -5.2910e-01, -6.6384e-01]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-3.5677e-01,  3.6482e-01, -1.8174e-01,  7.2786e-01, -2.3176e-01,
         6.5816e-01,  4.3364e-01,  9.1823e-03, -9.3887e-01,  8.6179e-01,
        -3.3974e-01,  8.1999e-01,  2.3528e-01,  4.3968e-01, -6.7660e-01,
         1.0309e-01,  5.4861e-01,  1.4907e+00,  1.0564e+00, -3.1145e-02,
         6.4272e-01, -1.7427e-01, -6.8055e-01, -3.8571e-01,  6.7339e-01,
         2.4329e-01,  6.5753e-01, -2.6564e-01, -9.2828e-04,  8.3973e-01,
        -2.2654e-01,  4.9546e-01], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 2.6161e-01],
        [-6.0314e-01],
        [-8.8726e-01],
        [ 3.3087e-01],
        [-6.9164e-01],
        [ 3.0222e-01],
        [-2.6353e-01],
        [-7.9615e-01],
        [-4.3549e-01],
        [ 1.3947e-01],
        [-1.1361e+00],
        [ 7.8202e-02],
        [ 3.3502e-01],
        [-3.0313e-01],
        [-4.1468e-01],
        [ 6.4982e-01],
        [-2.4421e+00],
        [-7.3053e+00],
        [-3.5008e+00],
        [-1.2678e+00],
        [ 5.2290e-01],
        [-2.4659e-01],
        [-2.6996e-01],
        [-8.7084e-01],
        [ 4.2985e-01],
        [-3.1791e-01],
        [ 1.1974e-01],
        [-7.7330e-01],
        [ 2.6228e-03],
        [ 3.1968e-01],
        [-8.2516e-01],
        [ 3.6124e+00]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0561], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/./TrainingBhaself.py", line 65, in <module>
    optimizer.add_param_group({'params': dglgraph.edata['efet']})
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/optim/optimizer.py", line 258, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor

real	0m33.676s
user	0m18.601s
sys	0m6.708s
