0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        9B:9E:55:A9:86:D9:50:0B:6D:2D:9F:BA:A7:E6:45:39:D4:DD:5F:C6
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sat Sep 17 08:01:55 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   23C    P0    32W / 250W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.358472704

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b8f55d898e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m5.168s
user	0m2.646s
sys	0m1.206s
[08:02:03] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[-1.1463],
        [ 0.7560],
        [-0.8438],
        ...,
        [ 0.0757],
        [-0.7668],
        [-0.3650]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-38.4180, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.0170,  0.0630,  0.0220, -0.0209,  0.1136,  0.0116,  0.1353,  0.0259,
          0.1045, -0.0324,  0.1164, -0.0977, -0.1306,  0.1458, -0.1039,  0.0641,
          0.1225,  0.0201, -0.1497, -0.0200, -0.0228,  0.1268,  0.1411, -0.0932,
          0.0779,  0.0339, -0.1293,  0.0901,  0.0103, -0.1277, -0.0678,  0.0677,
         -0.1482, -0.0584, -0.1276,  0.1293, -0.1210,  0.1038,  0.1244,  0.1150,
          0.0820,  0.0426,  0.1474,  0.1172, -0.0185,  0.0597,  0.1203, -0.0795,
          0.1445,  0.1096, -0.0029,  0.1085,  0.1304,  0.0875, -0.0274,  0.0844,
          0.1227,  0.0452, -0.1363, -0.0442,  0.0570, -0.0574, -0.0330,  0.1428,
         -0.0148,  0.0509, -0.0488,  0.0445,  0.0552,  0.0151, -0.0506,  0.1286,
          0.0336,  0.0974,  0.0587, -0.0167,  0.0716,  0.1131, -0.1095, -0.0856,
          0.1033, -0.0293,  0.1271, -0.0678,  0.0395, -0.0074, -0.0292, -0.0021,
         -0.0570,  0.1475,  0.1004, -0.1071,  0.0607, -0.1333,  0.0192, -0.0027,
         -0.0297,  0.0893,  0.0029,  0.0640,  0.1101, -0.1523, -0.0025, -0.1286,
          0.0205,  0.1146, -0.0402, -0.1119,  0.0242, -0.0882, -0.1525, -0.0034,
          0.0246,  0.0388, -0.0581,  0.0827,  0.0095,  0.0178, -0.1505, -0.0208,
          0.1173, -0.0099,  0.0483,  0.0376,  0.1280, -0.0078, -0.0229,  0.0077,
         -0.0591, -0.0763,  0.1286,  0.0181, -0.0546, -0.0526,  0.1385, -0.1029,
         -0.0785,  0.0827, -0.0769,  0.0900, -0.0432,  0.0195,  0.0586, -0.1183,
          0.0219,  0.0384, -0.1391,  0.1383, -0.0545,  0.1454, -0.0938, -0.1509,
          0.0188,  0.1151, -0.1250, -0.0269, -0.0337,  0.0972,  0.1493, -0.1363,
         -0.0869, -0.0923,  0.0032,  0.0930,  0.0312, -0.0449,  0.1220,  0.0874,
         -0.0152, -0.1363, -0.0104, -0.1012, -0.0126,  0.1415,  0.0320,  0.1148,
         -0.0414, -0.0006,  0.0861,  0.0692, -0.0710, -0.0003, -0.0022,  0.1375,
          0.1234, -0.1217,  0.1143,  0.1286,  0.0200, -0.1266, -0.0361, -0.0980,
          0.0766, -0.1201,  0.1050,  0.0590, -0.0339, -0.0135, -0.0811, -0.1159,
          0.1394,  0.0755, -0.0772,  0.0043,  0.1078,  0.0850, -0.0008,  0.0407,
          0.0367, -0.0288,  0.1128,  0.1125, -0.0481, -0.0770,  0.0754, -0.0855,
          0.1390, -0.0489,  0.1182,  0.0526,  0.1456, -0.0797, -0.1491, -0.0700,
         -0.1101,  0.0900, -0.0508,  0.1155,  0.1493,  0.0058, -0.0440,  0.0375,
         -0.0279, -0.1474,  0.0882, -0.0417,  0.0345,  0.0766, -0.0475, -0.0300,
          0.0619,  0.1174, -0.1426, -0.0615, -0.0153, -0.1030,  0.0157, -0.0311,
         -0.0520,  0.0442,  0.0968,  0.0284,  0.1373,  0.0796, -0.1050, -0.0524]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0170,  0.0630,  0.0220, -0.0209,  0.1136,  0.0116,  0.1353,  0.0259,
          0.1045, -0.0324,  0.1164, -0.0977, -0.1306,  0.1458, -0.1039,  0.0641,
          0.1225,  0.0201, -0.1497, -0.0200, -0.0228,  0.1268,  0.1411, -0.0932,
          0.0779,  0.0339, -0.1293,  0.0901,  0.0103, -0.1277, -0.0678,  0.0677,
         -0.1482, -0.0584, -0.1276,  0.1293, -0.1210,  0.1038,  0.1244,  0.1150,
          0.0820,  0.0426,  0.1474,  0.1172, -0.0185,  0.0597,  0.1203, -0.0795,
          0.1445,  0.1096, -0.0029,  0.1085,  0.1304,  0.0875, -0.0274,  0.0844,
          0.1227,  0.0452, -0.1363, -0.0442,  0.0570, -0.0574, -0.0330,  0.1428,
         -0.0148,  0.0509, -0.0488,  0.0445,  0.0552,  0.0151, -0.0506,  0.1286,
          0.0336,  0.0974,  0.0587, -0.0167,  0.0716,  0.1131, -0.1095, -0.0856,
          0.1033, -0.0293,  0.1271, -0.0678,  0.0395, -0.0074, -0.0292, -0.0021,
         -0.0570,  0.1475,  0.1004, -0.1071,  0.0607, -0.1333,  0.0192, -0.0027,
         -0.0297,  0.0893,  0.0029,  0.0640,  0.1101, -0.1523, -0.0025, -0.1286,
          0.0205,  0.1146, -0.0402, -0.1119,  0.0242, -0.0882, -0.1525, -0.0034,
          0.0246,  0.0388, -0.0581,  0.0827,  0.0095,  0.0178, -0.1505, -0.0208,
          0.1173, -0.0099,  0.0483,  0.0376,  0.1280, -0.0078, -0.0229,  0.0077,
         -0.0591, -0.0763,  0.1286,  0.0181, -0.0546, -0.0526,  0.1385, -0.1029,
         -0.0785,  0.0827, -0.0769,  0.0900, -0.0432,  0.0195,  0.0586, -0.1183,
          0.0219,  0.0384, -0.1391,  0.1383, -0.0545,  0.1454, -0.0938, -0.1509,
          0.0188,  0.1151, -0.1250, -0.0269, -0.0337,  0.0972,  0.1493, -0.1363,
         -0.0869, -0.0923,  0.0032,  0.0930,  0.0312, -0.0449,  0.1220,  0.0874,
         -0.0152, -0.1363, -0.0104, -0.1012, -0.0126,  0.1415,  0.0320,  0.1148,
         -0.0414, -0.0006,  0.0861,  0.0692, -0.0710, -0.0003, -0.0022,  0.1375,
          0.1234, -0.1217,  0.1143,  0.1286,  0.0200, -0.1266, -0.0361, -0.0980,
          0.0766, -0.1201,  0.1050,  0.0590, -0.0339, -0.0135, -0.0811, -0.1159,
          0.1394,  0.0755, -0.0772,  0.0043,  0.1078,  0.0850, -0.0008,  0.0407,
          0.0367, -0.0288,  0.1128,  0.1125, -0.0481, -0.0770,  0.0754, -0.0855,
          0.1390, -0.0489,  0.1182,  0.0526,  0.1456, -0.0797, -0.1491, -0.0700,
         -0.1101,  0.0900, -0.0508,  0.1155,  0.1493,  0.0058, -0.0440,  0.0375,
         -0.0279, -0.1474,  0.0882, -0.0417,  0.0345,  0.0766, -0.0475, -0.0300,
          0.0619,  0.1174, -0.1426, -0.0615, -0.0153, -0.1030,  0.0157, -0.0311,
         -0.0520,  0.0442,  0.0968,  0.0284,  0.1373,  0.0796, -0.1050, -0.0524]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.0897, -0.0487, -0.0915,  ..., -0.0745, -0.1107,  0.0769],
        [ 0.0293, -0.1027, -0.0713,  ...,  0.0618,  0.0207, -0.0721],
        [ 0.0784,  0.0064, -0.0946,  ..., -0.0402,  0.0375, -0.0477],
        ...,
        [ 0.0285, -0.0253, -0.0881,  ..., -0.0050, -0.0890,  0.1137],
        [-0.0989, -0.0354, -0.0359,  ...,  0.1132, -0.0311,  0.1032],
        [-0.0101, -0.0947, -0.0904,  ...,  0.0506, -0.0831,  0.1130]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0897, -0.0487, -0.0915,  ..., -0.0745, -0.1107,  0.0769],
        [ 0.0293, -0.1027, -0.0713,  ...,  0.0618,  0.0207, -0.0721],
        [ 0.0784,  0.0064, -0.0946,  ..., -0.0402,  0.0375, -0.0477],
        ...,
        [ 0.0285, -0.0253, -0.0881,  ..., -0.0050, -0.0890,  0.1137],
        [-0.0989, -0.0354, -0.0359,  ...,  0.1132, -0.0311,  0.1032],
        [-0.0101, -0.0947, -0.0904,  ...,  0.0506, -0.0831,  0.1130]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0080,  0.0504, -0.1376,  ...,  0.0973, -0.1184,  0.0541],
        [-0.0405, -0.1340, -0.0202,  ..., -0.1652,  0.0979,  0.0367],
        [ 0.1472,  0.1405,  0.1506,  ...,  0.0501, -0.0747,  0.0212],
        ...,
        [-0.0294, -0.0587, -0.1743,  ...,  0.0880,  0.1427, -0.0699],
        [-0.0390, -0.0513, -0.1043,  ...,  0.1072, -0.1613,  0.0754],
        [ 0.0349, -0.1468,  0.0690,  ..., -0.1362, -0.0337, -0.0150]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0080,  0.0504, -0.1376,  ...,  0.0973, -0.1184,  0.0541],
        [-0.0405, -0.1340, -0.0202,  ..., -0.1652,  0.0979,  0.0367],
        [ 0.1472,  0.1405,  0.1506,  ...,  0.0501, -0.0747,  0.0212],
        ...,
        [-0.0294, -0.0587, -0.1743,  ...,  0.0880,  0.1427, -0.0699],
        [-0.0390, -0.0513, -0.1043,  ...,  0.1072, -0.1613,  0.0754],
        [ 0.0349, -0.1468,  0.0690,  ..., -0.1362, -0.0337, -0.0150]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-0.0542,  0.1287,  0.2001,  ..., -0.1062, -0.0705, -0.2463],
        [ 0.0595, -0.1048,  0.0412,  ...,  0.0733, -0.0607,  0.0698],
        [-0.2452, -0.1283, -0.0714,  ..., -0.0340,  0.1456, -0.2449],
        ...,
        [ 0.1041, -0.1486,  0.1557,  ..., -0.1605,  0.0926, -0.1104],
        [ 0.0533,  0.0954, -0.1377,  ..., -0.0906,  0.1287, -0.2160],
        [ 0.2414, -0.1365, -0.1968,  ...,  0.1270,  0.1607,  0.1155]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0542,  0.1287,  0.2001,  ..., -0.1062, -0.0705, -0.2463],
        [ 0.0595, -0.1048,  0.0412,  ...,  0.0733, -0.0607,  0.0698],
        [-0.2452, -0.1283, -0.0714,  ..., -0.0340,  0.1456, -0.2449],
        ...,
        [ 0.1041, -0.1486,  0.1557,  ..., -0.1605,  0.0926, -0.1104],
        [ 0.0533,  0.0954, -0.1377,  ..., -0.0906,  0.1287, -0.2160],
        [ 0.2414, -0.1365, -0.1968,  ...,  0.1270,  0.1607,  0.1155]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.1825],
        [ 0.1989],
        [-0.3928],
        [ 0.3526],
        [ 0.2863],
        [ 0.1332],
        [ 0.0462],
        [ 0.2048],
        [ 0.3846],
        [ 0.0444],
        [ 0.2366],
        [ 0.2574],
        [-0.3624],
        [-0.4017],
        [ 0.1783],
        [-0.2794],
        [-0.2804],
        [-0.2868],
        [ 0.0683],
        [-0.3669],
        [-0.1573],
        [-0.2391],
        [ 0.1919],
        [ 0.3672],
        [ 0.3236],
        [ 0.0024],
        [ 0.0084],
        [-0.3076],
        [ 0.1096],
        [ 0.0503],
        [ 0.3063],
        [ 0.4077]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1825],
        [ 0.1989],
        [-0.3928],
        [ 0.3526],
        [ 0.2863],
        [ 0.1332],
        [ 0.0462],
        [ 0.2048],
        [ 0.3846],
        [ 0.0444],
        [ 0.2366],
        [ 0.2574],
        [-0.3624],
        [-0.4017],
        [ 0.1783],
        [-0.2794],
        [-0.2804],
        [-0.2868],
        [ 0.0683],
        [-0.3669],
        [-0.1573],
        [-0.2391],
        [ 0.1919],
        [ 0.3672],
        [ 0.3236],
        [ 0.0024],
        [ 0.0084],
        [-0.3076],
        [ 0.1096],
        [ 0.0503],
        [ 0.3063],
        [ 0.4077]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)

net when the batchsize is 2 GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network when the batchsize is 2:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-0.0899, -0.0675,  0.1151, -0.0131, -0.0791,  0.0883,  0.0016, -0.1469,
         -0.0788, -0.0815, -0.0589,  0.0254, -0.0005,  0.1462, -0.1418, -0.0520,
          0.0543,  0.0990,  0.1379,  0.0687,  0.1197, -0.0042, -0.0565,  0.0916,
         -0.0742,  0.1395, -0.0167,  0.0948, -0.0380,  0.0616, -0.1347,  0.0082,
          0.0864,  0.1234, -0.0641, -0.0538,  0.0362,  0.1351, -0.1473,  0.0155,
         -0.0084, -0.0200, -0.0301,  0.0499,  0.0708, -0.0165,  0.0641,  0.1128,
          0.0702,  0.0156,  0.0885,  0.0784,  0.0081,  0.0804,  0.0490,  0.0490,
         -0.0333, -0.0657, -0.1466,  0.0286, -0.0848, -0.0005, -0.0645,  0.1257,
         -0.1393, -0.0498, -0.0085,  0.0106, -0.1220,  0.0245, -0.0567, -0.0785,
          0.1018,  0.1311, -0.0183, -0.0247,  0.1429,  0.0469, -0.0950,  0.0281,
          0.0573, -0.1434, -0.0505,  0.0562,  0.1210, -0.0688, -0.0627, -0.1464,
         -0.0022,  0.0656, -0.0628,  0.0646,  0.1271, -0.0459,  0.1158, -0.0077,
         -0.1208,  0.0179,  0.0796,  0.1469,  0.0108,  0.0491,  0.1297,  0.1180,
         -0.0018, -0.1253, -0.1014,  0.0047, -0.0393,  0.0695,  0.0072, -0.1446,
          0.0445, -0.0898, -0.0342,  0.1366, -0.1242,  0.0211, -0.1397, -0.0297,
         -0.0460, -0.0748,  0.1358,  0.0704,  0.0802, -0.0020, -0.1382,  0.1191,
         -0.0644, -0.0317,  0.0092,  0.1376, -0.1378, -0.0677, -0.0452,  0.0258,
          0.1255,  0.0467, -0.0803, -0.1152,  0.1462,  0.0434, -0.0356,  0.0691,
         -0.0399, -0.0254,  0.0053,  0.0758,  0.0228, -0.1049, -0.0675,  0.1500,
          0.0266,  0.0316,  0.1174, -0.1394,  0.1470, -0.0554, -0.0133,  0.0846,
          0.0335,  0.0367,  0.0751, -0.1306, -0.0329,  0.0221, -0.0376,  0.0260,
          0.1339,  0.0172,  0.1116, -0.1429, -0.1169,  0.0466, -0.0637, -0.0288,
         -0.1397,  0.0486, -0.0614,  0.1404,  0.1033, -0.0600,  0.1230, -0.0811,
         -0.0440, -0.0935,  0.0982,  0.0100, -0.0330,  0.0378,  0.0817, -0.0569,
          0.0969, -0.0473,  0.1258,  0.1268,  0.0770,  0.0902, -0.0564,  0.0296,
          0.1137,  0.0106,  0.0983,  0.1380, -0.0844,  0.0083,  0.0747,  0.1520,
          0.0129,  0.0682, -0.0092, -0.0374, -0.1367,  0.1158, -0.0975,  0.0203,
          0.0620,  0.0598,  0.1373, -0.1273, -0.0302,  0.0870, -0.0510,  0.0462,
         -0.1371, -0.0568, -0.0383,  0.1071,  0.0334, -0.0658, -0.0853,  0.1206,
         -0.0231, -0.1420,  0.1178,  0.1182,  0.0793, -0.0472, -0.0725,  0.1290,
          0.1215, -0.0998,  0.0799, -0.0821, -0.1230,  0.0303, -0.0258, -0.0297,
          0.1306, -0.1119,  0.0918,  0.0354,  0.0741,  0.0136, -0.0912,  0.0532]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0899, -0.0675,  0.1151, -0.0131, -0.0791,  0.0883,  0.0016, -0.1469,
         -0.0788, -0.0815, -0.0589,  0.0254, -0.0005,  0.1462, -0.1418, -0.0520,
          0.0543,  0.0990,  0.1379,  0.0687,  0.1197, -0.0042, -0.0565,  0.0916,
         -0.0742,  0.1395, -0.0167,  0.0948, -0.0380,  0.0616, -0.1347,  0.0082,
          0.0864,  0.1234, -0.0641, -0.0538,  0.0362,  0.1351, -0.1473,  0.0155,
         -0.0084, -0.0200, -0.0301,  0.0499,  0.0708, -0.0165,  0.0641,  0.1128,
          0.0702,  0.0156,  0.0885,  0.0784,  0.0081,  0.0804,  0.0490,  0.0490,
         -0.0333, -0.0657, -0.1466,  0.0286, -0.0848, -0.0005, -0.0645,  0.1257,
         -0.1393, -0.0498, -0.0085,  0.0106, -0.1220,  0.0245, -0.0567, -0.0785,
          0.1018,  0.1311, -0.0183, -0.0247,  0.1429,  0.0469, -0.0950,  0.0281,
          0.0573, -0.1434, -0.0505,  0.0562,  0.1210, -0.0688, -0.0627, -0.1464,
         -0.0022,  0.0656, -0.0628,  0.0646,  0.1271, -0.0459,  0.1158, -0.0077,
         -0.1208,  0.0179,  0.0796,  0.1469,  0.0108,  0.0491,  0.1297,  0.1180,
         -0.0018, -0.1253, -0.1014,  0.0047, -0.0393,  0.0695,  0.0072, -0.1446,
          0.0445, -0.0898, -0.0342,  0.1366, -0.1242,  0.0211, -0.1397, -0.0297,
         -0.0460, -0.0748,  0.1358,  0.0704,  0.0802, -0.0020, -0.1382,  0.1191,
         -0.0644, -0.0317,  0.0092,  0.1376, -0.1378, -0.0677, -0.0452,  0.0258,
          0.1255,  0.0467, -0.0803, -0.1152,  0.1462,  0.0434, -0.0356,  0.0691,
         -0.0399, -0.0254,  0.0053,  0.0758,  0.0228, -0.1049, -0.0675,  0.1500,
          0.0266,  0.0316,  0.1174, -0.1394,  0.1470, -0.0554, -0.0133,  0.0846,
          0.0335,  0.0367,  0.0751, -0.1306, -0.0329,  0.0221, -0.0376,  0.0260,
          0.1339,  0.0172,  0.1116, -0.1429, -0.1169,  0.0466, -0.0637, -0.0288,
         -0.1397,  0.0486, -0.0614,  0.1404,  0.1033, -0.0600,  0.1230, -0.0811,
         -0.0440, -0.0935,  0.0982,  0.0100, -0.0330,  0.0378,  0.0817, -0.0569,
          0.0969, -0.0473,  0.1258,  0.1268,  0.0770,  0.0902, -0.0564,  0.0296,
          0.1137,  0.0106,  0.0983,  0.1380, -0.0844,  0.0083,  0.0747,  0.1520,
          0.0129,  0.0682, -0.0092, -0.0374, -0.1367,  0.1158, -0.0975,  0.0203,
          0.0620,  0.0598,  0.1373, -0.1273, -0.0302,  0.0870, -0.0510,  0.0462,
         -0.1371, -0.0568, -0.0383,  0.1071,  0.0334, -0.0658, -0.0853,  0.1206,
         -0.0231, -0.1420,  0.1178,  0.1182,  0.0793, -0.0472, -0.0725,  0.1290,
          0.1215, -0.0998,  0.0799, -0.0821, -0.1230,  0.0303, -0.0258, -0.0297,
          0.1306, -0.1119,  0.0918,  0.0354,  0.0741,  0.0136, -0.0912,  0.0532]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0106,  0.1250, -0.1096,  ...,  0.0380,  0.0580, -0.0953],
        [-0.0025, -0.1177,  0.0882,  ..., -0.0667, -0.1162,  0.0472],
        [-0.0910, -0.0503,  0.1146,  ...,  0.0263, -0.0246,  0.0781],
        ...,
        [-0.1044, -0.0361, -0.1003,  ..., -0.0681, -0.0266, -0.0401],
        [-0.0808,  0.0649, -0.0444,  ...,  0.1238, -0.0577, -0.0604],
        [ 0.1170, -0.1075, -0.0615,  ...,  0.0344,  0.0374, -0.1005]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0106,  0.1250, -0.1096,  ...,  0.0380,  0.0580, -0.0953],
        [-0.0025, -0.1177,  0.0882,  ..., -0.0667, -0.1162,  0.0472],
        [-0.0910, -0.0503,  0.1146,  ...,  0.0263, -0.0246,  0.0781],
        ...,
        [-0.1044, -0.0361, -0.1003,  ..., -0.0681, -0.0266, -0.0401],
        [-0.0808,  0.0649, -0.0444,  ...,  0.1238, -0.0577, -0.0604],
        [ 0.1170, -0.1075, -0.0615,  ...,  0.0344,  0.0374, -0.1005]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0723, -0.0600,  0.0494,  ..., -0.0912, -0.1653,  0.1247],
        [-0.1451, -0.1600, -0.0346,  ...,  0.1232,  0.1181, -0.1104],
        [-0.1444,  0.0267, -0.0123,  ..., -0.0040, -0.1135,  0.0976],
        ...,
        [ 0.0933,  0.1179, -0.1546,  ...,  0.1559,  0.0680, -0.1212],
        [ 0.1196, -0.1186,  0.0304,  ...,  0.1441, -0.1709,  0.1617],
        [-0.0956,  0.0375,  0.1203,  ..., -0.1213,  0.1304, -0.0311]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0723, -0.0600,  0.0494,  ..., -0.0912, -0.1653,  0.1247],
        [-0.1451, -0.1600, -0.0346,  ...,  0.1232,  0.1181, -0.1104],
        [-0.1444,  0.0267, -0.0123,  ..., -0.0040, -0.1135,  0.0976],
        ...,
        [ 0.0933,  0.1179, -0.1546,  ...,  0.1559,  0.0680, -0.1212],
        [ 0.1196, -0.1186,  0.0304,  ...,  0.1441, -0.1709,  0.1617],
        [-0.0956,  0.0375,  0.1203,  ..., -0.1213,  0.1304, -0.0311]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.0045,  0.1652,  0.2016,  ..., -0.2204, -0.1189, -0.1073],
        [-0.1763,  0.2005,  0.1255,  ...,  0.2453,  0.0536, -0.0396],
        [ 0.0274, -0.1109,  0.0699,  ...,  0.1687, -0.0841, -0.1071],
        ...,
        [-0.1880,  0.1053, -0.2276,  ..., -0.1365,  0.1665, -0.1722],
        [ 0.1244,  0.1660, -0.2374,  ..., -0.1718, -0.1107,  0.1852],
        [ 0.1978,  0.2125, -0.1131,  ..., -0.2188, -0.2251, -0.1902]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0045,  0.1652,  0.2016,  ..., -0.2204, -0.1189, -0.1073],
        [-0.1763,  0.2005,  0.1255,  ...,  0.2453,  0.0536, -0.0396],
        [ 0.0274, -0.1109,  0.0699,  ...,  0.1687, -0.0841, -0.1071],
        ...,
        [-0.1880,  0.1053, -0.2276,  ..., -0.1365,  0.1665, -0.1722],
        [ 0.1244,  0.1660, -0.2374,  ..., -0.1718, -0.1107,  0.1852],
        [ 0.1978,  0.2125, -0.1131,  ..., -0.2188, -0.2251, -0.1902]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.3269],
        [ 0.2177],
        [-0.1631],
        [ 0.1812],
        [ 0.2003],
        [ 0.1405],
        [-0.1553],
        [ 0.1775],
        [-0.4021],
        [-0.0123],
        [ 0.1785],
        [-0.4053],
        [ 0.4012],
        [ 0.0867],
        [ 0.2976],
        [ 0.2727],
        [ 0.0254],
        [-0.3879],
        [ 0.0859],
        [-0.3253],
        [ 0.0553],
        [ 0.2675],
        [-0.1120],
        [-0.1316],
        [-0.2573],
        [ 0.3090],
        [-0.1960],
        [ 0.2341],
        [ 0.4247],
        [ 0.1753],
        [ 0.2554],
        [-0.1313]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.3269],
        [ 0.2177],
        [-0.1631],
        [ 0.1812],
        [ 0.2003],
        [ 0.1405],
        [-0.1553],
        [ 0.1775],
        [-0.4021],
        [-0.0123],
        [ 0.1785],
        [-0.4053],
        [ 0.4012],
        [ 0.0867],
        [ 0.2976],
        [ 0.2727],
        [ 0.0254],
        [-0.3879],
        [ 0.0859],
        [-0.3253],
        [ 0.0553],
        [ 0.2675],
        [-0.1120],
        [-0.1316],
        [-0.2573],
        [ 0.3090],
        [-0.1960],
        [ 0.2341],
        [ 0.4247],
        [ 0.1753],
        [ 0.2554],
        [-0.1313]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-164.8922, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-0.0594, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-0.0607, device='cuda:0')



h[100].sum tensor(5.9603, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(6.0937, device='cuda:0')



h[200].sum tensor(7.9531, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(8.1311, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(8778.7891, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0123,  ..., 0.0077, 0.0067, 0.0127],
        [0.0000, 0.0000, 0.0058,  ..., 0.0036, 0.0031, 0.0059],
        [0.0000, 0.0000, 0.0016,  ..., 0.0010, 0.0009, 0.0017],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(53547.0273, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-0.6406, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-61.8288, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(1015.0361, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(64.5291, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0170],
        [0.0120],
        [0.0081],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(786.6989, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[0.0170],
        [0.0120],
        [0.0081],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=1463720,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([1463720, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(1463720., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[ 0.0101, -0.0028,  0.0067,  ...,  0.0053, -0.0129, -0.0144],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(-841.2769, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(66.6238, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(68.2963, device='cuda:0')



h[100].sum tensor(-42.4742, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-43.5404, device='cuda:0')



h[200].sum tensor(97.7397, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(100.1934, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0383, 0.0000, 0.0254,  ..., 0.0199, 0.0000, 0.0000],
        [0.0315, 0.0000, 0.0209,  ..., 0.0163, 0.0000, 0.0000],
        [0.0074, 0.0000, 0.0049,  ..., 0.0038, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(96403.6719, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.3233, 0.5125,  ..., 0.2095, 0.0000, 0.0000],
        [0.0000, 0.2770, 0.4392,  ..., 0.1795, 0.0000, 0.0000],
        [0.0000, 0.2224, 0.3526,  ..., 0.1441, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(625375.5000, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-370.8076, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(3871.6555, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(271.2548, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(12241.4648, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(857.6201, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=1463720,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-1.6211e+00],
        [-1.7540e+00],
        [-1.9354e+00],
        ...,
        [-2.1109e-05],
        [-3.5102e-05],
        [-5.0182e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(-112527.7422, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([1463720, 1]) 
g.edata[efet].sum tensor(1463720., device='cuda:0', grad_fn=<SumBackward0>)
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/./ModelBha.py", line 178, in <module>
    print(f'\nPassing two random events from the network before training', '\nresult1:', result1, '\nresult1.shape:', result1.shape, '\ninput:', traingnn80[EvBTr])
NameError: name 'traingnn80' is not defined

real	0m23.338s
user	0m15.906s
sys	0m5.029s
