0: gpu015.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-04c7ac12-a3b2-f729-c615-51d0a1bf26db)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        1A:4C:BC:79:AC:F4:80:9B:25:8E:21:10:C0:C4:44:9C:1F:5B:BD:6E
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sun Oct  9 00:52:25 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:B6:00.0 Off |                    0 |
| N/A   37C    P0    44W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2aace403d940> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m44.755s
user	0m3.588s
sys	0m2.310s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[-0.3474],
        [-0.8713],
        [-0.2022],
        ...,
        [-0.0916],
        [-2.2041],
        [-1.5708]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-30.1931, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.0874,  0.0104,  0.1315,  0.0180, -0.0104, -0.1127, -0.1367, -0.1361,
          0.0257,  0.0468, -0.0538, -0.1081, -0.1027,  0.0508, -0.1300, -0.0481,
          0.0833,  0.0809,  0.1474, -0.0486,  0.0380,  0.0427, -0.0356, -0.1162,
         -0.1058, -0.0332, -0.0502,  0.0131, -0.0920, -0.0023,  0.0151,  0.1430,
          0.0271,  0.1396, -0.1033, -0.1152, -0.1240, -0.0323,  0.0964,  0.0882,
          0.1106,  0.0608, -0.1166, -0.0068, -0.0261, -0.1410, -0.0317, -0.0775,
         -0.0277, -0.0970,  0.0318,  0.0010, -0.0631,  0.0672,  0.0739,  0.0317,
          0.0745, -0.0085,  0.0316, -0.0069,  0.1104, -0.0054,  0.0400,  0.0991,
         -0.1133,  0.0418, -0.0230,  0.0091, -0.0396, -0.0482, -0.0789, -0.1300,
          0.0266, -0.0235,  0.0136, -0.0145,  0.1083,  0.0122, -0.0769,  0.1447,
          0.1320,  0.0708, -0.0320, -0.1134, -0.0681,  0.0320,  0.0760,  0.0477,
         -0.1045,  0.0840,  0.1050, -0.0691, -0.0132,  0.1391, -0.1193,  0.1401,
          0.0747, -0.0904,  0.1383,  0.0893, -0.0580,  0.0750,  0.1052, -0.1130,
          0.0402,  0.1249, -0.1010,  0.1032, -0.0770,  0.0709, -0.0720, -0.1413,
         -0.0052,  0.0360, -0.0660, -0.0744,  0.0857,  0.0898, -0.1451,  0.1024,
          0.1308,  0.1277, -0.1293,  0.0460, -0.0115,  0.0568,  0.0693, -0.1159,
          0.1224,  0.1509, -0.0525, -0.0620, -0.0024,  0.1096,  0.0062, -0.0847,
         -0.0968, -0.0556, -0.1090, -0.0413,  0.0579, -0.0568, -0.1499,  0.1393,
          0.0369, -0.1266, -0.0846,  0.0269,  0.0841,  0.1258,  0.0175, -0.0752,
          0.0498, -0.0343,  0.0689, -0.1090,  0.1241,  0.0801,  0.1453,  0.0814,
         -0.1505,  0.0832,  0.0410, -0.0075,  0.1137,  0.0257,  0.0886, -0.0457,
         -0.0606, -0.0747,  0.1415,  0.0768, -0.0432,  0.0792,  0.0953,  0.1160,
         -0.0427,  0.0543, -0.0754, -0.0917, -0.0705, -0.0245, -0.1077,  0.0948,
         -0.0929,  0.0580,  0.1125, -0.0754,  0.0913, -0.1257,  0.0132, -0.1330,
         -0.0550,  0.0637,  0.0096,  0.0697,  0.0337,  0.0025, -0.0122,  0.0034,
         -0.0126, -0.0536,  0.0431,  0.1100,  0.0655,  0.1340, -0.0172,  0.0531,
          0.0846,  0.0881, -0.0004, -0.0394,  0.0868, -0.1043, -0.0330, -0.1466,
          0.1341, -0.0379, -0.1495,  0.0292,  0.0101, -0.0514,  0.1068,  0.0379,
          0.0910,  0.1176,  0.1362,  0.1232,  0.1424,  0.1127,  0.1150,  0.0742,
          0.0620,  0.0639, -0.1421,  0.0621,  0.1391,  0.0568, -0.1133, -0.1180,
         -0.0683, -0.1168,  0.0462, -0.0867,  0.0635, -0.0342, -0.0967,  0.1249,
          0.0314,  0.1040,  0.1346,  0.0785,  0.1390, -0.1516,  0.1197,  0.0320]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0874,  0.0104,  0.1315,  0.0180, -0.0104, -0.1127, -0.1367, -0.1361,
          0.0257,  0.0468, -0.0538, -0.1081, -0.1027,  0.0508, -0.1300, -0.0481,
          0.0833,  0.0809,  0.1474, -0.0486,  0.0380,  0.0427, -0.0356, -0.1162,
         -0.1058, -0.0332, -0.0502,  0.0131, -0.0920, -0.0023,  0.0151,  0.1430,
          0.0271,  0.1396, -0.1033, -0.1152, -0.1240, -0.0323,  0.0964,  0.0882,
          0.1106,  0.0608, -0.1166, -0.0068, -0.0261, -0.1410, -0.0317, -0.0775,
         -0.0277, -0.0970,  0.0318,  0.0010, -0.0631,  0.0672,  0.0739,  0.0317,
          0.0745, -0.0085,  0.0316, -0.0069,  0.1104, -0.0054,  0.0400,  0.0991,
         -0.1133,  0.0418, -0.0230,  0.0091, -0.0396, -0.0482, -0.0789, -0.1300,
          0.0266, -0.0235,  0.0136, -0.0145,  0.1083,  0.0122, -0.0769,  0.1447,
          0.1320,  0.0708, -0.0320, -0.1134, -0.0681,  0.0320,  0.0760,  0.0477,
         -0.1045,  0.0840,  0.1050, -0.0691, -0.0132,  0.1391, -0.1193,  0.1401,
          0.0747, -0.0904,  0.1383,  0.0893, -0.0580,  0.0750,  0.1052, -0.1130,
          0.0402,  0.1249, -0.1010,  0.1032, -0.0770,  0.0709, -0.0720, -0.1413,
         -0.0052,  0.0360, -0.0660, -0.0744,  0.0857,  0.0898, -0.1451,  0.1024,
          0.1308,  0.1277, -0.1293,  0.0460, -0.0115,  0.0568,  0.0693, -0.1159,
          0.1224,  0.1509, -0.0525, -0.0620, -0.0024,  0.1096,  0.0062, -0.0847,
         -0.0968, -0.0556, -0.1090, -0.0413,  0.0579, -0.0568, -0.1499,  0.1393,
          0.0369, -0.1266, -0.0846,  0.0269,  0.0841,  0.1258,  0.0175, -0.0752,
          0.0498, -0.0343,  0.0689, -0.1090,  0.1241,  0.0801,  0.1453,  0.0814,
         -0.1505,  0.0832,  0.0410, -0.0075,  0.1137,  0.0257,  0.0886, -0.0457,
         -0.0606, -0.0747,  0.1415,  0.0768, -0.0432,  0.0792,  0.0953,  0.1160,
         -0.0427,  0.0543, -0.0754, -0.0917, -0.0705, -0.0245, -0.1077,  0.0948,
         -0.0929,  0.0580,  0.1125, -0.0754,  0.0913, -0.1257,  0.0132, -0.1330,
         -0.0550,  0.0637,  0.0096,  0.0697,  0.0337,  0.0025, -0.0122,  0.0034,
         -0.0126, -0.0536,  0.0431,  0.1100,  0.0655,  0.1340, -0.0172,  0.0531,
          0.0846,  0.0881, -0.0004, -0.0394,  0.0868, -0.1043, -0.0330, -0.1466,
          0.1341, -0.0379, -0.1495,  0.0292,  0.0101, -0.0514,  0.1068,  0.0379,
          0.0910,  0.1176,  0.1362,  0.1232,  0.1424,  0.1127,  0.1150,  0.0742,
          0.0620,  0.0639, -0.1421,  0.0621,  0.1391,  0.0568, -0.1133, -0.1180,
         -0.0683, -0.1168,  0.0462, -0.0867,  0.0635, -0.0342, -0.0967,  0.1249,
          0.0314,  0.1040,  0.1346,  0.0785,  0.1390, -0.1516,  0.1197,  0.0320]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0421, -0.0709, -0.0466,  ..., -0.0545,  0.1106, -0.0586],
        [ 0.1112,  0.0999,  0.0461,  ...,  0.0320,  0.0870,  0.0303],
        [ 0.0962, -0.0752, -0.0761,  ..., -0.0777, -0.0322,  0.0819],
        ...,
        [ 0.0299,  0.0944, -0.0283,  ..., -0.0681,  0.1000,  0.1110],
        [-0.0476, -0.0807,  0.1162,  ..., -0.0462, -0.0307, -0.0751],
        [ 0.0392,  0.0251, -0.0318,  ..., -0.0017,  0.0893,  0.0498]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0421, -0.0709, -0.0466,  ..., -0.0545,  0.1106, -0.0586],
        [ 0.1112,  0.0999,  0.0461,  ...,  0.0320,  0.0870,  0.0303],
        [ 0.0962, -0.0752, -0.0761,  ..., -0.0777, -0.0322,  0.0819],
        ...,
        [ 0.0299,  0.0944, -0.0283,  ..., -0.0681,  0.1000,  0.1110],
        [-0.0476, -0.0807,  0.1162,  ..., -0.0462, -0.0307, -0.0751],
        [ 0.0392,  0.0251, -0.0318,  ..., -0.0017,  0.0893,  0.0498]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0437, -0.1142,  0.0759,  ...,  0.1378,  0.0048,  0.1310],
        [ 0.0519,  0.0650, -0.1514,  ..., -0.1157,  0.0939, -0.0021],
        [-0.0873, -0.0140,  0.0184,  ...,  0.0496, -0.0051, -0.0967],
        ...,
        [ 0.1510, -0.0282, -0.1333,  ...,  0.0704,  0.0082, -0.0544],
        [ 0.1337,  0.0761,  0.1317,  ...,  0.0870, -0.0034, -0.1217],
        [-0.0906,  0.0027, -0.1368,  ..., -0.0424,  0.0953, -0.0121]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0437, -0.1142,  0.0759,  ...,  0.1378,  0.0048,  0.1310],
        [ 0.0519,  0.0650, -0.1514,  ..., -0.1157,  0.0939, -0.0021],
        [-0.0873, -0.0140,  0.0184,  ...,  0.0496, -0.0051, -0.0967],
        ...,
        [ 0.1510, -0.0282, -0.1333,  ...,  0.0704,  0.0082, -0.0544],
        [ 0.1337,  0.0761,  0.1317,  ...,  0.0870, -0.0034, -0.1217],
        [-0.0906,  0.0027, -0.1368,  ..., -0.0424,  0.0953, -0.0121]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.1225, -0.1265, -0.0541,  ...,  0.2429,  0.0986,  0.1151],
        [ 0.2338,  0.0937,  0.0553,  ..., -0.1274,  0.1998,  0.0694],
        [-0.1092, -0.2364,  0.1919,  ..., -0.1459, -0.1039,  0.1195],
        ...,
        [-0.0023, -0.1721,  0.0884,  ..., -0.0446,  0.0245,  0.1707],
        [ 0.2309,  0.1421,  0.0393,  ...,  0.0352, -0.2350,  0.0174],
        [ 0.1543, -0.1112,  0.1387,  ..., -0.1450, -0.1143, -0.1139]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1225, -0.1265, -0.0541,  ...,  0.2429,  0.0986,  0.1151],
        [ 0.2338,  0.0937,  0.0553,  ..., -0.1274,  0.1998,  0.0694],
        [-0.1092, -0.2364,  0.1919,  ..., -0.1459, -0.1039,  0.1195],
        ...,
        [-0.0023, -0.1721,  0.0884,  ..., -0.0446,  0.0245,  0.1707],
        [ 0.2309,  0.1421,  0.0393,  ...,  0.0352, -0.2350,  0.0174],
        [ 0.1543, -0.1112,  0.1387,  ..., -0.1450, -0.1143, -0.1139]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.1777],
        [-0.0056],
        [-0.0637],
        [ 0.1267],
        [-0.1940],
        [-0.3623],
        [-0.2001],
        [-0.3631],
        [-0.1229],
        [ 0.2921],
        [ 0.1131],
        [-0.0173],
        [-0.2703],
        [-0.0518],
        [ 0.2303],
        [-0.0847],
        [-0.0009],
        [ 0.1349],
        [ 0.3471],
        [ 0.1560],
        [ 0.1399],
        [-0.0515],
        [-0.1645],
        [-0.2375],
        [ 0.0192],
        [ 0.3962],
        [ 0.3026],
        [ 0.2458],
        [ 0.4027],
        [ 0.0565],
        [ 0.1167],
        [-0.2356]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1777],
        [-0.0056],
        [-0.0637],
        [ 0.1267],
        [-0.1940],
        [-0.3623],
        [-0.2001],
        [-0.3631],
        [-0.1229],
        [ 0.2921],
        [ 0.1131],
        [-0.0173],
        [-0.2703],
        [-0.0518],
        [ 0.2303],
        [-0.0847],
        [-0.0009],
        [ 0.1349],
        [ 0.3471],
        [ 0.1560],
        [ 0.1399],
        [-0.0515],
        [-0.1645],
        [-0.2375],
        [ 0.0192],
        [ 0.3962],
        [ 0.3026],
        [ 0.2458],
        [ 0.4027],
        [ 0.0565],
        [ 0.1167],
        [-0.2356]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-156.9935, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-9.7656, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-10.4478, device='cuda:0')



h[100].sum tensor(-8.9990, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-9.6276, device='cuda:0')



h[200].sum tensor(-1.7143, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-1.8340, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(332451.5312, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000e+00, 0.0000e+00, 4.0055e-01,  ..., 0.0000e+00, 3.5212e-03,
         1.9557e+00],
        [0.0000e+00, 0.0000e+00, 2.0936e-01,  ..., 0.0000e+00, 1.8404e-03,
         1.0222e+00],
        [0.0000e+00, 0.0000e+00, 9.1295e-02,  ..., 0.0000e+00, 8.0258e-04,
         4.4576e-01],
        ...,
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00]], device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(1.0518e+08, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-38.2523, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(2513940., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(3651.9822, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-2336.5225, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-1907.6083],
        [-1381.9208],
        [ -971.8962],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-5.8353e+08, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet].sum tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[-1907.6083],
        [-1381.9208],
        [ -971.8962],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(47011080., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0073,  0.0197, -0.0029,  ..., -0.0113,  0.0022, -0.0132],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(1970.1489, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-51.2242, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-55.0178, device='cuda:0')



h[100].sum tensor(100.4294, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(107.8671, device='cuda:0')



h[200].sum tensor(134.0946, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(144.0257, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.8123, 0.0000,  ..., 0.0000, 0.0907, 0.0000],
        [0.0000, 0.6456, 0.0000,  ..., 0.0000, 0.0721, 0.0000],
        [0.0000, 0.1607, 0.0000,  ..., 0.0000, 0.0179, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(3466277., device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[ 0.0000, 27.5591, 29.4552,  ...,  0.0000, 19.8965,  0.0000],
        [ 0.0000, 24.4707, 26.1543,  ...,  0.0000, 17.6668,  0.0000],
        [ 0.0000, 21.4003, 22.8727,  ...,  0.0000, 15.4502,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(7.9313e+08, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-16979.5391, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(18063716., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(27572.9492, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-32623.2715, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[1.5317e+03],
        [1.6923e+03],
        [1.9628e+03],
        ...,
        [2.1992e-02],
        [3.6108e-02],
        [5.0143e-02]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(8.6739e+08, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet].sum tensor(47011080., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-1907.6083],
        [-1381.9208],
        [ -971.8962],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndnei.py", line 52, in <module>
    checkpoint_load(torch.load(F"{checkpoint_dir_path}/checkpoint_dir/{TraEvN}{6}{startmesh}saved_checkpoint.tar"))
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/checkpoint_dir/90016284saved_checkpoint.tar'

real	1m17.614s
user	0m23.482s
sys	0m9.844s
