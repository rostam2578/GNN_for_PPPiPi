0: gpu017.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-c8eed28e-aee2-6a6a-9751-8500b0767218)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        C4:64:50:D8:87:C7:BF:7B:09:37:45:B2:46:27:43:DB:88:3D:E5:26
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Sep 26 11:21:56 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1C:00.0 Off |                    0 |
| N/A   35C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b55b24478e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m4.082s
user	0m2.491s
sys	0m0.758s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 79982

node features (random input): tensor([[ 0.3291],
        [-0.3980],
        [ 0.7359],
        ...,
        [-1.5894],
        [-0.4445],
        [ 1.2723]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-146.6220, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
edges features sum: tensor(79982., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 15

In degrees of node 234: 15





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.0290, -0.0504,  0.1086, -0.0778, -0.1432,  0.0257, -0.0949,  0.0089,
          0.0105, -0.1415,  0.0236, -0.1150,  0.1094,  0.0129, -0.1446,  0.0593,
         -0.1118, -0.0686, -0.0158, -0.0101,  0.1172, -0.0386, -0.0938,  0.0976,
          0.0456, -0.0662, -0.1488,  0.0551, -0.1237, -0.1410,  0.0820, -0.0758,
          0.0255, -0.0337, -0.0215,  0.0870, -0.0556,  0.0748, -0.0121,  0.0179,
         -0.0529, -0.0168,  0.1058, -0.0980, -0.1320,  0.1329, -0.0456, -0.0541,
          0.1205, -0.1296, -0.0196, -0.0936, -0.1382, -0.1268, -0.1471,  0.0844,
          0.1409,  0.0618,  0.0029,  0.1485, -0.0330, -0.0467, -0.0235, -0.0987,
         -0.0759, -0.0211, -0.0274,  0.0696,  0.0375,  0.0654, -0.0871, -0.1483,
          0.0237,  0.0224, -0.0230,  0.1291, -0.0241,  0.0149,  0.1392,  0.0834,
         -0.0464,  0.0498, -0.0218, -0.0780, -0.0047,  0.0493,  0.0519,  0.1526,
          0.0402,  0.0168,  0.0374,  0.0230, -0.1005,  0.1204, -0.0892,  0.0704,
          0.0635,  0.0643,  0.0330,  0.0332,  0.0930,  0.1079, -0.1422, -0.0935,
         -0.1475,  0.0546, -0.1064,  0.1451, -0.0784, -0.1020,  0.0434,  0.1449,
         -0.1013,  0.0144, -0.0174, -0.1069, -0.0709, -0.0188,  0.0522,  0.1015,
         -0.0786,  0.1203, -0.1339, -0.0160, -0.0745, -0.0491, -0.0460,  0.0947,
         -0.1246, -0.0751, -0.0048,  0.0389, -0.0957,  0.0893,  0.0893, -0.1347,
         -0.0064,  0.0669, -0.0254, -0.0472,  0.0522, -0.0801,  0.1185,  0.0371,
          0.0434,  0.0139,  0.0193, -0.0725,  0.1492, -0.0651,  0.0429,  0.0523,
         -0.1125, -0.0705, -0.0154,  0.0955, -0.0153,  0.0694,  0.0409,  0.0382,
          0.0775,  0.0589,  0.0694,  0.0712,  0.0092,  0.0846, -0.0191,  0.0941,
          0.1439,  0.1333, -0.0563, -0.0671,  0.0241, -0.1146,  0.0031, -0.1153,
          0.0546,  0.0837, -0.1324, -0.0469, -0.1107, -0.1196,  0.0950, -0.0700,
         -0.0999, -0.0220,  0.0377,  0.0593, -0.0993, -0.1223,  0.0507,  0.0996,
          0.0685, -0.1417,  0.1031,  0.0350, -0.0931,  0.0735,  0.1340,  0.1125,
         -0.0458,  0.0203,  0.0204, -0.1249,  0.1040,  0.0151, -0.1176, -0.1504,
         -0.1360,  0.0435,  0.0508, -0.0975, -0.0614,  0.0888, -0.0276, -0.1003,
         -0.0362, -0.1128,  0.0437,  0.0475,  0.0138,  0.1359, -0.1293,  0.0074,
          0.1418,  0.1343,  0.0019, -0.1463, -0.0228, -0.1291, -0.0020,  0.0617,
          0.0587, -0.1319,  0.0444, -0.1333, -0.1273,  0.0433,  0.0871,  0.0554,
          0.1240,  0.0525,  0.0745, -0.1301, -0.0492,  0.0455,  0.0174, -0.0158,
         -0.0545, -0.0556,  0.1128,  0.1136,  0.1156, -0.1137, -0.0784, -0.0139]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0290, -0.0504,  0.1086, -0.0778, -0.1432,  0.0257, -0.0949,  0.0089,
          0.0105, -0.1415,  0.0236, -0.1150,  0.1094,  0.0129, -0.1446,  0.0593,
         -0.1118, -0.0686, -0.0158, -0.0101,  0.1172, -0.0386, -0.0938,  0.0976,
          0.0456, -0.0662, -0.1488,  0.0551, -0.1237, -0.1410,  0.0820, -0.0758,
          0.0255, -0.0337, -0.0215,  0.0870, -0.0556,  0.0748, -0.0121,  0.0179,
         -0.0529, -0.0168,  0.1058, -0.0980, -0.1320,  0.1329, -0.0456, -0.0541,
          0.1205, -0.1296, -0.0196, -0.0936, -0.1382, -0.1268, -0.1471,  0.0844,
          0.1409,  0.0618,  0.0029,  0.1485, -0.0330, -0.0467, -0.0235, -0.0987,
         -0.0759, -0.0211, -0.0274,  0.0696,  0.0375,  0.0654, -0.0871, -0.1483,
          0.0237,  0.0224, -0.0230,  0.1291, -0.0241,  0.0149,  0.1392,  0.0834,
         -0.0464,  0.0498, -0.0218, -0.0780, -0.0047,  0.0493,  0.0519,  0.1526,
          0.0402,  0.0168,  0.0374,  0.0230, -0.1005,  0.1204, -0.0892,  0.0704,
          0.0635,  0.0643,  0.0330,  0.0332,  0.0930,  0.1079, -0.1422, -0.0935,
         -0.1475,  0.0546, -0.1064,  0.1451, -0.0784, -0.1020,  0.0434,  0.1449,
         -0.1013,  0.0144, -0.0174, -0.1069, -0.0709, -0.0188,  0.0522,  0.1015,
         -0.0786,  0.1203, -0.1339, -0.0160, -0.0745, -0.0491, -0.0460,  0.0947,
         -0.1246, -0.0751, -0.0048,  0.0389, -0.0957,  0.0893,  0.0893, -0.1347,
         -0.0064,  0.0669, -0.0254, -0.0472,  0.0522, -0.0801,  0.1185,  0.0371,
          0.0434,  0.0139,  0.0193, -0.0725,  0.1492, -0.0651,  0.0429,  0.0523,
         -0.1125, -0.0705, -0.0154,  0.0955, -0.0153,  0.0694,  0.0409,  0.0382,
          0.0775,  0.0589,  0.0694,  0.0712,  0.0092,  0.0846, -0.0191,  0.0941,
          0.1439,  0.1333, -0.0563, -0.0671,  0.0241, -0.1146,  0.0031, -0.1153,
          0.0546,  0.0837, -0.1324, -0.0469, -0.1107, -0.1196,  0.0950, -0.0700,
         -0.0999, -0.0220,  0.0377,  0.0593, -0.0993, -0.1223,  0.0507,  0.0996,
          0.0685, -0.1417,  0.1031,  0.0350, -0.0931,  0.0735,  0.1340,  0.1125,
         -0.0458,  0.0203,  0.0204, -0.1249,  0.1040,  0.0151, -0.1176, -0.1504,
         -0.1360,  0.0435,  0.0508, -0.0975, -0.0614,  0.0888, -0.0276, -0.1003,
         -0.0362, -0.1128,  0.0437,  0.0475,  0.0138,  0.1359, -0.1293,  0.0074,
          0.1418,  0.1343,  0.0019, -0.1463, -0.0228, -0.1291, -0.0020,  0.0617,
          0.0587, -0.1319,  0.0444, -0.1333, -0.1273,  0.0433,  0.0871,  0.0554,
          0.1240,  0.0525,  0.0745, -0.1301, -0.0492,  0.0455,  0.0174, -0.0158,
         -0.0545, -0.0556,  0.1128,  0.1136,  0.1156, -0.1137, -0.0784, -0.0139]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.1155,  0.0973, -0.0960,  ...,  0.0219,  0.0618, -0.0087],
        [-0.1084,  0.1229,  0.0882,  ..., -0.1074, -0.0351,  0.0113],
        [ 0.1207,  0.0980,  0.0743,  ..., -0.1013, -0.1027, -0.0502],
        ...,
        [ 0.0683, -0.0272, -0.0890,  ...,  0.1034, -0.0983, -0.0304],
        [ 0.1239, -0.0372, -0.0554,  ...,  0.0595,  0.1083, -0.1228],
        [ 0.0867, -0.0829, -0.1183,  ...,  0.0302, -0.1224, -0.0427]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1155,  0.0973, -0.0960,  ...,  0.0219,  0.0618, -0.0087],
        [-0.1084,  0.1229,  0.0882,  ..., -0.1074, -0.0351,  0.0113],
        [ 0.1207,  0.0980,  0.0743,  ..., -0.1013, -0.1027, -0.0502],
        ...,
        [ 0.0683, -0.0272, -0.0890,  ...,  0.1034, -0.0983, -0.0304],
        [ 0.1239, -0.0372, -0.0554,  ...,  0.0595,  0.1083, -0.1228],
        [ 0.0867, -0.0829, -0.1183,  ...,  0.0302, -0.1224, -0.0427]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0481, -0.1359, -0.0714,  ...,  0.1169, -0.0989, -0.0060],
        [-0.0522, -0.0944,  0.0013,  ...,  0.0282,  0.1368, -0.1538],
        [ 0.1681,  0.0666,  0.0475,  ..., -0.1699,  0.0557,  0.0572],
        ...,
        [ 0.0906,  0.1655,  0.1140,  ..., -0.1321,  0.1387, -0.1204],
        [-0.1166, -0.0142,  0.0610,  ...,  0.1722, -0.0951, -0.1450],
        [ 0.0263, -0.0460, -0.0431,  ..., -0.0355, -0.0549, -0.1410]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0481, -0.1359, -0.0714,  ...,  0.1169, -0.0989, -0.0060],
        [-0.0522, -0.0944,  0.0013,  ...,  0.0282,  0.1368, -0.1538],
        [ 0.1681,  0.0666,  0.0475,  ..., -0.1699,  0.0557,  0.0572],
        ...,
        [ 0.0906,  0.1655,  0.1140,  ..., -0.1321,  0.1387, -0.1204],
        [-0.1166, -0.0142,  0.0610,  ...,  0.1722, -0.0951, -0.1450],
        [ 0.0263, -0.0460, -0.0431,  ..., -0.0355, -0.0549, -0.1410]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.1195,  0.1424, -0.1897,  ..., -0.0454, -0.1399, -0.0227],
        [ 0.1573,  0.2306, -0.0060,  ...,  0.0775, -0.1399, -0.2260],
        [-0.1602,  0.0186, -0.2067,  ..., -0.1218,  0.2298, -0.1745],
        ...,
        [ 0.0709,  0.2213,  0.1649,  ...,  0.0716, -0.1716,  0.1399],
        [-0.0147,  0.2334,  0.2108,  ...,  0.0477,  0.0638,  0.0765],
        [ 0.0678,  0.2043,  0.0916,  ...,  0.1652,  0.0378,  0.1755]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1195,  0.1424, -0.1897,  ..., -0.0454, -0.1399, -0.0227],
        [ 0.1573,  0.2306, -0.0060,  ...,  0.0775, -0.1399, -0.2260],
        [-0.1602,  0.0186, -0.2067,  ..., -0.1218,  0.2298, -0.1745],
        ...,
        [ 0.0709,  0.2213,  0.1649,  ...,  0.0716, -0.1716,  0.1399],
        [-0.0147,  0.2334,  0.2108,  ...,  0.0477,  0.0638,  0.0765],
        [ 0.0678,  0.2043,  0.0916,  ...,  0.1652,  0.0378,  0.1755]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[ 0.0299],
        [-0.3986],
        [-0.3724],
        [-0.3109],
        [-0.0342],
        [-0.2482],
        [ 0.2752],
        [ 0.2319],
        [ 0.1695],
        [-0.3031],
        [-0.2874],
        [-0.0601],
        [-0.2981],
        [ 0.1240],
        [ 0.3096],
        [-0.2720],
        [ 0.0284],
        [ 0.1514],
        [ 0.0395],
        [ 0.0059],
        [-0.2641],
        [ 0.2608],
        [ 0.0445],
        [-0.1852],
        [-0.1035],
        [-0.3073],
        [-0.0343],
        [ 0.3248],
        [ 0.1847],
        [ 0.1399],
        [ 0.2107],
        [ 0.2007]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0299],
        [-0.3986],
        [-0.3724],
        [-0.3109],
        [-0.0342],
        [-0.2482],
        [ 0.2752],
        [ 0.2319],
        [ 0.1695],
        [-0.3031],
        [-0.2874],
        [-0.0601],
        [-0.2981],
        [ 0.1240],
        [ 0.3096],
        [-0.2720],
        [ 0.0284],
        [ 0.1514],
        [ 0.0395],
        [ 0.0059],
        [-0.2641],
        [ 0.2608],
        [ 0.0445],
        [-0.1852],
        [-0.1035],
        [-0.3073],
        [-0.0343],
        [ 0.3248],
        [ 0.1847],
        [ 0.1399],
        [ 0.2107],
        [ 0.2007]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=79982,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([79982, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(79982., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-170.0429, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(6.2075, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(6.3171, device='cuda:0')



h[100].sum tensor(-7.8627, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-8.0015, device='cuda:0')



h[200].sum tensor(-6.3964, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-6.5093, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(9664.0225, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0043, 0.0000,  ..., 0.0177, 0.0106, 0.0030],
        [0.0000, 0.0011, 0.0000,  ..., 0.0045, 0.0027, 0.0008],
        [0.0000, 0.0003, 0.0000,  ..., 0.0014, 0.0008, 0.0002],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(59695.4141, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-45.4042, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-52.5121, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(416.9842, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(25.2936, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=79982,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.4006],
        [-0.2647],
        [-0.1698],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-19020.4648, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([79982, 1]) 
g.edata[efet].sum tensor(79982., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[-0.4006],
        [-0.2647],
        [-0.1698],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=1599640,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([1599640, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(1599640., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0127, -0.0128, -0.0143,  ..., -0.0156, -0.0137,  0.0130],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(-1733.5107, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-104.6823, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-106.5910, device='cuda:0')



h[100].sum tensor(146.4543, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(149.1247, device='cuda:0')



h[200].sum tensor(-145.6978, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-148.3543, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0778],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0426],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0102],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(101459.4531, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1564, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.1177, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0834, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(463812.1250, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-185.9337, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(17061.3906, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(1141.8223, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-931.0460, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=1599640,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[1.5633e+00],
        [1.6312e+00],
        [1.7521e+00],
        ...,
        [8.1338e-06],
        [1.3517e-05],
        [1.9305e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(96449.7734, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([1599640, 1]) 
g.edata[efet].sum tensor(1599640., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-0.4006],
        [-0.2647],
        [-0.1698],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/checkpoint_dir/90016284saved_checkpoint.tar



load_model True 
TraEvN 9001 
BatchSize 30 
EpochNum 80 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 
startmesh 284 
endmesh 285 






optimizer.param_groups
 [{'params': [Parameter containing:
tensor([[ 1.0076e-40, -4.7452e-13,  8.5099e-02,  9.7981e-02,  1.8748e-01,
          1.7174e-01, -3.7681e-12, -6.4529e-12,  1.1833e-01,  1.5747e-01,
          1.9213e-01,  1.1904e-01,  1.2590e-01, -3.3106e-13,  4.4109e-02,
         -1.7796e-17, -2.7480e-03,  1.1192e-01,  8.6889e-02,  1.3959e-01,
         -4.0209e-11, -1.7586e-33,  6.2472e-02,  1.3035e-01, -7.4809e-34,
         -7.2355e-04, -6.9009e-19,  6.3752e-02, -2.3849e-03,  1.0285e-01,
         -5.6311e-13,  7.3909e-02, -8.3398e-21, -5.3455e-23,  1.8028e-01,
          2.0822e-01, -1.2992e-10,  2.2170e-19,  1.0582e-01,  1.7794e-01,
          1.4241e-01,  1.5546e-01,  2.7655e-03,  1.6161e-01, -4.2103e-03,
          7.6704e-41,  9.7278e-02, -1.0763e-40,  1.3845e-01, -2.5767e-13,
         -3.2189e-30, -3.8767e-41,  1.1937e-05,  7.4505e-02, -2.8187e-41,
         -1.9561e-03, -2.5500e-05,  1.0375e-01, -1.2188e-09, -5.0265e-13,
          9.3991e-41,  1.7898e-01, -1.0861e-02, -8.3738e-23,  9.5822e-02,
          1.7488e-01,  2.5739e-01,  1.3917e-01,  3.3075e-41,  8.0075e-02,
         -3.0651e-12, -9.3809e-10,  1.0931e-01, -1.2632e-06,  8.2083e-02,
          8.7719e-02, -8.6903e-06,  7.2083e-02, -3.8073e-12, -3.7840e-29,
         -2.1479e-02, -5.4808e-41, -2.4659e-03, -6.5027e-12,  1.0087e-35,
          5.7344e-04, -3.9924e-13, -1.6431e-03,  1.9390e-40,  1.2487e-01,
         -8.8806e-41, -3.7880e-10,  1.4563e-01,  5.1986e-02, -9.1071e-02,
          4.8800e-14, -2.7304e+00,  7.5317e-02,  1.7143e-01, -5.6215e-12,
          2.7830e-03,  1.8333e-01,  1.0798e-01, -3.5132e-41, -7.7982e-42,
         -1.5986e-15, -2.3301e-03, -2.7785e-21, -1.6885e-09,  1.2168e-01,
         -1.2117e-12, -9.3940e-10,  1.0729e-01,  6.2461e-02,  5.7822e-02,
          1.0425e-01, -5.6811e-41,  1.1143e-01, -5.6213e-10, -4.6760e-13,
          2.1131e-16, -2.4723e-03, -3.1646e-03,  2.3806e-01, -2.1715e-03,
         -7.5765e-10,  1.4553e-01, -5.2708e-14,  8.4413e-03,  3.8607e-41,
          8.8876e-02,  1.2897e-01, -3.2161e-12, -4.0855e-03,  2.4055e-09,
          5.1016e-02,  2.1028e-01,  1.9203e-01,  1.6598e-01,  2.0248e-01,
          1.4678e-01,  7.8349e-04,  1.9454e-01, -3.2202e-03, -1.5898e-03,
         -6.4877e-41, -5.0396e-02,  3.2932e-41,  1.3742e-01, -1.3744e-02,
         -1.5774e-03,  1.0404e-01,  1.4925e-01, -2.3755e-15,  1.1806e-03,
         -4.2991e-13,  1.7377e-01,  5.1399e-02, -7.5344e-30, -3.8368e-12,
         -3.3036e-12,  1.7028e-01, -1.0773e-10,  2.2634e-01, -3.8273e-12,
         -5.3807e-13, -2.4105e-17,  1.9463e-01,  7.8645e-02,  2.0077e-01,
         -1.5703e-14,  1.3155e-40,  1.3898e-01,  9.2085e-04,  8.9895e-02,
         -5.5980e-12,  1.4376e-01, -4.9409e-12,  6.5518e-02, -2.6928e-02,
          1.3006e-01,  1.6913e-01,  1.9898e-01,  1.5325e-01,  1.5412e-01,
          1.9705e-01, -1.0609e-10,  1.2143e-01,  1.2357e-01,  9.5935e-02,
          1.6458e-01,  1.9604e-01,  9.4026e-02,  8.6880e-02, -3.3936e-03,
          1.0404e-01, -3.1436e-12, -2.2484e-21,  1.0961e-01, -1.7790e-13,
         -2.1130e-02, -3.5353e-03,  9.1966e-02, -4.0469e-12,  8.0849e-02,
          4.7105e-41, -2.1600e-02,  1.2787e-01, -1.9811e-04,  1.6660e-01,
          8.3242e-02,  6.0632e-02, -3.1735e-12, -6.4173e-12, -7.4182e-41,
         -2.0316e-28, -1.5908e-02,  9.6841e-11, -5.6313e-03, -4.4687e-12,
          1.7767e-01, -1.4026e-20, -3.1723e-12,  3.1621e-03,  1.4207e-40,
          1.1499e-01,  9.2266e-02, -3.4287e-16, -8.1983e-04,  1.5851e-01,
          6.4657e-02, -2.6482e-03,  2.0335e-01, -6.7958e-06, -2.6435e-03,
         -4.3234e-02,  1.1632e-01, -1.7353e-03,  1.7324e-40,  8.2986e-02,
          1.5746e-01, -2.3766e-03, -1.1877e-09, -5.3763e-10,  5.5299e-03,
         -2.6275e-03,  2.3566e-01, -1.0962e-09, -6.4193e-12, -2.4130e-27,
         -1.3185e-08,  1.2546e-01, -4.0478e-12,  8.9223e-02, -5.7288e-03,
         -2.3289e-21]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-4.0970e-27, -4.6670e-04, -6.2237e-05, -1.1598e-03, -2.7719e-03,
         7.6853e-05, -4.8550e-04, -4.7713e-04, -2.1069e-03, -8.5922e-05,
        -3.5546e-02, -9.6324e-04,  5.6761e-05, -4.7675e-04, -2.9204e-03,
        -3.3829e-04, -3.1080e-03, -6.7404e-03, -6.2335e-03,  9.5737e-05,
        -3.1175e-03, -1.4791e-03, -7.0601e-03, -5.7334e-03, -2.9433e-06,
        -3.0594e-03, -3.2186e-04, -6.3575e-03, -3.1855e-03, -1.2895e-04,
        -4.7780e-04, -7.3646e-03, -1.6757e-04, -2.3207e-04, -6.4764e-05,
        -2.9000e-03, -3.4198e-04, -9.2444e-05, -1.1563e-02, -2.4294e-03,
        -2.1517e-03,  4.6985e-03, -2.8580e-03, -2.4926e-03, -2.6077e-03,
        -1.9990e-05, -3.9400e-05, -2.0805e-06, -1.2535e-02, -4.7664e-04,
        -2.1589e-04, -1.5572e-05, -3.5219e-03, -1.8704e-04, -4.8822e-10,
        -3.9412e-03, -3.0762e-03, -1.2169e-03, -8.0378e-05, -4.6975e-04,
        -2.0236e-32,  5.4889e-05,  5.3119e-03, -2.1030e-04, -6.0694e-03,
         4.5732e-05, -4.4752e-03,  6.6859e-05, -4.4238e-27,  1.1315e-04,
        -5.0877e-04, -8.2313e-05, -5.9483e-03, -2.2141e-03, -2.3535e-03,
        -3.5667e-03, -3.1738e-03, -2.0396e-03, -4.8371e-04, -2.1792e-04,
         1.6381e-02, -3.3856e-05, -2.8341e-03, -4.7636e-04, -1.5217e-35,
        -3.0909e-03, -4.7690e-04, -7.5494e-04, -1.9833e-35, -5.5674e-05,
        -5.0159e-07, -3.0645e-03, -2.6573e-03, -5.4994e-03,  1.2745e-02,
        -1.5831e-03,  3.0621e-02, -4.5264e-04,  2.7211e-04, -4.9092e-04,
        -3.1516e-03, -3.3847e-03, -4.8200e-03, -1.0286e-33, -1.4010e-04,
        -5.7633e-04, -2.8477e-03, -2.5995e-04, -1.3537e-04, -8.2447e-05,
        -4.6740e-04, -8.1097e-05, -1.6410e-04,  1.9210e-02,  9.9016e-03,
        -9.0509e-03, -1.9406e-05, -1.4196e-03, -9.7979e-05, -4.7004e-04,
        -6.4701e-15, -3.4989e-03, -3.1763e-03, -6.7712e-03, -2.7294e-03,
        -7.2318e-05,  6.5509e-03, -4.7171e-04,  7.5435e-03, -1.9049e-04,
        -1.4186e-02, -1.8458e-04, -5.0348e-04, -3.7528e-03, -1.9872e-03,
         1.7165e-03,  1.6097e-04, -3.2210e-04, -2.1457e-03, -3.3318e-05,
         9.9298e-05, -5.4099e-03, -1.1175e-04, -3.0269e-03, -3.2087e-03,
        -3.1555e-05,  1.6110e-02, -3.2061e-12, -3.6950e-04,  9.8527e-03,
        -3.9356e-03, -2.6388e-02, -1.1434e-04, -4.7969e-04, -3.1762e-03,
        -4.6852e-04, -1.8794e-02, -6.0725e-03, -1.7742e-04, -4.8207e-04,
        -5.0066e-04,  1.1799e-04, -3.4676e-04,  9.4854e-04, -4.8234e-04,
        -4.7751e-04, -3.8839e-04, -9.3605e-03,  4.8658e-03,  3.0029e-04,
        -4.6055e-04, -5.7309e-12, -1.7947e-03, -3.2558e-03, -5.6730e-03,
        -4.9134e-04,  2.8115e-03, -5.0413e-04, -1.6648e-03,  8.4502e-03,
        -4.2433e-03,  8.7693e-05,  1.9806e-03,  5.1977e-05, -7.8430e-03,
        -5.2866e-03, -3.4751e-04, -7.1738e-03, -1.5401e-03, -1.3761e-03,
        -1.4972e-02, -4.9674e-05, -8.9552e-04, -1.0467e-03, -3.5624e-03,
        -5.6799e-05, -5.0591e-04, -1.8794e-04, -3.1208e-03, -4.7640e-04,
         3.6855e-03, -3.0937e-03, -1.4555e-02, -4.6554e-04,  1.5073e-02,
        -7.6132e-06,  1.0062e-02,  9.9715e-04, -8.5160e-05,  8.9093e-05,
         7.0559e-03, -1.6324e-02, -5.0489e-04, -4.7767e-04, -1.8995e-04,
        -2.9255e-04,  1.4859e-02, -1.7602e-05,  8.0499e-03, -5.1466e-04,
         4.5473e-04, -2.8963e-04, -5.0493e-04, -3.1623e-03, -1.8079e-26,
        -5.9618e-05,  3.2258e-05, -3.7061e-04, -1.3062e-03, -2.9027e-03,
         5.8721e-03, -2.6838e-03,  2.8622e-05, -2.9678e-03, -3.4241e-03,
         8.2101e-03, -1.4102e-04, -3.2503e-03, -2.2129e-10, -3.5589e-03,
         5.4069e-03, -2.9055e-03, -7.7519e-05, -2.0380e-03, -5.4663e-03,
        -4.0726e-03, -2.6797e-03, -7.4450e-05, -4.7764e-04, -2.2492e-04,
        -1.3554e-04, -1.6017e-03, -4.7709e-04, -9.4620e-04, -4.2668e-03,
        -2.0677e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-1.1535e-40,  3.7978e-41, -1.6032e-40,  ...,  1.2296e-40,
         -7.1522e-42, -1.7370e-40],
        [-1.2442e-40, -6.6534e-41, -2.1963e-23,  ..., -1.5558e-40,
          2.8617e-07, -3.0932e-09],
        [-2.2950e-04,  1.0051e-40, -4.6974e-02,  ...,  8.0645e-42,
         -1.0101e-01, -1.4687e-03],
        ...,
        [-1.9803e-04, -6.4310e-41, -8.0334e-02,  ...,  1.0305e-40,
          8.8672e-02,  5.4892e-02],
        [-6.8367e-41,  6.0899e-41, -5.7258e-04,  ...,  1.8142e-40,
          5.3009e-04, -7.0033e-04],
        [ 1.2070e-40, -2.0071e-40, -4.0788e-37,  ...,  2.7823e-41,
         -8.4646e-11, -6.7265e-19]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-3.0593e-03, -4.6836e-07,  5.2427e-02,  1.4727e-02,  2.9469e-02,
         1.9121e-02,  8.1748e-03,  1.4238e-01,  1.9708e-01,  8.9397e-02,
        -2.3764e-03, -1.1579e-03, -3.7575e-03,  1.1831e-01, -3.3481e-04,
        -2.4162e-08,  2.2032e-02,  1.2948e-01, -1.4263e-02, -7.4856e-09,
        -1.5522e-02,  1.1004e-01, -2.9805e-30, -1.4338e-02,  1.2109e-01,
         2.9334e-02,  1.8958e-02,  6.7604e-02, -9.8335e-03,  1.5636e-01,
         1.0623e-01,  6.3771e-02,  7.7482e-03,  6.5942e-02, -4.3590e-04,
        -2.9529e-03,  1.0599e-01, -4.0316e-03, -2.1062e-02, -3.7802e-02,
        -9.4286e-02, -3.0936e-03, -3.8688e-03,  1.1176e-01,  1.2382e-01,
        -4.1302e-02,  1.9920e-01, -4.1849e-06, -3.0638e-03, -3.7121e-03,
         1.0870e-02, -3.7012e-03,  9.3570e-02,  7.2967e-02,  2.1057e-02,
        -3.6404e-02,  1.5247e-02,  1.5220e-02,  7.7266e-02, -2.4349e-11,
         9.8994e-02,  1.5281e-02,  7.7790e-02, -4.5749e-03, -2.9225e-03,
         4.9633e-02,  5.7546e-02, -4.6389e-03,  5.6994e-02,  4.1217e-02,
        -7.2509e-18, -1.3337e-03,  1.9703e-01, -1.9044e-03, -2.2977e-02,
         9.4437e-02,  1.4711e-02,  7.5851e-02, -2.1134e-03,  7.4420e-02,
        -4.4075e-02,  1.7227e-01, -2.9456e-03,  3.4963e-02, -4.3526e-03,
         1.5553e-01, -5.7740e-06,  5.5662e-02, -8.0279e-07, -1.0274e-02,
        -2.2904e-19, -3.3350e-03,  2.4884e-02, -5.4770e-06, -8.5508e-03,
         2.5205e-02, -2.5545e-05,  1.6238e-02,  1.0975e-01,  1.5459e-02,
        -4.1836e-06, -1.5096e-06,  4.0276e-02, -5.7221e-28,  7.3796e-02,
        -4.1599e-06,  2.8426e-02,  1.8025e-02,  2.1303e-02, -2.1740e-03,
         5.4848e-02,  2.9835e-02, -9.4852e-05, -2.5634e-02, -5.9871e-03,
        -3.1261e-03,  9.9833e-02,  1.1814e-01,  1.0885e-01, -1.2015e-02,
         2.0164e-03,  8.6022e-02, -3.2582e-03,  7.4467e-02, -2.5858e-03,
        -6.1815e-07, -2.5535e-03,  8.3091e-03], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[ 6.6477e-04,  1.3075e-03,  2.2982e-03,  ...,  1.1541e-40,
         -1.1725e-03,  6.4443e-04],
        [-1.1076e-14,  5.5210e-09,  3.2529e-10,  ..., -1.1499e-40,
         -5.3909e-32,  1.2864e-28],
        [ 1.5442e-01, -8.7943e-02,  8.2164e-02,  ..., -1.6282e-08,
          6.8936e-02,  2.4873e-02],
        ...,
        [-1.1485e-14,  5.4268e-09,  2.9419e-10,  ..., -8.0736e-41,
         -1.1528e-30,  2.2491e-29],
        [ 1.7418e-02,  9.0034e-02,  1.9307e-02,  ..., -2.4034e-03,
          5.7133e-02,  8.1395e-02],
        [ 3.0718e-02,  1.5153e-01, -1.1221e-01,  ..., -2.5011e-03,
          1.4741e-01, -1.4788e-01]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 5.0386e-02,  8.0924e-02,  1.9932e-02,  4.0687e-02, -1.2189e-01,
         2.0797e-01,  3.6408e-03, -6.5747e-02, -3.5210e-02,  1.2937e-01,
        -2.6029e-03,  7.4614e-02, -3.1932e-02,  9.2721e-02, -3.0023e-03,
        -2.6529e-03,  5.6282e-03,  1.5434e-01,  1.9262e-02, -3.9509e-02,
        -3.9298e-03,  4.2272e-41, -8.9533e-02, -1.8858e-08,  2.3813e-02,
         2.2635e-02, -6.5586e-02, -1.0886e-14, -4.2543e-03, -8.4905e-02,
         9.9519e-02,  4.2990e-02,  1.7715e-02,  5.1336e-01,  2.8310e-02,
         5.9292e-01, -1.2059e-02, -3.3644e-41, -1.0261e-01,  5.8166e-01,
         6.0275e-01,  1.7001e-01,  3.5869e-01,  7.3710e-02, -2.4171e-02,
         7.5741e-02, -6.0251e-02, -7.2692e-02,  5.3216e-01, -2.9029e-02,
        -4.3077e-02,  4.3459e-01,  4.8081e-02, -2.1208e-02, -6.5748e-02,
        -1.2977e-01,  3.6575e-02,  1.1258e-01,  2.0047e-01,  3.2170e-02,
         6.8401e-02, -2.1159e-03, -1.4777e-02,  3.5003e-01], device='cuda:0',
       requires_grad=True), Parameter containing:
tensor([[ 4.5361e-02, -2.5416e-01,  1.7201e-01,  ..., -4.3167e-02,
         -2.3020e-01, -1.5807e-02],
        [ 1.8317e-01,  5.0939e-03, -6.8991e-02,  ..., -2.0485e-01,
          6.8011e-03,  2.3558e-02],
        [-3.0885e-02,  1.8940e-01, -3.8720e-02,  ...,  2.4586e-02,
         -1.6983e-01,  3.4412e-02],
        ...,
        [-8.8702e-41,  3.3552e-39, -1.9257e-29,  ...,  1.8260e-41,
          3.1571e-42,  2.0025e-41],
        [ 1.2266e-02, -1.5358e-01,  2.0889e-01,  ..., -1.1895e-02,
         -1.4659e-01, -6.5047e-02],
        [-8.5310e-01, -3.3321e-01, -7.8892e-01,  ...,  2.7579e-01,
         -5.2910e-01, -6.6384e-01]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-3.5677e-01,  3.6482e-01, -1.8174e-01,  7.2786e-01, -2.3176e-01,
         6.5816e-01,  4.3364e-01,  9.1823e-03, -9.3887e-01,  8.6179e-01,
        -3.3974e-01,  8.1999e-01,  2.3528e-01,  4.3968e-01, -6.7660e-01,
         1.0309e-01,  5.4861e-01,  1.4907e+00,  1.0564e+00, -3.1145e-02,
         6.4272e-01, -1.7427e-01, -6.8055e-01, -3.8571e-01,  6.7339e-01,
         2.4329e-01,  6.5753e-01, -2.6564e-01, -9.2828e-04,  8.3973e-01,
        -2.2654e-01,  4.9546e-01], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 2.6161e-01],
        [-6.0314e-01],
        [-8.8726e-01],
        [ 3.3087e-01],
        [-6.9164e-01],
        [ 3.0222e-01],
        [-2.6353e-01],
        [-7.9615e-01],
        [-4.3549e-01],
        [ 1.3947e-01],
        [-1.1361e+00],
        [ 7.8202e-02],
        [ 3.3502e-01],
        [-3.0313e-01],
        [-4.1468e-01],
        [ 6.4982e-01],
        [-2.4421e+00],
        [-7.3053e+00],
        [-3.5008e+00],
        [-1.2678e+00],
        [ 5.2290e-01],
        [-2.4659e-01],
        [-2.6996e-01],
        [-8.7084e-01],
        [ 4.2985e-01],
        [-3.1791e-01],
        [ 1.1974e-01],
        [-7.7330e-01],
        [ 2.6228e-03],
        [ 3.1968e-01],
        [-8.2516e-01],
        [ 3.6124e+00]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0561], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4/./TrainingBhaself.py", line 65, in <module>
    optimizer.add_param_group({'params': dglgraph.edata['efet'].requires_grad_()})
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/optim/optimizer.py", line 258, in add_param_group
    raise ValueError("can't optimize a non-leaf Tensor")
ValueError: can't optimize a non-leaf Tensor

real	0m44.938s
user	0m23.377s
sys	0m6.742s
