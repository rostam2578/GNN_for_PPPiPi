0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        9B:9E:55:A9:86:D9:50:0B:6D:2D:9F:BA:A7:E6:45:39:D4:DD:5F:C6
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sat Sep 17 08:20:12 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   22C    P0    32W / 250W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.358472704

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2aafde2b68e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m5.240s
user	0m2.690s
sys	0m1.148s
[08:20:20] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[-2.0386],
        [ 0.2122],
        [ 0.5933],
        ...,
        [-1.0811],
        [-0.1948],
        [-1.4630]], device='cuda:0', requires_grad=True) 
node features sum: tensor(21.7379, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.0153, -0.1236, -0.0589, -0.0619,  0.0051, -0.1165, -0.0913, -0.0982,
          0.0530, -0.1516,  0.0425, -0.0587,  0.1114, -0.0429,  0.1265,  0.0772,
         -0.0486, -0.1465,  0.0855, -0.1487,  0.1214,  0.1146, -0.0877, -0.0907,
          0.0369, -0.1419,  0.0435, -0.1304, -0.0046,  0.1067, -0.0825,  0.1441,
         -0.1374,  0.0811, -0.1328, -0.1222, -0.1295,  0.0859, -0.0333, -0.1444,
         -0.1044, -0.1102,  0.1309, -0.0349, -0.0152, -0.1017,  0.1085,  0.0676,
          0.0346, -0.0771,  0.1359, -0.0817, -0.1443,  0.0258, -0.0580,  0.0787,
         -0.0707, -0.1190,  0.0016, -0.0952, -0.0473, -0.0089, -0.0650, -0.0779,
         -0.0504, -0.0549, -0.1345,  0.0356,  0.0281,  0.0072, -0.1396,  0.1282,
         -0.1236,  0.0930, -0.0404, -0.0089, -0.1259,  0.0181, -0.0796,  0.1139,
         -0.0704,  0.0988,  0.0004,  0.1267,  0.1243, -0.1478,  0.0577,  0.0577,
         -0.1279,  0.0409, -0.0744,  0.1223,  0.1104, -0.0751, -0.0269, -0.0202,
          0.1185,  0.0051, -0.0474,  0.0524,  0.1122,  0.0338,  0.0234, -0.0107,
          0.1186,  0.0375, -0.1350,  0.0165,  0.0390,  0.0598,  0.0651, -0.0822,
         -0.0662, -0.0319,  0.1209, -0.1325, -0.0966, -0.0032,  0.1178,  0.1395,
          0.0416,  0.0585,  0.0071,  0.0159, -0.1377,  0.1509,  0.0055, -0.1422,
          0.1211,  0.0305, -0.0257, -0.1513,  0.0934, -0.0202,  0.1140,  0.1151,
          0.0390,  0.0027, -0.1139,  0.0934, -0.0905, -0.1463, -0.0221, -0.1109,
         -0.0343,  0.0138,  0.0341, -0.0267, -0.0504,  0.0231, -0.1328, -0.0789,
         -0.0152, -0.0927,  0.1004,  0.0602, -0.0979,  0.1355,  0.1386,  0.0446,
          0.1452, -0.1042, -0.0193,  0.0681, -0.0922,  0.0385,  0.1425, -0.1514,
         -0.0116,  0.0072,  0.0766, -0.0207,  0.1355, -0.1473, -0.0823,  0.0888,
          0.0455, -0.1201, -0.0431, -0.1332, -0.0311,  0.0885,  0.0636,  0.1123,
          0.0293,  0.1341,  0.1343, -0.0043, -0.0930,  0.1312, -0.0784, -0.0662,
          0.0255,  0.0166,  0.0784,  0.1116,  0.1299, -0.1168, -0.1019, -0.0726,
          0.0822,  0.1087, -0.0904,  0.0843, -0.0626,  0.1061,  0.0643, -0.1251,
          0.0265, -0.0485, -0.0275, -0.0127,  0.0135, -0.0777,  0.1001, -0.1208,
         -0.1488,  0.1271, -0.0159, -0.0908, -0.1195,  0.0697, -0.1245,  0.0786,
         -0.0736,  0.1292,  0.0118,  0.0221, -0.0130, -0.0747, -0.1192, -0.1267,
          0.1262,  0.1112,  0.1059,  0.0363,  0.0690, -0.0159,  0.1284,  0.0269,
         -0.0089, -0.1233, -0.0200, -0.0929,  0.0669,  0.0742,  0.0645, -0.0518,
          0.1516, -0.1366,  0.1519, -0.0493, -0.1061, -0.0385,  0.0632, -0.0606]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0153, -0.1236, -0.0589, -0.0619,  0.0051, -0.1165, -0.0913, -0.0982,
          0.0530, -0.1516,  0.0425, -0.0587,  0.1114, -0.0429,  0.1265,  0.0772,
         -0.0486, -0.1465,  0.0855, -0.1487,  0.1214,  0.1146, -0.0877, -0.0907,
          0.0369, -0.1419,  0.0435, -0.1304, -0.0046,  0.1067, -0.0825,  0.1441,
         -0.1374,  0.0811, -0.1328, -0.1222, -0.1295,  0.0859, -0.0333, -0.1444,
         -0.1044, -0.1102,  0.1309, -0.0349, -0.0152, -0.1017,  0.1085,  0.0676,
          0.0346, -0.0771,  0.1359, -0.0817, -0.1443,  0.0258, -0.0580,  0.0787,
         -0.0707, -0.1190,  0.0016, -0.0952, -0.0473, -0.0089, -0.0650, -0.0779,
         -0.0504, -0.0549, -0.1345,  0.0356,  0.0281,  0.0072, -0.1396,  0.1282,
         -0.1236,  0.0930, -0.0404, -0.0089, -0.1259,  0.0181, -0.0796,  0.1139,
         -0.0704,  0.0988,  0.0004,  0.1267,  0.1243, -0.1478,  0.0577,  0.0577,
         -0.1279,  0.0409, -0.0744,  0.1223,  0.1104, -0.0751, -0.0269, -0.0202,
          0.1185,  0.0051, -0.0474,  0.0524,  0.1122,  0.0338,  0.0234, -0.0107,
          0.1186,  0.0375, -0.1350,  0.0165,  0.0390,  0.0598,  0.0651, -0.0822,
         -0.0662, -0.0319,  0.1209, -0.1325, -0.0966, -0.0032,  0.1178,  0.1395,
          0.0416,  0.0585,  0.0071,  0.0159, -0.1377,  0.1509,  0.0055, -0.1422,
          0.1211,  0.0305, -0.0257, -0.1513,  0.0934, -0.0202,  0.1140,  0.1151,
          0.0390,  0.0027, -0.1139,  0.0934, -0.0905, -0.1463, -0.0221, -0.1109,
         -0.0343,  0.0138,  0.0341, -0.0267, -0.0504,  0.0231, -0.1328, -0.0789,
         -0.0152, -0.0927,  0.1004,  0.0602, -0.0979,  0.1355,  0.1386,  0.0446,
          0.1452, -0.1042, -0.0193,  0.0681, -0.0922,  0.0385,  0.1425, -0.1514,
         -0.0116,  0.0072,  0.0766, -0.0207,  0.1355, -0.1473, -0.0823,  0.0888,
          0.0455, -0.1201, -0.0431, -0.1332, -0.0311,  0.0885,  0.0636,  0.1123,
          0.0293,  0.1341,  0.1343, -0.0043, -0.0930,  0.1312, -0.0784, -0.0662,
          0.0255,  0.0166,  0.0784,  0.1116,  0.1299, -0.1168, -0.1019, -0.0726,
          0.0822,  0.1087, -0.0904,  0.0843, -0.0626,  0.1061,  0.0643, -0.1251,
          0.0265, -0.0485, -0.0275, -0.0127,  0.0135, -0.0777,  0.1001, -0.1208,
         -0.1488,  0.1271, -0.0159, -0.0908, -0.1195,  0.0697, -0.1245,  0.0786,
         -0.0736,  0.1292,  0.0118,  0.0221, -0.0130, -0.0747, -0.1192, -0.1267,
          0.1262,  0.1112,  0.1059,  0.0363,  0.0690, -0.0159,  0.1284,  0.0269,
         -0.0089, -0.1233, -0.0200, -0.0929,  0.0669,  0.0742,  0.0645, -0.0518,
          0.1516, -0.1366,  0.1519, -0.0493, -0.1061, -0.0385,  0.0632, -0.0606]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.1113, -0.0374, -0.0364,  ..., -0.0128, -0.1197, -0.0498],
        [-0.0109,  0.0987, -0.0880,  ..., -0.1078, -0.0679, -0.0943],
        [-0.0980,  0.0928, -0.0547,  ..., -0.0849, -0.0202,  0.0448],
        ...,
        [ 0.0625,  0.0528,  0.0816,  ...,  0.0227, -0.0034,  0.0994],
        [-0.0394,  0.0287, -0.0243,  ..., -0.0972,  0.0691,  0.0887],
        [ 0.0830,  0.0442,  0.0119,  ...,  0.1146, -0.0844,  0.0829]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1113, -0.0374, -0.0364,  ..., -0.0128, -0.1197, -0.0498],
        [-0.0109,  0.0987, -0.0880,  ..., -0.1078, -0.0679, -0.0943],
        [-0.0980,  0.0928, -0.0547,  ..., -0.0849, -0.0202,  0.0448],
        ...,
        [ 0.0625,  0.0528,  0.0816,  ...,  0.0227, -0.0034,  0.0994],
        [-0.0394,  0.0287, -0.0243,  ..., -0.0972,  0.0691,  0.0887],
        [ 0.0830,  0.0442,  0.0119,  ...,  0.1146, -0.0844,  0.0829]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0809,  0.0609, -0.0935,  ...,  0.0022, -0.1058,  0.0938],
        [-0.1321,  0.1706, -0.0941,  ..., -0.1678,  0.0367, -0.0503],
        [ 0.1276,  0.0541, -0.1512,  ...,  0.0591, -0.1525,  0.0773],
        ...,
        [ 0.0361, -0.0954,  0.0202,  ..., -0.1028,  0.0269, -0.1398],
        [-0.0669, -0.1215,  0.1018,  ...,  0.1106, -0.0673, -0.0391],
        [-0.1411, -0.1247,  0.0174,  ...,  0.0384, -0.1386,  0.0583]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0809,  0.0609, -0.0935,  ...,  0.0022, -0.1058,  0.0938],
        [-0.1321,  0.1706, -0.0941,  ..., -0.1678,  0.0367, -0.0503],
        [ 0.1276,  0.0541, -0.1512,  ...,  0.0591, -0.1525,  0.0773],
        ...,
        [ 0.0361, -0.0954,  0.0202,  ..., -0.1028,  0.0269, -0.1398],
        [-0.0669, -0.1215,  0.1018,  ...,  0.1106, -0.0673, -0.0391],
        [-0.1411, -0.1247,  0.0174,  ...,  0.0384, -0.1386,  0.0583]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-0.0542,  0.2302, -0.0157,  ..., -0.0214, -0.1670,  0.2474],
        [-0.2488,  0.0183, -0.2044,  ...,  0.1059, -0.0627,  0.1506],
        [ 0.1640, -0.0872,  0.0596,  ...,  0.2488,  0.1952, -0.1595],
        ...,
        [ 0.1960, -0.0604,  0.1295,  ...,  0.0679, -0.0424,  0.0332],
        [ 0.0640,  0.0703,  0.0949,  ..., -0.2301,  0.1017,  0.0844],
        [ 0.0728,  0.0458,  0.2309,  ...,  0.0929, -0.1232, -0.1736]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0542,  0.2302, -0.0157,  ..., -0.0214, -0.1670,  0.2474],
        [-0.2488,  0.0183, -0.2044,  ...,  0.1059, -0.0627,  0.1506],
        [ 0.1640, -0.0872,  0.0596,  ...,  0.2488,  0.1952, -0.1595],
        ...,
        [ 0.1960, -0.0604,  0.1295,  ...,  0.0679, -0.0424,  0.0332],
        [ 0.0640,  0.0703,  0.0949,  ..., -0.2301,  0.1017,  0.0844],
        [ 0.0728,  0.0458,  0.2309,  ...,  0.0929, -0.1232, -0.1736]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[ 0.3116],
        [ 0.1000],
        [-0.3424],
        [ 0.1990],
        [-0.3955],
        [ 0.2345],
        [-0.2804],
        [-0.3764],
        [ 0.1409],
        [-0.1874],
        [ 0.0769],
        [-0.1626],
        [-0.3694],
        [-0.3231],
        [-0.1902],
        [-0.3378],
        [-0.2031],
        [-0.3292],
        [ 0.3486],
        [-0.0384],
        [-0.2348],
        [ 0.0585],
        [ 0.1066],
        [ 0.1531],
        [-0.2143],
        [-0.1134],
        [ 0.4251],
        [-0.4034],
        [ 0.1236],
        [ 0.0953],
        [ 0.1009],
        [ 0.2315]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.3116],
        [ 0.1000],
        [-0.3424],
        [ 0.1990],
        [-0.3955],
        [ 0.2345],
        [-0.2804],
        [-0.3764],
        [ 0.1409],
        [-0.1874],
        [ 0.0769],
        [-0.1626],
        [-0.3694],
        [-0.3231],
        [-0.1902],
        [-0.3378],
        [-0.2031],
        [-0.3292],
        [ 0.3486],
        [-0.0384],
        [-0.2348],
        [ 0.0585],
        [ 0.1066],
        [ 0.1531],
        [-0.2143],
        [-0.1134],
        [ 0.4251],
        [-0.4034],
        [ 0.1236],
        [ 0.0953],
        [ 0.1009],
        [ 0.2315]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)

net when the batchsize is 2 GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network when the batchsize is 2:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.1059,  0.1138, -0.0639, -0.0567, -0.1032,  0.0569, -0.1513, -0.1431,
          0.1376,  0.0500, -0.1389,  0.0624, -0.0390, -0.0983,  0.1235,  0.0365,
         -0.1459, -0.0782, -0.1223,  0.1307, -0.1257,  0.0589,  0.1449, -0.1158,
          0.0121, -0.0126,  0.0351,  0.0813,  0.0793,  0.0707,  0.0582,  0.0620,
          0.1462,  0.0781,  0.0342,  0.1484,  0.0902, -0.0099,  0.0573, -0.1326,
          0.0588,  0.0720, -0.0598, -0.0147,  0.0327,  0.0766, -0.0156,  0.0628,
         -0.0834,  0.1096, -0.0519, -0.0470, -0.0290, -0.0541, -0.0959,  0.0803,
         -0.0911, -0.0570,  0.0086, -0.0911,  0.0834,  0.0755, -0.1189, -0.0654,
          0.0364, -0.0482, -0.0654, -0.0372,  0.0180, -0.0197,  0.0617,  0.0937,
         -0.0049,  0.0359, -0.0096, -0.1305,  0.1038, -0.0204, -0.0186, -0.0872,
          0.0456, -0.0072,  0.0003,  0.1181, -0.0025,  0.0130, -0.1135,  0.0899,
          0.0269,  0.0403,  0.1067,  0.0577,  0.0554, -0.1053,  0.0819, -0.1235,
          0.0470, -0.0784, -0.0120, -0.0029,  0.0049, -0.0470,  0.0168, -0.1029,
          0.0633, -0.1176,  0.0657,  0.1356, -0.0238,  0.0170,  0.0736,  0.1457,
         -0.0974, -0.0091,  0.0478, -0.0429, -0.0393, -0.1315,  0.0271, -0.1072,
          0.0882, -0.1481,  0.1444,  0.1317,  0.0455, -0.0517, -0.0263, -0.0016,
         -0.0717,  0.1046,  0.0793,  0.0967, -0.0126, -0.0973,  0.1348, -0.0827,
         -0.1456,  0.0924, -0.0621,  0.1262,  0.0802,  0.0850, -0.0045,  0.0939,
         -0.0521, -0.1223, -0.1339, -0.0258,  0.0166, -0.0145, -0.0045, -0.0380,
          0.0016, -0.0829, -0.0655, -0.1484,  0.0541, -0.0915,  0.0561,  0.0201,
         -0.0983,  0.0331, -0.0337, -0.0208, -0.1503,  0.1067,  0.1335,  0.0363,
          0.0053, -0.1176,  0.0259, -0.0673, -0.0568,  0.1388,  0.0775, -0.0533,
          0.0333,  0.1000,  0.1304, -0.1151,  0.0939,  0.0261,  0.0370, -0.0963,
          0.0956, -0.0345, -0.0465, -0.1372,  0.0386,  0.1091,  0.0166, -0.1447,
          0.1228, -0.0052, -0.0995,  0.0425, -0.1377,  0.0630, -0.1343, -0.0188,
          0.0184, -0.0932,  0.1249,  0.0510,  0.0224, -0.0480,  0.0651,  0.1407,
          0.0470, -0.0294,  0.1242, -0.1096, -0.0549, -0.0062, -0.0269, -0.0431,
         -0.1423, -0.1228, -0.0857,  0.0087, -0.0176, -0.1131,  0.1053,  0.1119,
         -0.0831, -0.0598, -0.1231,  0.0088,  0.0531,  0.0223,  0.1192, -0.0956,
          0.0550,  0.0764,  0.0516, -0.0268,  0.1178, -0.1447,  0.0445,  0.1310,
         -0.0268,  0.0059,  0.0012, -0.0111,  0.0657, -0.1027, -0.0944, -0.0251,
         -0.0645, -0.1507, -0.0068, -0.0996, -0.0547, -0.1360, -0.0282,  0.0203]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1059,  0.1138, -0.0639, -0.0567, -0.1032,  0.0569, -0.1513, -0.1431,
          0.1376,  0.0500, -0.1389,  0.0624, -0.0390, -0.0983,  0.1235,  0.0365,
         -0.1459, -0.0782, -0.1223,  0.1307, -0.1257,  0.0589,  0.1449, -0.1158,
          0.0121, -0.0126,  0.0351,  0.0813,  0.0793,  0.0707,  0.0582,  0.0620,
          0.1462,  0.0781,  0.0342,  0.1484,  0.0902, -0.0099,  0.0573, -0.1326,
          0.0588,  0.0720, -0.0598, -0.0147,  0.0327,  0.0766, -0.0156,  0.0628,
         -0.0834,  0.1096, -0.0519, -0.0470, -0.0290, -0.0541, -0.0959,  0.0803,
         -0.0911, -0.0570,  0.0086, -0.0911,  0.0834,  0.0755, -0.1189, -0.0654,
          0.0364, -0.0482, -0.0654, -0.0372,  0.0180, -0.0197,  0.0617,  0.0937,
         -0.0049,  0.0359, -0.0096, -0.1305,  0.1038, -0.0204, -0.0186, -0.0872,
          0.0456, -0.0072,  0.0003,  0.1181, -0.0025,  0.0130, -0.1135,  0.0899,
          0.0269,  0.0403,  0.1067,  0.0577,  0.0554, -0.1053,  0.0819, -0.1235,
          0.0470, -0.0784, -0.0120, -0.0029,  0.0049, -0.0470,  0.0168, -0.1029,
          0.0633, -0.1176,  0.0657,  0.1356, -0.0238,  0.0170,  0.0736,  0.1457,
         -0.0974, -0.0091,  0.0478, -0.0429, -0.0393, -0.1315,  0.0271, -0.1072,
          0.0882, -0.1481,  0.1444,  0.1317,  0.0455, -0.0517, -0.0263, -0.0016,
         -0.0717,  0.1046,  0.0793,  0.0967, -0.0126, -0.0973,  0.1348, -0.0827,
         -0.1456,  0.0924, -0.0621,  0.1262,  0.0802,  0.0850, -0.0045,  0.0939,
         -0.0521, -0.1223, -0.1339, -0.0258,  0.0166, -0.0145, -0.0045, -0.0380,
          0.0016, -0.0829, -0.0655, -0.1484,  0.0541, -0.0915,  0.0561,  0.0201,
         -0.0983,  0.0331, -0.0337, -0.0208, -0.1503,  0.1067,  0.1335,  0.0363,
          0.0053, -0.1176,  0.0259, -0.0673, -0.0568,  0.1388,  0.0775, -0.0533,
          0.0333,  0.1000,  0.1304, -0.1151,  0.0939,  0.0261,  0.0370, -0.0963,
          0.0956, -0.0345, -0.0465, -0.1372,  0.0386,  0.1091,  0.0166, -0.1447,
          0.1228, -0.0052, -0.0995,  0.0425, -0.1377,  0.0630, -0.1343, -0.0188,
          0.0184, -0.0932,  0.1249,  0.0510,  0.0224, -0.0480,  0.0651,  0.1407,
          0.0470, -0.0294,  0.1242, -0.1096, -0.0549, -0.0062, -0.0269, -0.0431,
         -0.1423, -0.1228, -0.0857,  0.0087, -0.0176, -0.1131,  0.1053,  0.1119,
         -0.0831, -0.0598, -0.1231,  0.0088,  0.0531,  0.0223,  0.1192, -0.0956,
          0.0550,  0.0764,  0.0516, -0.0268,  0.1178, -0.1447,  0.0445,  0.1310,
         -0.0268,  0.0059,  0.0012, -0.0111,  0.0657, -0.1027, -0.0944, -0.0251,
         -0.0645, -0.1507, -0.0068, -0.0996, -0.0547, -0.1360, -0.0282,  0.0203]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.0412,  0.0151, -0.0087,  ...,  0.0263, -0.0952, -0.1103],
        [-0.0459, -0.0977,  0.0261,  ..., -0.0869, -0.0888, -0.0765],
        [-0.0196, -0.0835, -0.0675,  ...,  0.0969,  0.0035,  0.0109],
        ...,
        [-0.0440, -0.0077,  0.1176,  ..., -0.1181, -0.0509, -0.1120],
        [ 0.0433, -0.0115,  0.0012,  ..., -0.0612, -0.1212,  0.0329],
        [-0.0053,  0.1247,  0.0676,  ...,  0.0192, -0.0477,  0.0340]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0412,  0.0151, -0.0087,  ...,  0.0263, -0.0952, -0.1103],
        [-0.0459, -0.0977,  0.0261,  ..., -0.0869, -0.0888, -0.0765],
        [-0.0196, -0.0835, -0.0675,  ...,  0.0969,  0.0035,  0.0109],
        ...,
        [-0.0440, -0.0077,  0.1176,  ..., -0.1181, -0.0509, -0.1120],
        [ 0.0433, -0.0115,  0.0012,  ..., -0.0612, -0.1212,  0.0329],
        [-0.0053,  0.1247,  0.0676,  ...,  0.0192, -0.0477,  0.0340]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0168,  0.0229, -0.1636,  ..., -0.0232,  0.0160,  0.1465],
        [-0.1551, -0.0283,  0.0364,  ..., -0.1130,  0.0607, -0.1670],
        [ 0.1554, -0.0439,  0.1431,  ..., -0.1142, -0.0933,  0.1530],
        ...,
        [ 0.1164, -0.0892, -0.0432,  ...,  0.1509, -0.1364,  0.0233],
        [-0.1569,  0.1183, -0.1084,  ...,  0.1235, -0.0179,  0.1609],
        [ 0.0606,  0.0711, -0.1482,  ..., -0.0390, -0.0110,  0.0627]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0168,  0.0229, -0.1636,  ..., -0.0232,  0.0160,  0.1465],
        [-0.1551, -0.0283,  0.0364,  ..., -0.1130,  0.0607, -0.1670],
        [ 0.1554, -0.0439,  0.1431,  ..., -0.1142, -0.0933,  0.1530],
        ...,
        [ 0.1164, -0.0892, -0.0432,  ...,  0.1509, -0.1364,  0.0233],
        [-0.1569,  0.1183, -0.1084,  ...,  0.1235, -0.0179,  0.1609],
        [ 0.0606,  0.0711, -0.1482,  ..., -0.0390, -0.0110,  0.0627]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.0694,  0.0513,  0.0176,  ..., -0.0897, -0.1438, -0.1098],
        [ 0.0109,  0.1336,  0.1342,  ...,  0.0452, -0.1503,  0.0638],
        [-0.0980,  0.0800,  0.2341,  ..., -0.0087,  0.2402, -0.1974],
        ...,
        [ 0.2122,  0.0315, -0.2454,  ..., -0.1053,  0.1793, -0.0418],
        [-0.0679,  0.0801,  0.1136,  ..., -0.0944,  0.2136,  0.0737],
        [-0.0231, -0.2467, -0.0417,  ...,  0.0049, -0.0453,  0.1815]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0694,  0.0513,  0.0176,  ..., -0.0897, -0.1438, -0.1098],
        [ 0.0109,  0.1336,  0.1342,  ...,  0.0452, -0.1503,  0.0638],
        [-0.0980,  0.0800,  0.2341,  ..., -0.0087,  0.2402, -0.1974],
        ...,
        [ 0.2122,  0.0315, -0.2454,  ..., -0.1053,  0.1793, -0.0418],
        [-0.0679,  0.0801,  0.1136,  ..., -0.0944,  0.2136,  0.0737],
        [-0.0231, -0.2467, -0.0417,  ...,  0.0049, -0.0453,  0.1815]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.2671],
        [-0.0228],
        [ 0.2949],
        [ 0.2171],
        [ 0.4089],
        [ 0.1668],
        [-0.0899],
        [ 0.1729],
        [ 0.3192],
        [-0.2652],
        [-0.2410],
        [-0.2743],
        [-0.1126],
        [ 0.0638],
        [-0.3796],
        [-0.1435],
        [ 0.2781],
        [-0.3634],
        [ 0.4091],
        [ 0.2620],
        [-0.2078],
        [-0.1583],
        [-0.2527],
        [-0.1751],
        [ 0.2092],
        [ 0.3137],
        [-0.4005],
        [ 0.1139],
        [-0.2754],
        [ 0.2971],
        [-0.1216],
        [-0.1956]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.2671],
        [-0.0228],
        [ 0.2949],
        [ 0.2171],
        [ 0.4089],
        [ 0.1668],
        [-0.0899],
        [ 0.1729],
        [ 0.3192],
        [-0.2652],
        [-0.2410],
        [-0.2743],
        [-0.1126],
        [ 0.0638],
        [-0.3796],
        [-0.1435],
        [ 0.2781],
        [-0.3634],
        [ 0.4091],
        [ 0.2620],
        [-0.2078],
        [-0.1583],
        [-0.2527],
        [-0.1751],
        [ 0.2092],
        [ 0.3137],
        [-0.4005],
        [ 0.1139],
        [-0.2754],
        [ 0.2971],
        [-0.1216],
        [-0.1956]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-182.6371, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(3.8746, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(3.9613, device='cuda:0')



h[100].sum tensor(8.3582, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(8.5453, device='cuda:0')



h[200].sum tensor(-8.5315, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-8.7224, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(9891.8320, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0184,  ..., 0.0085, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0086,  ..., 0.0040, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0024,  ..., 0.0011, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(58559.0273, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-43.1171, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-157.1116, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(970.4738, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(61.7078, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.0531],
        [-0.0375],
        [-0.0252],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-2460.4766, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[-0.0531],
        [-0.0375],
        [-0.0252],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=1463720,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([1463720, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(1463720., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0149, -0.0028, -0.0032,  ..., -0.0145,  0.0146,  0.0142],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(322.1166, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-98.1114, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-100.5744, device='cuda:0')



h[100].sum tensor(-47.0187, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-48.1991, device='cuda:0')



h[200].sum tensor(-1.5704, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-1.6098, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0551, 0.0538],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0453, 0.0442],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0106, 0.0104],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(108735.2500, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0665, 0.0000, 0.2941,  ..., 0.0548, 0.0075, 0.1094],
        [0.0570, 0.0000, 0.2520,  ..., 0.0469, 0.0064, 0.0937],
        [0.0457, 0.0000, 0.2023,  ..., 0.0377, 0.0051, 0.0752],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(586268.6875, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(3291.7490, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(230.4672, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(3510.3640, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(245.9796, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-196.3137, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=1463720,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-8.3511e-01],
        [-9.0357e-01],
        [-9.9703e-01],
        ...,
        [-1.0880e-05],
        [-1.8087e-05],
        [-2.5855e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(-57969.4844, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([1463720, 1]) 
g.edata[efet].sum tensor(1463720., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-0.0531],
        [-0.0375],
        [-0.0252],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')

real	0m25.835s
user	0m18.311s
sys	0m5.057s
