0: gpu020.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-5e8cba4b-c110-261e-b669-40158a81defb)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        5D:EA:F4:F9:6B:E7:60:EC:37:91:76:30:82:9F:92:2E:89:FC:B5:0C
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Sun Oct  9 00:52:57 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:B6:00.0 Off |                    0 |
| N/A   36C    P0    42W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2aedeea5a940> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m14.885s
user	0m3.424s
sys	0m2.445s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[ 1.3041],
        [ 0.5823],
        [-0.2909],
        ...,
        [ 0.8288],
        [-0.5295],
        [-0.3669]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-31.8357, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.1353,  0.0314,  0.1269, -0.1180,  0.0420, -0.0178, -0.0165, -0.0997,
         -0.0390,  0.0741,  0.0204, -0.0919, -0.0673, -0.0297,  0.1186, -0.0218,
          0.0166, -0.1057,  0.0995, -0.1363,  0.0927, -0.0432,  0.0177,  0.0152,
         -0.1397,  0.0112, -0.0249,  0.1474, -0.1259,  0.0244,  0.1483,  0.0938,
          0.1220,  0.0710,  0.0650,  0.0035,  0.0730,  0.1438, -0.1356,  0.1432,
          0.0923, -0.0679,  0.0825,  0.1507, -0.0993,  0.1098,  0.0872, -0.0759,
          0.1526, -0.0996, -0.0546, -0.0389, -0.0987,  0.1308,  0.0962, -0.0363,
          0.0562, -0.0033,  0.1128,  0.0148,  0.0368, -0.0243, -0.1524,  0.1258,
         -0.0199,  0.0320, -0.0014, -0.0831,  0.0379, -0.0072,  0.1093, -0.0824,
          0.1179,  0.0829,  0.0632,  0.0437, -0.1125, -0.0523, -0.0777, -0.0676,
          0.0089, -0.1398,  0.0887, -0.1365,  0.0183,  0.1266, -0.0318,  0.1082,
          0.0999,  0.0576, -0.0321, -0.0160,  0.0868, -0.0799,  0.1502, -0.0700,
         -0.0087,  0.1341, -0.1335, -0.0065,  0.1028, -0.0083, -0.0030,  0.0439,
          0.0992,  0.1420, -0.1320, -0.1036,  0.1010, -0.1000,  0.0325,  0.1447,
          0.0928, -0.0359, -0.1025, -0.0890,  0.0371,  0.1120,  0.0211,  0.0880,
         -0.0952, -0.0651, -0.0157, -0.1231, -0.0221, -0.1317,  0.0026,  0.0812,
          0.1416,  0.0347, -0.0904, -0.1065,  0.0919,  0.0043,  0.0624,  0.0939,
          0.0840,  0.1146, -0.1237,  0.0133, -0.0744,  0.0933,  0.0032,  0.1385,
         -0.1181,  0.0976,  0.0051,  0.0490, -0.0602,  0.1090,  0.1343, -0.1314,
         -0.0194, -0.1256, -0.1441,  0.0592,  0.0828,  0.0889,  0.1389, -0.0231,
          0.0048, -0.0633, -0.0874, -0.0578, -0.0400,  0.0865,  0.1489, -0.1296,
          0.0883,  0.0240,  0.1230, -0.1527, -0.0631, -0.1017,  0.0274, -0.1177,
         -0.1517,  0.0041, -0.0172, -0.1446,  0.0714,  0.0817,  0.0491,  0.0463,
         -0.0556, -0.0486,  0.1107, -0.0873,  0.1524, -0.1041, -0.0182, -0.1352,
          0.0225, -0.0012,  0.0606,  0.0203, -0.1015,  0.1518,  0.0156,  0.1133,
          0.0205,  0.0826, -0.0568,  0.0675, -0.1432,  0.1037, -0.0562, -0.0580,
          0.1338, -0.0433, -0.0526, -0.1406,  0.0473, -0.1040,  0.1072,  0.1426,
         -0.1359,  0.0213,  0.0605,  0.0522, -0.1214, -0.0918,  0.1304,  0.0877,
         -0.0321,  0.0772,  0.0448, -0.1136,  0.0031,  0.0099,  0.0880, -0.0973,
         -0.0141, -0.0097,  0.0359, -0.0232,  0.0715, -0.0241, -0.1421, -0.0889,
          0.0234,  0.0175,  0.1174, -0.1093, -0.0130,  0.0736,  0.0046,  0.0349,
          0.0741, -0.0880,  0.1243,  0.1281, -0.1446,  0.0988,  0.0326,  0.0621]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1353,  0.0314,  0.1269, -0.1180,  0.0420, -0.0178, -0.0165, -0.0997,
         -0.0390,  0.0741,  0.0204, -0.0919, -0.0673, -0.0297,  0.1186, -0.0218,
          0.0166, -0.1057,  0.0995, -0.1363,  0.0927, -0.0432,  0.0177,  0.0152,
         -0.1397,  0.0112, -0.0249,  0.1474, -0.1259,  0.0244,  0.1483,  0.0938,
          0.1220,  0.0710,  0.0650,  0.0035,  0.0730,  0.1438, -0.1356,  0.1432,
          0.0923, -0.0679,  0.0825,  0.1507, -0.0993,  0.1098,  0.0872, -0.0759,
          0.1526, -0.0996, -0.0546, -0.0389, -0.0987,  0.1308,  0.0962, -0.0363,
          0.0562, -0.0033,  0.1128,  0.0148,  0.0368, -0.0243, -0.1524,  0.1258,
         -0.0199,  0.0320, -0.0014, -0.0831,  0.0379, -0.0072,  0.1093, -0.0824,
          0.1179,  0.0829,  0.0632,  0.0437, -0.1125, -0.0523, -0.0777, -0.0676,
          0.0089, -0.1398,  0.0887, -0.1365,  0.0183,  0.1266, -0.0318,  0.1082,
          0.0999,  0.0576, -0.0321, -0.0160,  0.0868, -0.0799,  0.1502, -0.0700,
         -0.0087,  0.1341, -0.1335, -0.0065,  0.1028, -0.0083, -0.0030,  0.0439,
          0.0992,  0.1420, -0.1320, -0.1036,  0.1010, -0.1000,  0.0325,  0.1447,
          0.0928, -0.0359, -0.1025, -0.0890,  0.0371,  0.1120,  0.0211,  0.0880,
         -0.0952, -0.0651, -0.0157, -0.1231, -0.0221, -0.1317,  0.0026,  0.0812,
          0.1416,  0.0347, -0.0904, -0.1065,  0.0919,  0.0043,  0.0624,  0.0939,
          0.0840,  0.1146, -0.1237,  0.0133, -0.0744,  0.0933,  0.0032,  0.1385,
         -0.1181,  0.0976,  0.0051,  0.0490, -0.0602,  0.1090,  0.1343, -0.1314,
         -0.0194, -0.1256, -0.1441,  0.0592,  0.0828,  0.0889,  0.1389, -0.0231,
          0.0048, -0.0633, -0.0874, -0.0578, -0.0400,  0.0865,  0.1489, -0.1296,
          0.0883,  0.0240,  0.1230, -0.1527, -0.0631, -0.1017,  0.0274, -0.1177,
         -0.1517,  0.0041, -0.0172, -0.1446,  0.0714,  0.0817,  0.0491,  0.0463,
         -0.0556, -0.0486,  0.1107, -0.0873,  0.1524, -0.1041, -0.0182, -0.1352,
          0.0225, -0.0012,  0.0606,  0.0203, -0.1015,  0.1518,  0.0156,  0.1133,
          0.0205,  0.0826, -0.0568,  0.0675, -0.1432,  0.1037, -0.0562, -0.0580,
          0.1338, -0.0433, -0.0526, -0.1406,  0.0473, -0.1040,  0.1072,  0.1426,
         -0.1359,  0.0213,  0.0605,  0.0522, -0.1214, -0.0918,  0.1304,  0.0877,
         -0.0321,  0.0772,  0.0448, -0.1136,  0.0031,  0.0099,  0.0880, -0.0973,
         -0.0141, -0.0097,  0.0359, -0.0232,  0.0715, -0.0241, -0.1421, -0.0889,
          0.0234,  0.0175,  0.1174, -0.1093, -0.0130,  0.0736,  0.0046,  0.0349,
          0.0741, -0.0880,  0.1243,  0.1281, -0.1446,  0.0988,  0.0326,  0.0621]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0435, -0.0534, -0.0226,  ..., -0.1045, -0.0570,  0.0674],
        [-0.0157, -0.0905,  0.0251,  ...,  0.0802, -0.0299,  0.0378],
        [-0.0451,  0.0922, -0.0115,  ...,  0.0330,  0.0206,  0.0619],
        ...,
        [-0.0411, -0.0463,  0.0724,  ...,  0.1167,  0.1004,  0.1037],
        [ 0.0606,  0.0366, -0.0251,  ..., -0.0910,  0.0342,  0.0721],
        [ 0.0588,  0.0346,  0.0313,  ...,  0.0586,  0.0151,  0.0395]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0435, -0.0534, -0.0226,  ..., -0.1045, -0.0570,  0.0674],
        [-0.0157, -0.0905,  0.0251,  ...,  0.0802, -0.0299,  0.0378],
        [-0.0451,  0.0922, -0.0115,  ...,  0.0330,  0.0206,  0.0619],
        ...,
        [-0.0411, -0.0463,  0.0724,  ...,  0.1167,  0.1004,  0.1037],
        [ 0.0606,  0.0366, -0.0251,  ..., -0.0910,  0.0342,  0.0721],
        [ 0.0588,  0.0346,  0.0313,  ...,  0.0586,  0.0151,  0.0395]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0797,  0.1052,  0.1762,  ..., -0.1003,  0.0738,  0.0839],
        [ 0.1284,  0.1665,  0.1154,  ..., -0.0581,  0.1500,  0.1057],
        [-0.1122,  0.0002,  0.0953,  ..., -0.0917, -0.0861,  0.0538],
        ...,
        [-0.0159,  0.1371,  0.1346,  ..., -0.0346, -0.1636,  0.0076],
        [ 0.1363,  0.0416,  0.1763,  ..., -0.1666,  0.0874, -0.1684],
        [ 0.0097, -0.0863, -0.0057,  ...,  0.0513, -0.0073,  0.1326]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0797,  0.1052,  0.1762,  ..., -0.1003,  0.0738,  0.0839],
        [ 0.1284,  0.1665,  0.1154,  ..., -0.0581,  0.1500,  0.1057],
        [-0.1122,  0.0002,  0.0953,  ..., -0.0917, -0.0861,  0.0538],
        ...,
        [-0.0159,  0.1371,  0.1346,  ..., -0.0346, -0.1636,  0.0076],
        [ 0.1363,  0.0416,  0.1763,  ..., -0.1666,  0.0874, -0.1684],
        [ 0.0097, -0.0863, -0.0057,  ...,  0.0513, -0.0073,  0.1326]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-1.8775e-01, -1.6688e-01,  1.6978e-01,  ..., -3.6844e-02,
          2.1750e-01, -1.7471e-01],
        [ 8.2730e-02,  2.2865e-01,  9.7941e-02,  ..., -2.3845e-01,
          1.6657e-01,  1.6495e-01],
        [-8.2113e-02, -1.6052e-01,  1.6009e-01,  ...,  2.1198e-04,
          2.0956e-01, -4.6957e-03],
        ...,
        [ 1.9371e-01,  2.2156e-01,  1.6789e-02,  ..., -5.5187e-02,
         -2.5958e-02, -2.3781e-02],
        [-3.9016e-02,  6.1573e-02, -1.8992e-01,  ...,  2.3988e-01,
         -1.8478e-01,  1.6733e-01],
        [ 1.9127e-01,  1.4069e-01, -2.3809e-01,  ...,  1.2858e-01,
         -1.8169e-01,  2.0648e-01]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-1.8775e-01, -1.6688e-01,  1.6978e-01,  ..., -3.6844e-02,
          2.1750e-01, -1.7471e-01],
        [ 8.2730e-02,  2.2865e-01,  9.7941e-02,  ..., -2.3845e-01,
          1.6657e-01,  1.6495e-01],
        [-8.2113e-02, -1.6052e-01,  1.6009e-01,  ...,  2.1198e-04,
          2.0956e-01, -4.6957e-03],
        ...,
        [ 1.9371e-01,  2.2156e-01,  1.6789e-02,  ..., -5.5187e-02,
         -2.5958e-02, -2.3781e-02],
        [-3.9016e-02,  6.1573e-02, -1.8992e-01,  ...,  2.3988e-01,
         -1.8478e-01,  1.6733e-01],
        [ 1.9127e-01,  1.4069e-01, -2.3809e-01,  ...,  1.2858e-01,
         -1.8169e-01,  2.0648e-01]], device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.0840],
        [ 0.3105],
        [-0.1260],
        [ 0.2024],
        [ 0.0036],
        [-0.0713],
        [-0.0742],
        [ 0.0894],
        [ 0.0251],
        [-0.1561],
        [-0.1027],
        [ 0.2861],
        [-0.1128],
        [ 0.0187],
        [ 0.0246],
        [ 0.3242],
        [ 0.0518],
        [ 0.2037],
        [-0.2878],
        [ 0.2693],
        [-0.0587],
        [ 0.0488],
        [ 0.3899],
        [ 0.0527],
        [ 0.0768],
        [-0.1185],
        [-0.1096],
        [-0.4161],
        [-0.1554],
        [-0.3989],
        [ 0.2304],
        [ 0.0832]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0840],
        [ 0.3105],
        [-0.1260],
        [ 0.2024],
        [ 0.0036],
        [-0.0713],
        [-0.0742],
        [ 0.0894],
        [ 0.0251],
        [-0.1561],
        [-0.1027],
        [ 0.2861],
        [-0.1128],
        [ 0.0187],
        [ 0.0246],
        [ 0.3242],
        [ 0.0518],
        [ 0.2037],
        [-0.2878],
        [ 0.2693],
        [-0.0587],
        [ 0.0488],
        [ 0.3899],
        [ 0.0527],
        [ 0.0768],
        [-0.1185],
        [-0.1096],
        [-0.4161],
        [-0.1554],
        [-0.3989],
        [ 0.2304],
        [ 0.0832]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(131.3262, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(3.1154, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(3.3330, device='cuda:0')



h[100].sum tensor(10.4920, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(11.2249, device='cuda:0')



h[200].sum tensor(-11.4733, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-12.2747, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(363689.8438, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 1.8927, 1.8607, 0.2805],
        [0.0000, 0.0000, 0.0000,  ..., 0.9892, 0.9725, 0.1466],
        [0.0000, 0.0000, 0.0000,  ..., 0.4314, 0.4241, 0.0639],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(98341712., device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-1334.1541, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-387.7234, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-4020.6470, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-1768.4958],
        [-1281.1447],
        [ -901.0209],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-5.4098e+08, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet].sum tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[-1768.4958],
        [-1281.1447],
        [ -901.0209],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(47011080., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[ 0.0164,  0.0109, -0.0167,  ...,  0.0111, -0.0018, -0.0078],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(-153.7872, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(114.4008, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(122.8733, device='cuda:0')



h[100].sum tensor(18.8978, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(20.2973, device='cuda:0')



h[200].sum tensor(-27.8193, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-29.8795, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.6778, 0.4508, 0.0000,  ..., 0.4568, 0.0000, 0.0000],
        [0.5387, 0.3583, 0.0000,  ..., 0.3631, 0.0000, 0.0000],
        [0.1341, 0.0892, 0.0000,  ..., 0.0904, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(2961927., device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[ 0.0000,  9.7466, 32.9990,  ..., 23.5497, 53.9637,  0.0000],
        [ 0.0000,  8.6544, 29.3010,  ..., 20.9107, 47.9164,  0.0000],
        [ 0.0000,  7.5685, 25.6245,  ..., 18.2870, 41.9042,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(7.1846e+08, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-17987.0391, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-48099.6875, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-4920.9873, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-1.0987e+04],
        [-1.2140e+04],
        [-1.4080e+04],
        ...,
        [-1.5775e-01],
        [-2.5901e-01],
        [-3.5969e-01]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(-6.2220e+09, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet].sum tensor(47011080., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-1768.4958],
        [-1281.1447],
        [ -901.0209],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndnei.py", line 52, in <module>
    checkpoint_load(torch.load(F"{checkpoint_dir_path}/checkpoint_dir/{TraEvN}{6}{startmesh}saved_checkpoint.tar"))
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/checkpoint_dir/90016284saved_checkpoint.tar'

real	1m15.553s
user	0m23.609s
sys	0m9.468s
