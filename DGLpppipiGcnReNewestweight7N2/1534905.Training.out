0: gpu018.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ef573c50-e11c-cebc-5462-19270aa737e6)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        450.36.06
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.8
srcversion:     BB5CB243542347D4EB0C79C
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_MapRegistersEarly:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_EnableBacklightHandler:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_AssignGpus:charp

nvidia-smi:
Tue Aug  9 17:15:07 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:B6:00.0 Off |                    0 |
| N/A   45C    P0    45W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089730048

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b9e37a908e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m17.844s
user	0m3.359s
sys	0m2.270s
[17:15:28] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 0.1760],
        [-0.3978],
        [-0.0549],
        ...,
        [-0.6003],
        [ 0.2676],
        [ 0.2173]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-123.3129, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (80000, 6796) (80000, 6796)
sum 5574226 8401300
shape torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLpppipiGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.1337, -0.0529, -0.0926, -0.0034, -0.0262, -0.1518,  0.0109, -0.1080,
         -0.1466,  0.1198, -0.0339, -0.0687, -0.0697, -0.0432, -0.0838,  0.1169,
          0.0624, -0.0344,  0.0614,  0.0696,  0.0262,  0.0400,  0.0141,  0.0931,
         -0.0206,  0.0271,  0.0845,  0.1361, -0.0632,  0.1002,  0.1458,  0.1183,
          0.0447, -0.1392, -0.1263, -0.0592, -0.0161, -0.0772,  0.0675, -0.0828,
         -0.1051,  0.0838,  0.0743, -0.1148, -0.0304,  0.0684, -0.1101,  0.0703,
         -0.0006, -0.0240,  0.1276, -0.0518, -0.1160,  0.0536,  0.0188, -0.0915,
         -0.0919, -0.0813, -0.0320,  0.0434,  0.1338,  0.0144, -0.0198, -0.0205,
         -0.1037,  0.1367, -0.0822, -0.1219, -0.0255,  0.0926, -0.0868,  0.0003,
         -0.0058, -0.0448, -0.0449,  0.0337,  0.0328,  0.0113,  0.1498, -0.0549,
         -0.0525,  0.1226, -0.0362,  0.1165, -0.0059,  0.1210, -0.0880, -0.1280,
          0.0195,  0.1156, -0.1070, -0.0361, -0.0014, -0.0595,  0.1479, -0.1165,
         -0.0269, -0.1001,  0.1167,  0.1006, -0.0918, -0.0389, -0.1375,  0.0048,
          0.1189,  0.0998,  0.1088, -0.0202,  0.0273,  0.1039,  0.0536, -0.0920,
          0.0719,  0.0957,  0.0182,  0.0159,  0.1476,  0.0239, -0.0925,  0.1203,
         -0.0392, -0.1501,  0.0322,  0.0365, -0.1288, -0.0149, -0.1083, -0.0032,
          0.1086, -0.0262,  0.0024, -0.0247,  0.1428,  0.1414, -0.0661, -0.0309,
          0.1465,  0.1137,  0.0219, -0.1196, -0.0444, -0.1049,  0.0704,  0.1244,
          0.1303,  0.0459, -0.0341,  0.1000,  0.0716, -0.0523,  0.0290,  0.0566,
          0.1396,  0.0857,  0.1076,  0.0185,  0.0840, -0.0443,  0.0741, -0.0024,
         -0.1129, -0.0139,  0.0973,  0.0648, -0.0601,  0.0712, -0.0025, -0.1147,
         -0.1136,  0.1347,  0.1237,  0.0117,  0.0227, -0.1341, -0.1433, -0.0095,
         -0.0956, -0.0422,  0.0254, -0.0007, -0.0953,  0.0988, -0.0460, -0.0122,
          0.0083,  0.0951,  0.0455,  0.1360, -0.0262, -0.1254,  0.0736,  0.0400,
          0.0582,  0.0440,  0.1035, -0.0243, -0.0650,  0.0983,  0.0023,  0.1123,
         -0.0719, -0.1517,  0.0108,  0.0525, -0.1155, -0.0748, -0.0847, -0.0359,
          0.0715, -0.1117, -0.0512,  0.0858, -0.0022,  0.0054,  0.0952, -0.0528,
          0.0584, -0.1035, -0.0281, -0.1448, -0.0851,  0.0129,  0.0033, -0.1511,
         -0.1462,  0.1019,  0.0542,  0.0252, -0.0900, -0.0508, -0.1003, -0.1498,
         -0.0937, -0.1162,  0.1305,  0.0004,  0.0213,  0.0229,  0.1524,  0.0054,
         -0.0666, -0.0864, -0.0237, -0.0487,  0.1226,  0.1511,  0.0271,  0.0208,
          0.0410, -0.0316, -0.0544, -0.1137, -0.0577,  0.0002,  0.1281, -0.0498]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1337, -0.0529, -0.0926, -0.0034, -0.0262, -0.1518,  0.0109, -0.1080,
         -0.1466,  0.1198, -0.0339, -0.0687, -0.0697, -0.0432, -0.0838,  0.1169,
          0.0624, -0.0344,  0.0614,  0.0696,  0.0262,  0.0400,  0.0141,  0.0931,
         -0.0206,  0.0271,  0.0845,  0.1361, -0.0632,  0.1002,  0.1458,  0.1183,
          0.0447, -0.1392, -0.1263, -0.0592, -0.0161, -0.0772,  0.0675, -0.0828,
         -0.1051,  0.0838,  0.0743, -0.1148, -0.0304,  0.0684, -0.1101,  0.0703,
         -0.0006, -0.0240,  0.1276, -0.0518, -0.1160,  0.0536,  0.0188, -0.0915,
         -0.0919, -0.0813, -0.0320,  0.0434,  0.1338,  0.0144, -0.0198, -0.0205,
         -0.1037,  0.1367, -0.0822, -0.1219, -0.0255,  0.0926, -0.0868,  0.0003,
         -0.0058, -0.0448, -0.0449,  0.0337,  0.0328,  0.0113,  0.1498, -0.0549,
         -0.0525,  0.1226, -0.0362,  0.1165, -0.0059,  0.1210, -0.0880, -0.1280,
          0.0195,  0.1156, -0.1070, -0.0361, -0.0014, -0.0595,  0.1479, -0.1165,
         -0.0269, -0.1001,  0.1167,  0.1006, -0.0918, -0.0389, -0.1375,  0.0048,
          0.1189,  0.0998,  0.1088, -0.0202,  0.0273,  0.1039,  0.0536, -0.0920,
          0.0719,  0.0957,  0.0182,  0.0159,  0.1476,  0.0239, -0.0925,  0.1203,
         -0.0392, -0.1501,  0.0322,  0.0365, -0.1288, -0.0149, -0.1083, -0.0032,
          0.1086, -0.0262,  0.0024, -0.0247,  0.1428,  0.1414, -0.0661, -0.0309,
          0.1465,  0.1137,  0.0219, -0.1196, -0.0444, -0.1049,  0.0704,  0.1244,
          0.1303,  0.0459, -0.0341,  0.1000,  0.0716, -0.0523,  0.0290,  0.0566,
          0.1396,  0.0857,  0.1076,  0.0185,  0.0840, -0.0443,  0.0741, -0.0024,
         -0.1129, -0.0139,  0.0973,  0.0648, -0.0601,  0.0712, -0.0025, -0.1147,
         -0.1136,  0.1347,  0.1237,  0.0117,  0.0227, -0.1341, -0.1433, -0.0095,
         -0.0956, -0.0422,  0.0254, -0.0007, -0.0953,  0.0988, -0.0460, -0.0122,
          0.0083,  0.0951,  0.0455,  0.1360, -0.0262, -0.1254,  0.0736,  0.0400,
          0.0582,  0.0440,  0.1035, -0.0243, -0.0650,  0.0983,  0.0023,  0.1123,
         -0.0719, -0.1517,  0.0108,  0.0525, -0.1155, -0.0748, -0.0847, -0.0359,
          0.0715, -0.1117, -0.0512,  0.0858, -0.0022,  0.0054,  0.0952, -0.0528,
          0.0584, -0.1035, -0.0281, -0.1448, -0.0851,  0.0129,  0.0033, -0.1511,
         -0.1462,  0.1019,  0.0542,  0.0252, -0.0900, -0.0508, -0.1003, -0.1498,
         -0.0937, -0.1162,  0.1305,  0.0004,  0.0213,  0.0229,  0.1524,  0.0054,
         -0.0666, -0.0864, -0.0237, -0.0487,  0.1226,  0.1511,  0.0271,  0.0208,
          0.0410, -0.0316, -0.0544, -0.1137, -0.0577,  0.0002,  0.1281, -0.0498]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0225, -0.0171,  0.1228,  ...,  0.0646,  0.1130, -0.0247],
        [-0.0335, -0.0267, -0.0395,  ..., -0.0136, -0.0598, -0.1118],
        [ 0.0767, -0.0089, -0.0379,  ...,  0.0491,  0.0434,  0.0475],
        ...,
        [-0.0348,  0.0548,  0.1145,  ..., -0.1199,  0.0699,  0.1089],
        [ 0.0532,  0.0064,  0.0362,  ..., -0.1215,  0.0687,  0.0683],
        [ 0.0176,  0.0010, -0.0874,  ...,  0.1019,  0.0275,  0.0947]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0225, -0.0171,  0.1228,  ...,  0.0646,  0.1130, -0.0247],
        [-0.0335, -0.0267, -0.0395,  ..., -0.0136, -0.0598, -0.1118],
        [ 0.0767, -0.0089, -0.0379,  ...,  0.0491,  0.0434,  0.0475],
        ...,
        [-0.0348,  0.0548,  0.1145,  ..., -0.1199,  0.0699,  0.1089],
        [ 0.0532,  0.0064,  0.0362,  ..., -0.1215,  0.0687,  0.0683],
        [ 0.0176,  0.0010, -0.0874,  ...,  0.1019,  0.0275,  0.0947]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.0697, -0.1689,  0.1325,  ..., -0.0947, -0.0445, -0.0258],
        [-0.0526,  0.0908, -0.1237,  ..., -0.1001, -0.1513, -0.1723],
        [ 0.0301,  0.0949,  0.0854,  ...,  0.1569,  0.0677,  0.0950],
        ...,
        [ 0.1715,  0.0219, -0.0262,  ..., -0.0490, -0.1202, -0.0652],
        [-0.0871,  0.0452, -0.0596,  ..., -0.0730,  0.0603,  0.1384],
        [ 0.1058, -0.0361, -0.0560,  ..., -0.0005, -0.0730, -0.1321]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0697, -0.1689,  0.1325,  ..., -0.0947, -0.0445, -0.0258],
        [-0.0526,  0.0908, -0.1237,  ..., -0.1001, -0.1513, -0.1723],
        [ 0.0301,  0.0949,  0.0854,  ...,  0.1569,  0.0677,  0.0950],
        ...,
        [ 0.1715,  0.0219, -0.0262,  ..., -0.0490, -0.1202, -0.0652],
        [-0.0871,  0.0452, -0.0596,  ..., -0.0730,  0.0603,  0.1384],
        [ 0.1058, -0.0361, -0.0560,  ..., -0.0005, -0.0730, -0.1321]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[ 0.2384,  0.1648, -0.0977,  ...,  0.1690, -0.2198, -0.0515],
        [-0.1091, -0.2451,  0.1742,  ..., -0.0252,  0.1088,  0.0635],
        [ 0.0026, -0.1393,  0.1762,  ...,  0.2232, -0.1643,  0.0052],
        ...,
        [-0.1066,  0.0776,  0.1116,  ..., -0.0263,  0.2317,  0.1120],
        [-0.1329, -0.1277,  0.1973,  ...,  0.0697, -0.0740, -0.0556],
        [-0.2498,  0.1128, -0.1006,  ..., -0.0847, -0.0827,  0.0575]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.2384,  0.1648, -0.0977,  ...,  0.1690, -0.2198, -0.0515],
        [-0.1091, -0.2451,  0.1742,  ..., -0.0252,  0.1088,  0.0635],
        [ 0.0026, -0.1393,  0.1762,  ...,  0.2232, -0.1643,  0.0052],
        ...,
        [-0.1066,  0.0776,  0.1116,  ..., -0.0263,  0.2317,  0.1120],
        [-0.1329, -0.1277,  0.1973,  ...,  0.0697, -0.0740, -0.0556],
        [-0.2498,  0.1128, -0.1006,  ..., -0.0847, -0.0827,  0.0575]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[-0.1244],
        [ 0.2250],
        [ 0.1565],
        [-0.1474],
        [-0.4044],
        [-0.2602],
        [ 0.3888],
        [ 0.3974],
        [ 0.2639],
        [ 0.2951],
        [-0.3796],
        [ 0.3965],
        [-0.3011],
        [ 0.1092],
        [-0.0416],
        [-0.1411],
        [-0.1858],
        [-0.3821],
        [ 0.0861],
        [ 0.1678],
        [ 0.1347],
        [-0.0272],
        [ 0.1997],
        [-0.1734],
        [-0.3755],
        [ 0.0484],
        [ 0.0334],
        [ 0.0568],
        [-0.0957],
        [ 0.0697],
        [-0.2105],
        [-0.2930]], device='cuda:0') 
 Parameter containing:
tensor([[-0.1244],
        [ 0.2250],
        [ 0.1565],
        [-0.1474],
        [-0.4044],
        [-0.2602],
        [ 0.3888],
        [ 0.3974],
        [ 0.2639],
        [ 0.2951],
        [-0.3796],
        [ 0.3965],
        [-0.3011],
        [ 0.1092],
        [-0.0416],
        [-0.1411],
        [-0.1858],
        [-0.3821],
        [ 0.0861],
        [ 0.1678],
        [ 0.1347],
        [-0.0272],
        [ 0.1997],
        [-0.1734],
        [-0.3755],
        [ 0.0484],
        [ 0.0334],
        [ 0.0568],
        [-0.0957],
        [ 0.0697],
        [-0.2105],
        [-0.2930]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.0287,  0.0329,  0.0762, -0.0740, -0.0698,  0.1367, -0.0965, -0.1482,
         -0.1084, -0.0309,  0.0925,  0.1021,  0.0157, -0.0991, -0.0438, -0.0474,
          0.1021, -0.1392, -0.0674,  0.1388,  0.0637, -0.0860,  0.1403,  0.0893,
          0.0379, -0.0766, -0.0507, -0.1032, -0.1050,  0.0653,  0.1121, -0.0981,
         -0.1309,  0.0894, -0.0891,  0.0812,  0.0162,  0.1481, -0.0121, -0.0243,
          0.0890, -0.0049,  0.0434,  0.0742,  0.1086,  0.1507,  0.0914,  0.1146,
         -0.0437,  0.0180,  0.0603, -0.0769, -0.0868,  0.0592,  0.0092, -0.0414,
          0.1207,  0.1495, -0.0856, -0.1203,  0.0582,  0.1369, -0.0137, -0.1047,
          0.0410,  0.0229,  0.0315,  0.1498,  0.0412,  0.0325,  0.0917,  0.1224,
         -0.0992, -0.0204,  0.1401, -0.1500,  0.0141, -0.0741, -0.0414,  0.1369,
          0.0682,  0.0953,  0.1502, -0.0945,  0.1337,  0.0353, -0.1083,  0.0218,
         -0.0388,  0.0686, -0.1045,  0.0684,  0.0484,  0.0581,  0.0907,  0.1246,
         -0.1091,  0.0526, -0.1469,  0.0451, -0.1504, -0.0267,  0.0872,  0.0778,
         -0.1406,  0.0996,  0.1044, -0.0948, -0.1419, -0.0659,  0.0863, -0.0314,
          0.0917,  0.0277, -0.1173, -0.0193, -0.0979,  0.0884,  0.0306, -0.0408,
          0.0150,  0.1084,  0.0325, -0.0775,  0.1161, -0.0032,  0.1112, -0.0173,
          0.1166,  0.0038, -0.1442, -0.1358,  0.0612, -0.1034,  0.0161,  0.1299,
          0.1352, -0.0199,  0.0867, -0.1026,  0.0265,  0.1200, -0.0940, -0.0899,
         -0.1048, -0.0653, -0.0032, -0.1216,  0.1104,  0.0112,  0.0917, -0.1381,
         -0.0202,  0.0078,  0.0632,  0.0781,  0.1084,  0.1363,  0.0028, -0.0434,
         -0.0942,  0.1293,  0.1081, -0.0590,  0.0756, -0.0693,  0.1030,  0.0066,
         -0.0979, -0.1334, -0.0471,  0.0982, -0.0506,  0.1135,  0.0460, -0.1477,
          0.0267, -0.0103, -0.0464, -0.0140, -0.0625, -0.0815,  0.0422, -0.0636,
          0.1454,  0.1454,  0.1429,  0.0056, -0.1331,  0.0337,  0.0529, -0.0953,
          0.0336, -0.0687,  0.0632,  0.1028,  0.0980,  0.0436, -0.1316,  0.0815,
          0.1318,  0.0586,  0.1424, -0.0074,  0.0664, -0.0802,  0.0875, -0.0727,
          0.0929, -0.1299,  0.0098,  0.0541, -0.0506, -0.0871, -0.1380, -0.0635,
         -0.0657, -0.1056, -0.1492, -0.0935,  0.0630,  0.0446, -0.0759,  0.0820,
          0.0720,  0.0152, -0.1221, -0.1335, -0.0169, -0.0963,  0.0250,  0.0725,
          0.1317,  0.1485, -0.1045, -0.0711, -0.0793,  0.0109,  0.0189, -0.0239,
          0.1193, -0.0689,  0.1002, -0.0008,  0.0989,  0.0917, -0.0147,  0.0621,
         -0.0378, -0.1327, -0.0009, -0.1168,  0.0625, -0.0636,  0.0895, -0.1183]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0287,  0.0329,  0.0762, -0.0740, -0.0698,  0.1367, -0.0965, -0.1482,
         -0.1084, -0.0309,  0.0925,  0.1021,  0.0157, -0.0991, -0.0438, -0.0474,
          0.1021, -0.1392, -0.0674,  0.1388,  0.0637, -0.0860,  0.1403,  0.0893,
          0.0379, -0.0766, -0.0507, -0.1032, -0.1050,  0.0653,  0.1121, -0.0981,
         -0.1309,  0.0894, -0.0891,  0.0812,  0.0162,  0.1481, -0.0121, -0.0243,
          0.0890, -0.0049,  0.0434,  0.0742,  0.1086,  0.1507,  0.0914,  0.1146,
         -0.0437,  0.0180,  0.0603, -0.0769, -0.0868,  0.0592,  0.0092, -0.0414,
          0.1207,  0.1495, -0.0856, -0.1203,  0.0582,  0.1369, -0.0137, -0.1047,
          0.0410,  0.0229,  0.0315,  0.1498,  0.0412,  0.0325,  0.0917,  0.1224,
         -0.0992, -0.0204,  0.1401, -0.1500,  0.0141, -0.0741, -0.0414,  0.1369,
          0.0682,  0.0953,  0.1502, -0.0945,  0.1337,  0.0353, -0.1083,  0.0218,
         -0.0388,  0.0686, -0.1045,  0.0684,  0.0484,  0.0581,  0.0907,  0.1246,
         -0.1091,  0.0526, -0.1469,  0.0451, -0.1504, -0.0267,  0.0872,  0.0778,
         -0.1406,  0.0996,  0.1044, -0.0948, -0.1419, -0.0659,  0.0863, -0.0314,
          0.0917,  0.0277, -0.1173, -0.0193, -0.0979,  0.0884,  0.0306, -0.0408,
          0.0150,  0.1084,  0.0325, -0.0775,  0.1161, -0.0032,  0.1112, -0.0173,
          0.1166,  0.0038, -0.1442, -0.1358,  0.0612, -0.1034,  0.0161,  0.1299,
          0.1352, -0.0199,  0.0867, -0.1026,  0.0265,  0.1200, -0.0940, -0.0899,
         -0.1048, -0.0653, -0.0032, -0.1216,  0.1104,  0.0112,  0.0917, -0.1381,
         -0.0202,  0.0078,  0.0632,  0.0781,  0.1084,  0.1363,  0.0028, -0.0434,
         -0.0942,  0.1293,  0.1081, -0.0590,  0.0756, -0.0693,  0.1030,  0.0066,
         -0.0979, -0.1334, -0.0471,  0.0982, -0.0506,  0.1135,  0.0460, -0.1477,
          0.0267, -0.0103, -0.0464, -0.0140, -0.0625, -0.0815,  0.0422, -0.0636,
          0.1454,  0.1454,  0.1429,  0.0056, -0.1331,  0.0337,  0.0529, -0.0953,
          0.0336, -0.0687,  0.0632,  0.1028,  0.0980,  0.0436, -0.1316,  0.0815,
          0.1318,  0.0586,  0.1424, -0.0074,  0.0664, -0.0802,  0.0875, -0.0727,
          0.0929, -0.1299,  0.0098,  0.0541, -0.0506, -0.0871, -0.1380, -0.0635,
         -0.0657, -0.1056, -0.1492, -0.0935,  0.0630,  0.0446, -0.0759,  0.0820,
          0.0720,  0.0152, -0.1221, -0.1335, -0.0169, -0.0963,  0.0250,  0.0725,
          0.1317,  0.1485, -0.1045, -0.0711, -0.0793,  0.0109,  0.0189, -0.0239,
          0.1193, -0.0689,  0.1002, -0.0008,  0.0989,  0.0917, -0.0147,  0.0621,
         -0.0378, -0.1327, -0.0009, -0.1168,  0.0625, -0.0636,  0.0895, -0.1183]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0774, -0.0441,  0.0615,  ..., -0.0648,  0.0295, -0.1209],
        [-0.0720,  0.0179,  0.0110,  ...,  0.1192,  0.0828, -0.1156],
        [ 0.0274, -0.0027,  0.0403,  ..., -0.0466, -0.0249, -0.0015],
        ...,
        [ 0.0584, -0.0111, -0.0603,  ..., -0.0400, -0.0771, -0.0750],
        [-0.1087, -0.0026,  0.0742,  ...,  0.0724, -0.1123, -0.0883],
        [-0.0205,  0.0890, -0.0100,  ...,  0.0547, -0.0785,  0.0046]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0774, -0.0441,  0.0615,  ..., -0.0648,  0.0295, -0.1209],
        [-0.0720,  0.0179,  0.0110,  ...,  0.1192,  0.0828, -0.1156],
        [ 0.0274, -0.0027,  0.0403,  ..., -0.0466, -0.0249, -0.0015],
        ...,
        [ 0.0584, -0.0111, -0.0603,  ..., -0.0400, -0.0771, -0.0750],
        [-0.1087, -0.0026,  0.0742,  ...,  0.0724, -0.1123, -0.0883],
        [-0.0205,  0.0890, -0.0100,  ...,  0.0547, -0.0785,  0.0046]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.0202, -0.1232, -0.0859,  ..., -0.0651,  0.0317,  0.0426],
        [ 0.1707,  0.1163,  0.1305,  ..., -0.0796,  0.0948,  0.0104],
        [ 0.1070,  0.1161, -0.1409,  ..., -0.0968, -0.1472, -0.1005],
        ...,
        [-0.0714,  0.0446, -0.0720,  ..., -0.1341, -0.1401,  0.0534],
        [ 0.0020,  0.1200,  0.0365,  ...,  0.1635,  0.1511,  0.0663],
        [-0.1669,  0.1331,  0.0677,  ...,  0.0973, -0.0856,  0.0421]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0202, -0.1232, -0.0859,  ..., -0.0651,  0.0317,  0.0426],
        [ 0.1707,  0.1163,  0.1305,  ..., -0.0796,  0.0948,  0.0104],
        [ 0.1070,  0.1161, -0.1409,  ..., -0.0968, -0.1472, -0.1005],
        ...,
        [-0.0714,  0.0446, -0.0720,  ..., -0.1341, -0.1401,  0.0534],
        [ 0.0020,  0.1200,  0.0365,  ...,  0.1635,  0.1511,  0.0663],
        [-0.1669,  0.1331,  0.0677,  ...,  0.0973, -0.0856,  0.0421]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.1679,  0.1383, -0.1994,  ...,  0.1629,  0.1807, -0.1241],
        [-0.2343, -0.0587, -0.0382,  ..., -0.1374,  0.0407,  0.1379],
        [-0.1712, -0.1146, -0.1902,  ...,  0.0433,  0.1436,  0.2060],
        ...,
        [-0.0054, -0.1973,  0.2467,  ...,  0.0663,  0.0670,  0.2163],
        [-0.1235, -0.0221, -0.0980,  ..., -0.2097, -0.0412, -0.0355],
        [ 0.2291,  0.0519,  0.1680,  ...,  0.0059, -0.2025,  0.0723]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1679,  0.1383, -0.1994,  ...,  0.1629,  0.1807, -0.1241],
        [-0.2343, -0.0587, -0.0382,  ..., -0.1374,  0.0407,  0.1379],
        [-0.1712, -0.1146, -0.1902,  ...,  0.0433,  0.1436,  0.2060],
        ...,
        [-0.0054, -0.1973,  0.2467,  ...,  0.0663,  0.0670,  0.2163],
        [-0.1235, -0.0221, -0.0980,  ..., -0.2097, -0.0412, -0.0355],
        [ 0.2291,  0.0519,  0.1680,  ...,  0.0059, -0.2025,  0.0723]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[-0.3645],
        [-0.1219],
        [ 0.0749],
        [ 0.0136],
        [-0.3961],
        [ 0.2935],
        [-0.2091],
        [ 0.3191],
        [ 0.3169],
        [ 0.2928],
        [ 0.3620],
        [-0.3267],
        [ 0.0457],
        [-0.0724],
        [-0.3146],
        [ 0.0927],
        [ 0.3740],
        [ 0.3546],
        [-0.1073],
        [-0.2949],
        [-0.3464],
        [-0.4132],
        [-0.2077],
        [ 0.0111],
        [-0.1588],
        [-0.0646],
        [ 0.1479],
        [ 0.3771],
        [-0.3540],
        [-0.0919],
        [-0.0804],
        [-0.1465]], device='cuda:0') 
 Parameter containing:
tensor([[-0.3645],
        [-0.1219],
        [ 0.0749],
        [ 0.0136],
        [-0.3961],
        [ 0.2935],
        [-0.2091],
        [ 0.3191],
        [ 0.3169],
        [ 0.2928],
        [ 0.3620],
        [-0.3267],
        [ 0.0457],
        [-0.0724],
        [-0.3146],
        [ 0.0927],
        [ 0.3740],
        [ 0.3546],
        [-0.1073],
        [-0.2949],
        [-0.3464],
        [-0.4132],
        [-0.2077],
        [ 0.0111],
        [-0.1588],
        [-0.0646],
        [ 0.1479],
        [ 0.3771],
        [-0.3540],
        [-0.0919],
        [-0.0804],
        [-0.1465]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-16.5747, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(3.1831, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(3.2668, device='cuda:0')



h[100].sum tensor(4.7013, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(4.8250, device='cuda:0')



h[200].sum tensor(-2.6912, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-2.7620, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(2738.5427, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0009, 0.0015, 0.0000,  ..., 0.0000, 0.0025, 0.0000],
        [0.0045, 0.0080, 0.0000,  ..., 0.0000, 0.0129, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(12980.0391, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(175.1056, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(14.0080, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-14.1514, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-15.0444, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0365],
        [0.0447],
        [0.0644],
        ...,
        [0.0103],
        [0.0103],
        [0.0082]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(921.2584, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[0.0365],
        [0.0447],
        [0.0644],
        ...,
        [0.0103],
        [0.0103],
        [0.0082]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(280.0683, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(2.2026, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(2.1848, device='cuda:0')



h[100].sum tensor(12.5362, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(12.4346, device='cuda:0')



h[200].sum tensor(4.1004, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(4.0672, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(16709.0762, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0018, 0.0000, 0.0000,  ..., 0.0019, 0.0000, 0.0000],
        [0.0004, 0.0000, 0.0000,  ..., 0.0004, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(82516.1328, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(142.6917, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(10.0390, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(942.5005, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(66.3093, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-219.6608, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.1215],
        [-0.0745],
        [-0.0456],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(-7135.5449, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[0.0365],
        [0.0447],
        [0.0644],
        ...,
        [0.0103],
        [0.0103],
        [0.0082]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/saved_checkpoint.pth.tar



load_model True 
TraEvN 30001 
BatchSize 5 
EpochNum 50 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[ 0.0445, -0.0171,  0.1381, -0.0046,  0.1376, -0.0198, -0.1090, -0.0483,
         -0.1220, -0.0047,  0.1401, -0.1008, -0.0027,  0.0142, -0.0586, -0.1324,
          0.1192,  0.0009, -0.0450, -0.0264,  0.0592, -0.0883, -0.0637, -0.1075,
         -0.0605, -0.1234,  0.0906, -0.0647,  0.0305, -0.0588, -0.1275,  0.1470,
         -0.0656, -0.0556, -0.0605,  0.0552, -0.0743, -0.1091, -0.0541, -0.1354,
          0.1121, -0.0633,  0.1130,  0.1410,  0.1437, -0.1155, -0.0016,  0.1324,
          0.0715, -0.0380,  0.0506, -0.0526,  0.0217, -0.1149,  0.1497, -0.0809,
         -0.0106, -0.0239,  0.0784, -0.1366,  0.0998, -0.0900, -0.0029,  0.0242,
          0.1330,  0.0234,  0.0302,  0.0607,  0.0859, -0.0659,  0.1254,  0.0399,
          0.0109,  0.1397, -0.0305,  0.0327, -0.1177, -0.0592, -0.0468, -0.1407,
         -0.0659,  0.1492,  0.1159, -0.0452,  0.1422,  0.0333,  0.1459, -0.0670,
          0.1085, -0.0874, -0.0433,  0.0506, -0.1319, -0.0957, -0.0683, -0.0264,
         -0.1471, -0.0829, -0.1068,  0.0542,  0.1277,  0.1462,  0.0599,  0.0995,
          0.0014,  0.0007,  0.0625, -0.0562,  0.0214, -0.0575,  0.0338, -0.1360,
         -0.0777,  0.0696,  0.1262, -0.1048,  0.1426, -0.1331,  0.0079,  0.1072,
          0.0667, -0.0453, -0.1189, -0.0306, -0.1281,  0.1189, -0.0022, -0.0510,
         -0.0598, -0.1071,  0.0648, -0.0972, -0.0544,  0.1024, -0.1108, -0.0669,
         -0.0302,  0.1165, -0.0408, -0.1286, -0.0549,  0.0711, -0.0839, -0.0780,
         -0.0900,  0.0235,  0.1245,  0.0059, -0.0567, -0.0553,  0.0533, -0.0807,
          0.0121, -0.0834, -0.1486, -0.0617,  0.1108,  0.0778,  0.0555, -0.1388,
         -0.0858,  0.0869, -0.0785, -0.1016,  0.0511,  0.0205, -0.1291, -0.0032,
         -0.0983, -0.1478,  0.1094, -0.0827, -0.1377, -0.1025, -0.0857, -0.0248,
         -0.0874,  0.0208,  0.1294, -0.0657,  0.0952,  0.0863, -0.1142, -0.1186,
          0.0094, -0.0157,  0.1378,  0.0995,  0.0847, -0.0658,  0.1475, -0.0651,
          0.0594,  0.1495, -0.1458,  0.0024, -0.0004,  0.0038,  0.0519,  0.0881,
          0.0384, -0.0904,  0.0850,  0.0135,  0.1441,  0.1160,  0.1354, -0.0433,
         -0.1461, -0.1214, -0.0629, -0.1185,  0.1263,  0.1294, -0.0993, -0.1246,
         -0.0764,  0.0650, -0.0459, -0.0266,  0.0983,  0.0284, -0.0477,  0.0215,
          0.0430,  0.1032, -0.0310, -0.0815, -0.1517,  0.0593, -0.0047, -0.0051,
         -0.1466,  0.0488,  0.0615,  0.0205, -0.0615,  0.0990,  0.0965, -0.0842,
         -0.0664, -0.0871, -0.1519, -0.1041, -0.0066,  0.1122, -0.0354,  0.0251,
         -0.0734,  0.1029, -0.1173,  0.0376, -0.0961, -0.0981, -0.0490, -0.0972]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.1060,  0.0687, -0.0436,  ..., -0.0692, -0.0280,  0.0427],
        [-0.0488,  0.1209, -0.0552,  ..., -0.0982,  0.0254,  0.1201],
        [ 0.1123, -0.0144,  0.1150,  ..., -0.1026,  0.0776,  0.0202],
        ...,
        [-0.0731,  0.0577, -0.0823,  ...,  0.0124, -0.0934,  0.0951],
        [ 0.1090,  0.0166,  0.0610,  ..., -0.0931, -0.1028,  0.0147],
        [ 0.0662, -0.0480,  0.0550,  ..., -0.0884,  0.0771,  0.0615]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.1435,  0.1174, -0.0966,  ..., -0.1602,  0.0240,  0.0993],
        [ 0.1625,  0.0577, -0.1581,  ...,  0.0742, -0.1331,  0.0784],
        [ 0.1314,  0.0876, -0.1037,  ..., -0.0271, -0.0091,  0.0638],
        ...,
        [-0.1659, -0.0055,  0.1528,  ...,  0.0439,  0.0290, -0.1158],
        [ 0.0644, -0.1126, -0.0885,  ..., -0.0394,  0.0650, -0.1053],
        [ 0.1041, -0.1442, -0.0221,  ..., -0.0676, -0.0465, -0.1340]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1708, -0.0336, -0.2075,  ..., -0.2122, -0.1406, -0.1956],
        [ 0.0130, -0.0431,  0.1790,  ...,  0.0354,  0.0216,  0.2448],
        [ 0.1838, -0.1149, -0.2311,  ..., -0.2499, -0.2317,  0.1057],
        ...,
        [-0.2320,  0.2063,  0.0206,  ..., -0.0760,  0.0829, -0.2016],
        [-0.0098,  0.0372, -0.0123,  ..., -0.2450, -0.0628,  0.0185],
        [-0.1092,  0.1044,  0.0131,  ..., -0.0233,  0.1471, -0.1496]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.3919],
        [ 0.4109],
        [ 0.3530],
        [-0.2434],
        [ 0.3915],
        [ 0.3614],
        [-0.1820],
        [-0.4100],
        [-0.2530],
        [ 0.0156],
        [-0.0964],
        [-0.4026],
        [-0.3259],
        [ 0.3279],
        [ 0.3438],
        [-0.0161],
        [-0.0591],
        [ 0.0261],
        [-0.0549],
        [ 0.2733],
        [-0.1930],
        [ 0.2539],
        [-0.3846],
        [ 0.3129],
        [ 0.3783],
        [ 0.2063],
        [-0.0158],
        [ 0.1948],
        [ 0.4007],
        [ 0.0300],
        [ 0.1690],
        [-0.3398]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': array(0.0001), 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': array(5.e-05), 'amsgrad': False}]



optimizer.param_groups [{'params': [Parameter containing:
tensor([[ 0.0445, -0.0171,  0.1381, -0.0046,  0.1376, -0.0198, -0.1090, -0.0483,
         -0.1220, -0.0047,  0.1401, -0.1008, -0.0027,  0.0142, -0.0586, -0.1324,
          0.1192,  0.0009, -0.0450, -0.0264,  0.0592, -0.0883, -0.0637, -0.1075,
         -0.0605, -0.1234,  0.0906, -0.0647,  0.0305, -0.0588, -0.1275,  0.1470,
         -0.0656, -0.0556, -0.0605,  0.0552, -0.0743, -0.1091, -0.0541, -0.1354,
          0.1121, -0.0633,  0.1130,  0.1410,  0.1437, -0.1155, -0.0016,  0.1324,
          0.0715, -0.0380,  0.0506, -0.0526,  0.0217, -0.1149,  0.1497, -0.0809,
         -0.0106, -0.0239,  0.0784, -0.1366,  0.0998, -0.0900, -0.0029,  0.0242,
          0.1330,  0.0234,  0.0302,  0.0607,  0.0859, -0.0659,  0.1254,  0.0399,
          0.0109,  0.1397, -0.0305,  0.0327, -0.1177, -0.0592, -0.0468, -0.1407,
         -0.0659,  0.1492,  0.1159, -0.0452,  0.1422,  0.0333,  0.1459, -0.0670,
          0.1085, -0.0874, -0.0433,  0.0506, -0.1319, -0.0957, -0.0683, -0.0264,
         -0.1471, -0.0829, -0.1068,  0.0542,  0.1277,  0.1462,  0.0599,  0.0995,
          0.0014,  0.0007,  0.0625, -0.0562,  0.0214, -0.0575,  0.0338, -0.1360,
         -0.0777,  0.0696,  0.1262, -0.1048,  0.1426, -0.1331,  0.0079,  0.1072,
          0.0667, -0.0453, -0.1189, -0.0306, -0.1281,  0.1189, -0.0022, -0.0510,
         -0.0598, -0.1071,  0.0648, -0.0972, -0.0544,  0.1024, -0.1108, -0.0669,
         -0.0302,  0.1165, -0.0408, -0.1286, -0.0549,  0.0711, -0.0839, -0.0780,
         -0.0900,  0.0235,  0.1245,  0.0059, -0.0567, -0.0553,  0.0533, -0.0807,
          0.0121, -0.0834, -0.1486, -0.0617,  0.1108,  0.0778,  0.0555, -0.1388,
         -0.0858,  0.0869, -0.0785, -0.1016,  0.0511,  0.0205, -0.1291, -0.0032,
         -0.0983, -0.1478,  0.1094, -0.0827, -0.1377, -0.1025, -0.0857, -0.0248,
         -0.0874,  0.0208,  0.1294, -0.0657,  0.0952,  0.0863, -0.1142, -0.1186,
          0.0094, -0.0157,  0.1378,  0.0995,  0.0847, -0.0658,  0.1475, -0.0651,
          0.0594,  0.1495, -0.1458,  0.0024, -0.0004,  0.0038,  0.0519,  0.0881,
          0.0384, -0.0904,  0.0850,  0.0135,  0.1441,  0.1160,  0.1354, -0.0433,
         -0.1461, -0.1214, -0.0629, -0.1185,  0.1263,  0.1294, -0.0993, -0.1246,
         -0.0764,  0.0650, -0.0459, -0.0266,  0.0983,  0.0284, -0.0477,  0.0215,
          0.0430,  0.1032, -0.0310, -0.0815, -0.1517,  0.0593, -0.0047, -0.0051,
         -0.1466,  0.0488,  0.0615,  0.0205, -0.0615,  0.0990,  0.0965, -0.0842,
         -0.0664, -0.0871, -0.1519, -0.1041, -0.0066,  0.1122, -0.0354,  0.0251,
         -0.0734,  0.1029, -0.1173,  0.0376, -0.0961, -0.0981, -0.0490, -0.0972]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.1060,  0.0687, -0.0436,  ..., -0.0692, -0.0280,  0.0427],
        [-0.0488,  0.1209, -0.0552,  ..., -0.0982,  0.0254,  0.1201],
        [ 0.1123, -0.0144,  0.1150,  ..., -0.1026,  0.0776,  0.0202],
        ...,
        [-0.0731,  0.0577, -0.0823,  ...,  0.0124, -0.0934,  0.0951],
        [ 0.1090,  0.0166,  0.0610,  ..., -0.0931, -0.1028,  0.0147],
        [ 0.0662, -0.0480,  0.0550,  ..., -0.0884,  0.0771,  0.0615]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.1435,  0.1174, -0.0966,  ..., -0.1602,  0.0240,  0.0993],
        [ 0.1625,  0.0577, -0.1581,  ...,  0.0742, -0.1331,  0.0784],
        [ 0.1314,  0.0876, -0.1037,  ..., -0.0271, -0.0091,  0.0638],
        ...,
        [-0.1659, -0.0055,  0.1528,  ...,  0.0439,  0.0290, -0.1158],
        [ 0.0644, -0.1126, -0.0885,  ..., -0.0394,  0.0650, -0.1053],
        [ 0.1041, -0.1442, -0.0221,  ..., -0.0676, -0.0465, -0.1340]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1708, -0.0336, -0.2075,  ..., -0.2122, -0.1406, -0.1956],
        [ 0.0130, -0.0431,  0.1790,  ...,  0.0354,  0.0216,  0.2448],
        [ 0.1838, -0.1149, -0.2311,  ..., -0.2499, -0.2317,  0.1057],
        ...,
        [-0.2320,  0.2063,  0.0206,  ..., -0.0760,  0.0829, -0.2016],
        [-0.0098,  0.0372, -0.0123,  ..., -0.2450, -0.0628,  0.0185],
        [-0.1092,  0.1044,  0.0131,  ..., -0.0233,  0.1471, -0.1496]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.3919],
        [ 0.4109],
        [ 0.3530],
        [-0.2434],
        [ 0.3915],
        [ 0.3614],
        [-0.1820],
        [-0.4100],
        [-0.2530],
        [ 0.0156],
        [-0.0964],
        [-0.4026],
        [-0.3259],
        [ 0.3279],
        [ 0.3438],
        [-0.0161],
        [-0.0591],
        [ 0.0261],
        [-0.0549],
        [ 0.2733],
        [-0.1930],
        [ 0.2539],
        [-0.3846],
        [ 0.3129],
        [ 0.3783],
        [ 0.2063],
        [-0.0158],
        [ 0.1948],
        [ 0.4007],
        [ 0.0300],
        [ 0.1690],
        [-0.3398]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': array(0.0001), 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': array(5.e-05), 'amsgrad': False}, {'params': [tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True)], 'lr': array(0.0001), 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': array(5.e-05), 'amsgrad': False}]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py", line 77, in <module>
    featbatch = TraTen[i : i + BatchSize].reshape(BatchSize * 6796, 1)
TypeError: slice indices must be integers or None or have an __index__ method

real	0m53.812s
user	0m16.478s
sys	0m14.451s
