0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        465.19.01
supported:      external
license:        NVIDIA
firmware:       nvidia/465.19.01/gsp.bin
retpoline:      Y
rhelversion:    7.8
srcversion:     976AD09EB9C3B8943CBA8C4
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           nv_cap_enable_devfs:Enable (1) or disable (0) nv-caps devfs support. Default: 1 (int)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           rm_firmware_active:charp

nvidia-smi:
Tue Aug  9 17:12:36 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   25C    P0    32W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.505273344

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2ae3809c7880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m21.652s
user	0m3.648s
sys	0m3.194s
[17:13:00] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 2.6052],
        [ 0.2225],
        [-1.7871],
        ...,
        [ 0.3821],
        [ 0.1833],
        [-0.7568]], device='cuda:0', requires_grad=True) 
node features sum: tensor(13.9411, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (80000, 6796) (80000, 6796)
sum 5574226 8401300
shape torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLpppipiGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-1.3279e-01,  1.2908e-01,  2.9565e-02, -1.1145e-01, -5.6547e-02,
          1.0591e-01,  1.3496e-01, -1.0620e-01,  1.4173e-01,  6.0253e-02,
          1.3007e-01, -1.4119e-01, -1.0934e-01, -1.3534e-01,  4.6340e-02,
         -1.1308e-01,  1.2329e-01,  1.4558e-01,  1.5266e-01,  5.1378e-02,
          1.8506e-04,  7.7160e-02,  9.3944e-02, -1.4186e-01,  1.1389e-01,
          1.4468e-02,  9.3655e-02,  3.4915e-02,  8.7393e-02,  1.4591e-02,
          1.4921e-01,  1.5032e-01,  1.3340e-01, -1.2138e-01,  1.2301e-01,
          1.5394e-03,  8.2930e-02,  2.8806e-02,  7.7995e-02,  4.0358e-02,
         -8.8211e-02,  1.4993e-01,  3.1768e-02,  2.8288e-03,  5.0995e-02,
          8.8428e-02, -3.3935e-03, -7.3442e-02,  1.1283e-01, -4.8641e-02,
         -1.4834e-01,  1.0073e-01, -9.8752e-02,  7.0162e-02, -1.4365e-01,
          1.1050e-01,  1.1025e-01, -3.1199e-02, -1.0350e-01,  3.2632e-02,
         -1.4452e-01,  1.1684e-01, -1.2583e-02,  2.5527e-02,  1.4440e-02,
         -1.1094e-01,  9.6308e-02, -1.8343e-02,  3.7577e-05, -5.5285e-02,
         -6.3414e-02,  1.4257e-01,  1.2386e-01,  7.5688e-02, -7.3821e-02,
          1.3543e-01,  1.9746e-02,  1.9503e-02, -1.3046e-01, -8.4561e-02,
         -1.3483e-01, -1.3532e-01, -9.5897e-02,  6.3217e-04,  1.0418e-01,
          1.3292e-01, -8.0968e-02,  1.4387e-01,  3.8768e-02, -4.1167e-03,
          5.1158e-02,  1.4779e-01,  1.0259e-01,  8.5891e-02, -1.4691e-01,
          6.4528e-02, -6.3166e-02, -5.1824e-02,  1.4907e-01, -9.4404e-02,
         -9.1519e-02, -7.6944e-02, -2.3800e-02,  1.3290e-01,  6.0364e-02,
         -1.4139e-01,  3.3929e-02,  4.4061e-02, -1.0275e-01,  1.4053e-03,
         -1.0174e-01, -5.1891e-02,  7.3985e-02,  8.6902e-02,  8.9800e-02,
          9.6774e-02, -3.3859e-02,  7.5407e-03, -4.1385e-02, -9.9732e-02,
         -9.0994e-03,  4.5010e-02, -2.3453e-02,  1.9618e-03,  5.9712e-02,
         -5.8720e-02,  1.4148e-01, -8.6762e-02,  4.4632e-02, -5.1189e-02,
         -1.2446e-01,  1.1603e-01, -1.0352e-01,  4.6011e-02, -7.7580e-02,
          7.3695e-02, -1.1615e-02,  1.2706e-01, -5.5624e-02, -1.4730e-02,
          1.4005e-01, -4.7316e-02,  1.3540e-01,  7.3226e-02,  8.4115e-02,
          1.3033e-01,  1.2235e-01, -1.1419e-01, -1.4014e-01, -3.4315e-02,
         -1.4639e-01, -3.2207e-02, -7.0708e-02,  1.7250e-02, -6.8726e-03,
         -6.7458e-02,  3.6293e-02, -1.0921e-01,  1.6767e-02, -9.9799e-02,
          1.5241e-01,  6.8985e-02, -1.4146e-01, -3.1544e-02, -3.8104e-02,
         -1.2474e-01,  2.7421e-02, -6.9365e-03,  6.4597e-02, -8.9166e-02,
          1.2944e-02,  2.3065e-02, -9.2232e-02,  9.8133e-02, -9.9013e-02,
         -9.4434e-02,  9.0514e-02,  4.6111e-02, -1.3371e-02,  1.1883e-01,
         -2.1412e-02,  4.2224e-02, -1.3128e-02, -4.9416e-02,  9.4513e-03,
         -2.3376e-02,  1.0301e-01,  7.9463e-02, -8.5101e-02,  2.0985e-02,
          8.5980e-02,  3.3234e-02,  5.4712e-02,  8.0338e-02,  8.0024e-02,
         -1.1388e-01,  9.4664e-02,  1.4872e-01, -3.1558e-02, -5.9869e-02,
          8.6342e-02, -8.1740e-02,  1.3125e-01,  5.7209e-02,  7.5192e-02,
          9.3919e-02, -5.0520e-02, -8.5258e-02, -7.1466e-02,  5.9158e-02,
         -1.0813e-03,  4.2947e-02, -6.8724e-02, -2.6225e-02,  9.0633e-02,
         -4.2413e-03, -8.8276e-02,  9.3214e-02,  4.0961e-02,  1.5078e-01,
         -7.3470e-02, -9.6456e-02, -1.4716e-01,  5.0898e-02, -8.8086e-02,
          9.9685e-02,  6.0025e-02,  3.8334e-02, -5.2777e-02, -1.5166e-01,
          7.9747e-02,  8.0687e-02, -7.4239e-02,  5.3840e-02, -1.0358e-01,
         -5.7930e-02, -1.4585e-01,  8.4942e-02, -1.7494e-02, -1.4371e-01,
         -1.0528e-01, -1.0280e-01, -1.1348e-01, -1.3761e-01, -4.9578e-02,
         -6.4182e-02, -1.1540e-01, -5.1385e-02,  6.7779e-03,  1.2751e-01,
          1.5138e-01,  1.4671e-02,  2.9327e-03,  1.3165e-01,  9.5028e-02,
          4.8591e-02]], device='cuda:0') 
 Parameter containing:
tensor([[-1.3279e-01,  1.2908e-01,  2.9565e-02, -1.1145e-01, -5.6547e-02,
          1.0591e-01,  1.3496e-01, -1.0620e-01,  1.4173e-01,  6.0253e-02,
          1.3007e-01, -1.4119e-01, -1.0934e-01, -1.3534e-01,  4.6340e-02,
         -1.1308e-01,  1.2329e-01,  1.4558e-01,  1.5266e-01,  5.1378e-02,
          1.8506e-04,  7.7160e-02,  9.3944e-02, -1.4186e-01,  1.1389e-01,
          1.4468e-02,  9.3655e-02,  3.4915e-02,  8.7393e-02,  1.4591e-02,
          1.4921e-01,  1.5032e-01,  1.3340e-01, -1.2138e-01,  1.2301e-01,
          1.5394e-03,  8.2930e-02,  2.8806e-02,  7.7995e-02,  4.0358e-02,
         -8.8211e-02,  1.4993e-01,  3.1768e-02,  2.8288e-03,  5.0995e-02,
          8.8428e-02, -3.3935e-03, -7.3442e-02,  1.1283e-01, -4.8641e-02,
         -1.4834e-01,  1.0073e-01, -9.8752e-02,  7.0162e-02, -1.4365e-01,
          1.1050e-01,  1.1025e-01, -3.1199e-02, -1.0350e-01,  3.2632e-02,
         -1.4452e-01,  1.1684e-01, -1.2583e-02,  2.5527e-02,  1.4440e-02,
         -1.1094e-01,  9.6308e-02, -1.8343e-02,  3.7577e-05, -5.5285e-02,
         -6.3414e-02,  1.4257e-01,  1.2386e-01,  7.5688e-02, -7.3821e-02,
          1.3543e-01,  1.9746e-02,  1.9503e-02, -1.3046e-01, -8.4561e-02,
         -1.3483e-01, -1.3532e-01, -9.5897e-02,  6.3217e-04,  1.0418e-01,
          1.3292e-01, -8.0968e-02,  1.4387e-01,  3.8768e-02, -4.1167e-03,
          5.1158e-02,  1.4779e-01,  1.0259e-01,  8.5891e-02, -1.4691e-01,
          6.4528e-02, -6.3166e-02, -5.1824e-02,  1.4907e-01, -9.4404e-02,
         -9.1519e-02, -7.6944e-02, -2.3800e-02,  1.3290e-01,  6.0364e-02,
         -1.4139e-01,  3.3929e-02,  4.4061e-02, -1.0275e-01,  1.4053e-03,
         -1.0174e-01, -5.1891e-02,  7.3985e-02,  8.6902e-02,  8.9800e-02,
          9.6774e-02, -3.3859e-02,  7.5407e-03, -4.1385e-02, -9.9732e-02,
         -9.0994e-03,  4.5010e-02, -2.3453e-02,  1.9618e-03,  5.9712e-02,
         -5.8720e-02,  1.4148e-01, -8.6762e-02,  4.4632e-02, -5.1189e-02,
         -1.2446e-01,  1.1603e-01, -1.0352e-01,  4.6011e-02, -7.7580e-02,
          7.3695e-02, -1.1615e-02,  1.2706e-01, -5.5624e-02, -1.4730e-02,
          1.4005e-01, -4.7316e-02,  1.3540e-01,  7.3226e-02,  8.4115e-02,
          1.3033e-01,  1.2235e-01, -1.1419e-01, -1.4014e-01, -3.4315e-02,
         -1.4639e-01, -3.2207e-02, -7.0708e-02,  1.7250e-02, -6.8726e-03,
         -6.7458e-02,  3.6293e-02, -1.0921e-01,  1.6767e-02, -9.9799e-02,
          1.5241e-01,  6.8985e-02, -1.4146e-01, -3.1544e-02, -3.8104e-02,
         -1.2474e-01,  2.7421e-02, -6.9365e-03,  6.4597e-02, -8.9166e-02,
          1.2944e-02,  2.3065e-02, -9.2232e-02,  9.8133e-02, -9.9013e-02,
         -9.4434e-02,  9.0514e-02,  4.6111e-02, -1.3371e-02,  1.1883e-01,
         -2.1412e-02,  4.2224e-02, -1.3128e-02, -4.9416e-02,  9.4513e-03,
         -2.3376e-02,  1.0301e-01,  7.9463e-02, -8.5101e-02,  2.0985e-02,
          8.5980e-02,  3.3234e-02,  5.4712e-02,  8.0338e-02,  8.0024e-02,
         -1.1388e-01,  9.4664e-02,  1.4872e-01, -3.1558e-02, -5.9869e-02,
          8.6342e-02, -8.1740e-02,  1.3125e-01,  5.7209e-02,  7.5192e-02,
          9.3919e-02, -5.0520e-02, -8.5258e-02, -7.1466e-02,  5.9158e-02,
         -1.0813e-03,  4.2947e-02, -6.8724e-02, -2.6225e-02,  9.0633e-02,
         -4.2413e-03, -8.8276e-02,  9.3214e-02,  4.0961e-02,  1.5078e-01,
         -7.3470e-02, -9.6456e-02, -1.4716e-01,  5.0898e-02, -8.8086e-02,
          9.9685e-02,  6.0025e-02,  3.8334e-02, -5.2777e-02, -1.5166e-01,
          7.9747e-02,  8.0687e-02, -7.4239e-02,  5.3840e-02, -1.0358e-01,
         -5.7930e-02, -1.4585e-01,  8.4942e-02, -1.7494e-02, -1.4371e-01,
         -1.0528e-01, -1.0280e-01, -1.1348e-01, -1.3761e-01, -4.9578e-02,
         -6.4182e-02, -1.1540e-01, -5.1385e-02,  6.7779e-03,  1.2751e-01,
          1.5138e-01,  1.4671e-02,  2.9327e-03,  1.3165e-01,  9.5028e-02,
          4.8591e-02]], device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[-0.0423, -0.0903,  0.1086,  ...,  0.0233,  0.0784, -0.0426],
        [ 0.0311,  0.1069,  0.0861,  ...,  0.0881, -0.0015,  0.1128],
        [-0.0360, -0.0655, -0.0148,  ...,  0.0249, -0.0006,  0.1183],
        ...,
        [-0.0462, -0.0782, -0.0871,  ...,  0.0859, -0.0505,  0.1203],
        [ 0.0760,  0.0981,  0.0249,  ..., -0.0189, -0.0267, -0.1226],
        [ 0.0200,  0.0666, -0.1106,  ..., -0.0822, -0.0122,  0.0104]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0423, -0.0903,  0.1086,  ...,  0.0233,  0.0784, -0.0426],
        [ 0.0311,  0.1069,  0.0861,  ...,  0.0881, -0.0015,  0.1128],
        [-0.0360, -0.0655, -0.0148,  ...,  0.0249, -0.0006,  0.1183],
        ...,
        [-0.0462, -0.0782, -0.0871,  ...,  0.0859, -0.0505,  0.1203],
        [ 0.0760,  0.0981,  0.0249,  ..., -0.0189, -0.0267, -0.1226],
        [ 0.0200,  0.0666, -0.1106,  ..., -0.0822, -0.0122,  0.0104]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.0510, -0.1567, -0.1464,  ..., -0.0675,  0.0003, -0.0735],
        [ 0.1138, -0.1723, -0.1298,  ..., -0.0685,  0.1122, -0.1749],
        [-0.0097,  0.1524, -0.0844,  ..., -0.0208, -0.1729,  0.1515],
        ...,
        [ 0.0372, -0.1661,  0.0812,  ...,  0.1010, -0.0235, -0.0082],
        [-0.0480, -0.1741, -0.1614,  ..., -0.0097, -0.1691,  0.0252],
        [-0.1708, -0.1686,  0.0941,  ..., -0.1129, -0.1362, -0.0300]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0510, -0.1567, -0.1464,  ..., -0.0675,  0.0003, -0.0735],
        [ 0.1138, -0.1723, -0.1298,  ..., -0.0685,  0.1122, -0.1749],
        [-0.0097,  0.1524, -0.0844,  ..., -0.0208, -0.1729,  0.1515],
        ...,
        [ 0.0372, -0.1661,  0.0812,  ...,  0.1010, -0.0235, -0.0082],
        [-0.0480, -0.1741, -0.1614,  ..., -0.0097, -0.1691,  0.0252],
        [-0.1708, -0.1686,  0.0941,  ..., -0.1129, -0.1362, -0.0300]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.0702, -0.2178,  0.0928,  ...,  0.1287,  0.1177,  0.0290],
        [ 0.1202, -0.0777,  0.0870,  ..., -0.2162, -0.0281,  0.1182],
        [-0.1682,  0.1994, -0.1141,  ..., -0.1029, -0.0795, -0.2396],
        ...,
        [ 0.1190,  0.0729, -0.2113,  ..., -0.0998, -0.1821,  0.1203],
        [-0.0200,  0.1000, -0.0868,  ..., -0.0330, -0.1024,  0.2109],
        [-0.0060,  0.2146, -0.1143,  ...,  0.0032,  0.0129,  0.2134]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0702, -0.2178,  0.0928,  ...,  0.1287,  0.1177,  0.0290],
        [ 0.1202, -0.0777,  0.0870,  ..., -0.2162, -0.0281,  0.1182],
        [-0.1682,  0.1994, -0.1141,  ..., -0.1029, -0.0795, -0.2396],
        ...,
        [ 0.1190,  0.0729, -0.2113,  ..., -0.0998, -0.1821,  0.1203],
        [-0.0200,  0.1000, -0.0868,  ..., -0.0330, -0.1024,  0.2109],
        [-0.0060,  0.2146, -0.1143,  ...,  0.0032,  0.0129,  0.2134]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.3896],
        [ 0.2925],
        [-0.0098],
        [ 0.1254],
        [ 0.1495],
        [-0.0764],
        [ 0.1524],
        [ 0.4264],
        [-0.2324],
        [-0.0255],
        [ 0.2916],
        [-0.0386],
        [ 0.3981],
        [ 0.3930],
        [ 0.3924],
        [-0.0324],
        [-0.0353],
        [ 0.2226],
        [-0.2209],
        [ 0.1824],
        [ 0.3620],
        [ 0.0871],
        [-0.3388],
        [ 0.1480],
        [-0.2751],
        [-0.2271],
        [ 0.2800],
        [-0.3519],
        [ 0.1850],
        [-0.1865],
        [-0.0783],
        [-0.2677]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.3896],
        [ 0.2925],
        [-0.0098],
        [ 0.1254],
        [ 0.1495],
        [-0.0764],
        [ 0.1524],
        [ 0.4264],
        [-0.2324],
        [-0.0255],
        [ 0.2916],
        [-0.0386],
        [ 0.3981],
        [ 0.3930],
        [ 0.3924],
        [-0.0324],
        [-0.0353],
        [ 0.2226],
        [-0.2209],
        [ 0.1824],
        [ 0.3620],
        [ 0.0871],
        [-0.3388],
        [ 0.1480],
        [-0.2751],
        [-0.2271],
        [ 0.2800],
        [-0.3519],
        [ 0.1850],
        [-0.1865],
        [-0.0783],
        [-0.2677]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.1057,  0.1068, -0.0647, -0.1024, -0.0751,  0.0818,  0.0164, -0.0255,
          0.1101, -0.0915, -0.0914,  0.0736, -0.0687, -0.0020,  0.1269, -0.1422,
          0.0899, -0.0261,  0.0041, -0.1017, -0.0826,  0.0121, -0.0506,  0.0615,
         -0.0017,  0.0675, -0.0380,  0.0114,  0.0994, -0.0440,  0.1141, -0.1159,
          0.1475, -0.0798,  0.1162, -0.1054,  0.0918, -0.0286,  0.1145,  0.1019,
         -0.0445,  0.0103, -0.0730,  0.0450,  0.0580, -0.0357, -0.0353,  0.1047,
          0.0628,  0.0656, -0.0631, -0.1293,  0.1219,  0.0842, -0.0532,  0.1514,
          0.0542,  0.1149, -0.0839, -0.0137,  0.1439, -0.0650, -0.0486, -0.0927,
         -0.0464, -0.0442, -0.0780,  0.0314, -0.1314, -0.0199, -0.0177, -0.0370,
          0.0827, -0.0133, -0.0743,  0.0435,  0.1137, -0.1325, -0.1444, -0.1367,
         -0.0422, -0.1397, -0.0213,  0.1506, -0.0773, -0.0226, -0.1232, -0.1483,
          0.1133, -0.0371, -0.1073, -0.1384, -0.1220,  0.0129, -0.0434,  0.0589,
          0.0402, -0.0723, -0.1174,  0.0537,  0.0335,  0.0506,  0.0713, -0.1125,
          0.1157,  0.0874,  0.0386,  0.1371, -0.0986, -0.1059, -0.0344, -0.0331,
          0.0876, -0.0981, -0.0314,  0.0909, -0.0171,  0.0048,  0.1334, -0.1167,
         -0.1066, -0.0125, -0.0171, -0.1157,  0.1008,  0.0910, -0.1152, -0.0431,
         -0.0379, -0.0475,  0.1200,  0.0636,  0.0035, -0.1190, -0.0562, -0.0013,
          0.0313,  0.0386, -0.1246, -0.0163, -0.0064,  0.0672,  0.0134,  0.0940,
          0.0188, -0.0025, -0.0689,  0.0763,  0.1066,  0.0117, -0.0769, -0.0186,
          0.0413,  0.0019,  0.0112, -0.0083, -0.0792, -0.0584, -0.0342, -0.0155,
         -0.1068, -0.0304, -0.0808, -0.0288,  0.1507,  0.0591,  0.0997, -0.1169,
          0.0062, -0.1383, -0.1004,  0.0405, -0.1038,  0.0680, -0.0253,  0.1463,
         -0.0846,  0.0326,  0.0577, -0.1257,  0.0399,  0.1225, -0.0062,  0.0569,
          0.1034, -0.0717, -0.0885, -0.1114, -0.0949,  0.0844,  0.0113, -0.0718,
          0.1478, -0.0897,  0.0949, -0.0307,  0.1112, -0.1263, -0.0597, -0.0976,
          0.0075, -0.0505,  0.1222, -0.0699, -0.1124, -0.1389,  0.0074,  0.0905,
          0.0621,  0.0678,  0.1352,  0.0527, -0.0342,  0.0006,  0.0563,  0.0655,
         -0.1320,  0.0718, -0.0971,  0.1262, -0.1168,  0.0634,  0.0449,  0.0407,
          0.0947, -0.1157,  0.0972, -0.1434, -0.0822,  0.1102, -0.0075,  0.0749,
         -0.1090, -0.0846, -0.1214, -0.0765,  0.1095,  0.0998, -0.0848,  0.1341,
          0.1319, -0.0013, -0.0196,  0.0033,  0.0189,  0.0047, -0.1291,  0.1033,
         -0.0932,  0.1505,  0.1160, -0.0321,  0.1411,  0.0374, -0.0357, -0.0165]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1057,  0.1068, -0.0647, -0.1024, -0.0751,  0.0818,  0.0164, -0.0255,
          0.1101, -0.0915, -0.0914,  0.0736, -0.0687, -0.0020,  0.1269, -0.1422,
          0.0899, -0.0261,  0.0041, -0.1017, -0.0826,  0.0121, -0.0506,  0.0615,
         -0.0017,  0.0675, -0.0380,  0.0114,  0.0994, -0.0440,  0.1141, -0.1159,
          0.1475, -0.0798,  0.1162, -0.1054,  0.0918, -0.0286,  0.1145,  0.1019,
         -0.0445,  0.0103, -0.0730,  0.0450,  0.0580, -0.0357, -0.0353,  0.1047,
          0.0628,  0.0656, -0.0631, -0.1293,  0.1219,  0.0842, -0.0532,  0.1514,
          0.0542,  0.1149, -0.0839, -0.0137,  0.1439, -0.0650, -0.0486, -0.0927,
         -0.0464, -0.0442, -0.0780,  0.0314, -0.1314, -0.0199, -0.0177, -0.0370,
          0.0827, -0.0133, -0.0743,  0.0435,  0.1137, -0.1325, -0.1444, -0.1367,
         -0.0422, -0.1397, -0.0213,  0.1506, -0.0773, -0.0226, -0.1232, -0.1483,
          0.1133, -0.0371, -0.1073, -0.1384, -0.1220,  0.0129, -0.0434,  0.0589,
          0.0402, -0.0723, -0.1174,  0.0537,  0.0335,  0.0506,  0.0713, -0.1125,
          0.1157,  0.0874,  0.0386,  0.1371, -0.0986, -0.1059, -0.0344, -0.0331,
          0.0876, -0.0981, -0.0314,  0.0909, -0.0171,  0.0048,  0.1334, -0.1167,
         -0.1066, -0.0125, -0.0171, -0.1157,  0.1008,  0.0910, -0.1152, -0.0431,
         -0.0379, -0.0475,  0.1200,  0.0636,  0.0035, -0.1190, -0.0562, -0.0013,
          0.0313,  0.0386, -0.1246, -0.0163, -0.0064,  0.0672,  0.0134,  0.0940,
          0.0188, -0.0025, -0.0689,  0.0763,  0.1066,  0.0117, -0.0769, -0.0186,
          0.0413,  0.0019,  0.0112, -0.0083, -0.0792, -0.0584, -0.0342, -0.0155,
         -0.1068, -0.0304, -0.0808, -0.0288,  0.1507,  0.0591,  0.0997, -0.1169,
          0.0062, -0.1383, -0.1004,  0.0405, -0.1038,  0.0680, -0.0253,  0.1463,
         -0.0846,  0.0326,  0.0577, -0.1257,  0.0399,  0.1225, -0.0062,  0.0569,
          0.1034, -0.0717, -0.0885, -0.1114, -0.0949,  0.0844,  0.0113, -0.0718,
          0.1478, -0.0897,  0.0949, -0.0307,  0.1112, -0.1263, -0.0597, -0.0976,
          0.0075, -0.0505,  0.1222, -0.0699, -0.1124, -0.1389,  0.0074,  0.0905,
          0.0621,  0.0678,  0.1352,  0.0527, -0.0342,  0.0006,  0.0563,  0.0655,
         -0.1320,  0.0718, -0.0971,  0.1262, -0.1168,  0.0634,  0.0449,  0.0407,
          0.0947, -0.1157,  0.0972, -0.1434, -0.0822,  0.1102, -0.0075,  0.0749,
         -0.1090, -0.0846, -0.1214, -0.0765,  0.1095,  0.0998, -0.0848,  0.1341,
          0.1319, -0.0013, -0.0196,  0.0033,  0.0189,  0.0047, -0.1291,  0.1033,
         -0.0932,  0.1505,  0.1160, -0.0321,  0.1411,  0.0374, -0.0357, -0.0165]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0859,  0.0160, -0.0663,  ..., -0.1139,  0.0643,  0.1170],
        [-0.0652, -0.0733,  0.1048,  ...,  0.0727,  0.0268,  0.0224],
        [ 0.0951, -0.0891,  0.0150,  ..., -0.0865, -0.0566, -0.0359],
        ...,
        [ 0.0929, -0.0657,  0.0290,  ...,  0.1093,  0.0728,  0.0525],
        [-0.1141, -0.0216,  0.0399,  ..., -0.1217, -0.1177, -0.0834],
        [-0.1169,  0.0714,  0.0069,  ...,  0.0644,  0.0842, -0.1054]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0859,  0.0160, -0.0663,  ..., -0.1139,  0.0643,  0.1170],
        [-0.0652, -0.0733,  0.1048,  ...,  0.0727,  0.0268,  0.0224],
        [ 0.0951, -0.0891,  0.0150,  ..., -0.0865, -0.0566, -0.0359],
        ...,
        [ 0.0929, -0.0657,  0.0290,  ...,  0.1093,  0.0728,  0.0525],
        [-0.1141, -0.0216,  0.0399,  ..., -0.1217, -0.1177, -0.0834],
        [-0.1169,  0.0714,  0.0069,  ...,  0.0644,  0.0842, -0.1054]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.0757, -0.0705,  0.1630,  ...,  0.0455, -0.1396,  0.0859],
        [-0.0248, -0.0749, -0.0923,  ..., -0.1420, -0.0158,  0.1002],
        [-0.0325,  0.1233,  0.0225,  ..., -0.0663,  0.1558,  0.0352],
        ...,
        [-0.1488, -0.0744, -0.0623,  ..., -0.0216,  0.0115,  0.1024],
        [ 0.0558, -0.0808,  0.0182,  ...,  0.0013, -0.1310, -0.1278],
        [ 0.0649, -0.0289,  0.1213,  ...,  0.0123, -0.0709,  0.1708]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0757, -0.0705,  0.1630,  ...,  0.0455, -0.1396,  0.0859],
        [-0.0248, -0.0749, -0.0923,  ..., -0.1420, -0.0158,  0.1002],
        [-0.0325,  0.1233,  0.0225,  ..., -0.0663,  0.1558,  0.0352],
        ...,
        [-0.1488, -0.0744, -0.0623,  ..., -0.0216,  0.0115,  0.1024],
        [ 0.0558, -0.0808,  0.0182,  ...,  0.0013, -0.1310, -0.1278],
        [ 0.0649, -0.0289,  0.1213,  ...,  0.0123, -0.0709,  0.1708]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[ 0.2028,  0.1973, -0.0295,  ...,  0.0048, -0.2219, -0.1736],
        [ 0.0072, -0.1952, -0.2338,  ...,  0.1277,  0.1202,  0.1598],
        [ 0.0618, -0.1832, -0.2345,  ..., -0.0148,  0.1361, -0.0341],
        ...,
        [ 0.0233,  0.0882, -0.2378,  ...,  0.1528, -0.0349, -0.0438],
        [ 0.1521,  0.0185,  0.0790,  ..., -0.0901, -0.1727, -0.0385],
        [ 0.1571,  0.1442,  0.0062,  ..., -0.2386, -0.0529,  0.2476]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.2028,  0.1973, -0.0295,  ...,  0.0048, -0.2219, -0.1736],
        [ 0.0072, -0.1952, -0.2338,  ...,  0.1277,  0.1202,  0.1598],
        [ 0.0618, -0.1832, -0.2345,  ..., -0.0148,  0.1361, -0.0341],
        ...,
        [ 0.0233,  0.0882, -0.2378,  ...,  0.1528, -0.0349, -0.0438],
        [ 0.1521,  0.0185,  0.0790,  ..., -0.0901, -0.1727, -0.0385],
        [ 0.1571,  0.1442,  0.0062,  ..., -0.2386, -0.0529,  0.2476]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[-0.3751],
        [ 0.4091],
        [ 0.0893],
        [-0.2354],
        [-0.0313],
        [-0.3119],
        [ 0.2597],
        [ 0.4139],
        [-0.2598],
        [-0.0082],
        [-0.2951],
        [-0.4060],
        [-0.2788],
        [-0.4075],
        [ 0.0622],
        [-0.0243],
        [-0.3671],
        [ 0.2035],
        [ 0.2497],
        [ 0.2029],
        [ 0.4030],
        [ 0.3560],
        [-0.2175],
        [ 0.0729],
        [-0.3292],
        [ 0.3258],
        [ 0.3366],
        [ 0.3475],
        [ 0.4097],
        [-0.1860],
        [-0.3345],
        [ 0.3507]], device='cuda:0') 
 Parameter containing:
tensor([[-0.3751],
        [ 0.4091],
        [ 0.0893],
        [-0.2354],
        [-0.0313],
        [-0.3119],
        [ 0.2597],
        [ 0.4139],
        [-0.2598],
        [-0.0082],
        [-0.2951],
        [-0.4060],
        [-0.2788],
        [-0.4075],
        [ 0.0622],
        [-0.0243],
        [-0.3671],
        [ 0.2035],
        [ 0.2497],
        [ 0.2029],
        [ 0.4030],
        [ 0.3560],
        [-0.2175],
        [ 0.0729],
        [-0.3292],
        [ 0.3258],
        [ 0.3366],
        [ 0.3475],
        [ 0.4097],
        [-0.1860],
        [-0.3345],
        [ 0.3507]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(7.2591, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-4.4812, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-4.5992, device='cuda:0')



h[100].sum tensor(-0.9960, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-1.0222, device='cuda:0')



h[200].sum tensor(-2.7051, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-2.7763, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(2795.9998, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 8.6134e-05, 4.6194e-04,  ..., 2.9725e-04, 1.9994e-03,
         2.1891e-03],
        [0.0000e+00, 4.4823e-04, 2.4094e-03,  ..., 1.5507e-03, 1.0432e-02,
         1.1422e-02],
        ...,
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00]], device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(11475.1582, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-18.8792, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-0.8491, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-12.6915, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.0190],
        [-0.0232],
        [-0.0335],
        ...,
        [-0.0054],
        [-0.0054],
        [-0.0043]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-478.9330, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[-0.0190],
        [-0.0232],
        [-0.0335],
        ...,
        [-0.0054],
        [-0.0054],
        [-0.0043]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(107.4691, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-9.5766, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-9.4990, device='cuda:0')



h[100].sum tensor(-19.7634, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-19.6032, device='cuda:0')



h[200].sum tensor(-11.3363, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-11.2445, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(15172.3477, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0109,  ..., 0.0000, 0.0000, 0.0125],
        [0.0000, 0.0000, 0.0023,  ..., 0.0000, 0.0000, 0.0026],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(79320.3906, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-359.4918, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-97.0976, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(2958.5796, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(208.1306, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.1171],
        [-0.0718],
        [-0.0439],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(-6875.6025, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-0.0190],
        [-0.0232],
        [-0.0335],
        ...,
        [-0.0054],
        [-0.0054],
        [-0.0043]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py", line 5, in <module>
    from ModelBha import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/ModelBha.py", line 169, in <module>
    fig.colorbar(ax3.matshow(sitonsquare(traingnnpppipi[EvBTr + 10]).get(), aspect=2, vmin=0, vmax=1, extent=[0, 288, 0, 43], origin='lower')\
AttributeError: 'numpy.ndarray' object has no attribute 'get'

real	0m50.673s
user	0m17.540s
sys	0m12.125s
