0: gpu016.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-2135d612-642f-4ad0-ea96-14ef624f2286)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        450.36.06
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.8
srcversion:     BB5CB243542347D4EB0C79C
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_MapRegistersEarly:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_EnableBacklightHandler:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_AssignGpus:charp

nvidia-smi:
Wed Aug  3 01:19:25 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |
| N/A   31C    P0    44W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089730048

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b0361a96fa0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	1m23.091s
user	0m3.392s
sys	0m2.414s
[01:20:53] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py:125: RuntimeWarning: invalid value encountered in true_divide
  purres = purity.sum(axis = 0) / (purity!=0).sum(axis = 0)
/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py:126: RuntimeWarning: invalid value encountered in true_divide
  effres = efficiency.sum(axis = 0) / (efficiency!=0).sum(axis = 0)
/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py:127: RuntimeWarning: invalid value encountered in true_divide
  eval_purres = eval_purity.sum(axis = 0) / (eval_purity!=0).sum(axis = 0)
/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py:128: RuntimeWarning: invalid value encountered in true_divide
  eval_effres = eval_efficiency.sum(axis = 0) / (eval_efficiency!=0).sum(axis = 0)




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 1.4975],
        [ 1.1802],
        [-1.4970],
        ...,
        [ 0.0177],
        [-0.6530],
        [ 0.3686]], device='cuda:0', requires_grad=True) 
node features sum: tensor(1.8428, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (80000, 6796) (80000, 6796)
sum 5574226 8401300
shape torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLpppipiGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.1163, -0.1043, -0.0203, -0.0014, -0.1373, -0.0351,  0.1118, -0.0626,
         -0.0553, -0.0999, -0.0816, -0.0124, -0.1272, -0.0647,  0.1253, -0.0241,
          0.0455, -0.1219, -0.1231,  0.0342,  0.1474,  0.0123, -0.0903, -0.0174,
          0.0491,  0.0503, -0.0362,  0.0585,  0.0221, -0.1069, -0.0423,  0.1198,
         -0.1371,  0.0505,  0.1017, -0.1292, -0.0631,  0.0782, -0.0041,  0.0010,
         -0.0994, -0.1028, -0.1256,  0.1374, -0.1044,  0.0973, -0.1445, -0.1243,
          0.0497,  0.0773, -0.1337, -0.1131,  0.0822,  0.1312, -0.0835, -0.0187,
          0.1055, -0.0244, -0.0423, -0.1157, -0.1020, -0.0898,  0.0108,  0.1134,
         -0.0286,  0.1455, -0.0379,  0.1037, -0.1319,  0.0353, -0.0623, -0.0709,
         -0.0547, -0.0365, -0.0181, -0.0062, -0.1232,  0.1307,  0.0539, -0.0767,
         -0.0361, -0.0207,  0.0024,  0.0650,  0.1084,  0.0569, -0.0419, -0.0124,
         -0.1084, -0.1480, -0.1130, -0.0965, -0.0958,  0.0628,  0.0017,  0.1328,
         -0.0333,  0.1141, -0.1517,  0.0024,  0.1014,  0.1286,  0.0359, -0.0840,
          0.1289,  0.0804,  0.0330, -0.1268,  0.0597, -0.0199,  0.0284, -0.0996,
         -0.0759,  0.1463,  0.0667,  0.1372, -0.1004,  0.1121,  0.1224,  0.1263,
         -0.0466, -0.0443,  0.1184, -0.1000,  0.0607, -0.1047, -0.0309, -0.0757,
          0.0211,  0.0498,  0.1125, -0.0644,  0.0615,  0.1493,  0.0923, -0.0862,
         -0.0624, -0.1100,  0.1519,  0.0345,  0.0960,  0.1280, -0.0686,  0.0135,
         -0.0647,  0.0919,  0.0991, -0.1326, -0.0826, -0.1422,  0.0690,  0.0832,
          0.1093, -0.1317, -0.0882,  0.0098,  0.1182, -0.0842,  0.0677, -0.0935,
          0.0528,  0.1241,  0.0834, -0.1166, -0.1154,  0.1114, -0.0898, -0.0750,
          0.1159, -0.0474,  0.0958,  0.0315,  0.1231, -0.0674,  0.0577, -0.0297,
         -0.0552,  0.0069,  0.1020,  0.1083,  0.1368,  0.1165,  0.1445, -0.0090,
          0.1367,  0.0889, -0.1408,  0.0258,  0.1017, -0.1190,  0.1170, -0.1047,
          0.1377, -0.1491,  0.1331, -0.0178, -0.0942,  0.1215,  0.0674,  0.0857,
          0.0331, -0.1247, -0.0071,  0.0302, -0.1227,  0.1405, -0.0742,  0.0716,
          0.0813,  0.0351, -0.0075, -0.1482, -0.0386,  0.0637, -0.0195,  0.0317,
         -0.0681,  0.0288,  0.1302, -0.0833,  0.0415,  0.0005,  0.1347, -0.1169,
          0.0174,  0.0940,  0.0577,  0.0778,  0.0624,  0.0381, -0.0619,  0.0532,
         -0.0376,  0.0455,  0.1101, -0.1057, -0.0015,  0.1037,  0.0884,  0.0074,
         -0.0633,  0.0637, -0.0335, -0.0186,  0.1107,  0.0064,  0.0254,  0.0307,
          0.0842,  0.0167,  0.1143,  0.0259, -0.0417,  0.0722, -0.0606, -0.0960]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1163, -0.1043, -0.0203, -0.0014, -0.1373, -0.0351,  0.1118, -0.0626,
         -0.0553, -0.0999, -0.0816, -0.0124, -0.1272, -0.0647,  0.1253, -0.0241,
          0.0455, -0.1219, -0.1231,  0.0342,  0.1474,  0.0123, -0.0903, -0.0174,
          0.0491,  0.0503, -0.0362,  0.0585,  0.0221, -0.1069, -0.0423,  0.1198,
         -0.1371,  0.0505,  0.1017, -0.1292, -0.0631,  0.0782, -0.0041,  0.0010,
         -0.0994, -0.1028, -0.1256,  0.1374, -0.1044,  0.0973, -0.1445, -0.1243,
          0.0497,  0.0773, -0.1337, -0.1131,  0.0822,  0.1312, -0.0835, -0.0187,
          0.1055, -0.0244, -0.0423, -0.1157, -0.1020, -0.0898,  0.0108,  0.1134,
         -0.0286,  0.1455, -0.0379,  0.1037, -0.1319,  0.0353, -0.0623, -0.0709,
         -0.0547, -0.0365, -0.0181, -0.0062, -0.1232,  0.1307,  0.0539, -0.0767,
         -0.0361, -0.0207,  0.0024,  0.0650,  0.1084,  0.0569, -0.0419, -0.0124,
         -0.1084, -0.1480, -0.1130, -0.0965, -0.0958,  0.0628,  0.0017,  0.1328,
         -0.0333,  0.1141, -0.1517,  0.0024,  0.1014,  0.1286,  0.0359, -0.0840,
          0.1289,  0.0804,  0.0330, -0.1268,  0.0597, -0.0199,  0.0284, -0.0996,
         -0.0759,  0.1463,  0.0667,  0.1372, -0.1004,  0.1121,  0.1224,  0.1263,
         -0.0466, -0.0443,  0.1184, -0.1000,  0.0607, -0.1047, -0.0309, -0.0757,
          0.0211,  0.0498,  0.1125, -0.0644,  0.0615,  0.1493,  0.0923, -0.0862,
         -0.0624, -0.1100,  0.1519,  0.0345,  0.0960,  0.1280, -0.0686,  0.0135,
         -0.0647,  0.0919,  0.0991, -0.1326, -0.0826, -0.1422,  0.0690,  0.0832,
          0.1093, -0.1317, -0.0882,  0.0098,  0.1182, -0.0842,  0.0677, -0.0935,
          0.0528,  0.1241,  0.0834, -0.1166, -0.1154,  0.1114, -0.0898, -0.0750,
          0.1159, -0.0474,  0.0958,  0.0315,  0.1231, -0.0674,  0.0577, -0.0297,
         -0.0552,  0.0069,  0.1020,  0.1083,  0.1368,  0.1165,  0.1445, -0.0090,
          0.1367,  0.0889, -0.1408,  0.0258,  0.1017, -0.1190,  0.1170, -0.1047,
          0.1377, -0.1491,  0.1331, -0.0178, -0.0942,  0.1215,  0.0674,  0.0857,
          0.0331, -0.1247, -0.0071,  0.0302, -0.1227,  0.1405, -0.0742,  0.0716,
          0.0813,  0.0351, -0.0075, -0.1482, -0.0386,  0.0637, -0.0195,  0.0317,
         -0.0681,  0.0288,  0.1302, -0.0833,  0.0415,  0.0005,  0.1347, -0.1169,
          0.0174,  0.0940,  0.0577,  0.0778,  0.0624,  0.0381, -0.0619,  0.0532,
         -0.0376,  0.0455,  0.1101, -0.1057, -0.0015,  0.1037,  0.0884,  0.0074,
         -0.0633,  0.0637, -0.0335, -0.0186,  0.1107,  0.0064,  0.0254,  0.0307,
          0.0842,  0.0167,  0.1143,  0.0259, -0.0417,  0.0722, -0.0606, -0.0960]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[-0.1126, -0.1103, -0.1043,  ..., -0.0227,  0.0347,  0.1012],
        [-0.0139, -0.0659, -0.0638,  ..., -0.1174,  0.1118,  0.0609],
        [ 0.0481, -0.0758, -0.0632,  ..., -0.0214, -0.0705,  0.1003],
        ...,
        [-0.0158,  0.0681, -0.0290,  ...,  0.0500, -0.0556,  0.0073],
        [-0.0858, -0.0420, -0.0687,  ...,  0.0513,  0.0681, -0.0376],
        [-0.0242, -0.0646,  0.0784,  ..., -0.0099, -0.0020,  0.0479]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1126, -0.1103, -0.1043,  ..., -0.0227,  0.0347,  0.1012],
        [-0.0139, -0.0659, -0.0638,  ..., -0.1174,  0.1118,  0.0609],
        [ 0.0481, -0.0758, -0.0632,  ..., -0.0214, -0.0705,  0.1003],
        ...,
        [-0.0158,  0.0681, -0.0290,  ...,  0.0500, -0.0556,  0.0073],
        [-0.0858, -0.0420, -0.0687,  ...,  0.0513,  0.0681, -0.0376],
        [-0.0242, -0.0646,  0.0784,  ..., -0.0099, -0.0020,  0.0479]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.1257,  0.0238,  0.0397,  ..., -0.1417, -0.1658, -0.0011],
        [-0.1164, -0.0489,  0.1011,  ...,  0.1385,  0.1573, -0.1720],
        [ 0.0756,  0.0173,  0.1360,  ...,  0.0943,  0.0317, -0.1506],
        ...,
        [-0.0164, -0.0544, -0.0432,  ...,  0.0947, -0.0034, -0.0987],
        [-0.0558, -0.0909, -0.0038,  ..., -0.0436, -0.0249,  0.1621],
        [-0.0516, -0.0270, -0.0905,  ..., -0.0423,  0.0608, -0.1652]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1257,  0.0238,  0.0397,  ..., -0.1417, -0.1658, -0.0011],
        [-0.1164, -0.0489,  0.1011,  ...,  0.1385,  0.1573, -0.1720],
        [ 0.0756,  0.0173,  0.1360,  ...,  0.0943,  0.0317, -0.1506],
        ...,
        [-0.0164, -0.0544, -0.0432,  ...,  0.0947, -0.0034, -0.0987],
        [-0.0558, -0.0909, -0.0038,  ..., -0.0436, -0.0249,  0.1621],
        [-0.0516, -0.0270, -0.0905,  ..., -0.0423,  0.0608, -0.1652]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[ 0.1119, -0.2449,  0.1183,  ..., -0.0404,  0.0598, -0.1226],
        [ 0.2097,  0.1695,  0.1426,  ...,  0.2425, -0.2215,  0.2298],
        [ 0.1894,  0.2002, -0.1608,  ...,  0.0787,  0.0692,  0.1434],
        ...,
        [ 0.1633,  0.1858,  0.1861,  ..., -0.2358,  0.0302,  0.1664],
        [ 0.1085,  0.0465, -0.1543,  ..., -0.0110, -0.1300,  0.0897],
        [-0.0853, -0.1300,  0.1102,  ...,  0.2351, -0.0922,  0.0693]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1119, -0.2449,  0.1183,  ..., -0.0404,  0.0598, -0.1226],
        [ 0.2097,  0.1695,  0.1426,  ...,  0.2425, -0.2215,  0.2298],
        [ 0.1894,  0.2002, -0.1608,  ...,  0.0787,  0.0692,  0.1434],
        ...,
        [ 0.1633,  0.1858,  0.1861,  ..., -0.2358,  0.0302,  0.1664],
        [ 0.1085,  0.0465, -0.1543,  ..., -0.0110, -0.1300,  0.0897],
        [-0.0853, -0.1300,  0.1102,  ...,  0.2351, -0.0922,  0.0693]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.0888],
        [-0.3194],
        [-0.2977],
        [-0.2289],
        [-0.0008],
        [ 0.2696],
        [ 0.2980],
        [ 0.1287],
        [ 0.0443],
        [ 0.2960],
        [-0.0414],
        [ 0.0266],
        [-0.3934],
        [-0.1533],
        [ 0.3822],
        [-0.1423],
        [ 0.2965],
        [ 0.2625],
        [ 0.1294],
        [ 0.1674],
        [ 0.3107],
        [-0.4101],
        [ 0.2746],
        [ 0.2709],
        [-0.0727],
        [ 0.1322],
        [-0.3049],
        [-0.3452],
        [ 0.2709],
        [ 0.0485],
        [-0.1264],
        [-0.0748]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.0888],
        [-0.3194],
        [-0.2977],
        [-0.2289],
        [-0.0008],
        [ 0.2696],
        [ 0.2980],
        [ 0.1287],
        [ 0.0443],
        [ 0.2960],
        [-0.0414],
        [ 0.0266],
        [-0.3934],
        [-0.1533],
        [ 0.3822],
        [-0.1423],
        [ 0.2965],
        [ 0.2625],
        [ 0.1294],
        [ 0.1674],
        [ 0.3107],
        [-0.4101],
        [ 0.2746],
        [ 0.2709],
        [-0.0727],
        [ 0.1322],
        [-0.3049],
        [-0.3452],
        [ 0.2709],
        [ 0.0485],
        [-0.1264],
        [-0.0748]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.0720, -0.0465, -0.0876, -0.1331, -0.0276,  0.0045, -0.0056,  0.1076,
         -0.1319, -0.0825,  0.0037, -0.0330, -0.0077,  0.0271, -0.0179, -0.1205,
         -0.0949,  0.1222, -0.0415,  0.0748,  0.0413, -0.0945,  0.1429,  0.0819,
          0.0593,  0.0843,  0.1156, -0.1079,  0.0405,  0.1041, -0.1115, -0.0441,
          0.0921, -0.0941, -0.1458,  0.0602, -0.1232,  0.0384,  0.1479, -0.0846,
         -0.0894, -0.1455,  0.0589,  0.0029,  0.1519, -0.0230,  0.0711, -0.0393,
         -0.1505, -0.0136,  0.1442, -0.0213,  0.1063,  0.1243,  0.0405, -0.1350,
          0.1197,  0.1265, -0.0843,  0.0885,  0.1377, -0.0635, -0.0688, -0.1242,
         -0.0040, -0.0730, -0.0540,  0.1518,  0.1205,  0.1369, -0.1442, -0.0784,
          0.0782, -0.0196, -0.1152,  0.1026,  0.0816,  0.1285, -0.0255,  0.1329,
          0.1164,  0.0809,  0.0681, -0.1513,  0.1123, -0.0404,  0.1142,  0.1292,
          0.0921, -0.0355,  0.1200,  0.0691, -0.1373, -0.1217, -0.0551,  0.1215,
         -0.1303, -0.1355, -0.0317,  0.0496, -0.0104, -0.0112,  0.0844, -0.0213,
         -0.0337,  0.1025,  0.0042,  0.1472, -0.0062,  0.0836, -0.0666, -0.1342,
         -0.1518, -0.1269,  0.0412,  0.0345,  0.0163,  0.1024, -0.0798,  0.0926,
          0.0158,  0.0801, -0.0153,  0.0893, -0.0975, -0.1195, -0.1390, -0.0616,
          0.0317,  0.1289,  0.0558,  0.0047,  0.1349,  0.1363, -0.0687,  0.0050,
          0.1092, -0.1293, -0.0823, -0.0863,  0.1063,  0.0865, -0.1311,  0.0979,
          0.0457,  0.0050,  0.0507, -0.1258, -0.0527, -0.1153,  0.1521,  0.1128,
         -0.0863,  0.1184, -0.0440,  0.1296,  0.0385,  0.1324, -0.1338, -0.0178,
         -0.0404,  0.0120,  0.0761, -0.0132,  0.0413, -0.1172, -0.0759,  0.1163,
          0.0769,  0.1469, -0.0132, -0.0216,  0.0786, -0.1249,  0.0440,  0.1497,
          0.0365,  0.1425, -0.1057,  0.0955,  0.0468,  0.0409, -0.0108, -0.1343,
          0.1089,  0.0682,  0.0646, -0.0755, -0.0268, -0.0711, -0.0853,  0.1076,
         -0.0128, -0.0650,  0.1086,  0.0186,  0.0923,  0.0300, -0.0823,  0.0047,
          0.0817, -0.0417, -0.0850, -0.1191,  0.0464,  0.0844,  0.0078,  0.0659,
          0.0959,  0.0249,  0.0221, -0.0935,  0.1412, -0.0985, -0.0617, -0.1036,
         -0.0975, -0.1131, -0.1349,  0.0561, -0.0147,  0.0333,  0.0623,  0.0634,
          0.1228,  0.1521, -0.0775,  0.0554, -0.0431, -0.0208,  0.0600,  0.1431,
          0.0246, -0.0096, -0.1108,  0.0993,  0.0877,  0.0709,  0.1353, -0.0956,
          0.0883, -0.0598, -0.0378, -0.1148,  0.1513,  0.0931, -0.0263, -0.1346,
          0.1326,  0.0529,  0.0992,  0.0865,  0.1137,  0.0900,  0.1459, -0.0928]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0720, -0.0465, -0.0876, -0.1331, -0.0276,  0.0045, -0.0056,  0.1076,
         -0.1319, -0.0825,  0.0037, -0.0330, -0.0077,  0.0271, -0.0179, -0.1205,
         -0.0949,  0.1222, -0.0415,  0.0748,  0.0413, -0.0945,  0.1429,  0.0819,
          0.0593,  0.0843,  0.1156, -0.1079,  0.0405,  0.1041, -0.1115, -0.0441,
          0.0921, -0.0941, -0.1458,  0.0602, -0.1232,  0.0384,  0.1479, -0.0846,
         -0.0894, -0.1455,  0.0589,  0.0029,  0.1519, -0.0230,  0.0711, -0.0393,
         -0.1505, -0.0136,  0.1442, -0.0213,  0.1063,  0.1243,  0.0405, -0.1350,
          0.1197,  0.1265, -0.0843,  0.0885,  0.1377, -0.0635, -0.0688, -0.1242,
         -0.0040, -0.0730, -0.0540,  0.1518,  0.1205,  0.1369, -0.1442, -0.0784,
          0.0782, -0.0196, -0.1152,  0.1026,  0.0816,  0.1285, -0.0255,  0.1329,
          0.1164,  0.0809,  0.0681, -0.1513,  0.1123, -0.0404,  0.1142,  0.1292,
          0.0921, -0.0355,  0.1200,  0.0691, -0.1373, -0.1217, -0.0551,  0.1215,
         -0.1303, -0.1355, -0.0317,  0.0496, -0.0104, -0.0112,  0.0844, -0.0213,
         -0.0337,  0.1025,  0.0042,  0.1472, -0.0062,  0.0836, -0.0666, -0.1342,
         -0.1518, -0.1269,  0.0412,  0.0345,  0.0163,  0.1024, -0.0798,  0.0926,
          0.0158,  0.0801, -0.0153,  0.0893, -0.0975, -0.1195, -0.1390, -0.0616,
          0.0317,  0.1289,  0.0558,  0.0047,  0.1349,  0.1363, -0.0687,  0.0050,
          0.1092, -0.1293, -0.0823, -0.0863,  0.1063,  0.0865, -0.1311,  0.0979,
          0.0457,  0.0050,  0.0507, -0.1258, -0.0527, -0.1153,  0.1521,  0.1128,
         -0.0863,  0.1184, -0.0440,  0.1296,  0.0385,  0.1324, -0.1338, -0.0178,
         -0.0404,  0.0120,  0.0761, -0.0132,  0.0413, -0.1172, -0.0759,  0.1163,
          0.0769,  0.1469, -0.0132, -0.0216,  0.0786, -0.1249,  0.0440,  0.1497,
          0.0365,  0.1425, -0.1057,  0.0955,  0.0468,  0.0409, -0.0108, -0.1343,
          0.1089,  0.0682,  0.0646, -0.0755, -0.0268, -0.0711, -0.0853,  0.1076,
         -0.0128, -0.0650,  0.1086,  0.0186,  0.0923,  0.0300, -0.0823,  0.0047,
          0.0817, -0.0417, -0.0850, -0.1191,  0.0464,  0.0844,  0.0078,  0.0659,
          0.0959,  0.0249,  0.0221, -0.0935,  0.1412, -0.0985, -0.0617, -0.1036,
         -0.0975, -0.1131, -0.1349,  0.0561, -0.0147,  0.0333,  0.0623,  0.0634,
          0.1228,  0.1521, -0.0775,  0.0554, -0.0431, -0.0208,  0.0600,  0.1431,
          0.0246, -0.0096, -0.1108,  0.0993,  0.0877,  0.0709,  0.1353, -0.0956,
          0.0883, -0.0598, -0.0378, -0.1148,  0.1513,  0.0931, -0.0263, -0.1346,
          0.1326,  0.0529,  0.0992,  0.0865,  0.1137,  0.0900,  0.1459, -0.0928]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[-0.0191,  0.0608, -0.0397,  ..., -0.0776, -0.0653, -0.1043],
        [ 0.0793, -0.0004,  0.0772,  ..., -0.1014,  0.0182, -0.0227],
        [ 0.0731,  0.0489,  0.0954,  ..., -0.0748, -0.0426, -0.0368],
        ...,
        [-0.0567, -0.0614, -0.0981,  ...,  0.0712, -0.0770, -0.0939],
        [-0.0295,  0.1012,  0.0914,  ..., -0.1242,  0.0152,  0.0130],
        [ 0.0297,  0.0482, -0.1235,  ...,  0.0427,  0.0503,  0.1222]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0191,  0.0608, -0.0397,  ..., -0.0776, -0.0653, -0.1043],
        [ 0.0793, -0.0004,  0.0772,  ..., -0.1014,  0.0182, -0.0227],
        [ 0.0731,  0.0489,  0.0954,  ..., -0.0748, -0.0426, -0.0368],
        ...,
        [-0.0567, -0.0614, -0.0981,  ...,  0.0712, -0.0770, -0.0939],
        [-0.0295,  0.1012,  0.0914,  ..., -0.1242,  0.0152,  0.0130],
        [ 0.0297,  0.0482, -0.1235,  ...,  0.0427,  0.0503,  0.1222]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[ 0.1606,  0.1280,  0.0450,  ...,  0.0371,  0.0351, -0.1593],
        [-0.0116,  0.0496, -0.1696,  ...,  0.0941, -0.0125, -0.1634],
        [ 0.0550,  0.1587,  0.0522,  ...,  0.1131,  0.0451,  0.1660],
        ...,
        [ 0.1616, -0.0985, -0.1089,  ...,  0.0724,  0.0300,  0.1586],
        [ 0.0934, -0.1751, -0.1173,  ..., -0.0540,  0.0236, -0.1483],
        [-0.0683, -0.1205, -0.0245,  ...,  0.0098,  0.1036, -0.0793]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1606,  0.1280,  0.0450,  ...,  0.0371,  0.0351, -0.1593],
        [-0.0116,  0.0496, -0.1696,  ...,  0.0941, -0.0125, -0.1634],
        [ 0.0550,  0.1587,  0.0522,  ...,  0.1131,  0.0451,  0.1660],
        ...,
        [ 0.1616, -0.0985, -0.1089,  ...,  0.0724,  0.0300,  0.1586],
        [ 0.0934, -0.1751, -0.1173,  ..., -0.0540,  0.0236, -0.1483],
        [-0.0683, -0.1205, -0.0245,  ...,  0.0098,  0.1036, -0.0793]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[ 0.1866,  0.1036, -0.0493,  ...,  0.2030, -0.0305, -0.2420],
        [-0.0484,  0.0543,  0.1098,  ..., -0.1500,  0.1208,  0.2345],
        [-0.0023, -0.1934,  0.1462,  ...,  0.1332,  0.0988,  0.1826],
        ...,
        [-0.2469, -0.2063, -0.0553,  ..., -0.1901, -0.1110, -0.1362],
        [ 0.1775, -0.2440,  0.0901,  ...,  0.1636, -0.0801,  0.0019],
        [ 0.0925,  0.1537, -0.1663,  ...,  0.2379,  0.0540, -0.1088]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1866,  0.1036, -0.0493,  ...,  0.2030, -0.0305, -0.2420],
        [-0.0484,  0.0543,  0.1098,  ..., -0.1500,  0.1208,  0.2345],
        [-0.0023, -0.1934,  0.1462,  ...,  0.1332,  0.0988,  0.1826],
        ...,
        [-0.2469, -0.2063, -0.0553,  ..., -0.1901, -0.1110, -0.1362],
        [ 0.1775, -0.2440,  0.0901,  ...,  0.1636, -0.0801,  0.0019],
        [ 0.0925,  0.1537, -0.1663,  ...,  0.2379,  0.0540, -0.1088]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.1239],
        [ 0.2858],
        [ 0.2825],
        [-0.2213],
        [ 0.3621],
        [-0.4090],
        [ 0.0151],
        [-0.3762],
        [ 0.2230],
        [-0.3112],
        [-0.0435],
        [ 0.3592],
        [ 0.1469],
        [ 0.1732],
        [ 0.1368],
        [ 0.3116],
        [-0.1025],
        [ 0.0245],
        [ 0.1272],
        [-0.0727],
        [ 0.1890],
        [-0.3431],
        [-0.1102],
        [ 0.0291],
        [ 0.2160],
        [-0.1090],
        [ 0.1661],
        [ 0.1951],
        [-0.2163],
        [ 0.3086],
        [-0.1255],
        [ 0.1199]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.1239],
        [ 0.2858],
        [ 0.2825],
        [-0.2213],
        [ 0.3621],
        [-0.4090],
        [ 0.0151],
        [-0.3762],
        [ 0.2230],
        [-0.3112],
        [-0.0435],
        [ 0.3592],
        [ 0.1469],
        [ 0.1732],
        [ 0.1368],
        [ 0.3116],
        [-0.1025],
        [ 0.0245],
        [ 0.1272],
        [-0.0727],
        [ 0.1890],
        [-0.3431],
        [-0.1102],
        [ 0.0291],
        [ 0.2160],
        [-0.1090],
        [ 0.1661],
        [ 0.1951],
        [-0.2163],
        [ 0.3086],
        [-0.1255],
        [ 0.1199]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-6.6793, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(1.1997, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(1.2313, device='cuda:0')



h[100].sum tensor(1.1546, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(1.1850, device='cuda:0')



h[200].sum tensor(3.5217, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(3.6144, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(2850.5959, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0007, 0.0001, 0.0001,  ..., 0.0000, 0.0025, 0.0025],
        [0.0039, 0.0006, 0.0007,  ..., 0.0000, 0.0128, 0.0128],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(14248.3281, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(151.5561, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(12.1241, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-3.5056, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(344.2338, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(27.5378, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.0343],
        [-0.0420],
        [-0.0606],
        ...,
        [-0.0097],
        [-0.0097],
        [-0.0077]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-865.7542, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[-0.0343],
        [-0.0420],
        [-0.0606],
        ...,
        [-0.0097],
        [-0.0097],
        [-0.0077]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(149.7247, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(12.4694, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(12.3683, device='cuda:0')



h[100].sum tensor(-13.1389, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-13.0324, device='cuda:0')



h[200].sum tensor(-18.0615, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-17.9151, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(15659.2002, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0099, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0021, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(92355.0078, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-29.1269, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-63.6193, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-34.5778, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0751],
        [0.0461],
        [0.0282],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(4412.0669, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-0.0343],
        [-0.0420],
        [-0.0606],
        ...,
        [-0.0097],
        [-0.0097],
        [-0.0077]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/saved_checkpoint.pth.tar



load_model True 
TraEvN 1998 
BatchSize 5 
EpochNum 0 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[-0.0059,  0.0231, -0.0578,  0.0421,  0.1323,  0.0895,  0.1153,  0.0672,
         -0.0169, -0.1206,  0.0070, -0.1347,  0.0456, -0.0746,  0.0581, -0.0037,
         -0.1518, -0.0452,  0.0905, -0.1054, -0.0249, -0.1299,  0.1291, -0.1012,
         -0.0709,  0.1086, -0.0379,  0.1373,  0.0306,  0.1445, -0.1102, -0.0657,
         -0.0891, -0.0559, -0.0750,  0.0344,  0.1436,  0.1060, -0.0380,  0.0063,
          0.0155,  0.0384,  0.0521,  0.0052,  0.0606,  0.0139,  0.0593, -0.0463,
         -0.0195, -0.0100,  0.0508,  0.1174,  0.0730,  0.0085, -0.0108,  0.1133,
          0.0199,  0.0283, -0.0934, -0.0497,  0.0615, -0.0120,  0.0323,  0.0176,
          0.1250, -0.1287, -0.1333,  0.0986, -0.0622,  0.0878,  0.0484, -0.0380,
         -0.1289, -0.1136,  0.0524, -0.0774, -0.1005,  0.0926,  0.0659, -0.1019,
          0.1372, -0.1278,  0.1302,  0.0891,  0.1251,  0.0579,  0.0571,  0.0626,
          0.1080,  0.0769,  0.1207, -0.0853,  0.0286,  0.1205,  0.0432,  0.1342,
         -0.1058, -0.1458,  0.0382,  0.1292, -0.0204,  0.0174, -0.0512,  0.0929,
         -0.1393,  0.1305,  0.0760,  0.0077,  0.0362, -0.0535, -0.1370,  0.0609,
         -0.1344,  0.1367, -0.1097,  0.0927,  0.0992,  0.0353, -0.0483,  0.1474,
         -0.1061, -0.1156,  0.0299,  0.0389, -0.1072,  0.0448,  0.0840, -0.0962,
         -0.0047,  0.1262,  0.1083,  0.1486, -0.1017, -0.1181, -0.1308, -0.1258,
          0.0577, -0.0665, -0.0756,  0.0095,  0.0664,  0.0724,  0.1357, -0.0984,
         -0.0237,  0.1017, -0.0086, -0.0784, -0.0124, -0.0917, -0.0965, -0.1474,
         -0.0091,  0.0626, -0.1174, -0.0308, -0.1140, -0.1445, -0.0732, -0.0926,
          0.0869, -0.0824, -0.1115,  0.1217,  0.0276,  0.1299, -0.0139, -0.0356,
         -0.0572,  0.1083,  0.0129, -0.0740,  0.1202, -0.1285,  0.0138,  0.0912,
          0.0442,  0.0102,  0.0174, -0.0033, -0.1042, -0.0361, -0.0107, -0.1114,
         -0.1505,  0.0050,  0.0309,  0.1199,  0.0919, -0.0397, -0.0579,  0.0401,
          0.0542,  0.1507, -0.0918,  0.1040,  0.1098,  0.0538, -0.0050,  0.0358,
          0.0121,  0.0053,  0.0408,  0.0189, -0.1363,  0.0617,  0.0952,  0.1035,
         -0.0279,  0.0324,  0.1401,  0.0119, -0.1151, -0.1305,  0.0152,  0.1261,
         -0.1245,  0.0304,  0.1207, -0.0042,  0.0491, -0.1516,  0.0075, -0.0546,
         -0.1454,  0.0744,  0.0804,  0.0977,  0.0026, -0.0276, -0.0492, -0.0628,
          0.0428,  0.0137, -0.0084,  0.0949, -0.1384,  0.0029,  0.0175,  0.0598,
          0.0939, -0.1407, -0.0069, -0.0986,  0.0795, -0.0153,  0.0097, -0.0103,
         -0.0732, -0.0464,  0.0032,  0.0971,  0.0946,  0.0997, -0.0997, -0.0414]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1170,  0.0512,  0.0376,  ..., -0.0657,  0.0967,  0.1202],
        [ 0.1014,  0.0052, -0.0139,  ...,  0.0153,  0.0376, -0.0936],
        [ 0.0508,  0.0732,  0.1070,  ...,  0.0227, -0.1110, -0.0499],
        ...,
        [ 0.0188,  0.0199,  0.0257,  ..., -0.1106,  0.0630,  0.0861],
        [-0.0789, -0.1112, -0.0449,  ...,  0.0017,  0.0829,  0.0212],
        [ 0.0227, -0.0708,  0.0509,  ...,  0.0237,  0.0582, -0.0334]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1452,  0.1512,  0.0938,  ...,  0.0800, -0.0664, -0.1632],
        [ 0.0819,  0.0484, -0.0140,  ...,  0.0281,  0.1300,  0.0476],
        [-0.0115,  0.0348, -0.0885,  ..., -0.1586, -0.1671,  0.0252],
        ...,
        [ 0.1413,  0.0133,  0.1476,  ..., -0.1111, -0.0121,  0.0765],
        [-0.0863,  0.0041,  0.0600,  ...,  0.1022,  0.0714,  0.0851],
        [ 0.0373,  0.0889,  0.1704,  ..., -0.0390, -0.1220, -0.1617]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0615, -0.2399, -0.2379,  ..., -0.1194,  0.2256,  0.0886],
        [-0.0814, -0.1017, -0.1471,  ...,  0.1654, -0.2435, -0.0638],
        [-0.1221, -0.1886,  0.1829,  ...,  0.2021,  0.1329, -0.0226],
        ...,
        [-0.2414, -0.1913,  0.1017,  ...,  0.1774,  0.1250, -0.1851],
        [ 0.1547,  0.2094,  0.0729,  ..., -0.0426, -0.0144,  0.0955],
        [ 0.2180, -0.2383,  0.1398,  ...,  0.1961, -0.0569,  0.1855]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1992],
        [ 0.0429],
        [-0.1066],
        [-0.3420],
        [-0.0435],
        [-0.3982],
        [ 0.0345],
        [ 0.0033],
        [-0.0598],
        [-0.2101],
        [-0.0488],
        [-0.0430],
        [ 0.1779],
        [ 0.2449],
        [ 0.2635],
        [-0.3428],
        [ 0.4191],
        [-0.1793],
        [-0.4126],
        [ 0.3178],
        [-0.0710],
        [-0.0521],
        [-0.2870],
        [-0.3080],
        [ 0.1451],
        [-0.1560],
        [-0.3924],
        [ 0.2323],
        [ 0.3613],
        [-0.2679],
        [-0.1509],
        [ 0.2426]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]



optimizer.param_groups [{'params': [Parameter containing:
tensor([[-0.0059,  0.0231, -0.0578,  0.0421,  0.1323,  0.0895,  0.1153,  0.0672,
         -0.0169, -0.1206,  0.0070, -0.1347,  0.0456, -0.0746,  0.0581, -0.0037,
         -0.1518, -0.0452,  0.0905, -0.1054, -0.0249, -0.1299,  0.1291, -0.1012,
         -0.0709,  0.1086, -0.0379,  0.1373,  0.0306,  0.1445, -0.1102, -0.0657,
         -0.0891, -0.0559, -0.0750,  0.0344,  0.1436,  0.1060, -0.0380,  0.0063,
          0.0155,  0.0384,  0.0521,  0.0052,  0.0606,  0.0139,  0.0593, -0.0463,
         -0.0195, -0.0100,  0.0508,  0.1174,  0.0730,  0.0085, -0.0108,  0.1133,
          0.0199,  0.0283, -0.0934, -0.0497,  0.0615, -0.0120,  0.0323,  0.0176,
          0.1250, -0.1287, -0.1333,  0.0986, -0.0622,  0.0878,  0.0484, -0.0380,
         -0.1289, -0.1136,  0.0524, -0.0774, -0.1005,  0.0926,  0.0659, -0.1019,
          0.1372, -0.1278,  0.1302,  0.0891,  0.1251,  0.0579,  0.0571,  0.0626,
          0.1080,  0.0769,  0.1207, -0.0853,  0.0286,  0.1205,  0.0432,  0.1342,
         -0.1058, -0.1458,  0.0382,  0.1292, -0.0204,  0.0174, -0.0512,  0.0929,
         -0.1393,  0.1305,  0.0760,  0.0077,  0.0362, -0.0535, -0.1370,  0.0609,
         -0.1344,  0.1367, -0.1097,  0.0927,  0.0992,  0.0353, -0.0483,  0.1474,
         -0.1061, -0.1156,  0.0299,  0.0389, -0.1072,  0.0448,  0.0840, -0.0962,
         -0.0047,  0.1262,  0.1083,  0.1486, -0.1017, -0.1181, -0.1308, -0.1258,
          0.0577, -0.0665, -0.0756,  0.0095,  0.0664,  0.0724,  0.1357, -0.0984,
         -0.0237,  0.1017, -0.0086, -0.0784, -0.0124, -0.0917, -0.0965, -0.1474,
         -0.0091,  0.0626, -0.1174, -0.0308, -0.1140, -0.1445, -0.0732, -0.0926,
          0.0869, -0.0824, -0.1115,  0.1217,  0.0276,  0.1299, -0.0139, -0.0356,
         -0.0572,  0.1083,  0.0129, -0.0740,  0.1202, -0.1285,  0.0138,  0.0912,
          0.0442,  0.0102,  0.0174, -0.0033, -0.1042, -0.0361, -0.0107, -0.1114,
         -0.1505,  0.0050,  0.0309,  0.1199,  0.0919, -0.0397, -0.0579,  0.0401,
          0.0542,  0.1507, -0.0918,  0.1040,  0.1098,  0.0538, -0.0050,  0.0358,
          0.0121,  0.0053,  0.0408,  0.0189, -0.1363,  0.0617,  0.0952,  0.1035,
         -0.0279,  0.0324,  0.1401,  0.0119, -0.1151, -0.1305,  0.0152,  0.1261,
         -0.1245,  0.0304,  0.1207, -0.0042,  0.0491, -0.1516,  0.0075, -0.0546,
         -0.1454,  0.0744,  0.0804,  0.0977,  0.0026, -0.0276, -0.0492, -0.0628,
          0.0428,  0.0137, -0.0084,  0.0949, -0.1384,  0.0029,  0.0175,  0.0598,
          0.0939, -0.1407, -0.0069, -0.0986,  0.0795, -0.0153,  0.0097, -0.0103,
         -0.0732, -0.0464,  0.0032,  0.0971,  0.0946,  0.0997, -0.0997, -0.0414]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1170,  0.0512,  0.0376,  ..., -0.0657,  0.0967,  0.1202],
        [ 0.1014,  0.0052, -0.0139,  ...,  0.0153,  0.0376, -0.0936],
        [ 0.0508,  0.0732,  0.1070,  ...,  0.0227, -0.1110, -0.0499],
        ...,
        [ 0.0188,  0.0199,  0.0257,  ..., -0.1106,  0.0630,  0.0861],
        [-0.0789, -0.1112, -0.0449,  ...,  0.0017,  0.0829,  0.0212],
        [ 0.0227, -0.0708,  0.0509,  ...,  0.0237,  0.0582, -0.0334]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1452,  0.1512,  0.0938,  ...,  0.0800, -0.0664, -0.1632],
        [ 0.0819,  0.0484, -0.0140,  ...,  0.0281,  0.1300,  0.0476],
        [-0.0115,  0.0348, -0.0885,  ..., -0.1586, -0.1671,  0.0252],
        ...,
        [ 0.1413,  0.0133,  0.1476,  ..., -0.1111, -0.0121,  0.0765],
        [-0.0863,  0.0041,  0.0600,  ...,  0.1022,  0.0714,  0.0851],
        [ 0.0373,  0.0889,  0.1704,  ..., -0.0390, -0.1220, -0.1617]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0615, -0.2399, -0.2379,  ..., -0.1194,  0.2256,  0.0886],
        [-0.0814, -0.1017, -0.1471,  ...,  0.1654, -0.2435, -0.0638],
        [-0.1221, -0.1886,  0.1829,  ...,  0.2021,  0.1329, -0.0226],
        ...,
        [-0.2414, -0.1913,  0.1017,  ...,  0.1774,  0.1250, -0.1851],
        [ 0.1547,  0.2094,  0.0729,  ..., -0.0426, -0.0144,  0.0955],
        [ 0.2180, -0.2383,  0.1398,  ...,  0.1961, -0.0569,  0.1855]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1992],
        [ 0.0429],
        [-0.1066],
        [-0.3420],
        [-0.0435],
        [-0.3982],
        [ 0.0345],
        [ 0.0033],
        [-0.0598],
        [-0.2101],
        [-0.0488],
        [-0.0430],
        [ 0.1779],
        [ 0.2449],
        [ 0.2635],
        [-0.3428],
        [ 0.4191],
        [-0.1793],
        [-0.4126],
        [ 0.3178],
        [-0.0710],
        [-0.0521],
        [-0.2870],
        [-0.3080],
        [ 0.1451],
        [-0.1560],
        [-0.3924],
        [ 0.2323],
        [ 0.3613],
        [-0.2679],
        [-0.1509],
        [ 0.2426]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}, {'params': [tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py", line 139, in <module>
    {'evaluation loss': evallossarray[EpochNum - 1], 'training loss': lossarray[EpochNum - 1], \
IndexError: index -1 is out of bounds for axis 0 with size 0

real	1m54.197s
user	0m20.319s
sys	0m13.344s
