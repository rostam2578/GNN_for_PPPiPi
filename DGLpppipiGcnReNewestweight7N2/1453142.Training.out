0: gpu023.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-17f9f45a-502c-34a8-e8fd-7e7f09ff023a)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        450.36.06
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.8
srcversion:     BB5CB243542347D4EB0C79C
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_MapRegistersEarly:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_EnableBacklightHandler:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_AssignGpus:charp

nvidia-smi:
Tue Jul  5 23:49:48 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
| N/A   27C    P0    41W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089730048

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b42ae62b9a0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m40.066s
user	0m3.065s
sys	0m2.423s
[23:50:31] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 0.4036],
        [ 1.2446],
        [ 0.5120],
        ...,
        [-2.5478],
        [ 0.0905],
        [-0.1039]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-106.4579, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (2000, 6796) (2000, 6796)
sum 189931 265535
shape torch.Size([2000, 6796]) torch.Size([2000, 6796])
Model name: DGLpppipiGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.1141, -0.0193,  0.0469,  0.1308, -0.0194, -0.0530,  0.0097,  0.0839,
          0.0292,  0.1520,  0.0041,  0.0885, -0.0575,  0.1016,  0.1122, -0.1215,
         -0.0755,  0.0177,  0.0996, -0.0082,  0.0162,  0.0790, -0.1247, -0.0690,
         -0.0267, -0.0104,  0.0418, -0.0665,  0.1095, -0.0894, -0.1192,  0.0718,
          0.1079, -0.0567, -0.0930,  0.0009,  0.0502,  0.0888,  0.0379,  0.0792,
          0.0891,  0.0410,  0.1333, -0.0732,  0.0784,  0.0787, -0.1200, -0.1270,
          0.0764, -0.1371,  0.0039, -0.0773,  0.0456,  0.0735,  0.1358, -0.0392,
          0.1261, -0.1171, -0.1469, -0.0502, -0.1515,  0.1139, -0.0632, -0.0024,
          0.0673,  0.0845, -0.0219,  0.0358, -0.0843,  0.0096, -0.0832,  0.0214,
         -0.0121,  0.0107, -0.0874, -0.1499, -0.0494, -0.0780,  0.0636, -0.1459,
          0.0609, -0.0434,  0.0930,  0.0295, -0.0005,  0.0559, -0.1034,  0.0711,
          0.1336, -0.0720, -0.0362, -0.0308,  0.0854, -0.0054,  0.1429,  0.0972,
         -0.0064, -0.1130, -0.0003, -0.0782, -0.0349,  0.0770, -0.0841, -0.1334,
          0.1388, -0.0097,  0.1330, -0.1151,  0.0137,  0.0482,  0.0045, -0.0559,
          0.0370,  0.0047, -0.0612, -0.0279,  0.1485,  0.0366,  0.0456, -0.0721,
         -0.0664, -0.0152,  0.1078,  0.1039, -0.0686,  0.0493, -0.1171, -0.1192,
         -0.1276,  0.0360,  0.0070, -0.1367, -0.1040,  0.1244, -0.0483, -0.0517,
          0.1289,  0.0934,  0.1200,  0.0177, -0.0025,  0.1336, -0.0400, -0.0191,
          0.1099, -0.0947, -0.1488, -0.0424,  0.0851,  0.0485,  0.0332,  0.1201,
         -0.1154,  0.1388,  0.0873,  0.1284,  0.0431, -0.0210,  0.0228,  0.0018,
          0.1146,  0.1067, -0.0207,  0.0053, -0.1284,  0.1219, -0.0147, -0.1066,
          0.0458,  0.1091, -0.1262,  0.0763,  0.0255, -0.0407, -0.0961,  0.0031,
         -0.0617, -0.1516,  0.0772,  0.0472,  0.0069, -0.1186,  0.1482,  0.0857,
          0.0832, -0.1509, -0.1073, -0.1523, -0.0990, -0.1090, -0.1050, -0.0101,
         -0.0671,  0.0866,  0.0436, -0.0102,  0.0692,  0.0074, -0.0552,  0.1386,
          0.0109, -0.1018,  0.1330,  0.1403, -0.0519, -0.1229, -0.1405,  0.1380,
          0.1514, -0.0251,  0.1381, -0.0246,  0.0020, -0.0765,  0.1380, -0.0519,
         -0.0431, -0.0446,  0.0814, -0.1345, -0.1433,  0.0095, -0.0932,  0.0991,
          0.1115, -0.1081,  0.0009, -0.0239,  0.1498, -0.0139,  0.1150,  0.1077,
         -0.0551,  0.1055,  0.1154, -0.1390, -0.0572,  0.0235, -0.0616,  0.1022,
          0.1526,  0.0894,  0.0636,  0.0069,  0.0426,  0.1135, -0.1384,  0.1325,
         -0.0252, -0.0530,  0.1061,  0.1365,  0.1276,  0.1051,  0.1351,  0.0056]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1141, -0.0193,  0.0469,  0.1308, -0.0194, -0.0530,  0.0097,  0.0839,
          0.0292,  0.1520,  0.0041,  0.0885, -0.0575,  0.1016,  0.1122, -0.1215,
         -0.0755,  0.0177,  0.0996, -0.0082,  0.0162,  0.0790, -0.1247, -0.0690,
         -0.0267, -0.0104,  0.0418, -0.0665,  0.1095, -0.0894, -0.1192,  0.0718,
          0.1079, -0.0567, -0.0930,  0.0009,  0.0502,  0.0888,  0.0379,  0.0792,
          0.0891,  0.0410,  0.1333, -0.0732,  0.0784,  0.0787, -0.1200, -0.1270,
          0.0764, -0.1371,  0.0039, -0.0773,  0.0456,  0.0735,  0.1358, -0.0392,
          0.1261, -0.1171, -0.1469, -0.0502, -0.1515,  0.1139, -0.0632, -0.0024,
          0.0673,  0.0845, -0.0219,  0.0358, -0.0843,  0.0096, -0.0832,  0.0214,
         -0.0121,  0.0107, -0.0874, -0.1499, -0.0494, -0.0780,  0.0636, -0.1459,
          0.0609, -0.0434,  0.0930,  0.0295, -0.0005,  0.0559, -0.1034,  0.0711,
          0.1336, -0.0720, -0.0362, -0.0308,  0.0854, -0.0054,  0.1429,  0.0972,
         -0.0064, -0.1130, -0.0003, -0.0782, -0.0349,  0.0770, -0.0841, -0.1334,
          0.1388, -0.0097,  0.1330, -0.1151,  0.0137,  0.0482,  0.0045, -0.0559,
          0.0370,  0.0047, -0.0612, -0.0279,  0.1485,  0.0366,  0.0456, -0.0721,
         -0.0664, -0.0152,  0.1078,  0.1039, -0.0686,  0.0493, -0.1171, -0.1192,
         -0.1276,  0.0360,  0.0070, -0.1367, -0.1040,  0.1244, -0.0483, -0.0517,
          0.1289,  0.0934,  0.1200,  0.0177, -0.0025,  0.1336, -0.0400, -0.0191,
          0.1099, -0.0947, -0.1488, -0.0424,  0.0851,  0.0485,  0.0332,  0.1201,
         -0.1154,  0.1388,  0.0873,  0.1284,  0.0431, -0.0210,  0.0228,  0.0018,
          0.1146,  0.1067, -0.0207,  0.0053, -0.1284,  0.1219, -0.0147, -0.1066,
          0.0458,  0.1091, -0.1262,  0.0763,  0.0255, -0.0407, -0.0961,  0.0031,
         -0.0617, -0.1516,  0.0772,  0.0472,  0.0069, -0.1186,  0.1482,  0.0857,
          0.0832, -0.1509, -0.1073, -0.1523, -0.0990, -0.1090, -0.1050, -0.0101,
         -0.0671,  0.0866,  0.0436, -0.0102,  0.0692,  0.0074, -0.0552,  0.1386,
          0.0109, -0.1018,  0.1330,  0.1403, -0.0519, -0.1229, -0.1405,  0.1380,
          0.1514, -0.0251,  0.1381, -0.0246,  0.0020, -0.0765,  0.1380, -0.0519,
         -0.0431, -0.0446,  0.0814, -0.1345, -0.1433,  0.0095, -0.0932,  0.0991,
          0.1115, -0.1081,  0.0009, -0.0239,  0.1498, -0.0139,  0.1150,  0.1077,
         -0.0551,  0.1055,  0.1154, -0.1390, -0.0572,  0.0235, -0.0616,  0.1022,
          0.1526,  0.0894,  0.0636,  0.0069,  0.0426,  0.1135, -0.1384,  0.1325,
         -0.0252, -0.0530,  0.1061,  0.1365,  0.1276,  0.1051,  0.1351,  0.0056]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[-0.0029,  0.0900, -0.1025,  ...,  0.0780, -0.0863,  0.1159],
        [-0.0348, -0.0608, -0.0302,  ..., -0.0674,  0.0190, -0.1184],
        [-0.0324, -0.1142, -0.0973,  ..., -0.0695, -0.0706, -0.1004],
        ...,
        [-0.0617,  0.1041, -0.1202,  ..., -0.0092, -0.1179,  0.0543],
        [-0.1116, -0.0415,  0.0315,  ...,  0.0004,  0.1141, -0.0983],
        [-0.0728, -0.0059,  0.1214,  ..., -0.0816, -0.0333,  0.0408]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0029,  0.0900, -0.1025,  ...,  0.0780, -0.0863,  0.1159],
        [-0.0348, -0.0608, -0.0302,  ..., -0.0674,  0.0190, -0.1184],
        [-0.0324, -0.1142, -0.0973,  ..., -0.0695, -0.0706, -0.1004],
        ...,
        [-0.0617,  0.1041, -0.1202,  ..., -0.0092, -0.1179,  0.0543],
        [-0.1116, -0.0415,  0.0315,  ...,  0.0004,  0.1141, -0.0983],
        [-0.0728, -0.0059,  0.1214,  ..., -0.0816, -0.0333,  0.0408]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[ 0.1334, -0.1107,  0.1326,  ..., -0.0308,  0.1186,  0.0525],
        [ 0.1716,  0.1174, -0.1688,  ...,  0.0685,  0.1463, -0.0916],
        [ 0.1332,  0.1408,  0.1388,  ...,  0.0281, -0.1709,  0.0076],
        ...,
        [ 0.0443, -0.0748, -0.1393,  ..., -0.1461, -0.1122, -0.0834],
        [-0.0057, -0.1714, -0.0773,  ...,  0.0932, -0.1389, -0.0263],
        [ 0.0463,  0.0186, -0.0740,  ...,  0.1058, -0.0607,  0.0523]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1334, -0.1107,  0.1326,  ..., -0.0308,  0.1186,  0.0525],
        [ 0.1716,  0.1174, -0.1688,  ...,  0.0685,  0.1463, -0.0916],
        [ 0.1332,  0.1408,  0.1388,  ...,  0.0281, -0.1709,  0.0076],
        ...,
        [ 0.0443, -0.0748, -0.1393,  ..., -0.1461, -0.1122, -0.0834],
        [-0.0057, -0.1714, -0.0773,  ...,  0.0932, -0.1389, -0.0263],
        [ 0.0463,  0.0186, -0.0740,  ...,  0.1058, -0.0607,  0.0523]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.1948,  0.0309, -0.2052,  ...,  0.1132,  0.1612,  0.0089],
        [ 0.0859, -0.1641,  0.0412,  ...,  0.1471, -0.0864,  0.1380],
        [-0.1974,  0.1355, -0.1257,  ..., -0.1591,  0.1598, -0.0243],
        ...,
        [-0.0371,  0.2028,  0.2428,  ..., -0.0953,  0.1846, -0.1869],
        [ 0.1731, -0.1945,  0.0539,  ..., -0.2108,  0.1062,  0.0220],
        [-0.2047,  0.0397, -0.2183,  ..., -0.1433, -0.1399, -0.0319]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1948,  0.0309, -0.2052,  ...,  0.1132,  0.1612,  0.0089],
        [ 0.0859, -0.1641,  0.0412,  ...,  0.1471, -0.0864,  0.1380],
        [-0.1974,  0.1355, -0.1257,  ..., -0.1591,  0.1598, -0.0243],
        ...,
        [-0.0371,  0.2028,  0.2428,  ..., -0.0953,  0.1846, -0.1869],
        [ 0.1731, -0.1945,  0.0539,  ..., -0.2108,  0.1062,  0.0220],
        [-0.2047,  0.0397, -0.2183,  ..., -0.1433, -0.1399, -0.0319]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[-0.2941],
        [ 0.0524],
        [ 0.1892],
        [-0.0475],
        [ 0.4033],
        [ 0.4046],
        [-0.0743],
        [ 0.0485],
        [ 0.1422],
        [ 0.3633],
        [ 0.3287],
        [-0.0174],
        [ 0.2595],
        [-0.3222],
        [-0.0880],
        [ 0.1718],
        [ 0.0441],
        [ 0.0547],
        [ 0.3777],
        [-0.1719],
        [-0.4043],
        [ 0.1726],
        [ 0.0756],
        [-0.3217],
        [ 0.3568],
        [ 0.1022],
        [-0.2707],
        [ 0.0963],
        [-0.3928],
        [ 0.1072],
        [ 0.1394],
        [-0.1363]], device='cuda:0') 
 Parameter containing:
tensor([[-0.2941],
        [ 0.0524],
        [ 0.1892],
        [-0.0475],
        [ 0.4033],
        [ 0.4046],
        [-0.0743],
        [ 0.0485],
        [ 0.1422],
        [ 0.3633],
        [ 0.3287],
        [-0.0174],
        [ 0.2595],
        [-0.3222],
        [-0.0880],
        [ 0.1718],
        [ 0.0441],
        [ 0.0547],
        [ 0.3777],
        [-0.1719],
        [-0.4043],
        [ 0.1726],
        [ 0.0756],
        [-0.3217],
        [ 0.3568],
        [ 0.1022],
        [-0.2707],
        [ 0.0963],
        [-0.3928],
        [ 0.1072],
        [ 0.1394],
        [-0.1363]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-1.3123e-01, -1.2017e-01,  2.5961e-03,  1.2594e-02, -1.2967e-02,
          3.4064e-02, -2.9163e-02,  9.9633e-02, -2.7653e-02, -8.5937e-02,
          5.8512e-02,  2.9632e-02, -7.7510e-02,  1.4864e-01, -2.5658e-02,
          1.1987e-01, -6.0530e-02,  8.6876e-02, -6.2559e-02,  5.1797e-02,
          3.7831e-02,  1.4880e-01, -6.5274e-02, -1.4012e-01,  1.7908e-03,
          1.0066e-01,  1.2080e-01, -1.1212e-01,  8.9642e-02, -6.0089e-02,
          6.7584e-02, -1.3747e-01,  8.5017e-02, -1.5274e-02, -5.6872e-02,
          3.6097e-02,  4.4439e-03,  1.2157e-01,  8.8163e-02,  1.0449e-01,
         -3.4361e-02,  7.6965e-02,  3.2267e-02, -4.2375e-02,  3.8712e-02,
          8.1641e-02, -3.7663e-02,  4.4462e-02,  1.3343e-02,  1.1722e-01,
          7.2183e-02,  5.5005e-02, -4.7490e-02,  5.3408e-02, -5.9410e-02,
         -3.7613e-02, -8.4937e-02, -8.7700e-02,  1.5277e-01, -7.2032e-02,
          1.2115e-01, -1.4344e-01, -7.4182e-02,  9.9013e-02,  1.3084e-01,
         -3.3897e-02,  1.2653e-01, -1.0674e-01, -9.7198e-02,  1.0888e-01,
          1.8729e-03, -5.5073e-02,  7.8745e-02, -4.7167e-02, -1.5161e-01,
          1.2792e-01, -6.0550e-02, -1.0407e-01, -7.4426e-02,  8.4112e-03,
          5.7957e-02, -5.2873e-02,  4.9798e-02,  2.6267e-03, -1.3179e-01,
          1.3209e-01,  6.3298e-02, -4.0127e-02,  1.0412e-01, -1.4576e-01,
          1.0590e-01, -7.6560e-02, -5.3978e-02, -1.8427e-02, -7.2292e-02,
         -9.0752e-02, -1.4065e-01, -1.1910e-01,  1.3624e-01, -8.3127e-02,
         -1.3746e-01, -9.4389e-02, -5.2692e-02, -7.7839e-02, -5.2873e-02,
          1.0062e-01, -1.4793e-01,  7.6212e-02, -1.3804e-02,  3.8726e-02,
         -1.1565e-01, -6.6058e-02, -7.9205e-02, -5.6094e-02,  7.8256e-02,
          1.4888e-01,  4.2622e-02, -5.3234e-02,  3.0062e-02,  1.4807e-01,
          3.0254e-02,  1.4028e-01, -1.2734e-01,  1.3098e-01,  1.1582e-01,
         -9.0811e-02, -1.4253e-02,  1.5133e-01, -1.1432e-02, -1.4013e-01,
         -7.9281e-02, -1.1061e-01,  4.5203e-02, -4.0458e-02, -6.1558e-02,
          5.0713e-02,  4.4100e-02,  9.7909e-02,  9.0221e-02, -9.7360e-02,
          1.1354e-02, -1.6373e-02,  8.7762e-02,  1.4605e-01,  1.2109e-01,
          2.8910e-02, -4.5919e-02, -7.3016e-02,  1.3912e-01,  2.0841e-02,
          4.8424e-02, -4.7298e-02,  1.8737e-02,  5.7825e-02,  1.0486e-01,
         -9.1173e-02, -1.2877e-01,  1.3680e-01,  8.3540e-03, -9.5449e-02,
          6.9078e-02, -6.6120e-02,  1.4427e-01,  4.2552e-02, -1.5098e-01,
          8.0494e-02, -1.5278e-01, -5.1871e-02,  7.1338e-02, -1.5268e-01,
         -4.1293e-02, -7.6224e-02,  1.0125e-01,  9.5952e-02, -1.0097e-01,
          1.4571e-02,  8.0433e-03,  1.3986e-01, -4.7326e-02, -4.1304e-02,
          6.9042e-02, -2.3955e-02, -2.2652e-02,  1.1080e-01,  6.3088e-02,
          7.9572e-02, -9.4716e-05,  3.4976e-02, -3.6227e-02, -1.3154e-01,
         -4.1716e-02,  1.0725e-01,  1.4286e-01, -7.0601e-02,  1.3651e-01,
         -2.1957e-02,  8.2685e-02, -1.1159e-01,  1.3958e-04,  8.2449e-02,
         -1.0922e-01, -3.8144e-03,  2.5926e-02,  5.5844e-02,  1.4907e-01,
         -1.1553e-01, -1.2464e-02, -5.0449e-02,  5.7926e-02,  5.9857e-02,
         -3.7133e-02,  2.8657e-02, -1.2650e-01, -1.1415e-01, -1.5079e-01,
         -3.3646e-02,  3.7337e-02,  1.2414e-01, -6.7748e-02, -1.5003e-01,
         -9.8251e-02,  1.4680e-01,  2.9873e-02,  6.1133e-02, -3.9841e-02,
         -5.2105e-02,  1.6631e-02, -1.1785e-02,  2.8503e-02,  1.0238e-01,
         -1.5005e-01, -8.9153e-02,  1.0466e-01, -5.7228e-02, -5.4974e-02,
         -1.4250e-01, -9.9339e-02,  1.3948e-01,  1.2345e-01, -4.8953e-02,
         -6.5410e-02,  9.1768e-02, -1.1686e-01,  1.0120e-01, -6.3359e-02,
          1.1315e-01,  1.1752e-01, -9.3136e-02, -1.0927e-01,  6.5805e-02,
         -5.5976e-02,  1.3841e-01, -1.4121e-01, -1.4012e-01,  1.4726e-02,
          3.0717e-03]], device='cuda:0') 
 Parameter containing:
tensor([[-1.3123e-01, -1.2017e-01,  2.5961e-03,  1.2594e-02, -1.2967e-02,
          3.4064e-02, -2.9163e-02,  9.9633e-02, -2.7653e-02, -8.5937e-02,
          5.8512e-02,  2.9632e-02, -7.7510e-02,  1.4864e-01, -2.5658e-02,
          1.1987e-01, -6.0530e-02,  8.6876e-02, -6.2559e-02,  5.1797e-02,
          3.7831e-02,  1.4880e-01, -6.5274e-02, -1.4012e-01,  1.7908e-03,
          1.0066e-01,  1.2080e-01, -1.1212e-01,  8.9642e-02, -6.0089e-02,
          6.7584e-02, -1.3747e-01,  8.5017e-02, -1.5274e-02, -5.6872e-02,
          3.6097e-02,  4.4439e-03,  1.2157e-01,  8.8163e-02,  1.0449e-01,
         -3.4361e-02,  7.6965e-02,  3.2267e-02, -4.2375e-02,  3.8712e-02,
          8.1641e-02, -3.7663e-02,  4.4462e-02,  1.3343e-02,  1.1722e-01,
          7.2183e-02,  5.5005e-02, -4.7490e-02,  5.3408e-02, -5.9410e-02,
         -3.7613e-02, -8.4937e-02, -8.7700e-02,  1.5277e-01, -7.2032e-02,
          1.2115e-01, -1.4344e-01, -7.4182e-02,  9.9013e-02,  1.3084e-01,
         -3.3897e-02,  1.2653e-01, -1.0674e-01, -9.7198e-02,  1.0888e-01,
          1.8729e-03, -5.5073e-02,  7.8745e-02, -4.7167e-02, -1.5161e-01,
          1.2792e-01, -6.0550e-02, -1.0407e-01, -7.4426e-02,  8.4112e-03,
          5.7957e-02, -5.2873e-02,  4.9798e-02,  2.6267e-03, -1.3179e-01,
          1.3209e-01,  6.3298e-02, -4.0127e-02,  1.0412e-01, -1.4576e-01,
          1.0590e-01, -7.6560e-02, -5.3978e-02, -1.8427e-02, -7.2292e-02,
         -9.0752e-02, -1.4065e-01, -1.1910e-01,  1.3624e-01, -8.3127e-02,
         -1.3746e-01, -9.4389e-02, -5.2692e-02, -7.7839e-02, -5.2873e-02,
          1.0062e-01, -1.4793e-01,  7.6212e-02, -1.3804e-02,  3.8726e-02,
         -1.1565e-01, -6.6058e-02, -7.9205e-02, -5.6094e-02,  7.8256e-02,
          1.4888e-01,  4.2622e-02, -5.3234e-02,  3.0062e-02,  1.4807e-01,
          3.0254e-02,  1.4028e-01, -1.2734e-01,  1.3098e-01,  1.1582e-01,
         -9.0811e-02, -1.4253e-02,  1.5133e-01, -1.1432e-02, -1.4013e-01,
         -7.9281e-02, -1.1061e-01,  4.5203e-02, -4.0458e-02, -6.1558e-02,
          5.0713e-02,  4.4100e-02,  9.7909e-02,  9.0221e-02, -9.7360e-02,
          1.1354e-02, -1.6373e-02,  8.7762e-02,  1.4605e-01,  1.2109e-01,
          2.8910e-02, -4.5919e-02, -7.3016e-02,  1.3912e-01,  2.0841e-02,
          4.8424e-02, -4.7298e-02,  1.8737e-02,  5.7825e-02,  1.0486e-01,
         -9.1173e-02, -1.2877e-01,  1.3680e-01,  8.3540e-03, -9.5449e-02,
          6.9078e-02, -6.6120e-02,  1.4427e-01,  4.2552e-02, -1.5098e-01,
          8.0494e-02, -1.5278e-01, -5.1871e-02,  7.1338e-02, -1.5268e-01,
         -4.1293e-02, -7.6224e-02,  1.0125e-01,  9.5952e-02, -1.0097e-01,
          1.4571e-02,  8.0433e-03,  1.3986e-01, -4.7326e-02, -4.1304e-02,
          6.9042e-02, -2.3955e-02, -2.2652e-02,  1.1080e-01,  6.3088e-02,
          7.9572e-02, -9.4716e-05,  3.4976e-02, -3.6227e-02, -1.3154e-01,
         -4.1716e-02,  1.0725e-01,  1.4286e-01, -7.0601e-02,  1.3651e-01,
         -2.1957e-02,  8.2685e-02, -1.1159e-01,  1.3958e-04,  8.2449e-02,
         -1.0922e-01, -3.8144e-03,  2.5926e-02,  5.5844e-02,  1.4907e-01,
         -1.1553e-01, -1.2464e-02, -5.0449e-02,  5.7926e-02,  5.9857e-02,
         -3.7133e-02,  2.8657e-02, -1.2650e-01, -1.1415e-01, -1.5079e-01,
         -3.3646e-02,  3.7337e-02,  1.2414e-01, -6.7748e-02, -1.5003e-01,
         -9.8251e-02,  1.4680e-01,  2.9873e-02,  6.1133e-02, -3.9841e-02,
         -5.2105e-02,  1.6631e-02, -1.1785e-02,  2.8503e-02,  1.0238e-01,
         -1.5005e-01, -8.9153e-02,  1.0466e-01, -5.7228e-02, -5.4974e-02,
         -1.4250e-01, -9.9339e-02,  1.3948e-01,  1.2345e-01, -4.8953e-02,
         -6.5410e-02,  9.1768e-02, -1.1686e-01,  1.0120e-01, -6.3359e-02,
          1.1315e-01,  1.1752e-01, -9.3136e-02, -1.0927e-01,  6.5805e-02,
         -5.5976e-02,  1.3841e-01, -1.4121e-01, -1.4012e-01,  1.4726e-02,
          3.0717e-03]], device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0622, -0.1054, -0.0385,  ..., -0.0607,  0.1220,  0.0355],
        [ 0.0840,  0.0135, -0.0663,  ..., -0.0636,  0.0588,  0.0378],
        [ 0.0987,  0.1040, -0.0729,  ...,  0.0169,  0.0424, -0.0887],
        ...,
        [ 0.0182, -0.0932,  0.0040,  ...,  0.0322, -0.0737, -0.0736],
        [-0.0209,  0.1022,  0.0926,  ..., -0.0339,  0.0256, -0.0959],
        [-0.0040, -0.1120, -0.0092,  ..., -0.0237, -0.0750, -0.0495]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0622, -0.1054, -0.0385,  ..., -0.0607,  0.1220,  0.0355],
        [ 0.0840,  0.0135, -0.0663,  ..., -0.0636,  0.0588,  0.0378],
        [ 0.0987,  0.1040, -0.0729,  ...,  0.0169,  0.0424, -0.0887],
        ...,
        [ 0.0182, -0.0932,  0.0040,  ...,  0.0322, -0.0737, -0.0736],
        [-0.0209,  0.1022,  0.0926,  ..., -0.0339,  0.0256, -0.0959],
        [-0.0040, -0.1120, -0.0092,  ..., -0.0237, -0.0750, -0.0495]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[ 0.0263, -0.0407,  0.1151,  ..., -0.0719, -0.0858,  0.1112],
        [-0.1240, -0.1028, -0.1087,  ...,  0.1283, -0.1672, -0.0341],
        [ 0.0836, -0.0617,  0.1632,  ...,  0.0362,  0.0223, -0.0055],
        ...,
        [ 0.1039,  0.1592,  0.0689,  ...,  0.1725, -0.0374, -0.0410],
        [ 0.1605,  0.0188, -0.0297,  ..., -0.1029,  0.0150, -0.0283],
        [ 0.0525, -0.1345, -0.1441,  ..., -0.1219,  0.1011,  0.1142]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0263, -0.0407,  0.1151,  ..., -0.0719, -0.0858,  0.1112],
        [-0.1240, -0.1028, -0.1087,  ...,  0.1283, -0.1672, -0.0341],
        [ 0.0836, -0.0617,  0.1632,  ...,  0.0362,  0.0223, -0.0055],
        ...,
        [ 0.1039,  0.1592,  0.0689,  ...,  0.1725, -0.0374, -0.0410],
        [ 0.1605,  0.0188, -0.0297,  ..., -0.1029,  0.0150, -0.0283],
        [ 0.0525, -0.1345, -0.1441,  ..., -0.1219,  0.1011,  0.1142]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.1384, -0.0147, -0.2471,  ...,  0.1681,  0.2210, -0.1515],
        [ 0.1357,  0.1103, -0.0746,  ..., -0.1438, -0.1849,  0.1307],
        [-0.1291, -0.2469,  0.0923,  ...,  0.1376,  0.1668, -0.2217],
        ...,
        [-0.0652, -0.1721,  0.0839,  ..., -0.0920,  0.0518, -0.2056],
        [ 0.0195, -0.1175, -0.0534,  ...,  0.1892, -0.1950, -0.1457],
        [ 0.0555, -0.1210, -0.0293,  ..., -0.1204, -0.2140,  0.0116]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1384, -0.0147, -0.2471,  ...,  0.1681,  0.2210, -0.1515],
        [ 0.1357,  0.1103, -0.0746,  ..., -0.1438, -0.1849,  0.1307],
        [-0.1291, -0.2469,  0.0923,  ...,  0.1376,  0.1668, -0.2217],
        ...,
        [-0.0652, -0.1721,  0.0839,  ..., -0.0920,  0.0518, -0.2056],
        [ 0.0195, -0.1175, -0.0534,  ...,  0.1892, -0.1950, -0.1457],
        [ 0.0555, -0.1210, -0.0293,  ..., -0.1204, -0.2140,  0.0116]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[-0.1911],
        [ 0.3409],
        [ 0.2417],
        [ 0.1601],
        [-0.3889],
        [ 0.0423],
        [ 0.3137],
        [ 0.3653],
        [-0.1565],
        [-0.3395],
        [-0.1519],
        [ 0.0489],
        [ 0.3615],
        [ 0.3647],
        [-0.2133],
        [-0.1333],
        [ 0.1770],
        [ 0.2173],
        [ 0.0095],
        [-0.0814],
        [-0.3916],
        [-0.3792],
        [-0.1014],
        [ 0.1393],
        [ 0.0998],
        [ 0.3743],
        [ 0.3901],
        [ 0.2848],
        [-0.0953],
        [ 0.0396],
        [-0.3578],
        [ 0.1058]], device='cuda:0') 
 Parameter containing:
tensor([[-0.1911],
        [ 0.3409],
        [ 0.2417],
        [ 0.1601],
        [-0.3889],
        [ 0.0423],
        [ 0.3137],
        [ 0.3653],
        [-0.1565],
        [-0.3395],
        [-0.1519],
        [ 0.0489],
        [ 0.3615],
        [ 0.3647],
        [-0.2133],
        [-0.1333],
        [ 0.1770],
        [ 0.2173],
        [ 0.0095],
        [-0.0814],
        [-0.3916],
        [-0.3792],
        [-0.1014],
        [ 0.1393],
        [ 0.0998],
        [ 0.3743],
        [ 0.3901],
        [ 0.2848],
        [-0.0953],
        [ 0.0396],
        [-0.3578],
        [ 0.1058]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.0000],
        [0.0000],
        [0.2988],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(173.1525, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.0000],
        [0.0000],
        [0.2988],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].sum tensor(173.1525, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0075, -0.0073, -0.0073,  ..., -0.0015,  0.0011,  0.0072],
        [-0.0249, -0.0243, -0.0243,  ..., -0.0050,  0.0035,  0.0238],
        [-0.0165, -0.0161, -0.0161,  ..., -0.0033,  0.0023,  0.0158],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-163.5130, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-20.8405, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-21.6517, device='cuda:0')



h[100].sum tensor(-10.0458, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-10.4368, device='cuda:0')



h[200].sum tensor(9.9208, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(10.3069, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0080, 0.0546],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0071, 0.0480],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0097, 0.0660],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(20184.9727, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2126, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2085, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2095, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(98165.5469, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-136.4571, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-124.3392, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(2349.5532, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(149.8981, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.9318],
        [-0.8970],
        [-0.8055],
        ...,
        [-0.0069],
        [-0.0071],
        [-0.0073]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-47911.2891, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[-0.9318],
        [-0.8970],
        [-0.8055],
        ...,
        [-0.0069],
        [-0.0071],
        [-0.0073]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0.     0.     0.2988 ... 0.     0.     0.    ]



input node feature: 
g.ndata[nfet] tensor([[0.0000],
        [0.0000],
        [0.2988],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(273.7637, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.0000],
        [0.0000],
        [0.2988],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].sum tensor(273.7637, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[ 0.0068,  0.0038,  0.0045,  ..., -0.0051,  0.0005,  0.0074],
        [ 0.0224,  0.0125,  0.0149,  ..., -0.0168,  0.0015,  0.0244],
        [ 0.0148,  0.0083,  0.0099,  ..., -0.0111,  0.0010,  0.0162],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(827.4442, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(29.6806, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(30.7916, device='cuda:0')



h[100].sum tensor(38.2972, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(39.7308, device='cuda:0')



h[200].sum tensor(-7.0157, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-7.2783, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0513, 0.0288, 0.0342,  ..., 0.0000, 0.0034, 0.0560],
        [0.0452, 0.0254, 0.0301,  ..., 0.0000, 0.0030, 0.0493],
        [0.0621, 0.0349, 0.0414,  ..., 0.0000, 0.0042, 0.0678],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(33296.1367, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.4169, 0.0025,  ..., 0.0396, 0.0000, 0.0418],
        [0.0000, 0.4088, 0.0025,  ..., 0.0388, 0.0000, 0.0410],
        [0.0000, 0.4108, 0.0025,  ..., 0.0390, 0.0000, 0.0412],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(183484.3438, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-272.4286, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(4611.4453, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(309.2509, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(4255.2979, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(285.3671, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[1.9671e-01],
        [1.8936e-01],
        [1.7005e-01],
        ...,
        [6.5984e-06],
        [1.0895e-04],
        [7.3023e-04]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(13793.2715, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-0.9318],
        [-0.8970],
        [-0.8055],
        ...,
        [-0.0069],
        [-0.0071],
        [-0.0073]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0.     0.     0.2988 ... 0.     0.     0.    ]



load_model False 
TraEvN 2000 
BatchSize 15 
EpochNum 10 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[-0.0289,  0.1215, -0.0744, -0.0131,  0.0083,  0.0933, -0.0072, -0.0836,
          0.1225,  0.1420,  0.0460, -0.0142, -0.1433,  0.0424,  0.1149,  0.0007,
         -0.0373,  0.1415, -0.0592,  0.1376, -0.0103, -0.0337, -0.1120,  0.1210,
         -0.1160, -0.0283,  0.0416, -0.1046,  0.1062,  0.1287,  0.0869, -0.0370,
          0.1462,  0.0318, -0.1300, -0.1106,  0.1508,  0.0729, -0.1139, -0.0657,
         -0.0201,  0.0689,  0.1384, -0.1411,  0.1193,  0.1311,  0.0274, -0.0423,
         -0.0935, -0.0304,  0.1471, -0.0097,  0.0393,  0.0404,  0.0849, -0.1105,
          0.0430,  0.0002,  0.0691, -0.1080,  0.0161, -0.0457, -0.0512, -0.1076,
          0.1129,  0.0963,  0.0726,  0.0121, -0.1497,  0.0676,  0.0440, -0.1501,
         -0.0895,  0.1398, -0.0570, -0.0489,  0.1409,  0.0624, -0.0014,  0.0710,
         -0.1465, -0.0248, -0.0578,  0.0569,  0.0403, -0.0220, -0.1100, -0.0959,
          0.0389,  0.0735,  0.0126,  0.0520, -0.0514,  0.0170, -0.0389, -0.0370,
         -0.1320, -0.1505, -0.0468,  0.0063, -0.1279, -0.0459,  0.1009,  0.0509,
         -0.0949,  0.1166,  0.0319,  0.0211,  0.1484,  0.0863, -0.0446, -0.1351,
         -0.0587,  0.0316, -0.1443,  0.1342, -0.1154,  0.0026, -0.1450,  0.0179,
         -0.1343, -0.0603,  0.0358,  0.0455,  0.0577, -0.0838,  0.1527,  0.0317,
         -0.0571, -0.1274, -0.0516, -0.0015,  0.0855,  0.0865, -0.0776,  0.1180,
          0.0516, -0.0960,  0.0198,  0.1416,  0.0390,  0.0287,  0.1076,  0.1187,
         -0.0263, -0.0772,  0.0756, -0.1160,  0.0363,  0.0855, -0.0980,  0.0415,
          0.1355,  0.0533, -0.0262, -0.0928, -0.0902,  0.0573, -0.0320, -0.1308,
          0.1280, -0.0875, -0.0970,  0.0478, -0.0329, -0.1099, -0.0476, -0.1436,
          0.0041, -0.1128, -0.0137, -0.1356,  0.0429, -0.0003,  0.1513,  0.1269,
         -0.0765, -0.0667,  0.0154, -0.0940, -0.0890, -0.0852, -0.1422,  0.1065,
         -0.0544, -0.0798,  0.1300,  0.1128,  0.0315, -0.1236, -0.1256, -0.0441,
         -0.1261,  0.0414,  0.0606, -0.0817,  0.1479,  0.0216, -0.0303,  0.0806,
         -0.1366,  0.0726, -0.0539, -0.1525,  0.0478, -0.0622, -0.1295, -0.0072,
          0.0009,  0.0956, -0.0058, -0.0961,  0.0529,  0.0019,  0.0659,  0.0822,
         -0.1223, -0.0414,  0.0170, -0.1422, -0.1068, -0.1147,  0.1288,  0.0296,
         -0.0700,  0.1370, -0.0615, -0.1085,  0.1209, -0.0887,  0.0014,  0.0130,
          0.0558, -0.0603,  0.0546, -0.1024, -0.0925, -0.0621, -0.0672,  0.0958,
         -0.1208,  0.0978, -0.1446, -0.1421, -0.1333,  0.1161, -0.0529, -0.1412,
         -0.0056,  0.0718,  0.0440, -0.0722, -0.1338,  0.1158, -0.0766, -0.0932]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0427,  0.1168,  0.0598,  ...,  0.0303,  0.0555, -0.0908],
        [ 0.0470,  0.0310, -0.1138,  ..., -0.0930, -0.0533,  0.0212],
        [-0.0329, -0.0105,  0.1050,  ...,  0.0707,  0.0014,  0.1106],
        ...,
        [ 0.1047,  0.0448,  0.0987,  ..., -0.1198, -0.0516,  0.0307],
        [ 0.0023, -0.0604,  0.0931,  ..., -0.0334,  0.1060, -0.0902],
        [-0.0786,  0.0847,  0.0565,  ...,  0.0775,  0.0576,  0.0383]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0996, -0.0094,  0.1225,  ..., -0.1302, -0.1648,  0.1144],
        [-0.0663,  0.1594,  0.0154,  ..., -0.1324, -0.1680,  0.1253],
        [ 0.0156, -0.1521,  0.1000,  ...,  0.0509,  0.0409, -0.1596],
        ...,
        [-0.0286, -0.0079,  0.0075,  ...,  0.0047, -0.1001,  0.0463],
        [ 0.0912,  0.1231, -0.1733,  ..., -0.0140,  0.1638,  0.1503],
        [-0.0961, -0.1520, -0.0536,  ..., -0.1201,  0.0643,  0.1522]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0246,  0.0999,  0.1789,  ..., -0.0039,  0.0446, -0.0544],
        [-0.1718,  0.1758,  0.0351,  ..., -0.1404, -0.0813,  0.1360],
        [ 0.0230,  0.0813,  0.2216,  ...,  0.0035, -0.1712, -0.2467],
        ...,
        [ 0.2026,  0.0784,  0.0578,  ..., -0.2101, -0.2106, -0.0614],
        [-0.0268, -0.0983, -0.2323,  ...,  0.2500,  0.0353,  0.2134],
        [-0.0839,  0.0087,  0.0241,  ...,  0.0882,  0.0108,  0.0601]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.3007],
        [-0.1809],
        [ 0.3816],
        [ 0.1063],
        [ 0.1098],
        [-0.2087],
        [-0.2722],
        [-0.3770],
        [-0.2920],
        [-0.3010],
        [ 0.2389],
        [ 0.1602],
        [ 0.2747],
        [ 0.1420],
        [-0.3822],
        [ 0.2203],
        [ 0.0222],
        [ 0.3109],
        [ 0.3392],
        [ 0.3223],
        [ 0.3642],
        [-0.1064],
        [ 0.1802],
        [ 0.1679],
        [ 0.0024],
        [ 0.3915],
        [-0.3912],
        [-0.4202],
        [-0.1896],
        [-0.1307],
        [ 0.1198],
        [ 0.0337]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]



optimizer.param_groups [{'params': [Parameter containing:
tensor([[-0.0289,  0.1215, -0.0744, -0.0131,  0.0083,  0.0933, -0.0072, -0.0836,
          0.1225,  0.1420,  0.0460, -0.0142, -0.1433,  0.0424,  0.1149,  0.0007,
         -0.0373,  0.1415, -0.0592,  0.1376, -0.0103, -0.0337, -0.1120,  0.1210,
         -0.1160, -0.0283,  0.0416, -0.1046,  0.1062,  0.1287,  0.0869, -0.0370,
          0.1462,  0.0318, -0.1300, -0.1106,  0.1508,  0.0729, -0.1139, -0.0657,
         -0.0201,  0.0689,  0.1384, -0.1411,  0.1193,  0.1311,  0.0274, -0.0423,
         -0.0935, -0.0304,  0.1471, -0.0097,  0.0393,  0.0404,  0.0849, -0.1105,
          0.0430,  0.0002,  0.0691, -0.1080,  0.0161, -0.0457, -0.0512, -0.1076,
          0.1129,  0.0963,  0.0726,  0.0121, -0.1497,  0.0676,  0.0440, -0.1501,
         -0.0895,  0.1398, -0.0570, -0.0489,  0.1409,  0.0624, -0.0014,  0.0710,
         -0.1465, -0.0248, -0.0578,  0.0569,  0.0403, -0.0220, -0.1100, -0.0959,
          0.0389,  0.0735,  0.0126,  0.0520, -0.0514,  0.0170, -0.0389, -0.0370,
         -0.1320, -0.1505, -0.0468,  0.0063, -0.1279, -0.0459,  0.1009,  0.0509,
         -0.0949,  0.1166,  0.0319,  0.0211,  0.1484,  0.0863, -0.0446, -0.1351,
         -0.0587,  0.0316, -0.1443,  0.1342, -0.1154,  0.0026, -0.1450,  0.0179,
         -0.1343, -0.0603,  0.0358,  0.0455,  0.0577, -0.0838,  0.1527,  0.0317,
         -0.0571, -0.1274, -0.0516, -0.0015,  0.0855,  0.0865, -0.0776,  0.1180,
          0.0516, -0.0960,  0.0198,  0.1416,  0.0390,  0.0287,  0.1076,  0.1187,
         -0.0263, -0.0772,  0.0756, -0.1160,  0.0363,  0.0855, -0.0980,  0.0415,
          0.1355,  0.0533, -0.0262, -0.0928, -0.0902,  0.0573, -0.0320, -0.1308,
          0.1280, -0.0875, -0.0970,  0.0478, -0.0329, -0.1099, -0.0476, -0.1436,
          0.0041, -0.1128, -0.0137, -0.1356,  0.0429, -0.0003,  0.1513,  0.1269,
         -0.0765, -0.0667,  0.0154, -0.0940, -0.0890, -0.0852, -0.1422,  0.1065,
         -0.0544, -0.0798,  0.1300,  0.1128,  0.0315, -0.1236, -0.1256, -0.0441,
         -0.1261,  0.0414,  0.0606, -0.0817,  0.1479,  0.0216, -0.0303,  0.0806,
         -0.1366,  0.0726, -0.0539, -0.1525,  0.0478, -0.0622, -0.1295, -0.0072,
          0.0009,  0.0956, -0.0058, -0.0961,  0.0529,  0.0019,  0.0659,  0.0822,
         -0.1223, -0.0414,  0.0170, -0.1422, -0.1068, -0.1147,  0.1288,  0.0296,
         -0.0700,  0.1370, -0.0615, -0.1085,  0.1209, -0.0887,  0.0014,  0.0130,
          0.0558, -0.0603,  0.0546, -0.1024, -0.0925, -0.0621, -0.0672,  0.0958,
         -0.1208,  0.0978, -0.1446, -0.1421, -0.1333,  0.1161, -0.0529, -0.1412,
         -0.0056,  0.0718,  0.0440, -0.0722, -0.1338,  0.1158, -0.0766, -0.0932]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0427,  0.1168,  0.0598,  ...,  0.0303,  0.0555, -0.0908],
        [ 0.0470,  0.0310, -0.1138,  ..., -0.0930, -0.0533,  0.0212],
        [-0.0329, -0.0105,  0.1050,  ...,  0.0707,  0.0014,  0.1106],
        ...,
        [ 0.1047,  0.0448,  0.0987,  ..., -0.1198, -0.0516,  0.0307],
        [ 0.0023, -0.0604,  0.0931,  ..., -0.0334,  0.1060, -0.0902],
        [-0.0786,  0.0847,  0.0565,  ...,  0.0775,  0.0576,  0.0383]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0996, -0.0094,  0.1225,  ..., -0.1302, -0.1648,  0.1144],
        [-0.0663,  0.1594,  0.0154,  ..., -0.1324, -0.1680,  0.1253],
        [ 0.0156, -0.1521,  0.1000,  ...,  0.0509,  0.0409, -0.1596],
        ...,
        [-0.0286, -0.0079,  0.0075,  ...,  0.0047, -0.1001,  0.0463],
        [ 0.0912,  0.1231, -0.1733,  ..., -0.0140,  0.1638,  0.1503],
        [-0.0961, -0.1520, -0.0536,  ..., -0.1201,  0.0643,  0.1522]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0246,  0.0999,  0.1789,  ..., -0.0039,  0.0446, -0.0544],
        [-0.1718,  0.1758,  0.0351,  ..., -0.1404, -0.0813,  0.1360],
        [ 0.0230,  0.0813,  0.2216,  ...,  0.0035, -0.1712, -0.2467],
        ...,
        [ 0.2026,  0.0784,  0.0578,  ..., -0.2101, -0.2106, -0.0614],
        [-0.0268, -0.0983, -0.2323,  ...,  0.2500,  0.0353,  0.2134],
        [-0.0839,  0.0087,  0.0241,  ...,  0.0882,  0.0108,  0.0601]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.3007],
        [-0.1809],
        [ 0.3816],
        [ 0.1063],
        [ 0.1098],
        [-0.2087],
        [-0.2722],
        [-0.3770],
        [-0.2920],
        [-0.3010],
        [ 0.2389],
        [ 0.1602],
        [ 0.2747],
        [ 0.1420],
        [-0.3822],
        [ 0.2203],
        [ 0.0222],
        [ 0.3109],
        [ 0.3392],
        [ 0.3223],
        [ 0.3642],
        [-0.1064],
        [ 0.1802],
        [ 0.1679],
        [ 0.0024],
        [ 0.3915],
        [-0.3912],
        [-0.4202],
        [-0.1896],
        [-0.1307],
        [ 0.1198],
        [ 0.0337]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}, {'params': [tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./Training.py", line 76, in <module>
    featbatch = TraTen[i : i + BatchSize].reshape(BatchSize * 6796, 1)
RuntimeError: shape '[101940, 1]' is invalid for input of size 0

real	1m42.967s
user	0m8.163s
sys	0m7.311s
