0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        465.19.01
supported:      external
license:        NVIDIA
firmware:       nvidia/465.19.01/gsp.bin
retpoline:      Y
rhelversion:    7.8
srcversion:     976AD09EB9C3B8943CBA8C4
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           nv_cap_enable_devfs:Enable (1) or disable (0) nv-caps devfs support. Default: 1 (int)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           rm_firmware_active:charp

nvidia-smi:
Fri Aug 12 16:26:02 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   23C    P0    32W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.505273344

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b6c49612880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m38.880s
user	0m3.709s
sys	0m3.024s
[16:26:42] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 1.2367],
        [-0.6588],
        [-0.8599],
        ...,
        [-0.4285],
        [-0.4374],
        [-0.3826]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-92.9947, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (80000, 6796) (80000, 6796)
sum 5574226 8401300
shape torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 0.0439,  0.0791, -0.0837,  0.0637, -0.0617,  0.0639,  0.1386,  0.0092,
          0.1098,  0.1367, -0.0999, -0.0603,  0.1137,  0.0498,  0.0027, -0.0259,
          0.0132,  0.0598, -0.0826,  0.0914, -0.1125,  0.1493,  0.0443, -0.0134,
          0.0219, -0.0805, -0.0219, -0.0761,  0.0071,  0.1311, -0.1150, -0.0625,
          0.0252, -0.1379,  0.1522,  0.0863,  0.0562,  0.1392,  0.0522, -0.0028,
          0.0284, -0.0970,  0.0688,  0.0712, -0.0361, -0.1423,  0.0022,  0.0347,
          0.0351, -0.0689,  0.0313, -0.1369,  0.1304,  0.0212,  0.1417, -0.0827,
         -0.1457,  0.0764, -0.1278,  0.0339, -0.1428, -0.1502,  0.0962,  0.0124,
         -0.0808,  0.1086,  0.1406, -0.1129, -0.1383,  0.1470,  0.0139, -0.0417,
         -0.0047, -0.0965,  0.0381,  0.1011, -0.1036, -0.1122, -0.0961, -0.0760,
          0.0343,  0.1288,  0.0833,  0.1452,  0.1155, -0.0799, -0.1038, -0.0547,
          0.0920,  0.0152, -0.1461, -0.1091, -0.1469, -0.0063, -0.1124, -0.1158,
         -0.0146, -0.1116,  0.0334, -0.0822, -0.1061,  0.0768,  0.0284, -0.1044,
         -0.0042,  0.0023, -0.0856,  0.1390,  0.0296, -0.0625, -0.0708,  0.1346,
         -0.0048,  0.1280, -0.0609, -0.0066, -0.0677,  0.1152, -0.0066, -0.0740,
          0.0528,  0.0582,  0.1177,  0.0885, -0.0193,  0.0501, -0.0850,  0.0404,
          0.1303,  0.0944,  0.0725,  0.0624, -0.0298,  0.0513,  0.0031,  0.0917,
         -0.1399,  0.0610, -0.1388, -0.0420, -0.0035, -0.0363, -0.0785,  0.0762,
         -0.0193,  0.1450,  0.0635,  0.0209, -0.0305,  0.0704,  0.1066, -0.0475,
         -0.0357,  0.1374,  0.0415, -0.1022, -0.0430, -0.1153, -0.0998,  0.0848,
         -0.0005, -0.1376, -0.0004, -0.1410,  0.0800,  0.0672, -0.1335,  0.0947,
          0.0768,  0.0806,  0.0120,  0.0640,  0.1356, -0.0828, -0.0664,  0.0764,
          0.1039, -0.0513,  0.0295, -0.1116,  0.0969,  0.1065,  0.1208, -0.0635,
         -0.1085, -0.0204,  0.0981,  0.0417, -0.0565,  0.1365,  0.1295, -0.0069,
          0.1121,  0.1397, -0.0173,  0.1267,  0.0248, -0.1140,  0.1070,  0.0003,
          0.1150,  0.0738,  0.0319, -0.1257,  0.0373, -0.0580,  0.0813,  0.0154,
          0.0846, -0.0521,  0.0588,  0.0359,  0.0676, -0.1107,  0.1190, -0.0123,
         -0.0339, -0.0491,  0.1032, -0.1049,  0.1349, -0.1169, -0.0177,  0.0057,
         -0.0493, -0.0943, -0.0364, -0.0353,  0.1224, -0.0693, -0.0199,  0.0846,
         -0.1372, -0.0698, -0.1330,  0.1198, -0.0689, -0.0548, -0.0026,  0.0613,
          0.1373,  0.0934,  0.0328, -0.0299, -0.0838,  0.0430,  0.0183, -0.0262,
         -0.1305, -0.1507,  0.0711, -0.1228, -0.0742, -0.0305,  0.0051, -0.1476]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0439,  0.0791, -0.0837,  0.0637, -0.0617,  0.0639,  0.1386,  0.0092,
          0.1098,  0.1367, -0.0999, -0.0603,  0.1137,  0.0498,  0.0027, -0.0259,
          0.0132,  0.0598, -0.0826,  0.0914, -0.1125,  0.1493,  0.0443, -0.0134,
          0.0219, -0.0805, -0.0219, -0.0761,  0.0071,  0.1311, -0.1150, -0.0625,
          0.0252, -0.1379,  0.1522,  0.0863,  0.0562,  0.1392,  0.0522, -0.0028,
          0.0284, -0.0970,  0.0688,  0.0712, -0.0361, -0.1423,  0.0022,  0.0347,
          0.0351, -0.0689,  0.0313, -0.1369,  0.1304,  0.0212,  0.1417, -0.0827,
         -0.1457,  0.0764, -0.1278,  0.0339, -0.1428, -0.1502,  0.0962,  0.0124,
         -0.0808,  0.1086,  0.1406, -0.1129, -0.1383,  0.1470,  0.0139, -0.0417,
         -0.0047, -0.0965,  0.0381,  0.1011, -0.1036, -0.1122, -0.0961, -0.0760,
          0.0343,  0.1288,  0.0833,  0.1452,  0.1155, -0.0799, -0.1038, -0.0547,
          0.0920,  0.0152, -0.1461, -0.1091, -0.1469, -0.0063, -0.1124, -0.1158,
         -0.0146, -0.1116,  0.0334, -0.0822, -0.1061,  0.0768,  0.0284, -0.1044,
         -0.0042,  0.0023, -0.0856,  0.1390,  0.0296, -0.0625, -0.0708,  0.1346,
         -0.0048,  0.1280, -0.0609, -0.0066, -0.0677,  0.1152, -0.0066, -0.0740,
          0.0528,  0.0582,  0.1177,  0.0885, -0.0193,  0.0501, -0.0850,  0.0404,
          0.1303,  0.0944,  0.0725,  0.0624, -0.0298,  0.0513,  0.0031,  0.0917,
         -0.1399,  0.0610, -0.1388, -0.0420, -0.0035, -0.0363, -0.0785,  0.0762,
         -0.0193,  0.1450,  0.0635,  0.0209, -0.0305,  0.0704,  0.1066, -0.0475,
         -0.0357,  0.1374,  0.0415, -0.1022, -0.0430, -0.1153, -0.0998,  0.0848,
         -0.0005, -0.1376, -0.0004, -0.1410,  0.0800,  0.0672, -0.1335,  0.0947,
          0.0768,  0.0806,  0.0120,  0.0640,  0.1356, -0.0828, -0.0664,  0.0764,
          0.1039, -0.0513,  0.0295, -0.1116,  0.0969,  0.1065,  0.1208, -0.0635,
         -0.1085, -0.0204,  0.0981,  0.0417, -0.0565,  0.1365,  0.1295, -0.0069,
          0.1121,  0.1397, -0.0173,  0.1267,  0.0248, -0.1140,  0.1070,  0.0003,
          0.1150,  0.0738,  0.0319, -0.1257,  0.0373, -0.0580,  0.0813,  0.0154,
          0.0846, -0.0521,  0.0588,  0.0359,  0.0676, -0.1107,  0.1190, -0.0123,
         -0.0339, -0.0491,  0.1032, -0.1049,  0.1349, -0.1169, -0.0177,  0.0057,
         -0.0493, -0.0943, -0.0364, -0.0353,  0.1224, -0.0693, -0.0199,  0.0846,
         -0.1372, -0.0698, -0.1330,  0.1198, -0.0689, -0.0548, -0.0026,  0.0613,
          0.1373,  0.0934,  0.0328, -0.0299, -0.0838,  0.0430,  0.0183, -0.0262,
         -0.1305, -0.1507,  0.0711, -0.1228, -0.0742, -0.0305,  0.0051, -0.1476]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[-0.0332, -0.0373,  0.1005,  ..., -0.1068,  0.0982,  0.0676],
        [ 0.0154, -0.1171,  0.0580,  ..., -0.1108,  0.1160,  0.0895],
        [-0.0513, -0.0780,  0.1159,  ..., -0.1147,  0.0464,  0.0789],
        ...,
        [ 0.0257,  0.0336, -0.0428,  ...,  0.1073, -0.0812,  0.0250],
        [-0.0912,  0.0803, -0.0344,  ..., -0.0842,  0.0562, -0.1166],
        [ 0.0238, -0.0980, -0.0090,  ..., -0.0313,  0.0947,  0.0477]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0332, -0.0373,  0.1005,  ..., -0.1068,  0.0982,  0.0676],
        [ 0.0154, -0.1171,  0.0580,  ..., -0.1108,  0.1160,  0.0895],
        [-0.0513, -0.0780,  0.1159,  ..., -0.1147,  0.0464,  0.0789],
        ...,
        [ 0.0257,  0.0336, -0.0428,  ...,  0.1073, -0.0812,  0.0250],
        [-0.0912,  0.0803, -0.0344,  ..., -0.0842,  0.0562, -0.1166],
        [ 0.0238, -0.0980, -0.0090,  ..., -0.0313,  0.0947,  0.0477]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.0111, -0.1682, -0.0096,  ...,  0.1754,  0.0276,  0.0670],
        [ 0.1616, -0.0859,  0.1193,  ..., -0.0753, -0.0150,  0.1159],
        [ 0.1098, -0.0474,  0.1088,  ..., -0.0538,  0.0566,  0.0840],
        ...,
        [-0.0533, -0.1682,  0.0620,  ...,  0.1506, -0.0469,  0.0417],
        [ 0.0383, -0.0150, -0.1214,  ...,  0.1385,  0.1640,  0.0264],
        [-0.0041,  0.0463,  0.1111,  ...,  0.1312, -0.1535,  0.1548]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0111, -0.1682, -0.0096,  ...,  0.1754,  0.0276,  0.0670],
        [ 0.1616, -0.0859,  0.1193,  ..., -0.0753, -0.0150,  0.1159],
        [ 0.1098, -0.0474,  0.1088,  ..., -0.0538,  0.0566,  0.0840],
        ...,
        [-0.0533, -0.1682,  0.0620,  ...,  0.1506, -0.0469,  0.0417],
        [ 0.0383, -0.0150, -0.1214,  ...,  0.1385,  0.1640,  0.0264],
        [-0.0041,  0.0463,  0.1111,  ...,  0.1312, -0.1535,  0.1548]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.0334, -0.2180,  0.0730,  ...,  0.1068, -0.0969,  0.1015],
        [-0.1179, -0.2325,  0.2351,  ..., -0.0217,  0.2122, -0.0076],
        [ 0.1297,  0.2288, -0.1747,  ..., -0.0912, -0.2004, -0.1104],
        ...,
        [ 0.0268,  0.1748, -0.0733,  ...,  0.2253,  0.0930, -0.1605],
        [-0.2353, -0.1232, -0.1185,  ...,  0.0162,  0.1622,  0.2380],
        [-0.1501,  0.1738,  0.0976,  ..., -0.0180, -0.1046,  0.1545]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0334, -0.2180,  0.0730,  ...,  0.1068, -0.0969,  0.1015],
        [-0.1179, -0.2325,  0.2351,  ..., -0.0217,  0.2122, -0.0076],
        [ 0.1297,  0.2288, -0.1747,  ..., -0.0912, -0.2004, -0.1104],
        ...,
        [ 0.0268,  0.1748, -0.0733,  ...,  0.2253,  0.0930, -0.1605],
        [-0.2353, -0.1232, -0.1185,  ...,  0.0162,  0.1622,  0.2380],
        [-0.1501,  0.1738,  0.0976,  ..., -0.0180, -0.1046,  0.1545]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.2887],
        [-0.1877],
        [ 0.2763],
        [ 0.3109],
        [ 0.1520],
        [ 0.3064],
        [ 0.0210],
        [-0.2250],
        [ 0.3091],
        [ 0.2069],
        [-0.0017],
        [ 0.2666],
        [-0.3312],
        [ 0.0373],
        [-0.1000],
        [ 0.3453],
        [ 0.1784],
        [-0.2467],
        [-0.4105],
        [-0.0247],
        [-0.3755],
        [ 0.0339],
        [ 0.1562],
        [-0.3113],
        [-0.2248],
        [-0.2188],
        [ 0.0294],
        [-0.3378],
        [ 0.3333],
        [-0.3839],
        [-0.1031],
        [-0.1886]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.2887],
        [-0.1877],
        [ 0.2763],
        [ 0.3109],
        [ 0.1520],
        [ 0.3064],
        [ 0.0210],
        [-0.2250],
        [ 0.3091],
        [ 0.2069],
        [-0.0017],
        [ 0.2666],
        [-0.3312],
        [ 0.0373],
        [-0.1000],
        [ 0.3453],
        [ 0.1784],
        [-0.2467],
        [-0.4105],
        [-0.0247],
        [-0.3755],
        [ 0.0339],
        [ 0.1562],
        [-0.3113],
        [-0.2248],
        [-0.2188],
        [ 0.0294],
        [-0.3378],
        [ 0.3333],
        [-0.3839],
        [-0.1031],
        [-0.1886]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 0.1119,  0.1284, -0.0045,  0.0140,  0.1138,  0.0205,  0.0207, -0.1279,
         -0.1519, -0.1331, -0.0553, -0.1403,  0.0681, -0.0120, -0.0509, -0.1399,
          0.0548, -0.1051, -0.1253,  0.1224, -0.0071,  0.0085, -0.0919, -0.1018,
          0.0570, -0.1364,  0.0210,  0.0534, -0.0008,  0.0952, -0.1063,  0.0939,
         -0.0246, -0.0266,  0.1504,  0.0529, -0.1527,  0.0743,  0.0889,  0.1356,
         -0.0820, -0.0207, -0.0003,  0.0753, -0.0353,  0.0415,  0.0294, -0.1072,
         -0.0498,  0.0978, -0.1395, -0.0272, -0.0387, -0.0681, -0.1100, -0.0828,
          0.0419,  0.0011, -0.1086,  0.1514, -0.1103, -0.1319,  0.0691, -0.1433,
         -0.0113,  0.0027,  0.0582,  0.0645, -0.0036, -0.1030, -0.0327, -0.1260,
         -0.0609,  0.1439,  0.0279,  0.0803,  0.0696,  0.1244,  0.0611, -0.1224,
         -0.0437,  0.0899, -0.0587, -0.0810, -0.0209, -0.1102,  0.0096, -0.1216,
         -0.0964, -0.0682, -0.0362, -0.0835,  0.1358,  0.0459, -0.0776,  0.0673,
          0.1137, -0.0580,  0.1003,  0.1465, -0.0948, -0.1028, -0.0539,  0.0656,
          0.0135, -0.0738,  0.1387,  0.1120, -0.1037,  0.0334, -0.0107, -0.0752,
         -0.0019, -0.0238,  0.1041,  0.1474,  0.0630,  0.1477,  0.1228, -0.0607,
          0.0797, -0.1457,  0.0076,  0.0843, -0.1417, -0.1144,  0.0846, -0.0038,
         -0.0525,  0.0607, -0.0843, -0.0228,  0.1447, -0.0592,  0.0022, -0.1108,
          0.1459, -0.1377,  0.1029, -0.1462,  0.1313,  0.0441,  0.1393, -0.0186,
          0.0923, -0.1356,  0.1414,  0.1243, -0.0502, -0.0797, -0.1410, -0.1429,
         -0.0874, -0.0589, -0.0504,  0.0960, -0.1282,  0.0094,  0.1507, -0.0549,
          0.0515, -0.1107,  0.0289, -0.0422, -0.0818, -0.1086,  0.0263, -0.0667,
          0.1098,  0.0656, -0.0923, -0.0115, -0.0591,  0.0239, -0.1443, -0.1271,
          0.0403, -0.0890,  0.0763, -0.1059, -0.0417, -0.1515,  0.0076, -0.0941,
         -0.0871, -0.0500, -0.0515,  0.1021,  0.1296,  0.0082,  0.0826, -0.0622,
         -0.1443, -0.0659,  0.1382,  0.0685, -0.0919, -0.1034,  0.0750, -0.0130,
         -0.1095, -0.1155, -0.0937,  0.0206,  0.1304,  0.0767, -0.0962, -0.1048,
         -0.0553,  0.1446, -0.0740, -0.1057,  0.1427,  0.1148,  0.1121, -0.0982,
          0.0494,  0.1186, -0.0788,  0.0204, -0.0607,  0.0963, -0.0636,  0.0127,
         -0.1296, -0.0024,  0.1428, -0.1133, -0.1353,  0.1103, -0.0941,  0.0435,
          0.0431, -0.1207,  0.0323, -0.0354, -0.0852, -0.1201, -0.0601,  0.0851,
          0.0190, -0.0646, -0.0768, -0.0608, -0.0345, -0.0310,  0.1226, -0.0836,
         -0.1098, -0.1408, -0.0018,  0.1510,  0.0784, -0.0150, -0.0545,  0.1063]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1119,  0.1284, -0.0045,  0.0140,  0.1138,  0.0205,  0.0207, -0.1279,
         -0.1519, -0.1331, -0.0553, -0.1403,  0.0681, -0.0120, -0.0509, -0.1399,
          0.0548, -0.1051, -0.1253,  0.1224, -0.0071,  0.0085, -0.0919, -0.1018,
          0.0570, -0.1364,  0.0210,  0.0534, -0.0008,  0.0952, -0.1063,  0.0939,
         -0.0246, -0.0266,  0.1504,  0.0529, -0.1527,  0.0743,  0.0889,  0.1356,
         -0.0820, -0.0207, -0.0003,  0.0753, -0.0353,  0.0415,  0.0294, -0.1072,
         -0.0498,  0.0978, -0.1395, -0.0272, -0.0387, -0.0681, -0.1100, -0.0828,
          0.0419,  0.0011, -0.1086,  0.1514, -0.1103, -0.1319,  0.0691, -0.1433,
         -0.0113,  0.0027,  0.0582,  0.0645, -0.0036, -0.1030, -0.0327, -0.1260,
         -0.0609,  0.1439,  0.0279,  0.0803,  0.0696,  0.1244,  0.0611, -0.1224,
         -0.0437,  0.0899, -0.0587, -0.0810, -0.0209, -0.1102,  0.0096, -0.1216,
         -0.0964, -0.0682, -0.0362, -0.0835,  0.1358,  0.0459, -0.0776,  0.0673,
          0.1137, -0.0580,  0.1003,  0.1465, -0.0948, -0.1028, -0.0539,  0.0656,
          0.0135, -0.0738,  0.1387,  0.1120, -0.1037,  0.0334, -0.0107, -0.0752,
         -0.0019, -0.0238,  0.1041,  0.1474,  0.0630,  0.1477,  0.1228, -0.0607,
          0.0797, -0.1457,  0.0076,  0.0843, -0.1417, -0.1144,  0.0846, -0.0038,
         -0.0525,  0.0607, -0.0843, -0.0228,  0.1447, -0.0592,  0.0022, -0.1108,
          0.1459, -0.1377,  0.1029, -0.1462,  0.1313,  0.0441,  0.1393, -0.0186,
          0.0923, -0.1356,  0.1414,  0.1243, -0.0502, -0.0797, -0.1410, -0.1429,
         -0.0874, -0.0589, -0.0504,  0.0960, -0.1282,  0.0094,  0.1507, -0.0549,
          0.0515, -0.1107,  0.0289, -0.0422, -0.0818, -0.1086,  0.0263, -0.0667,
          0.1098,  0.0656, -0.0923, -0.0115, -0.0591,  0.0239, -0.1443, -0.1271,
          0.0403, -0.0890,  0.0763, -0.1059, -0.0417, -0.1515,  0.0076, -0.0941,
         -0.0871, -0.0500, -0.0515,  0.1021,  0.1296,  0.0082,  0.0826, -0.0622,
         -0.1443, -0.0659,  0.1382,  0.0685, -0.0919, -0.1034,  0.0750, -0.0130,
         -0.1095, -0.1155, -0.0937,  0.0206,  0.1304,  0.0767, -0.0962, -0.1048,
         -0.0553,  0.1446, -0.0740, -0.1057,  0.1427,  0.1148,  0.1121, -0.0982,
          0.0494,  0.1186, -0.0788,  0.0204, -0.0607,  0.0963, -0.0636,  0.0127,
         -0.1296, -0.0024,  0.1428, -0.1133, -0.1353,  0.1103, -0.0941,  0.0435,
          0.0431, -0.1207,  0.0323, -0.0354, -0.0852, -0.1201, -0.0601,  0.0851,
          0.0190, -0.0646, -0.0768, -0.0608, -0.0345, -0.0310,  0.1226, -0.0836,
         -0.1098, -0.1408, -0.0018,  0.1510,  0.0784, -0.0150, -0.0545,  0.1063]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0033,  0.0043, -0.0652,  ..., -0.0624, -0.0043, -0.0024],
        [ 0.0002, -0.0469, -0.0486,  ..., -0.0763,  0.1157,  0.0560],
        [ 0.0069, -0.1203, -0.0953,  ...,  0.0044,  0.1123, -0.0002],
        ...,
        [ 0.1154,  0.0961, -0.1034,  ..., -0.0379, -0.1030,  0.0388],
        [ 0.0767,  0.1200, -0.0010,  ..., -0.1210, -0.0626, -0.0817],
        [-0.0850,  0.0247, -0.0873,  ..., -0.1185, -0.1045,  0.0272]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0033,  0.0043, -0.0652,  ..., -0.0624, -0.0043, -0.0024],
        [ 0.0002, -0.0469, -0.0486,  ..., -0.0763,  0.1157,  0.0560],
        [ 0.0069, -0.1203, -0.0953,  ...,  0.0044,  0.1123, -0.0002],
        ...,
        [ 0.1154,  0.0961, -0.1034,  ..., -0.0379, -0.1030,  0.0388],
        [ 0.0767,  0.1200, -0.0010,  ..., -0.1210, -0.0626, -0.0817],
        [-0.0850,  0.0247, -0.0873,  ..., -0.1185, -0.1045,  0.0272]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[ 0.1421,  0.0697, -0.0392,  ...,  0.0117,  0.1232,  0.0643],
        [ 0.1172,  0.1457, -0.1071,  ..., -0.1508, -0.0768,  0.1672],
        [ 0.1227, -0.1368, -0.1115,  ..., -0.1569,  0.1263, -0.1305],
        ...,
        [ 0.1636, -0.0228, -0.0185,  ..., -0.0022, -0.0744, -0.0353],
        [ 0.0803,  0.0215, -0.1382,  ...,  0.1651,  0.0157,  0.0839],
        [ 0.1098,  0.0506, -0.0319,  ...,  0.0252, -0.1081,  0.0286]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1421,  0.0697, -0.0392,  ...,  0.0117,  0.1232,  0.0643],
        [ 0.1172,  0.1457, -0.1071,  ..., -0.1508, -0.0768,  0.1672],
        [ 0.1227, -0.1368, -0.1115,  ..., -0.1569,  0.1263, -0.1305],
        ...,
        [ 0.1636, -0.0228, -0.0185,  ..., -0.0022, -0.0744, -0.0353],
        [ 0.0803,  0.0215, -0.1382,  ...,  0.1651,  0.0157,  0.0839],
        [ 0.1098,  0.0506, -0.0319,  ...,  0.0252, -0.1081,  0.0286]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.2406,  0.1380, -0.0586,  ...,  0.2234, -0.1281, -0.1850],
        [-0.1671, -0.2301,  0.0114,  ..., -0.0859,  0.0622, -0.2479],
        [-0.0608, -0.2500, -0.0215,  ..., -0.0385,  0.2317, -0.0837],
        ...,
        [-0.0308, -0.1549, -0.2481,  ..., -0.0492, -0.2102,  0.1155],
        [ 0.2095, -0.2006, -0.1366,  ...,  0.1434, -0.0288, -0.2333],
        [-0.0045,  0.0161,  0.0342,  ..., -0.0632, -0.2351,  0.1358]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.2406,  0.1380, -0.0586,  ...,  0.2234, -0.1281, -0.1850],
        [-0.1671, -0.2301,  0.0114,  ..., -0.0859,  0.0622, -0.2479],
        [-0.0608, -0.2500, -0.0215,  ..., -0.0385,  0.2317, -0.0837],
        ...,
        [-0.0308, -0.1549, -0.2481,  ..., -0.0492, -0.2102,  0.1155],
        [ 0.2095, -0.2006, -0.1366,  ...,  0.1434, -0.0288, -0.2333],
        [-0.0045,  0.0161,  0.0342,  ..., -0.0632, -0.2351,  0.1358]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[-0.3747],
        [-0.0589],
        [ 0.1062],
        [-0.0896],
        [ 0.0436],
        [ 0.1725],
        [-0.3832],
        [ 0.2933],
        [ 0.2498],
        [ 0.1242],
        [-0.3623],
        [-0.1717],
        [-0.3460],
        [-0.1357],
        [ 0.2679],
        [-0.2954],
        [ 0.3967],
        [ 0.0356],
        [ 0.2519],
        [-0.1286],
        [-0.1315],
        [-0.2271],
        [ 0.3988],
        [ 0.2516],
        [-0.2052],
        [-0.2660],
        [ 0.4226],
        [ 0.1626],
        [-0.1063],
        [-0.1253],
        [-0.3235],
        [-0.0210]], device='cuda:0') 
 Parameter containing:
tensor([[-0.3747],
        [-0.0589],
        [ 0.1062],
        [-0.0896],
        [ 0.0436],
        [ 0.1725],
        [-0.3832],
        [ 0.2933],
        [ 0.2498],
        [ 0.1242],
        [-0.3623],
        [-0.1717],
        [-0.3460],
        [-0.1357],
        [ 0.2679],
        [-0.2954],
        [ 0.3967],
        [ 0.0356],
        [ 0.2519],
        [-0.1286],
        [-0.1315],
        [-0.2271],
        [ 0.3988],
        [ 0.2516],
        [-0.2052],
        [-0.2660],
        [ 0.4226],
        [ 0.1626],
        [-0.1063],
        [-0.1253],
        [-0.3235],
        [-0.0210]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(23.4113, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(4.8945, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(5.0233, device='cuda:0')



h[100].sum tensor(4.2124, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(4.3232, device='cuda:0')



h[200].sum tensor(1.7150, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(1.7602, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(3058.7100, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0013, 0.0013, 0.0030,  ..., 0.0000, 0.0000, 0.0000],
        [0.0069, 0.0069, 0.0159,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(16186.1455, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(267.4043, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(21.3902, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-17.4078, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(235.7703, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(18.8645, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.2324],
        [0.2846],
        [0.4102],
        ...,
        [0.0657],
        [0.0657],
        [0.0521]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(5865.1348, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[0.2324],
        [0.2846],
        [0.4102],
        ...,
        [0.0657],
        [0.0657],
        [0.0521]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(536.6049, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(10.8405, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(10.7526, device='cuda:0')



h[100].sum tensor(11.4503, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(11.3575, device='cuda:0')



h[200].sum tensor(10.5985, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(10.5126, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(17763.1699, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0030, 0.0306, 0.0260,  ..., 0.0156, 0.0000, 0.0108],
        [0.0006, 0.0064, 0.0054,  ..., 0.0033, 0.0000, 0.0023],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(84483.6250, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(246.5288, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(17.3704, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-119.6422, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(550.8030, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(38.7539, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.5115],
        [-0.3136],
        [-0.1919],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(-30042.6641, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[0.2324],
        [0.2846],
        [0.4102],
        ...,
        [0.0657],
        [0.0657],
        [0.0521]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py", line 5, in <module>
    from ModelBha import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/ModelBha.py", line 209, in <module>
    plt.savefig(f'/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/{modelname}/results/{t}\
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/pyplot.py", line 966, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/figure.py", line 3015, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 2255, in print_figure
    result = print_method(
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 1669, in wrapper
    return func(*args, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py", line 509, in print_png
    mpl.image.imsave(
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/image.py", line 1616, in imsave
    image.save(fname, **pil_kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/PIL/Image.py", line 2237, in save
    fp = builtins.open(filename, "w+b")
FileNotFoundError: [Errno 2] No such file or directory: '/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N2/results/2022-08-12 16:27:42.157260    passing three random events (20, 30, 31) from network before training.png'

real	1m5.359s
user	0m11.575s
sys	0m12.466s
