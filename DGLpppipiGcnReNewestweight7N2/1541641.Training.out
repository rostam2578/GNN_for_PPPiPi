0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        465.19.01
supported:      external
license:        NVIDIA
firmware:       nvidia/465.19.01/gsp.bin
retpoline:      Y
rhelversion:    7.8
srcversion:     976AD09EB9C3B8943CBA8C4
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           nv_cap_enable_devfs:Enable (1) or disable (0) nv-caps devfs support. Default: 1 (int)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           rm_firmware_active:charp

nvidia-smi:
Sat Aug 13 06:36:25 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   31C    P0    33W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.505273344

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b14a8835880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m5.024s
user	0m2.729s
sys	0m0.984s
[06:36:33] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[-1.3740],
        [ 0.7136],
        [-0.0025],
        ...,
        [-1.2216],
        [ 1.6439],
        [-0.6954]], device='cuda:0', requires_grad=True) 
node features sum: tensor(40.9364, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (80000, 6796) (80000, 6796)
sum 5574226 8401300
shape torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLpppipiGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 0.0483, -0.1028,  0.0579, -0.0466,  0.0937, -0.0365,  0.0065,  0.0700,
         -0.1519,  0.1287, -0.1446,  0.0410, -0.0878,  0.0172,  0.0231,  0.0559,
         -0.0777,  0.1212, -0.0025,  0.0358,  0.0623, -0.0534, -0.0174, -0.0088,
         -0.0455,  0.0158, -0.0629, -0.0564, -0.1467,  0.1031, -0.1083, -0.0595,
          0.0084, -0.1279,  0.0993,  0.1100, -0.0510, -0.0847,  0.0163,  0.1220,
         -0.1391, -0.0968,  0.1186,  0.1228,  0.1502, -0.0852,  0.0062,  0.0707,
         -0.0477, -0.0552,  0.1502, -0.1283, -0.0369, -0.1304, -0.1504, -0.1109,
         -0.0572,  0.0875,  0.0630,  0.1341, -0.1150,  0.1045,  0.1511, -0.0949,
          0.1019,  0.1004,  0.0263, -0.1418, -0.0472,  0.0406,  0.0295,  0.0047,
          0.1396,  0.0208, -0.1224,  0.0038, -0.0047,  0.1255, -0.0209,  0.0666,
          0.0405,  0.1432, -0.0732,  0.1163, -0.0010,  0.1141,  0.0140, -0.0296,
         -0.0320,  0.0289,  0.1426, -0.0192,  0.0383,  0.1407,  0.0843, -0.1020,
          0.0089, -0.1336, -0.1302,  0.0642, -0.0563,  0.1147,  0.0642,  0.1158,
         -0.1447, -0.0412,  0.0167,  0.0912,  0.0171, -0.0565, -0.0412, -0.0677,
         -0.1012, -0.0723,  0.0746,  0.0307,  0.0867,  0.1278, -0.1393,  0.0044,
          0.0700,  0.1517, -0.0338,  0.0229, -0.0218, -0.0779, -0.1121, -0.1003,
          0.1255,  0.0941,  0.0093,  0.1422, -0.1222,  0.0437,  0.1453, -0.1323,
         -0.1171, -0.0948,  0.1043,  0.1292,  0.0701,  0.0635,  0.1142, -0.0874,
          0.0460, -0.0154, -0.0457, -0.0869, -0.0410,  0.1239, -0.1332, -0.1095,
         -0.0424,  0.0386, -0.0093, -0.1494, -0.1392, -0.0014, -0.0838,  0.0286,
          0.1095, -0.0321, -0.0998,  0.0359,  0.1257, -0.0798,  0.0798, -0.0604,
         -0.1013, -0.1172,  0.0697,  0.0891,  0.0837,  0.0780, -0.0644,  0.1057,
          0.1100,  0.1164,  0.0999, -0.0334,  0.1411, -0.1341, -0.0419, -0.1300,
          0.0722,  0.0947, -0.0374, -0.1043, -0.0425, -0.0181,  0.0624, -0.0284,
         -0.1090, -0.1263, -0.0970,  0.1214,  0.0397,  0.0707,  0.0078,  0.1473,
         -0.1152, -0.0085, -0.0220,  0.0841,  0.1233, -0.1471,  0.1233, -0.1086,
         -0.1353,  0.1357,  0.0698, -0.1462,  0.1079,  0.0384,  0.1120,  0.0633,
          0.0444, -0.0334, -0.1112, -0.0777, -0.1047,  0.1089, -0.1147, -0.0600,
         -0.0711,  0.0028, -0.0925, -0.0092, -0.0276, -0.0658,  0.0998,  0.0435,
         -0.0486, -0.0730, -0.0061, -0.1047,  0.0743,  0.0311, -0.0002,  0.0478,
         -0.1463,  0.0601,  0.1168, -0.1509,  0.0909, -0.1079, -0.1219,  0.0195,
         -0.1201,  0.0690,  0.1297,  0.0792, -0.0065, -0.1436,  0.0029, -0.1019]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0483, -0.1028,  0.0579, -0.0466,  0.0937, -0.0365,  0.0065,  0.0700,
         -0.1519,  0.1287, -0.1446,  0.0410, -0.0878,  0.0172,  0.0231,  0.0559,
         -0.0777,  0.1212, -0.0025,  0.0358,  0.0623, -0.0534, -0.0174, -0.0088,
         -0.0455,  0.0158, -0.0629, -0.0564, -0.1467,  0.1031, -0.1083, -0.0595,
          0.0084, -0.1279,  0.0993,  0.1100, -0.0510, -0.0847,  0.0163,  0.1220,
         -0.1391, -0.0968,  0.1186,  0.1228,  0.1502, -0.0852,  0.0062,  0.0707,
         -0.0477, -0.0552,  0.1502, -0.1283, -0.0369, -0.1304, -0.1504, -0.1109,
         -0.0572,  0.0875,  0.0630,  0.1341, -0.1150,  0.1045,  0.1511, -0.0949,
          0.1019,  0.1004,  0.0263, -0.1418, -0.0472,  0.0406,  0.0295,  0.0047,
          0.1396,  0.0208, -0.1224,  0.0038, -0.0047,  0.1255, -0.0209,  0.0666,
          0.0405,  0.1432, -0.0732,  0.1163, -0.0010,  0.1141,  0.0140, -0.0296,
         -0.0320,  0.0289,  0.1426, -0.0192,  0.0383,  0.1407,  0.0843, -0.1020,
          0.0089, -0.1336, -0.1302,  0.0642, -0.0563,  0.1147,  0.0642,  0.1158,
         -0.1447, -0.0412,  0.0167,  0.0912,  0.0171, -0.0565, -0.0412, -0.0677,
         -0.1012, -0.0723,  0.0746,  0.0307,  0.0867,  0.1278, -0.1393,  0.0044,
          0.0700,  0.1517, -0.0338,  0.0229, -0.0218, -0.0779, -0.1121, -0.1003,
          0.1255,  0.0941,  0.0093,  0.1422, -0.1222,  0.0437,  0.1453, -0.1323,
         -0.1171, -0.0948,  0.1043,  0.1292,  0.0701,  0.0635,  0.1142, -0.0874,
          0.0460, -0.0154, -0.0457, -0.0869, -0.0410,  0.1239, -0.1332, -0.1095,
         -0.0424,  0.0386, -0.0093, -0.1494, -0.1392, -0.0014, -0.0838,  0.0286,
          0.1095, -0.0321, -0.0998,  0.0359,  0.1257, -0.0798,  0.0798, -0.0604,
         -0.1013, -0.1172,  0.0697,  0.0891,  0.0837,  0.0780, -0.0644,  0.1057,
          0.1100,  0.1164,  0.0999, -0.0334,  0.1411, -0.1341, -0.0419, -0.1300,
          0.0722,  0.0947, -0.0374, -0.1043, -0.0425, -0.0181,  0.0624, -0.0284,
         -0.1090, -0.1263, -0.0970,  0.1214,  0.0397,  0.0707,  0.0078,  0.1473,
         -0.1152, -0.0085, -0.0220,  0.0841,  0.1233, -0.1471,  0.1233, -0.1086,
         -0.1353,  0.1357,  0.0698, -0.1462,  0.1079,  0.0384,  0.1120,  0.0633,
          0.0444, -0.0334, -0.1112, -0.0777, -0.1047,  0.1089, -0.1147, -0.0600,
         -0.0711,  0.0028, -0.0925, -0.0092, -0.0276, -0.0658,  0.0998,  0.0435,
         -0.0486, -0.0730, -0.0061, -0.1047,  0.0743,  0.0311, -0.0002,  0.0478,
         -0.1463,  0.0601,  0.1168, -0.1509,  0.0909, -0.1079, -0.1219,  0.0195,
         -0.1201,  0.0690,  0.1297,  0.0792, -0.0065, -0.1436,  0.0029, -0.1019]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.1194, -0.0440, -0.0936,  ...,  0.0870, -0.0333,  0.0127],
        [ 0.0847,  0.0009, -0.0168,  ..., -0.0815, -0.0065,  0.0913],
        [ 0.1211,  0.0346, -0.0360,  ...,  0.0596, -0.0312,  0.0662],
        ...,
        [-0.0605, -0.0292,  0.1028,  ..., -0.0028,  0.1205, -0.1198],
        [-0.0732,  0.0628, -0.0912,  ..., -0.0990,  0.0194, -0.0113],
        [-0.0828, -0.0957,  0.0541,  ...,  0.0766, -0.0064,  0.0525]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1194, -0.0440, -0.0936,  ...,  0.0870, -0.0333,  0.0127],
        [ 0.0847,  0.0009, -0.0168,  ..., -0.0815, -0.0065,  0.0913],
        [ 0.1211,  0.0346, -0.0360,  ...,  0.0596, -0.0312,  0.0662],
        ...,
        [-0.0605, -0.0292,  0.1028,  ..., -0.0028,  0.1205, -0.1198],
        [-0.0732,  0.0628, -0.0912,  ..., -0.0990,  0.0194, -0.0113],
        [-0.0828, -0.0957,  0.0541,  ...,  0.0766, -0.0064,  0.0525]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[ 0.0264,  0.1465,  0.0711,  ..., -0.0133,  0.0072,  0.1015],
        [ 0.0649,  0.1474,  0.1290,  ..., -0.1577, -0.1279, -0.0328],
        [-0.0429, -0.1285, -0.1227,  ..., -0.1505, -0.0058, -0.1125],
        ...,
        [ 0.0915,  0.0991, -0.1670,  ..., -0.0588, -0.0648,  0.1075],
        [-0.1103, -0.1716,  0.1287,  ..., -0.1356, -0.0908, -0.0670],
        [ 0.0905, -0.0522,  0.1687,  ..., -0.0839,  0.0652, -0.1147]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0264,  0.1465,  0.0711,  ..., -0.0133,  0.0072,  0.1015],
        [ 0.0649,  0.1474,  0.1290,  ..., -0.1577, -0.1279, -0.0328],
        [-0.0429, -0.1285, -0.1227,  ..., -0.1505, -0.0058, -0.1125],
        ...,
        [ 0.0915,  0.0991, -0.1670,  ..., -0.0588, -0.0648,  0.1075],
        [-0.1103, -0.1716,  0.1287,  ..., -0.1356, -0.0908, -0.0670],
        [ 0.0905, -0.0522,  0.1687,  ..., -0.0839,  0.0652, -0.1147]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[ 0.0943,  0.0636,  0.1514,  ..., -0.1017,  0.2483,  0.1228],
        [-0.1783,  0.0188, -0.0512,  ...,  0.0341, -0.1971, -0.2075],
        [ 0.0036, -0.1425,  0.1650,  ...,  0.1013, -0.0095,  0.1448],
        ...,
        [ 0.2146, -0.0822, -0.0454,  ...,  0.0712,  0.0616,  0.0174],
        [ 0.0715, -0.1829,  0.0701,  ..., -0.2300,  0.1113,  0.0309],
        [ 0.2033,  0.1632,  0.0896,  ..., -0.1197,  0.1282,  0.0221]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0943,  0.0636,  0.1514,  ..., -0.1017,  0.2483,  0.1228],
        [-0.1783,  0.0188, -0.0512,  ...,  0.0341, -0.1971, -0.2075],
        [ 0.0036, -0.1425,  0.1650,  ...,  0.1013, -0.0095,  0.1448],
        ...,
        [ 0.2146, -0.0822, -0.0454,  ...,  0.0712,  0.0616,  0.0174],
        [ 0.0715, -0.1829,  0.0701,  ..., -0.2300,  0.1113,  0.0309],
        [ 0.2033,  0.1632,  0.0896,  ..., -0.1197,  0.1282,  0.0221]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.1878],
        [ 0.0101],
        [ 0.3472],
        [-0.2346],
        [ 0.1306],
        [ 0.4173],
        [-0.2119],
        [-0.3740],
        [-0.0477],
        [ 0.0314],
        [ 0.3003],
        [ 0.2490],
        [ 0.0510],
        [-0.3429],
        [-0.1467],
        [ 0.4099],
        [ 0.3939],
        [ 0.0336],
        [ 0.2275],
        [-0.1444],
        [-0.2453],
        [-0.0236],
        [ 0.3183],
        [-0.2559],
        [ 0.3139],
        [ 0.2104],
        [ 0.2041],
        [-0.3279],
        [ 0.3879],
        [ 0.1619],
        [ 0.2597],
        [-0.0174]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.1878],
        [ 0.0101],
        [ 0.3472],
        [-0.2346],
        [ 0.1306],
        [ 0.4173],
        [-0.2119],
        [-0.3740],
        [-0.0477],
        [ 0.0314],
        [ 0.3003],
        [ 0.2490],
        [ 0.0510],
        [-0.3429],
        [-0.1467],
        [ 0.4099],
        [ 0.3939],
        [ 0.0336],
        [ 0.2275],
        [-0.1444],
        [-0.2453],
        [-0.0236],
        [ 0.3183],
        [-0.2559],
        [ 0.3139],
        [ 0.2104],
        [ 0.2041],
        [-0.3279],
        [ 0.3879],
        [ 0.1619],
        [ 0.2597],
        [-0.0174]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 0.0687,  0.0820,  0.1239, -0.0570, -0.1075, -0.0873, -0.0850, -0.1367,
          0.0440,  0.1393,  0.1504,  0.0086, -0.0038,  0.0022, -0.0431,  0.0651,
         -0.0495, -0.0405, -0.0642,  0.0856, -0.0677,  0.0352,  0.0627,  0.0305,
         -0.0213,  0.1484, -0.1510, -0.1508,  0.0692,  0.1403,  0.0634, -0.0507,
          0.1282, -0.0522,  0.0346, -0.1346, -0.0164, -0.0212, -0.0529, -0.0130,
         -0.1012, -0.0391, -0.0340,  0.1451, -0.0844, -0.1184, -0.0487, -0.1156,
          0.0746, -0.1037,  0.0627, -0.0939,  0.0216,  0.0498,  0.0390, -0.0645,
          0.0841, -0.0938, -0.1203, -0.0319,  0.1152, -0.0187, -0.1496, -0.1260,
         -0.1043, -0.1520, -0.0273, -0.1311,  0.1262, -0.0292, -0.0029,  0.0472,
          0.1086, -0.1072,  0.0009, -0.0011,  0.0596, -0.0588, -0.0777,  0.1212,
          0.0649, -0.1352, -0.0893,  0.1501, -0.1076, -0.0676, -0.0992, -0.1371,
          0.0550,  0.0365,  0.0450,  0.1260, -0.0353, -0.0278,  0.0842,  0.0178,
          0.1298,  0.0143,  0.0999, -0.1271,  0.0199,  0.0065, -0.1098, -0.1247,
          0.0306,  0.0865, -0.0563,  0.0061,  0.1015,  0.0390, -0.0854, -0.0269,
          0.0125,  0.1173, -0.0127, -0.0198, -0.0369, -0.1076, -0.0965,  0.0635,
          0.0170, -0.0801,  0.0528,  0.0008, -0.1400,  0.0944,  0.1304, -0.0311,
         -0.0912,  0.0865,  0.1363,  0.0128, -0.0160,  0.0633, -0.0560,  0.1456,
          0.0948, -0.0460,  0.1349, -0.0585,  0.0540, -0.0300, -0.0900, -0.0516,
          0.1341, -0.0753, -0.1418,  0.1101,  0.1331,  0.0348,  0.1381, -0.0726,
          0.0632,  0.1173, -0.1107, -0.0063, -0.0694,  0.0931,  0.0265,  0.0784,
          0.0243,  0.0711,  0.0030,  0.0444, -0.0375,  0.0922,  0.0933, -0.1143,
         -0.1322, -0.0817,  0.0461,  0.0695,  0.0540,  0.0873,  0.0893, -0.0884,
         -0.0809, -0.0536,  0.0800,  0.0524, -0.1040,  0.0866, -0.1184,  0.0807,
         -0.0434, -0.1335,  0.1122, -0.0751, -0.0899, -0.0663,  0.0987,  0.0221,
         -0.1126, -0.0294, -0.1234, -0.0823, -0.0741, -0.1218,  0.0394, -0.1369,
          0.0738,  0.1470,  0.0216, -0.1480,  0.1195,  0.0959, -0.0729,  0.0955,
          0.0391, -0.1478,  0.1498, -0.0297,  0.1460, -0.1362,  0.0899, -0.1253,
          0.0409, -0.1113, -0.0904,  0.1488,  0.1487, -0.1128,  0.0939, -0.0084,
          0.1112,  0.0992, -0.1391, -0.0021,  0.0847,  0.0434,  0.0585, -0.0825,
         -0.0833, -0.0667,  0.0704, -0.0876, -0.0693,  0.1087,  0.1439, -0.1278,
          0.0246, -0.1412,  0.0772,  0.0680, -0.1435, -0.0520, -0.1203,  0.1092,
          0.1010, -0.0578, -0.1326,  0.0453, -0.0756,  0.0451, -0.0498,  0.1154]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0687,  0.0820,  0.1239, -0.0570, -0.1075, -0.0873, -0.0850, -0.1367,
          0.0440,  0.1393,  0.1504,  0.0086, -0.0038,  0.0022, -0.0431,  0.0651,
         -0.0495, -0.0405, -0.0642,  0.0856, -0.0677,  0.0352,  0.0627,  0.0305,
         -0.0213,  0.1484, -0.1510, -0.1508,  0.0692,  0.1403,  0.0634, -0.0507,
          0.1282, -0.0522,  0.0346, -0.1346, -0.0164, -0.0212, -0.0529, -0.0130,
         -0.1012, -0.0391, -0.0340,  0.1451, -0.0844, -0.1184, -0.0487, -0.1156,
          0.0746, -0.1037,  0.0627, -0.0939,  0.0216,  0.0498,  0.0390, -0.0645,
          0.0841, -0.0938, -0.1203, -0.0319,  0.1152, -0.0187, -0.1496, -0.1260,
         -0.1043, -0.1520, -0.0273, -0.1311,  0.1262, -0.0292, -0.0029,  0.0472,
          0.1086, -0.1072,  0.0009, -0.0011,  0.0596, -0.0588, -0.0777,  0.1212,
          0.0649, -0.1352, -0.0893,  0.1501, -0.1076, -0.0676, -0.0992, -0.1371,
          0.0550,  0.0365,  0.0450,  0.1260, -0.0353, -0.0278,  0.0842,  0.0178,
          0.1298,  0.0143,  0.0999, -0.1271,  0.0199,  0.0065, -0.1098, -0.1247,
          0.0306,  0.0865, -0.0563,  0.0061,  0.1015,  0.0390, -0.0854, -0.0269,
          0.0125,  0.1173, -0.0127, -0.0198, -0.0369, -0.1076, -0.0965,  0.0635,
          0.0170, -0.0801,  0.0528,  0.0008, -0.1400,  0.0944,  0.1304, -0.0311,
         -0.0912,  0.0865,  0.1363,  0.0128, -0.0160,  0.0633, -0.0560,  0.1456,
          0.0948, -0.0460,  0.1349, -0.0585,  0.0540, -0.0300, -0.0900, -0.0516,
          0.1341, -0.0753, -0.1418,  0.1101,  0.1331,  0.0348,  0.1381, -0.0726,
          0.0632,  0.1173, -0.1107, -0.0063, -0.0694,  0.0931,  0.0265,  0.0784,
          0.0243,  0.0711,  0.0030,  0.0444, -0.0375,  0.0922,  0.0933, -0.1143,
         -0.1322, -0.0817,  0.0461,  0.0695,  0.0540,  0.0873,  0.0893, -0.0884,
         -0.0809, -0.0536,  0.0800,  0.0524, -0.1040,  0.0866, -0.1184,  0.0807,
         -0.0434, -0.1335,  0.1122, -0.0751, -0.0899, -0.0663,  0.0987,  0.0221,
         -0.1126, -0.0294, -0.1234, -0.0823, -0.0741, -0.1218,  0.0394, -0.1369,
          0.0738,  0.1470,  0.0216, -0.1480,  0.1195,  0.0959, -0.0729,  0.0955,
          0.0391, -0.1478,  0.1498, -0.0297,  0.1460, -0.1362,  0.0899, -0.1253,
          0.0409, -0.1113, -0.0904,  0.1488,  0.1487, -0.1128,  0.0939, -0.0084,
          0.1112,  0.0992, -0.1391, -0.0021,  0.0847,  0.0434,  0.0585, -0.0825,
         -0.0833, -0.0667,  0.0704, -0.0876, -0.0693,  0.1087,  0.1439, -0.1278,
          0.0246, -0.1412,  0.0772,  0.0680, -0.1435, -0.0520, -0.1203,  0.1092,
          0.1010, -0.0578, -0.1326,  0.0453, -0.0756,  0.0451, -0.0498,  0.1154]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0014,  0.0683, -0.0663,  ...,  0.0957, -0.0855, -0.0437],
        [ 0.0474,  0.0060, -0.0480,  ..., -0.0438,  0.0299,  0.0684],
        [ 0.0294,  0.0807,  0.0763,  ..., -0.0164,  0.0015, -0.1100],
        ...,
        [ 0.1095, -0.0060, -0.0559,  ..., -0.0679,  0.1216,  0.0709],
        [-0.0781,  0.0477,  0.0444,  ...,  0.0618,  0.0367, -0.1168],
        [ 0.1100,  0.0704,  0.0318,  ...,  0.0712,  0.0582, -0.0114]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0014,  0.0683, -0.0663,  ...,  0.0957, -0.0855, -0.0437],
        [ 0.0474,  0.0060, -0.0480,  ..., -0.0438,  0.0299,  0.0684],
        [ 0.0294,  0.0807,  0.0763,  ..., -0.0164,  0.0015, -0.1100],
        ...,
        [ 0.1095, -0.0060, -0.0559,  ..., -0.0679,  0.1216,  0.0709],
        [-0.0781,  0.0477,  0.0444,  ...,  0.0618,  0.0367, -0.1168],
        [ 0.1100,  0.0704,  0.0318,  ...,  0.0712,  0.0582, -0.0114]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.1508,  0.1129, -0.1226,  ..., -0.1269,  0.1106, -0.1418],
        [ 0.0390, -0.0707,  0.1129,  ...,  0.0671,  0.0151,  0.0385],
        [ 0.1418,  0.1353,  0.0555,  ..., -0.0951,  0.1516, -0.1184],
        ...,
        [ 0.0687,  0.1226,  0.0410,  ..., -0.0040,  0.1442, -0.0672],
        [-0.1204, -0.0760, -0.0326,  ..., -0.0564,  0.1474,  0.0985],
        [ 0.0316,  0.0472,  0.0218,  ...,  0.0148, -0.0535,  0.0654]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1508,  0.1129, -0.1226,  ..., -0.1269,  0.1106, -0.1418],
        [ 0.0390, -0.0707,  0.1129,  ...,  0.0671,  0.0151,  0.0385],
        [ 0.1418,  0.1353,  0.0555,  ..., -0.0951,  0.1516, -0.1184],
        ...,
        [ 0.0687,  0.1226,  0.0410,  ..., -0.0040,  0.1442, -0.0672],
        [-0.1204, -0.0760, -0.0326,  ..., -0.0564,  0.1474,  0.0985],
        [ 0.0316,  0.0472,  0.0218,  ...,  0.0148, -0.0535,  0.0654]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[ 0.1945, -0.2099, -0.1180,  ...,  0.1273,  0.1221,  0.1757],
        [ 0.0477,  0.0516,  0.0681,  ...,  0.1709,  0.0879,  0.1224],
        [ 0.1506, -0.1278, -0.2068,  ..., -0.1151,  0.1941, -0.1139],
        ...,
        [ 0.1127,  0.2292, -0.1306,  ...,  0.1827,  0.0171,  0.2231],
        [ 0.1409,  0.1857,  0.0534,  ...,  0.2019,  0.1716,  0.0067],
        [-0.1363, -0.0718, -0.0828,  ..., -0.0887,  0.1892,  0.1509]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1945, -0.2099, -0.1180,  ...,  0.1273,  0.1221,  0.1757],
        [ 0.0477,  0.0516,  0.0681,  ...,  0.1709,  0.0879,  0.1224],
        [ 0.1506, -0.1278, -0.2068,  ..., -0.1151,  0.1941, -0.1139],
        ...,
        [ 0.1127,  0.2292, -0.1306,  ...,  0.1827,  0.0171,  0.2231],
        [ 0.1409,  0.1857,  0.0534,  ...,  0.2019,  0.1716,  0.0067],
        [-0.1363, -0.0718, -0.0828,  ..., -0.0887,  0.1892,  0.1509]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.1772],
        [ 0.3307],
        [-0.1848],
        [ 0.2501],
        [-0.3902],
        [-0.3471],
        [ 0.1085],
        [-0.0627],
        [ 0.0202],
        [ 0.3728],
        [-0.3143],
        [-0.2242],
        [ 0.3398],
        [-0.0660],
        [-0.1566],
        [ 0.3374],
        [-0.4196],
        [ 0.0019],
        [ 0.1851],
        [ 0.2095],
        [ 0.0876],
        [ 0.2108],
        [-0.2696],
        [ 0.2784],
        [ 0.2341],
        [-0.3994],
        [ 0.0211],
        [ 0.1641],
        [-0.0832],
        [-0.0216],
        [-0.3954],
        [-0.3382]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.1772],
        [ 0.3307],
        [-0.1848],
        [ 0.2501],
        [-0.3902],
        [-0.3471],
        [ 0.1085],
        [-0.0627],
        [ 0.0202],
        [ 0.3728],
        [-0.3143],
        [-0.2242],
        [ 0.3398],
        [-0.0660],
        [-0.1566],
        [ 0.3374],
        [-0.4196],
        [ 0.0019],
        [ 0.1851],
        [ 0.2095],
        [ 0.0876],
        [ 0.2108],
        [-0.2696],
        [ 0.2784],
        [ 0.2341],
        [-0.3994],
        [ 0.0211],
        [ 0.1641],
        [-0.0832],
        [-0.0216],
        [-0.3954],
        [-0.3382]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(3.3393, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-2.2070, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-2.2651, device='cuda:0')



h[100].sum tensor(-4.5735, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-4.6939, device='cuda:0')



h[200].sum tensor(-1.4128, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-1.4500, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(2976.6479, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0008, 0.0000, 0.0013,  ..., 0.0005, 0.0007, 0.0000],
        [0.0044, 0.0000, 0.0066,  ..., 0.0025, 0.0036, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(13972.1309, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(172.6558, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(13.8069, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(167.7573, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(13.4245, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(40.7147, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(3.2595, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.0348],
        [-0.0426],
        [-0.0614],
        ...,
        [-0.0098],
        [-0.0098],
        [-0.0078]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-877.0926, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[-0.0348],
        [-0.0426],
        [-0.0614],
        ...,
        [-0.0098],
        [-0.0098],
        [-0.0078]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(-110.2419, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-12.2081, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-12.1092, device='cuda:0')



h[100].sum tensor(10.9861, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(10.8970, device='cuda:0')



h[200].sum tensor(-17.6606, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-17.5175, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(13619.1699, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0018, 0.0000, 0.0000,  ..., 0.0036, 0.0000, 0.0081],
        [0.0004, 0.0000, 0.0000,  ..., 0.0007, 0.0000, 0.0017],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(74101.2656, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(146.9499, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(10.3073, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(2221.1663, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(156.2756, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-155.6933, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-0.3770],
        [-0.2311],
        [-0.1415],
        ...,
        [ 0.0000],
        [ 0.0000],
        [ 0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(-22141.5234, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-0.0348],
        [-0.0426],
        [-0.0614],
        ...,
        [-0.0098],
        [-0.0098],
        [-0.0078]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py", line 54, in <module>
    checkpoint_load(torch.load(F"{checkpoint_dir_path}/checkpoint_dir/{TraEvN}{EpochNum}{startmesh}saved_checkpoint.tar"))
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/checkpoint_dir/9001600284saved_checkpoint.tar'

real	0m18.985s
user	0m11.173s
sys	0m6.227s
