0: gpu013.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-c1a56c3f-754e-9c2c-9172-b1afbc42439d)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        450.36.06
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.8
srcversion:     BB5CB243542347D4EB0C79C
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_MapRegistersEarly:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_EnableBacklightHandler:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_AssignGpus:charp

nvidia-smi:
Tue Jul 19 23:37:02 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:B4:00.0 Off |                    0 |
| N/A   32C    P0    43W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089730048

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2ab3e43fe910> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m3.689s
user	0m2.154s
sys	0m0.764s
[23:37:08] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 1.6533],
        [-0.7446],
        [-1.2312],
        ...,
        [ 0.1867],
        [ 0.9128],
        [ 0.2541]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-63.4180, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (80000, 6796) (80000, 6796)
sum 5574226 8401300
shape torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLbhabhaGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.0065,  0.0788, -0.0217,  0.0327,  0.0687, -0.1301, -0.0623, -0.0389,
         -0.0255, -0.0083, -0.0536, -0.1011,  0.0602,  0.1084, -0.0818, -0.1172,
         -0.1339, -0.0797,  0.0217,  0.0359,  0.0146, -0.0826,  0.0392, -0.0332,
         -0.0259, -0.1329, -0.0914,  0.0244,  0.0202, -0.1439, -0.0739,  0.0734,
          0.0138, -0.0239,  0.0945, -0.1514, -0.0582,  0.0881,  0.0589, -0.0017,
          0.1409, -0.1154,  0.0269,  0.0388, -0.1527,  0.0428, -0.0433, -0.1277,
         -0.0324,  0.1168, -0.0195,  0.0324, -0.0137,  0.0817,  0.1109, -0.0176,
          0.0832,  0.1042,  0.1289, -0.0213, -0.0876, -0.0188, -0.0672, -0.1340,
         -0.1286, -0.0843,  0.1058, -0.1078, -0.0746,  0.1108,  0.0972,  0.0832,
          0.1494, -0.1094,  0.0804,  0.0840,  0.1409,  0.0088,  0.0024,  0.1155,
          0.0002, -0.0952,  0.1386, -0.0130,  0.0585, -0.0033,  0.0986,  0.0758,
          0.0822, -0.1252, -0.0248,  0.0846,  0.0603, -0.0411,  0.0749,  0.1042,
          0.1400, -0.0428, -0.1414, -0.0179, -0.0101, -0.0039, -0.0138, -0.1325,
         -0.1400,  0.0564, -0.1407, -0.0422, -0.0051,  0.0377,  0.0032, -0.0209,
          0.1512, -0.0615, -0.0716,  0.0384, -0.0968, -0.1417,  0.0808,  0.1277,
          0.0388, -0.1507,  0.0351, -0.1389,  0.0436, -0.0128,  0.1276, -0.1071,
          0.1292, -0.0176,  0.1384, -0.1160, -0.1432, -0.0284, -0.0199, -0.1374,
          0.0231,  0.1282, -0.0668,  0.0116,  0.1448,  0.1359,  0.0363, -0.0876,
          0.0009, -0.0882, -0.0568, -0.1317,  0.1250,  0.1357, -0.0916,  0.0457,
          0.1265, -0.1105,  0.0258,  0.1288,  0.0387,  0.0925, -0.0743, -0.0643,
          0.0857,  0.0660, -0.1045, -0.0978,  0.0343, -0.0017, -0.0984, -0.0980,
         -0.0829,  0.0735, -0.1111,  0.1398,  0.0803,  0.1260,  0.0126,  0.1298,
          0.0997, -0.1372,  0.0361, -0.0291, -0.0929,  0.0429, -0.0617,  0.0370,
          0.1498,  0.0048, -0.1258,  0.1517,  0.0821, -0.0755, -0.1182,  0.0718,
          0.0040, -0.1311,  0.0184, -0.1309, -0.0981, -0.0804,  0.0493, -0.1486,
          0.1454,  0.0871,  0.0775, -0.0558,  0.0419,  0.0016, -0.1143, -0.0132,
         -0.1278, -0.0934,  0.0622, -0.0152,  0.1040,  0.0843,  0.0549, -0.0884,
          0.0109,  0.1161,  0.0535, -0.1081, -0.1181,  0.1219, -0.0918,  0.0974,
         -0.1353, -0.0427, -0.1062, -0.0706, -0.0117,  0.0520,  0.1043,  0.0825,
         -0.0379, -0.1401, -0.1171, -0.0012,  0.0474,  0.0897, -0.0475, -0.0960,
          0.1083, -0.0963,  0.0158, -0.0333, -0.0236,  0.0006, -0.1504,  0.0547,
         -0.0849, -0.0889, -0.1465,  0.1315,  0.0157,  0.1076, -0.0667,  0.0387]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0065,  0.0788, -0.0217,  0.0327,  0.0687, -0.1301, -0.0623, -0.0389,
         -0.0255, -0.0083, -0.0536, -0.1011,  0.0602,  0.1084, -0.0818, -0.1172,
         -0.1339, -0.0797,  0.0217,  0.0359,  0.0146, -0.0826,  0.0392, -0.0332,
         -0.0259, -0.1329, -0.0914,  0.0244,  0.0202, -0.1439, -0.0739,  0.0734,
          0.0138, -0.0239,  0.0945, -0.1514, -0.0582,  0.0881,  0.0589, -0.0017,
          0.1409, -0.1154,  0.0269,  0.0388, -0.1527,  0.0428, -0.0433, -0.1277,
         -0.0324,  0.1168, -0.0195,  0.0324, -0.0137,  0.0817,  0.1109, -0.0176,
          0.0832,  0.1042,  0.1289, -0.0213, -0.0876, -0.0188, -0.0672, -0.1340,
         -0.1286, -0.0843,  0.1058, -0.1078, -0.0746,  0.1108,  0.0972,  0.0832,
          0.1494, -0.1094,  0.0804,  0.0840,  0.1409,  0.0088,  0.0024,  0.1155,
          0.0002, -0.0952,  0.1386, -0.0130,  0.0585, -0.0033,  0.0986,  0.0758,
          0.0822, -0.1252, -0.0248,  0.0846,  0.0603, -0.0411,  0.0749,  0.1042,
          0.1400, -0.0428, -0.1414, -0.0179, -0.0101, -0.0039, -0.0138, -0.1325,
         -0.1400,  0.0564, -0.1407, -0.0422, -0.0051,  0.0377,  0.0032, -0.0209,
          0.1512, -0.0615, -0.0716,  0.0384, -0.0968, -0.1417,  0.0808,  0.1277,
          0.0388, -0.1507,  0.0351, -0.1389,  0.0436, -0.0128,  0.1276, -0.1071,
          0.1292, -0.0176,  0.1384, -0.1160, -0.1432, -0.0284, -0.0199, -0.1374,
          0.0231,  0.1282, -0.0668,  0.0116,  0.1448,  0.1359,  0.0363, -0.0876,
          0.0009, -0.0882, -0.0568, -0.1317,  0.1250,  0.1357, -0.0916,  0.0457,
          0.1265, -0.1105,  0.0258,  0.1288,  0.0387,  0.0925, -0.0743, -0.0643,
          0.0857,  0.0660, -0.1045, -0.0978,  0.0343, -0.0017, -0.0984, -0.0980,
         -0.0829,  0.0735, -0.1111,  0.1398,  0.0803,  0.1260,  0.0126,  0.1298,
          0.0997, -0.1372,  0.0361, -0.0291, -0.0929,  0.0429, -0.0617,  0.0370,
          0.1498,  0.0048, -0.1258,  0.1517,  0.0821, -0.0755, -0.1182,  0.0718,
          0.0040, -0.1311,  0.0184, -0.1309, -0.0981, -0.0804,  0.0493, -0.1486,
          0.1454,  0.0871,  0.0775, -0.0558,  0.0419,  0.0016, -0.1143, -0.0132,
         -0.1278, -0.0934,  0.0622, -0.0152,  0.1040,  0.0843,  0.0549, -0.0884,
          0.0109,  0.1161,  0.0535, -0.1081, -0.1181,  0.1219, -0.0918,  0.0974,
         -0.1353, -0.0427, -0.1062, -0.0706, -0.0117,  0.0520,  0.1043,  0.0825,
         -0.0379, -0.1401, -0.1171, -0.0012,  0.0474,  0.0897, -0.0475, -0.0960,
          0.1083, -0.0963,  0.0158, -0.0333, -0.0236,  0.0006, -0.1504,  0.0547,
         -0.0849, -0.0889, -0.1465,  0.1315,  0.0157,  0.1076, -0.0667,  0.0387]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.1238,  0.0675, -0.0501,  ...,  0.0958,  0.0307,  0.0851],
        [-0.1056,  0.0769,  0.0372,  ..., -0.0281,  0.0061, -0.0500],
        [ 0.0631, -0.0864,  0.1172,  ...,  0.0894, -0.0267, -0.0412],
        ...,
        [ 0.1181, -0.0933,  0.0902,  ...,  0.0144,  0.0231,  0.1107],
        [-0.0982,  0.0104, -0.1223,  ...,  0.0819, -0.0475, -0.0776],
        [ 0.0197, -0.1004,  0.0253,  ..., -0.0688,  0.0809,  0.0796]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1238,  0.0675, -0.0501,  ...,  0.0958,  0.0307,  0.0851],
        [-0.1056,  0.0769,  0.0372,  ..., -0.0281,  0.0061, -0.0500],
        [ 0.0631, -0.0864,  0.1172,  ...,  0.0894, -0.0267, -0.0412],
        ...,
        [ 0.1181, -0.0933,  0.0902,  ...,  0.0144,  0.0231,  0.1107],
        [-0.0982,  0.0104, -0.1223,  ...,  0.0819, -0.0475, -0.0776],
        [ 0.0197, -0.1004,  0.0253,  ..., -0.0688,  0.0809,  0.0796]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.0181,  0.0516,  0.0408,  ..., -0.0826,  0.0872, -0.0010],
        [-0.1060,  0.0768, -0.0099,  ..., -0.1051, -0.1114,  0.1054],
        [-0.0169,  0.0675,  0.0717,  ..., -0.1383,  0.1395,  0.0630],
        ...,
        [ 0.0503, -0.0220,  0.1584,  ..., -0.0753, -0.0114,  0.1167],
        [ 0.1690, -0.1483, -0.0403,  ..., -0.0786,  0.0523,  0.0414],
        [ 0.1179, -0.0941,  0.0053,  ..., -0.0949,  0.1760,  0.0846]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0181,  0.0516,  0.0408,  ..., -0.0826,  0.0872, -0.0010],
        [-0.1060,  0.0768, -0.0099,  ..., -0.1051, -0.1114,  0.1054],
        [-0.0169,  0.0675,  0.0717,  ..., -0.1383,  0.1395,  0.0630],
        ...,
        [ 0.0503, -0.0220,  0.1584,  ..., -0.0753, -0.0114,  0.1167],
        [ 0.1690, -0.1483, -0.0403,  ..., -0.0786,  0.0523,  0.0414],
        [ 0.1179, -0.0941,  0.0053,  ..., -0.0949,  0.1760,  0.0846]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.0226,  0.2268,  0.1182,  ...,  0.1837,  0.2413,  0.2397],
        [ 0.2354, -0.0441, -0.1440,  ...,  0.2175, -0.2328, -0.1295],
        [ 0.1082,  0.1399, -0.2437,  ...,  0.1477, -0.0052, -0.0815],
        ...,
        [ 0.1808, -0.1019,  0.0383,  ...,  0.0168, -0.0361, -0.0921],
        [-0.1465,  0.1269,  0.0820,  ..., -0.0632,  0.1798, -0.1866],
        [ 0.0719, -0.0835, -0.1477,  ..., -0.0061,  0.2423, -0.0848]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0226,  0.2268,  0.1182,  ...,  0.1837,  0.2413,  0.2397],
        [ 0.2354, -0.0441, -0.1440,  ...,  0.2175, -0.2328, -0.1295],
        [ 0.1082,  0.1399, -0.2437,  ...,  0.1477, -0.0052, -0.0815],
        ...,
        [ 0.1808, -0.1019,  0.0383,  ...,  0.0168, -0.0361, -0.0921],
        [-0.1465,  0.1269,  0.0820,  ..., -0.0632,  0.1798, -0.1866],
        [ 0.0719, -0.0835, -0.1477,  ..., -0.0061,  0.2423, -0.0848]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.2736],
        [-0.1473],
        [-0.2583],
        [ 0.3807],
        [-0.4053],
        [ 0.1262],
        [ 0.3988],
        [-0.0212],
        [ 0.1090],
        [ 0.1453],
        [ 0.3997],
        [ 0.0479],
        [-0.1951],
        [ 0.3252],
        [-0.3348],
        [-0.0348],
        [-0.4065],
        [-0.1543],
        [-0.2930],
        [-0.2042],
        [ 0.2783],
        [-0.4203],
        [-0.0581],
        [-0.0967],
        [ 0.0684],
        [ 0.1574],
        [-0.3942],
        [ 0.2374],
        [ 0.2430],
        [ 0.1756],
        [ 0.0847],
        [-0.0721]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.2736],
        [-0.1473],
        [-0.2583],
        [ 0.3807],
        [-0.4053],
        [ 0.1262],
        [ 0.3988],
        [-0.0212],
        [ 0.1090],
        [ 0.1453],
        [ 0.3997],
        [ 0.0479],
        [-0.1951],
        [ 0.3252],
        [-0.3348],
        [-0.0348],
        [-0.4065],
        [-0.1543],
        [-0.2930],
        [-0.2042],
        [ 0.2783],
        [-0.4203],
        [-0.0581],
        [-0.0967],
        [ 0.0684],
        [ 0.1574],
        [-0.3942],
        [ 0.2374],
        [ 0.2430],
        [ 0.1756],
        [ 0.0847],
        [-0.0721]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 0.0165, -0.0917,  0.0329, -0.0653,  0.0659,  0.0870,  0.0680,  0.0811,
          0.0422, -0.0132, -0.1077, -0.0029,  0.0154, -0.0719, -0.0436, -0.0500,
         -0.0443,  0.1468, -0.0629, -0.0390, -0.0177, -0.0542,  0.1513, -0.0855,
         -0.0606, -0.1302,  0.0004,  0.1367, -0.1181,  0.0893, -0.0229,  0.1020,
         -0.1390,  0.0982,  0.0247,  0.1159,  0.0507,  0.0657, -0.1003,  0.0940,
         -0.0945,  0.0726, -0.0931, -0.0218,  0.0464, -0.1016,  0.0630,  0.0195,
         -0.0904,  0.0827,  0.0659,  0.0233, -0.0328,  0.0808,  0.0480,  0.0501,
         -0.0750, -0.1419,  0.1109,  0.1307,  0.0168,  0.1434, -0.1192,  0.1384,
          0.1126,  0.1176, -0.1209, -0.1340, -0.1064,  0.0307,  0.0168, -0.0144,
         -0.0293, -0.1208, -0.0548, -0.1442,  0.0535,  0.0663,  0.0168,  0.0999,
         -0.0285,  0.1305,  0.0945,  0.0638, -0.0172,  0.0641,  0.0252,  0.0697,
         -0.0844, -0.0503, -0.0893, -0.0765, -0.0839, -0.0173, -0.0019,  0.0646,
          0.0737,  0.1355, -0.1269,  0.0811, -0.1272, -0.1026,  0.0256, -0.0524,
          0.1299,  0.0131, -0.1344, -0.1144,  0.0402,  0.1427,  0.0439,  0.1457,
          0.0798,  0.0894, -0.0223, -0.0147, -0.1110,  0.0624, -0.1254, -0.0969,
          0.0424,  0.0595, -0.0453, -0.0643, -0.0978,  0.0787, -0.0816,  0.1132,
         -0.0504,  0.0092, -0.0152,  0.1438,  0.1067, -0.0332,  0.0185,  0.0128,
         -0.0945, -0.0114,  0.1389, -0.0660, -0.1247, -0.1168,  0.0100, -0.1474,
          0.1421,  0.0912,  0.0667, -0.1386, -0.0213,  0.0621,  0.1481,  0.0033,
         -0.0609, -0.1423, -0.0416,  0.1065,  0.0497,  0.1220,  0.1058,  0.0944,
         -0.0642,  0.0497,  0.0718, -0.1015, -0.1116, -0.0985,  0.1007, -0.0938,
         -0.0284, -0.0611,  0.0748,  0.0294, -0.0775,  0.0386,  0.0901, -0.0658,
         -0.0883, -0.0515,  0.0424, -0.1364, -0.0318, -0.1511, -0.0777, -0.0079,
         -0.0314, -0.1470,  0.0492,  0.0067,  0.1363,  0.1212,  0.0323, -0.0621,
          0.1304, -0.0877, -0.1417,  0.0303,  0.0278, -0.1434, -0.0814, -0.0564,
          0.0550, -0.1413,  0.0516,  0.1191,  0.0349,  0.1350, -0.0052, -0.0158,
          0.0261, -0.0096,  0.0233,  0.1183,  0.0864, -0.0789, -0.1291, -0.0257,
         -0.1090,  0.0474,  0.0575,  0.0042,  0.0886, -0.1430, -0.0642,  0.1207,
          0.0720,  0.1270, -0.1098, -0.1084,  0.1199, -0.0959, -0.1110, -0.1146,
          0.1271, -0.1014, -0.0652, -0.1199,  0.1084, -0.0382,  0.0345,  0.1187,
          0.0242,  0.0394, -0.0068, -0.0493, -0.1394, -0.0454,  0.1402,  0.0123,
         -0.0137,  0.0919, -0.0261, -0.0824,  0.0172,  0.0385, -0.0115,  0.0002]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0165, -0.0917,  0.0329, -0.0653,  0.0659,  0.0870,  0.0680,  0.0811,
          0.0422, -0.0132, -0.1077, -0.0029,  0.0154, -0.0719, -0.0436, -0.0500,
         -0.0443,  0.1468, -0.0629, -0.0390, -0.0177, -0.0542,  0.1513, -0.0855,
         -0.0606, -0.1302,  0.0004,  0.1367, -0.1181,  0.0893, -0.0229,  0.1020,
         -0.1390,  0.0982,  0.0247,  0.1159,  0.0507,  0.0657, -0.1003,  0.0940,
         -0.0945,  0.0726, -0.0931, -0.0218,  0.0464, -0.1016,  0.0630,  0.0195,
         -0.0904,  0.0827,  0.0659,  0.0233, -0.0328,  0.0808,  0.0480,  0.0501,
         -0.0750, -0.1419,  0.1109,  0.1307,  0.0168,  0.1434, -0.1192,  0.1384,
          0.1126,  0.1176, -0.1209, -0.1340, -0.1064,  0.0307,  0.0168, -0.0144,
         -0.0293, -0.1208, -0.0548, -0.1442,  0.0535,  0.0663,  0.0168,  0.0999,
         -0.0285,  0.1305,  0.0945,  0.0638, -0.0172,  0.0641,  0.0252,  0.0697,
         -0.0844, -0.0503, -0.0893, -0.0765, -0.0839, -0.0173, -0.0019,  0.0646,
          0.0737,  0.1355, -0.1269,  0.0811, -0.1272, -0.1026,  0.0256, -0.0524,
          0.1299,  0.0131, -0.1344, -0.1144,  0.0402,  0.1427,  0.0439,  0.1457,
          0.0798,  0.0894, -0.0223, -0.0147, -0.1110,  0.0624, -0.1254, -0.0969,
          0.0424,  0.0595, -0.0453, -0.0643, -0.0978,  0.0787, -0.0816,  0.1132,
         -0.0504,  0.0092, -0.0152,  0.1438,  0.1067, -0.0332,  0.0185,  0.0128,
         -0.0945, -0.0114,  0.1389, -0.0660, -0.1247, -0.1168,  0.0100, -0.1474,
          0.1421,  0.0912,  0.0667, -0.1386, -0.0213,  0.0621,  0.1481,  0.0033,
         -0.0609, -0.1423, -0.0416,  0.1065,  0.0497,  0.1220,  0.1058,  0.0944,
         -0.0642,  0.0497,  0.0718, -0.1015, -0.1116, -0.0985,  0.1007, -0.0938,
         -0.0284, -0.0611,  0.0748,  0.0294, -0.0775,  0.0386,  0.0901, -0.0658,
         -0.0883, -0.0515,  0.0424, -0.1364, -0.0318, -0.1511, -0.0777, -0.0079,
         -0.0314, -0.1470,  0.0492,  0.0067,  0.1363,  0.1212,  0.0323, -0.0621,
          0.1304, -0.0877, -0.1417,  0.0303,  0.0278, -0.1434, -0.0814, -0.0564,
          0.0550, -0.1413,  0.0516,  0.1191,  0.0349,  0.1350, -0.0052, -0.0158,
          0.0261, -0.0096,  0.0233,  0.1183,  0.0864, -0.0789, -0.1291, -0.0257,
         -0.1090,  0.0474,  0.0575,  0.0042,  0.0886, -0.1430, -0.0642,  0.1207,
          0.0720,  0.1270, -0.1098, -0.1084,  0.1199, -0.0959, -0.1110, -0.1146,
          0.1271, -0.1014, -0.0652, -0.1199,  0.1084, -0.0382,  0.0345,  0.1187,
          0.0242,  0.0394, -0.0068, -0.0493, -0.1394, -0.0454,  0.1402,  0.0123,
         -0.0137,  0.0919, -0.0261, -0.0824,  0.0172,  0.0385, -0.0115,  0.0002]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[-0.0320, -0.0990,  0.0465,  ...,  0.0131,  0.0099,  0.0752],
        [ 0.0646,  0.0535, -0.0060,  ...,  0.0341, -0.0234,  0.0910],
        [-0.0968, -0.0916,  0.1246,  ...,  0.1224, -0.0502, -0.0512],
        ...,
        [ 0.0928,  0.1196, -0.0953,  ...,  0.0557, -0.0969,  0.1111],
        [-0.1114,  0.0484,  0.0058,  ...,  0.1036, -0.0251,  0.0196],
        [-0.0583, -0.0628, -0.1122,  ...,  0.1077, -0.0719, -0.0501]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0320, -0.0990,  0.0465,  ...,  0.0131,  0.0099,  0.0752],
        [ 0.0646,  0.0535, -0.0060,  ...,  0.0341, -0.0234,  0.0910],
        [-0.0968, -0.0916,  0.1246,  ...,  0.1224, -0.0502, -0.0512],
        ...,
        [ 0.0928,  0.1196, -0.0953,  ...,  0.0557, -0.0969,  0.1111],
        [-0.1114,  0.0484,  0.0058,  ...,  0.1036, -0.0251,  0.0196],
        [-0.0583, -0.0628, -0.1122,  ...,  0.1077, -0.0719, -0.0501]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.0705,  0.0935, -0.1351,  ...,  0.1428, -0.0270, -0.0713],
        [-0.0571,  0.0438,  0.0577,  ...,  0.1365,  0.0516, -0.0388],
        [-0.0072,  0.0813,  0.0422,  ...,  0.1081,  0.1767, -0.0676],
        ...,
        [-0.0033,  0.0883, -0.1216,  ...,  0.1001,  0.1073, -0.1002],
        [-0.0209,  0.1140,  0.1725,  ..., -0.0214,  0.1234,  0.0488],
        [ 0.1559, -0.0391, -0.0754,  ...,  0.1368, -0.1175,  0.0388]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0705,  0.0935, -0.1351,  ...,  0.1428, -0.0270, -0.0713],
        [-0.0571,  0.0438,  0.0577,  ...,  0.1365,  0.0516, -0.0388],
        [-0.0072,  0.0813,  0.0422,  ...,  0.1081,  0.1767, -0.0676],
        ...,
        [-0.0033,  0.0883, -0.1216,  ...,  0.1001,  0.1073, -0.1002],
        [-0.0209,  0.1140,  0.1725,  ..., -0.0214,  0.1234,  0.0488],
        [ 0.1559, -0.0391, -0.0754,  ...,  0.1368, -0.1175,  0.0388]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.0759,  0.0120,  0.2191,  ..., -0.1870,  0.1533,  0.1640],
        [ 0.0753, -0.0212, -0.0152,  ...,  0.1284,  0.0472, -0.0057],
        [-0.0856, -0.1514, -0.2289,  ...,  0.0347,  0.0794,  0.1540],
        ...,
        [ 0.2100,  0.0686, -0.1626,  ..., -0.0203,  0.1837,  0.0416],
        [-0.2104,  0.1608, -0.0711,  ..., -0.2421,  0.0613,  0.0562],
        [ 0.1415, -0.1295, -0.1287,  ...,  0.1120,  0.1351, -0.2281]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0759,  0.0120,  0.2191,  ..., -0.1870,  0.1533,  0.1640],
        [ 0.0753, -0.0212, -0.0152,  ...,  0.1284,  0.0472, -0.0057],
        [-0.0856, -0.1514, -0.2289,  ...,  0.0347,  0.0794,  0.1540],
        ...,
        [ 0.2100,  0.0686, -0.1626,  ..., -0.0203,  0.1837,  0.0416],
        [-0.2104,  0.1608, -0.0711,  ..., -0.2421,  0.0613,  0.0562],
        [ 0.1415, -0.1295, -0.1287,  ...,  0.1120,  0.1351, -0.2281]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.1413],
        [ 0.2790],
        [-0.2778],
        [ 0.4076],
        [-0.2711],
        [-0.0836],
        [-0.2912],
        [-0.3087],
        [ 0.4210],
        [ 0.0218],
        [-0.2432],
        [-0.0343],
        [ 0.2141],
        [-0.3453],
        [-0.1904],
        [-0.1171],
        [ 0.2735],
        [ 0.3197],
        [ 0.1544],
        [-0.0802],
        [ 0.3218],
        [-0.0619],
        [-0.3261],
        [-0.1225],
        [ 0.2307],
        [-0.2313],
        [-0.2060],
        [ 0.1904],
        [ 0.2608],
        [ 0.3119],
        [ 0.3589],
        [ 0.1303]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.1413],
        [ 0.2790],
        [-0.2778],
        [ 0.4076],
        [-0.2711],
        [-0.0836],
        [-0.2912],
        [-0.3087],
        [ 0.4210],
        [ 0.0218],
        [-0.2432],
        [-0.0343],
        [ 0.2141],
        [-0.3453],
        [-0.1904],
        [-0.1171],
        [ 0.2735],
        [ 0.3197],
        [ 0.1544],
        [-0.0802],
        [ 0.3218],
        [-0.0619],
        [-0.3261],
        [-0.1225],
        [ 0.2307],
        [-0.2313],
        [-0.2060],
        [ 0.1904],
        [ 0.2608],
        [ 0.3119],
        [ 0.3589],
        [ 0.1303]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(4.0017, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(2.9863, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(3.0649, device='cuda:0')



h[100].sum tensor(-1.1136, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-1.1429, device='cuda:0')



h[200].sum tensor(1.3588, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(1.3946, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(2935.3369, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0016, 0.0000, 0.0000,  ..., 0.0019, 0.0010, 0.0009],
        [0.0084, 0.0000, 0.0000,  ..., 0.0099, 0.0051, 0.0045],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(15301.9375, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(327.7046, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(26.2155, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-8.6011, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-18.2646, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0271],
        [0.0332],
        [0.0478],
        ...,
        [0.0077],
        [0.0077],
        [0.0061]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(683.4451, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[0.0271],
        [0.0332],
        [0.0478],
        ...,
        [0.0077],
        [0.0077],
        [0.0061]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(-120.3989, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(13.4939, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(13.3845, device='cuda:0')



h[100].sum tensor(-17.6372, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-17.4942, device='cuda:0')



h[200].sum tensor(-6.3449, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-6.2935, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(14008.2441, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0006, 0.0020, 0.0173,  ..., 0.0023, 0.0000, 0.0068],
        [0.0001, 0.0004, 0.0036,  ..., 0.0005, 0.0000, 0.0014],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(62070.5430, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(49.2393, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(3.4642, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(685.0562, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(48.1969, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(915.1936, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(64.3881, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0646],
        [0.0396],
        [0.0242],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(3793.4263, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[0.0271],
        [0.0332],
        [0.0478],
        ...,
        [0.0077],
        [0.0077],
        [0.0061]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py", line 5, in <module>
    from ModelBha import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/ModelBha.py", line 209, in <module>
    plt.savefig(f'/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/{modelname}/results/{t}\
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/pyplot.py", line 966, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/figure.py", line 3015, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 2255, in print_figure
    result = print_method(
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 1669, in wrapper
    return func(*args, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py", line 509, in print_png
    mpl.image.imsave(
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/image.py", line 1616, in imsave
    image.save(fname, **pil_kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/PIL/Image.py", line 2237, in save
    fp = builtins.open(filename, "w+b")
FileNotFoundError: [Errno 2] No such file or directory: '/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLbhabhaGcnReNewestweight7N2/results/2022-07-19 23:37:32.514155    passing three random events (20, 30, 31) from network before training.png'

real	0m29.216s
user	0m16.320s
sys	0m8.646s
