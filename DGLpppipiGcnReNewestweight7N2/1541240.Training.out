0: gpu023.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-e9f3b3a6-da2a-e925-a85d-a9926bf2b7fe)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        450.36.06
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.8
srcversion:     BB5CB243542347D4EB0C79C
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_MapRegistersEarly:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_EnableBacklightHandler:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_AssignGpus:charp

nvidia-smi:
Fri Aug 12 16:12:12 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:16:00.0 Off |                    0 |
| N/A   33C    P0    41W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089730048

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b0aa9eab880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	5m51.855s
user	0m3.560s
sys	0m3.221s
[16:18:08] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[-1.6526],
        [ 0.4790],
        [ 0.1281],
        ...,
        [ 0.9217],
        [ 1.8139],
        [ 0.4262]], device='cuda:0', requires_grad=True) 
node features sum: tensor(129.6952, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (80000, 6796) (80000, 6796)
sum 5574226 8401300
shape torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 0.0908, -0.0724,  0.1440,  0.1111,  0.1071, -0.0287,  0.0188,  0.0716,
         -0.1244,  0.0754, -0.0847, -0.1520,  0.0150,  0.0183, -0.0383, -0.0497,
         -0.1262, -0.1214, -0.0341,  0.0940, -0.0233, -0.0007,  0.0129,  0.1396,
         -0.0552,  0.0964,  0.0259, -0.1468,  0.0671,  0.0384, -0.0441, -0.0590,
          0.0995, -0.1102,  0.0592,  0.1361,  0.0212,  0.0400, -0.0593,  0.0420,
         -0.0539,  0.0630,  0.0753,  0.1047,  0.0557, -0.0564, -0.0102,  0.0216,
          0.1135,  0.0907,  0.0707, -0.1268, -0.0924,  0.0799,  0.0552, -0.1292,
         -0.0474, -0.0862,  0.0261,  0.1058, -0.0604, -0.1479, -0.1132,  0.1256,
         -0.1024,  0.1037, -0.0838, -0.1197, -0.1170, -0.1120,  0.1025, -0.1165,
          0.0091,  0.0646,  0.0477,  0.0782,  0.0800, -0.0271,  0.0518, -0.1037,
         -0.0450, -0.0840,  0.0117, -0.1515,  0.0764,  0.1308, -0.1324,  0.0653,
          0.1284,  0.0460,  0.0564,  0.1025, -0.0687,  0.1467,  0.0855, -0.0199,
          0.0979,  0.1151,  0.0015, -0.0638,  0.0360,  0.0043, -0.1321, -0.0673,
          0.0448,  0.1051,  0.1042,  0.1232, -0.0224,  0.0902, -0.0161, -0.0672,
          0.1250,  0.1284,  0.0858, -0.1090,  0.0674,  0.1012,  0.0906,  0.0619,
          0.0186, -0.0712,  0.0747, -0.0594, -0.1451,  0.0027,  0.0473, -0.0254,
         -0.0584,  0.0225, -0.0714, -0.0778,  0.0763,  0.1322, -0.0255, -0.1291,
         -0.0203,  0.1371, -0.0508, -0.0543, -0.1059,  0.1483,  0.0748, -0.0996,
         -0.0699,  0.0744, -0.0760, -0.0889, -0.1356,  0.0070, -0.0147, -0.0863,
          0.0952, -0.1034, -0.0703,  0.0837,  0.1188, -0.0577,  0.0231, -0.0892,
          0.1358, -0.0883,  0.1252,  0.1351, -0.1024, -0.1425, -0.0925, -0.1152,
          0.1467, -0.0089,  0.0713, -0.1024, -0.0111,  0.0404,  0.1241, -0.1033,
          0.1257,  0.1252, -0.0172,  0.0329,  0.0462, -0.1404, -0.0291,  0.1422,
          0.0644,  0.0198,  0.1473, -0.1505,  0.0920, -0.0263, -0.0180,  0.0275,
         -0.1175, -0.0428, -0.0290, -0.0174, -0.0220, -0.1398, -0.0249,  0.0445,
         -0.0723, -0.1213, -0.1377,  0.0539, -0.1452,  0.0639, -0.1377, -0.0379,
         -0.1440,  0.0643,  0.1150, -0.1243, -0.0520, -0.1441,  0.0405,  0.1372,
          0.0669,  0.1019, -0.0893,  0.1454,  0.0050, -0.0038, -0.0204, -0.0047,
          0.1467, -0.0241, -0.1065, -0.0672,  0.0626, -0.0243,  0.0738, -0.0553,
          0.1388,  0.1155, -0.0344, -0.0732,  0.1133,  0.1225, -0.0337,  0.0258,
         -0.0966,  0.0139,  0.1150, -0.0356, -0.0874,  0.1168, -0.0799,  0.0436,
          0.1394,  0.1096,  0.1408,  0.0660, -0.0970, -0.0935, -0.0363,  0.0795]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0908, -0.0724,  0.1440,  0.1111,  0.1071, -0.0287,  0.0188,  0.0716,
         -0.1244,  0.0754, -0.0847, -0.1520,  0.0150,  0.0183, -0.0383, -0.0497,
         -0.1262, -0.1214, -0.0341,  0.0940, -0.0233, -0.0007,  0.0129,  0.1396,
         -0.0552,  0.0964,  0.0259, -0.1468,  0.0671,  0.0384, -0.0441, -0.0590,
          0.0995, -0.1102,  0.0592,  0.1361,  0.0212,  0.0400, -0.0593,  0.0420,
         -0.0539,  0.0630,  0.0753,  0.1047,  0.0557, -0.0564, -0.0102,  0.0216,
          0.1135,  0.0907,  0.0707, -0.1268, -0.0924,  0.0799,  0.0552, -0.1292,
         -0.0474, -0.0862,  0.0261,  0.1058, -0.0604, -0.1479, -0.1132,  0.1256,
         -0.1024,  0.1037, -0.0838, -0.1197, -0.1170, -0.1120,  0.1025, -0.1165,
          0.0091,  0.0646,  0.0477,  0.0782,  0.0800, -0.0271,  0.0518, -0.1037,
         -0.0450, -0.0840,  0.0117, -0.1515,  0.0764,  0.1308, -0.1324,  0.0653,
          0.1284,  0.0460,  0.0564,  0.1025, -0.0687,  0.1467,  0.0855, -0.0199,
          0.0979,  0.1151,  0.0015, -0.0638,  0.0360,  0.0043, -0.1321, -0.0673,
          0.0448,  0.1051,  0.1042,  0.1232, -0.0224,  0.0902, -0.0161, -0.0672,
          0.1250,  0.1284,  0.0858, -0.1090,  0.0674,  0.1012,  0.0906,  0.0619,
          0.0186, -0.0712,  0.0747, -0.0594, -0.1451,  0.0027,  0.0473, -0.0254,
         -0.0584,  0.0225, -0.0714, -0.0778,  0.0763,  0.1322, -0.0255, -0.1291,
         -0.0203,  0.1371, -0.0508, -0.0543, -0.1059,  0.1483,  0.0748, -0.0996,
         -0.0699,  0.0744, -0.0760, -0.0889, -0.1356,  0.0070, -0.0147, -0.0863,
          0.0952, -0.1034, -0.0703,  0.0837,  0.1188, -0.0577,  0.0231, -0.0892,
          0.1358, -0.0883,  0.1252,  0.1351, -0.1024, -0.1425, -0.0925, -0.1152,
          0.1467, -0.0089,  0.0713, -0.1024, -0.0111,  0.0404,  0.1241, -0.1033,
          0.1257,  0.1252, -0.0172,  0.0329,  0.0462, -0.1404, -0.0291,  0.1422,
          0.0644,  0.0198,  0.1473, -0.1505,  0.0920, -0.0263, -0.0180,  0.0275,
         -0.1175, -0.0428, -0.0290, -0.0174, -0.0220, -0.1398, -0.0249,  0.0445,
         -0.0723, -0.1213, -0.1377,  0.0539, -0.1452,  0.0639, -0.1377, -0.0379,
         -0.1440,  0.0643,  0.1150, -0.1243, -0.0520, -0.1441,  0.0405,  0.1372,
          0.0669,  0.1019, -0.0893,  0.1454,  0.0050, -0.0038, -0.0204, -0.0047,
          0.1467, -0.0241, -0.1065, -0.0672,  0.0626, -0.0243,  0.0738, -0.0553,
          0.1388,  0.1155, -0.0344, -0.0732,  0.1133,  0.1225, -0.0337,  0.0258,
         -0.0966,  0.0139,  0.1150, -0.0356, -0.0874,  0.1168, -0.0799,  0.0436,
          0.1394,  0.1096,  0.1408,  0.0660, -0.0970, -0.0935, -0.0363,  0.0795]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0211,  0.0185, -0.0147,  ..., -0.1190,  0.1114, -0.0903],
        [ 0.1004,  0.0093,  0.0862,  ..., -0.0764,  0.0092, -0.0642],
        [ 0.0602, -0.1134, -0.1075,  ..., -0.0351, -0.0988, -0.0792],
        ...,
        [-0.0200,  0.0426,  0.0774,  ..., -0.0179,  0.0087,  0.0094],
        [-0.0452, -0.1116, -0.0951,  ...,  0.0163, -0.0199,  0.1086],
        [-0.0076, -0.0799,  0.0329,  ..., -0.0821,  0.0645,  0.0099]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0211,  0.0185, -0.0147,  ..., -0.1190,  0.1114, -0.0903],
        [ 0.1004,  0.0093,  0.0862,  ..., -0.0764,  0.0092, -0.0642],
        [ 0.0602, -0.1134, -0.1075,  ..., -0.0351, -0.0988, -0.0792],
        ...,
        [-0.0200,  0.0426,  0.0774,  ..., -0.0179,  0.0087,  0.0094],
        [-0.0452, -0.1116, -0.0951,  ...,  0.0163, -0.0199,  0.1086],
        [-0.0076, -0.0799,  0.0329,  ..., -0.0821,  0.0645,  0.0099]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.1131, -0.0254, -0.0442,  ...,  0.1003, -0.0324, -0.0864],
        [-0.0098,  0.1579,  0.0282,  ...,  0.1162,  0.1290, -0.1382],
        [-0.0928, -0.0301, -0.0801,  ..., -0.1048, -0.1216, -0.0211],
        ...,
        [-0.0365,  0.0054, -0.1574,  ...,  0.0597, -0.1085,  0.0234],
        [-0.0673, -0.1309,  0.1289,  ...,  0.1098, -0.0134, -0.0660],
        [ 0.0888,  0.1143, -0.0063,  ..., -0.0625, -0.0729, -0.0059]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1131, -0.0254, -0.0442,  ...,  0.1003, -0.0324, -0.0864],
        [-0.0098,  0.1579,  0.0282,  ...,  0.1162,  0.1290, -0.1382],
        [-0.0928, -0.0301, -0.0801,  ..., -0.1048, -0.1216, -0.0211],
        ...,
        [-0.0365,  0.0054, -0.1574,  ...,  0.0597, -0.1085,  0.0234],
        [-0.0673, -0.1309,  0.1289,  ...,  0.1098, -0.0134, -0.0660],
        [ 0.0888,  0.1143, -0.0063,  ..., -0.0625, -0.0729, -0.0059]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.2068,  0.0864, -0.0629,  ...,  0.1057, -0.2293,  0.0169],
        [-0.1456, -0.1436,  0.1255,  ...,  0.1212, -0.1919, -0.2142],
        [-0.1270, -0.0959,  0.2016,  ...,  0.2046, -0.0899,  0.1333],
        ...,
        [ 0.1807, -0.1559, -0.0083,  ..., -0.1675, -0.0065,  0.1018],
        [ 0.0849, -0.1817, -0.1232,  ..., -0.1900, -0.2357,  0.1941],
        [-0.0331,  0.2403, -0.0620,  ...,  0.1896,  0.1152,  0.2105]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.2068,  0.0864, -0.0629,  ...,  0.1057, -0.2293,  0.0169],
        [-0.1456, -0.1436,  0.1255,  ...,  0.1212, -0.1919, -0.2142],
        [-0.1270, -0.0959,  0.2016,  ...,  0.2046, -0.0899,  0.1333],
        ...,
        [ 0.1807, -0.1559, -0.0083,  ..., -0.1675, -0.0065,  0.1018],
        [ 0.0849, -0.1817, -0.1232,  ..., -0.1900, -0.2357,  0.1941],
        [-0.0331,  0.2403, -0.0620,  ...,  0.1896,  0.1152,  0.2105]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.4255],
        [ 0.3182],
        [-0.0121],
        [ 0.3468],
        [ 0.1169],
        [ 0.2525],
        [-0.1570],
        [-0.2925],
        [ 0.4230],
        [-0.3358],
        [ 0.3037],
        [-0.2688],
        [ 0.2780],
        [-0.2090],
        [-0.2519],
        [-0.2276],
        [-0.3508],
        [ 0.3174],
        [-0.2194],
        [-0.2272],
        [ 0.1593],
        [-0.2469],
        [ 0.1063],
        [-0.2720],
        [-0.2564],
        [-0.4251],
        [ 0.3583],
        [ 0.0672],
        [-0.1272],
        [ 0.3898],
        [ 0.1422],
        [ 0.0973]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.4255],
        [ 0.3182],
        [-0.0121],
        [ 0.3468],
        [ 0.1169],
        [ 0.2525],
        [-0.1570],
        [-0.2925],
        [ 0.4230],
        [-0.3358],
        [ 0.3037],
        [-0.2688],
        [ 0.2780],
        [-0.2090],
        [-0.2519],
        [-0.2276],
        [-0.3508],
        [ 0.3174],
        [-0.2194],
        [-0.2272],
        [ 0.1593],
        [-0.2469],
        [ 0.1063],
        [-0.2720],
        [-0.2564],
        [-0.4251],
        [ 0.3583],
        [ 0.0672],
        [-0.1272],
        [ 0.3898],
        [ 0.1422],
        [ 0.0973]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.1335, -0.1161,  0.0739, -0.0366, -0.0725,  0.1176,  0.0591, -0.1192,
          0.1177, -0.1370,  0.1079, -0.1374,  0.0767, -0.1384,  0.0623,  0.0620,
          0.0071, -0.0319, -0.0549, -0.0934,  0.1431,  0.0216, -0.1032, -0.1000,
          0.0774,  0.0618, -0.0815,  0.0475,  0.0427,  0.0893,  0.1125, -0.1140,
          0.0381,  0.0664, -0.0531,  0.1391,  0.0405,  0.1078, -0.0041,  0.0640,
          0.0879, -0.0007, -0.1478, -0.0597,  0.1214, -0.0235,  0.0979, -0.0112,
          0.0604, -0.1444,  0.0857,  0.0397,  0.0869,  0.1195, -0.0775,  0.1112,
         -0.1401,  0.1407, -0.1106,  0.1412,  0.0437, -0.0033,  0.0237,  0.0863,
         -0.0047,  0.0517, -0.1311,  0.0290,  0.0159, -0.0333,  0.0831,  0.1004,
         -0.1114, -0.0049,  0.0360, -0.0161, -0.0829,  0.0408, -0.0752, -0.0101,
          0.0716,  0.0410,  0.0482, -0.0814,  0.0347, -0.0346, -0.0488, -0.1295,
         -0.1095, -0.0926,  0.0703, -0.1427,  0.0854,  0.0427, -0.0028, -0.1145,
         -0.0186, -0.0422, -0.1339, -0.0745, -0.0129,  0.0225, -0.0489,  0.0978,
          0.1223, -0.0551, -0.1127,  0.1150,  0.1207, -0.0772, -0.0481, -0.1137,
         -0.0026,  0.0482,  0.0834, -0.0488, -0.0414, -0.0061, -0.0066, -0.1425,
         -0.0725,  0.1458,  0.1108,  0.0394, -0.1113,  0.0457, -0.1296, -0.1204,
         -0.1053, -0.1314,  0.1043,  0.0903, -0.1453, -0.0082,  0.1123, -0.1496,
         -0.0198,  0.0305, -0.1262,  0.0951,  0.1206,  0.1345,  0.1461,  0.1039,
         -0.0184,  0.0666, -0.1475,  0.0320, -0.0852, -0.1054, -0.0809, -0.1206,
         -0.1125, -0.0714,  0.1095,  0.1424, -0.1023,  0.0217, -0.1046,  0.0883,
          0.1220, -0.0875,  0.0207,  0.0516, -0.0606,  0.0475,  0.0093,  0.0092,
          0.0533,  0.1513,  0.0169,  0.0560, -0.0741, -0.1068, -0.0521, -0.0639,
         -0.1468,  0.0492,  0.0580, -0.1100,  0.0361, -0.0064,  0.1141,  0.0884,
          0.1250,  0.1373, -0.0776,  0.0258,  0.1233,  0.0188, -0.0100,  0.0902,
          0.1083,  0.1436,  0.1518, -0.0680,  0.0716,  0.1248, -0.1031,  0.0065,
         -0.0936,  0.0587,  0.1413,  0.1151, -0.1441, -0.0158,  0.0854, -0.0157,
         -0.1402,  0.1146, -0.1083,  0.0812,  0.0495,  0.0062,  0.1359,  0.0070,
         -0.0851, -0.0026,  0.1158,  0.0094, -0.0661,  0.1115, -0.0123,  0.0207,
         -0.1063, -0.1443, -0.1408, -0.0956,  0.0927, -0.1297,  0.0356,  0.1521,
          0.0803, -0.1044,  0.1300,  0.1099,  0.1222, -0.0723, -0.0689,  0.0359,
         -0.0348, -0.1274, -0.0774,  0.0073, -0.1370, -0.0341,  0.0774, -0.0257,
          0.0423,  0.1479,  0.1151, -0.0501,  0.1452,  0.1188, -0.0062,  0.1023]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1335, -0.1161,  0.0739, -0.0366, -0.0725,  0.1176,  0.0591, -0.1192,
          0.1177, -0.1370,  0.1079, -0.1374,  0.0767, -0.1384,  0.0623,  0.0620,
          0.0071, -0.0319, -0.0549, -0.0934,  0.1431,  0.0216, -0.1032, -0.1000,
          0.0774,  0.0618, -0.0815,  0.0475,  0.0427,  0.0893,  0.1125, -0.1140,
          0.0381,  0.0664, -0.0531,  0.1391,  0.0405,  0.1078, -0.0041,  0.0640,
          0.0879, -0.0007, -0.1478, -0.0597,  0.1214, -0.0235,  0.0979, -0.0112,
          0.0604, -0.1444,  0.0857,  0.0397,  0.0869,  0.1195, -0.0775,  0.1112,
         -0.1401,  0.1407, -0.1106,  0.1412,  0.0437, -0.0033,  0.0237,  0.0863,
         -0.0047,  0.0517, -0.1311,  0.0290,  0.0159, -0.0333,  0.0831,  0.1004,
         -0.1114, -0.0049,  0.0360, -0.0161, -0.0829,  0.0408, -0.0752, -0.0101,
          0.0716,  0.0410,  0.0482, -0.0814,  0.0347, -0.0346, -0.0488, -0.1295,
         -0.1095, -0.0926,  0.0703, -0.1427,  0.0854,  0.0427, -0.0028, -0.1145,
         -0.0186, -0.0422, -0.1339, -0.0745, -0.0129,  0.0225, -0.0489,  0.0978,
          0.1223, -0.0551, -0.1127,  0.1150,  0.1207, -0.0772, -0.0481, -0.1137,
         -0.0026,  0.0482,  0.0834, -0.0488, -0.0414, -0.0061, -0.0066, -0.1425,
         -0.0725,  0.1458,  0.1108,  0.0394, -0.1113,  0.0457, -0.1296, -0.1204,
         -0.1053, -0.1314,  0.1043,  0.0903, -0.1453, -0.0082,  0.1123, -0.1496,
         -0.0198,  0.0305, -0.1262,  0.0951,  0.1206,  0.1345,  0.1461,  0.1039,
         -0.0184,  0.0666, -0.1475,  0.0320, -0.0852, -0.1054, -0.0809, -0.1206,
         -0.1125, -0.0714,  0.1095,  0.1424, -0.1023,  0.0217, -0.1046,  0.0883,
          0.1220, -0.0875,  0.0207,  0.0516, -0.0606,  0.0475,  0.0093,  0.0092,
          0.0533,  0.1513,  0.0169,  0.0560, -0.0741, -0.1068, -0.0521, -0.0639,
         -0.1468,  0.0492,  0.0580, -0.1100,  0.0361, -0.0064,  0.1141,  0.0884,
          0.1250,  0.1373, -0.0776,  0.0258,  0.1233,  0.0188, -0.0100,  0.0902,
          0.1083,  0.1436,  0.1518, -0.0680,  0.0716,  0.1248, -0.1031,  0.0065,
         -0.0936,  0.0587,  0.1413,  0.1151, -0.1441, -0.0158,  0.0854, -0.0157,
         -0.1402,  0.1146, -0.1083,  0.0812,  0.0495,  0.0062,  0.1359,  0.0070,
         -0.0851, -0.0026,  0.1158,  0.0094, -0.0661,  0.1115, -0.0123,  0.0207,
         -0.1063, -0.1443, -0.1408, -0.0956,  0.0927, -0.1297,  0.0356,  0.1521,
          0.0803, -0.1044,  0.1300,  0.1099,  0.1222, -0.0723, -0.0689,  0.0359,
         -0.0348, -0.1274, -0.0774,  0.0073, -0.1370, -0.0341,  0.0774, -0.0257,
          0.0423,  0.1479,  0.1151, -0.0501,  0.1452,  0.1188, -0.0062,  0.1023]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0290,  0.0718,  0.0250,  ..., -0.0163,  0.1170,  0.0769],
        [ 0.0040,  0.0793,  0.0684,  ..., -0.0086,  0.0405, -0.0822],
        [-0.0397, -0.0769,  0.0574,  ..., -0.0562, -0.0043, -0.1069],
        ...,
        [ 0.1094, -0.0180, -0.0945,  ...,  0.1122, -0.0028,  0.0982],
        [-0.0355,  0.0705, -0.0021,  ..., -0.0669,  0.0676, -0.0450],
        [ 0.0632,  0.1005,  0.0570,  ..., -0.0271,  0.1157, -0.0127]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0290,  0.0718,  0.0250,  ..., -0.0163,  0.1170,  0.0769],
        [ 0.0040,  0.0793,  0.0684,  ..., -0.0086,  0.0405, -0.0822],
        [-0.0397, -0.0769,  0.0574,  ..., -0.0562, -0.0043, -0.1069],
        ...,
        [ 0.1094, -0.0180, -0.0945,  ...,  0.1122, -0.0028,  0.0982],
        [-0.0355,  0.0705, -0.0021,  ..., -0.0669,  0.0676, -0.0450],
        [ 0.0632,  0.1005,  0.0570,  ..., -0.0271,  0.1157, -0.0127]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.1520, -0.0610,  0.0643,  ...,  0.0820,  0.1471,  0.0183],
        [ 0.0998, -0.0444,  0.1236,  ..., -0.1677, -0.0641,  0.0396],
        [ 0.0619, -0.1537,  0.1577,  ...,  0.1169,  0.1408, -0.1492],
        ...,
        [-0.1068,  0.0991, -0.0932,  ..., -0.0026,  0.1096,  0.0600],
        [ 0.0440, -0.1175, -0.1081,  ...,  0.1355, -0.1636,  0.0546],
        [ 0.0078, -0.0537,  0.1331,  ..., -0.0026, -0.1485, -0.1736]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1520, -0.0610,  0.0643,  ...,  0.0820,  0.1471,  0.0183],
        [ 0.0998, -0.0444,  0.1236,  ..., -0.1677, -0.0641,  0.0396],
        [ 0.0619, -0.1537,  0.1577,  ...,  0.1169,  0.1408, -0.1492],
        ...,
        [-0.1068,  0.0991, -0.0932,  ..., -0.0026,  0.1096,  0.0600],
        [ 0.0440, -0.1175, -0.1081,  ...,  0.1355, -0.1636,  0.0546],
        [ 0.0078, -0.0537,  0.1331,  ..., -0.0026, -0.1485, -0.1736]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.0859, -0.1804,  0.1716,  ..., -0.1882,  0.1276,  0.1932],
        [-0.1122, -0.1790,  0.1021,  ..., -0.1835,  0.0398,  0.1643],
        [ 0.2459,  0.1620,  0.1959,  ..., -0.1750, -0.0977, -0.1291],
        ...,
        [-0.2331, -0.0175,  0.1714,  ...,  0.0177, -0.1070, -0.0471],
        [-0.0343, -0.0504,  0.1047,  ..., -0.1760, -0.0077, -0.0763],
        [ 0.0088,  0.0060, -0.0983,  ..., -0.0569,  0.0971,  0.1613]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0859, -0.1804,  0.1716,  ..., -0.1882,  0.1276,  0.1932],
        [-0.1122, -0.1790,  0.1021,  ..., -0.1835,  0.0398,  0.1643],
        [ 0.2459,  0.1620,  0.1959,  ..., -0.1750, -0.0977, -0.1291],
        ...,
        [-0.2331, -0.0175,  0.1714,  ...,  0.0177, -0.1070, -0.0471],
        [-0.0343, -0.0504,  0.1047,  ..., -0.1760, -0.0077, -0.0763],
        [ 0.0088,  0.0060, -0.0983,  ..., -0.0569,  0.0971,  0.1613]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[-0.3604],
        [-0.2606],
        [-0.2452],
        [ 0.1556],
        [-0.0647],
        [-0.4009],
        [-0.1043],
        [-0.2710],
        [ 0.2771],
        [-0.1837],
        [-0.0939],
        [ 0.1894],
        [-0.3421],
        [-0.0673],
        [-0.2991],
        [-0.0921],
        [-0.0774],
        [-0.4080],
        [ 0.3430],
        [ 0.0290],
        [ 0.0063],
        [-0.0969],
        [-0.0477],
        [ 0.0331],
        [-0.1296],
        [-0.0794],
        [ 0.2702],
        [ 0.2856],
        [-0.2463],
        [-0.2618],
        [-0.0086],
        [-0.2686]], device='cuda:0') 
 Parameter containing:
tensor([[-0.3604],
        [-0.2606],
        [-0.2452],
        [ 0.1556],
        [-0.0647],
        [-0.4009],
        [-0.1043],
        [-0.2710],
        [ 0.2771],
        [-0.1837],
        [-0.0939],
        [ 0.1894],
        [-0.3421],
        [-0.0673],
        [-0.2991],
        [-0.0921],
        [-0.0774],
        [-0.4080],
        [ 0.3430],
        [ 0.0290],
        [ 0.0063],
        [-0.0969],
        [-0.0477],
        [ 0.0331],
        [-0.1296],
        [-0.0794],
        [ 0.2702],
        [ 0.2856],
        [-0.2463],
        [-0.2618],
        [-0.0086],
        [-0.2686]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(112.4784, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(4.1610, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(4.2705, device='cuda:0')



h[100].sum tensor(-2.2039, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-2.2619, device='cuda:0')



h[200].sum tensor(-2.2167, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-2.2751, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(3471.0591, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0021, 0.0000, 0.0016,  ..., 0.0000, 0.0000, 0.0024],
        [0.0108, 0.0000, 0.0086,  ..., 0.0000, 0.0000, 0.0127],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(15933.7930, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(419.6336, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(33.5696, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(25.4892, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(2.0391, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(229.2971, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(18.3432, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0071],
        [0.0087],
        [0.0125],
        ...,
        [0.0020],
        [0.0020],
        [0.0016]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(178.3529, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[0.0071],
        [0.0087],
        [0.0125],
        ...,
        [0.0020],
        [0.0020],
        [0.0016]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(-163.1889, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(4.7310, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(4.6927, device='cuda:0')



h[100].sum tensor(6.6496, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(6.5957, device='cuda:0')



h[200].sum tensor(-10.2009, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-10.1183, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(13806.0244, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0125,  ..., 0.0149, 0.0200, 0.0448],
        [0.0000, 0.0000, 0.0026,  ..., 0.0031, 0.0042, 0.0094],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(78587.3281, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-38.4334, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(743.3481, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(52.2980, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(3135.0903, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(220.5681, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0531],
        [0.0325],
        [0.0199],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(3117.1372, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[0.0071],
        [0.0087],
        [0.0125],
        ...,
        [0.0020],
        [0.0020],
        [0.0016]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py", line 5, in <module>
    from ModelBha import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/ModelBha.py", line 209, in <module>
    plt.savefig(f'/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/{modelname}/results/{t}\
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/pyplot.py", line 966, in savefig
    res = fig.savefig(*args, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/figure.py", line 3015, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 2255, in print_figure
    result = print_method(
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backend_bases.py", line 1669, in wrapper
    return func(*args, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py", line 509, in print_png
    mpl.image.imsave(
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/matplotlib/image.py", line 1616, in imsave
    image.save(fname, **pil_kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/PIL/Image.py", line 2237, in save
    fp = builtins.open(filename, "w+b")
FileNotFoundError: [Errno 2] No such file or directory: '/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N2/results/2022-08-12 16:25:21.336226    passing three random events (20, 30, 31) from network before training.png'

real	7m45.405s
user	0m12.361s
sys	0m14.476s
