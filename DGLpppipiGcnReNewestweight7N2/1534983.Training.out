0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        465.19.01
supported:      external
license:        NVIDIA
firmware:       nvidia/465.19.01/gsp.bin
retpoline:      Y
rhelversion:    7.8
srcversion:     976AD09EB9C3B8943CBA8C4
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           nv_cap_enable_devfs:Enable (1) or disable (0) nv-caps devfs support. Default: 1 (int)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           rm_firmware_active:charp

nvidia-smi:
Tue Aug  9 17:24:05 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   22C    P0    32W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.505273344

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b2101e96880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m5.082s
user	0m2.691s
sys	0m1.052s
[17:24:13] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[ 0.9594],
        [-0.3652],
        [-2.0598],
        ...,
        [-0.0213],
        [-1.0689],
        [ 0.6775]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-87.9332, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (80000, 6796) (80000, 6796)
sum 5574226 8401300
shape torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLpppipiGcnReNewestweight7N2
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 1.4724e-01,  8.4922e-02,  1.2191e-01, -8.5112e-03, -2.8915e-02,
         -6.6825e-02,  6.6250e-02, -9.7949e-02, -5.4014e-03, -3.8907e-02,
          1.0329e-01,  6.3899e-02, -6.5804e-02,  5.3177e-02, -6.7667e-03,
          1.0383e-01,  3.1442e-02,  1.1794e-01,  4.1154e-02, -1.3184e-01,
          8.5302e-02, -1.6300e-02,  1.0562e-01,  4.1972e-02,  9.1492e-02,
          1.0855e-01, -1.1228e-02, -6.9625e-02,  1.3625e-02, -7.6762e-02,
         -7.4235e-02, -2.0219e-02,  8.6364e-02,  1.1384e-05, -3.9052e-02,
          8.2107e-03,  9.1414e-02,  1.1176e-01, -9.4838e-02,  1.5195e-01,
          1.5222e-01, -1.4453e-01, -6.1443e-02, -8.4566e-02,  8.8935e-02,
          6.7525e-02, -4.1580e-02, -1.4257e-01, -6.8026e-02, -4.0893e-02,
          2.2709e-02,  1.1164e-01, -1.4790e-01,  1.4425e-01, -1.2502e-01,
         -6.0158e-02, -5.4711e-03, -7.8304e-02,  8.0064e-02, -3.8832e-02,
         -2.1448e-02, -1.4592e-01,  5.4557e-02, -1.2817e-01,  5.3438e-02,
          1.2064e-01,  7.2376e-02,  1.0721e-01, -1.5097e-01,  1.8789e-02,
         -7.5298e-02,  1.3990e-01,  3.2131e-04, -2.8977e-02,  9.0520e-02,
         -2.3047e-02,  3.5684e-02, -6.4485e-02,  1.1817e-01,  2.9352e-02,
         -2.3015e-03, -1.3390e-01, -3.3967e-03,  5.7460e-02,  1.0561e-01,
          1.1025e-01, -6.6882e-02, -2.5225e-02,  8.2432e-02,  1.1049e-01,
          3.8937e-02,  8.6639e-02,  1.5253e-01, -1.5039e-01,  1.4906e-01,
          3.8969e-02,  8.2240e-02, -4.7009e-03, -5.1347e-02, -9.1161e-02,
          4.8537e-02, -2.6034e-02,  7.9767e-02, -5.5529e-03,  6.8279e-02,
         -6.6744e-02, -7.4513e-02, -1.2164e-01,  1.7220e-02,  7.7340e-02,
         -1.1160e-01,  1.7846e-02,  8.1744e-02, -1.1997e-01,  1.2429e-01,
         -4.4260e-02,  1.3995e-01, -1.9351e-02, -5.2490e-02,  9.3263e-02,
         -1.4206e-01, -2.3083e-02, -1.5265e-01, -1.0015e-01,  9.5894e-02,
         -5.7517e-03, -5.9995e-02, -8.0429e-02,  1.4518e-01,  2.1391e-02,
         -6.8444e-02, -2.0152e-02, -9.3883e-02, -7.4520e-02, -3.0779e-02,
          1.2114e-01,  9.9806e-02,  1.2978e-04,  2.4635e-02,  3.6427e-04,
          1.3839e-01, -1.8814e-02, -1.3605e-01,  1.1268e-01,  1.0348e-01,
          1.1106e-01,  1.0683e-01, -2.5842e-02, -6.7864e-02, -1.2050e-01,
         -1.4066e-02, -1.4579e-01, -6.1587e-02,  1.9845e-02,  6.8121e-02,
         -7.0750e-02,  1.1356e-01, -7.1604e-02, -1.3359e-01, -1.5014e-01,
          4.0482e-02,  1.0441e-01,  1.3537e-02,  5.8924e-03,  6.2807e-02,
         -1.2986e-02,  8.7885e-02,  7.0692e-02,  4.4625e-02, -1.1707e-01,
         -3.0125e-02,  1.2391e-01,  2.3549e-02, -1.4545e-01,  1.2988e-01,
          1.6355e-02, -1.0342e-01,  3.2172e-02, -3.0558e-02, -2.0745e-02,
         -1.4016e-01, -5.9023e-02, -1.2851e-01, -1.1225e-01, -3.2576e-02,
         -5.6827e-02, -7.1899e-02,  1.0579e-01, -8.9520e-02,  1.2616e-01,
         -7.6975e-02,  1.1055e-01,  7.6854e-02, -5.3812e-02,  2.1288e-02,
          6.9045e-02,  1.0552e-01,  4.8172e-02,  1.4964e-01,  3.5089e-02,
         -4.4449e-02,  1.5055e-01, -1.0285e-01, -4.2617e-03, -1.4540e-01,
         -1.1800e-01,  1.2387e-01,  3.1732e-03,  1.5439e-02,  1.1431e-01,
         -3.6038e-02, -9.0973e-02,  1.4866e-01, -4.2437e-02, -3.4155e-03,
         -1.1735e-01, -1.0674e-01,  1.2998e-01,  6.9350e-02, -1.1162e-01,
         -8.8670e-02,  1.2014e-01, -8.3271e-02,  4.5390e-02,  1.3647e-01,
         -6.3892e-02,  1.1874e-01, -6.6072e-02, -1.0105e-01, -5.0744e-02,
          7.2719e-02,  9.8139e-02, -6.9785e-02, -1.0168e-01, -8.0064e-02,
          5.2989e-03, -4.8367e-02, -6.4080e-02,  1.1508e-01,  1.5129e-01,
          1.1141e-01, -2.4285e-02,  1.2026e-01,  3.8405e-03, -1.1174e-01,
         -1.9518e-02, -5.3688e-02, -8.1795e-02, -4.8794e-02, -2.4567e-02,
         -2.9453e-02,  8.5444e-02,  1.2819e-01, -1.1579e-01, -1.3071e-01,
          1.0227e-01]], device='cuda:0') 
 Parameter containing:
tensor([[ 1.4724e-01,  8.4922e-02,  1.2191e-01, -8.5112e-03, -2.8915e-02,
         -6.6825e-02,  6.6250e-02, -9.7949e-02, -5.4014e-03, -3.8907e-02,
          1.0329e-01,  6.3899e-02, -6.5804e-02,  5.3177e-02, -6.7667e-03,
          1.0383e-01,  3.1442e-02,  1.1794e-01,  4.1154e-02, -1.3184e-01,
          8.5302e-02, -1.6300e-02,  1.0562e-01,  4.1972e-02,  9.1492e-02,
          1.0855e-01, -1.1228e-02, -6.9625e-02,  1.3625e-02, -7.6762e-02,
         -7.4235e-02, -2.0219e-02,  8.6364e-02,  1.1384e-05, -3.9052e-02,
          8.2107e-03,  9.1414e-02,  1.1176e-01, -9.4838e-02,  1.5195e-01,
          1.5222e-01, -1.4453e-01, -6.1443e-02, -8.4566e-02,  8.8935e-02,
          6.7525e-02, -4.1580e-02, -1.4257e-01, -6.8026e-02, -4.0893e-02,
          2.2709e-02,  1.1164e-01, -1.4790e-01,  1.4425e-01, -1.2502e-01,
         -6.0158e-02, -5.4711e-03, -7.8304e-02,  8.0064e-02, -3.8832e-02,
         -2.1448e-02, -1.4592e-01,  5.4557e-02, -1.2817e-01,  5.3438e-02,
          1.2064e-01,  7.2376e-02,  1.0721e-01, -1.5097e-01,  1.8789e-02,
         -7.5298e-02,  1.3990e-01,  3.2131e-04, -2.8977e-02,  9.0520e-02,
         -2.3047e-02,  3.5684e-02, -6.4485e-02,  1.1817e-01,  2.9352e-02,
         -2.3015e-03, -1.3390e-01, -3.3967e-03,  5.7460e-02,  1.0561e-01,
          1.1025e-01, -6.6882e-02, -2.5225e-02,  8.2432e-02,  1.1049e-01,
          3.8937e-02,  8.6639e-02,  1.5253e-01, -1.5039e-01,  1.4906e-01,
          3.8969e-02,  8.2240e-02, -4.7009e-03, -5.1347e-02, -9.1161e-02,
          4.8537e-02, -2.6034e-02,  7.9767e-02, -5.5529e-03,  6.8279e-02,
         -6.6744e-02, -7.4513e-02, -1.2164e-01,  1.7220e-02,  7.7340e-02,
         -1.1160e-01,  1.7846e-02,  8.1744e-02, -1.1997e-01,  1.2429e-01,
         -4.4260e-02,  1.3995e-01, -1.9351e-02, -5.2490e-02,  9.3263e-02,
         -1.4206e-01, -2.3083e-02, -1.5265e-01, -1.0015e-01,  9.5894e-02,
         -5.7517e-03, -5.9995e-02, -8.0429e-02,  1.4518e-01,  2.1391e-02,
         -6.8444e-02, -2.0152e-02, -9.3883e-02, -7.4520e-02, -3.0779e-02,
          1.2114e-01,  9.9806e-02,  1.2978e-04,  2.4635e-02,  3.6427e-04,
          1.3839e-01, -1.8814e-02, -1.3605e-01,  1.1268e-01,  1.0348e-01,
          1.1106e-01,  1.0683e-01, -2.5842e-02, -6.7864e-02, -1.2050e-01,
         -1.4066e-02, -1.4579e-01, -6.1587e-02,  1.9845e-02,  6.8121e-02,
         -7.0750e-02,  1.1356e-01, -7.1604e-02, -1.3359e-01, -1.5014e-01,
          4.0482e-02,  1.0441e-01,  1.3537e-02,  5.8924e-03,  6.2807e-02,
         -1.2986e-02,  8.7885e-02,  7.0692e-02,  4.4625e-02, -1.1707e-01,
         -3.0125e-02,  1.2391e-01,  2.3549e-02, -1.4545e-01,  1.2988e-01,
          1.6355e-02, -1.0342e-01,  3.2172e-02, -3.0558e-02, -2.0745e-02,
         -1.4016e-01, -5.9023e-02, -1.2851e-01, -1.1225e-01, -3.2576e-02,
         -5.6827e-02, -7.1899e-02,  1.0579e-01, -8.9520e-02,  1.2616e-01,
         -7.6975e-02,  1.1055e-01,  7.6854e-02, -5.3812e-02,  2.1288e-02,
          6.9045e-02,  1.0552e-01,  4.8172e-02,  1.4964e-01,  3.5089e-02,
         -4.4449e-02,  1.5055e-01, -1.0285e-01, -4.2617e-03, -1.4540e-01,
         -1.1800e-01,  1.2387e-01,  3.1732e-03,  1.5439e-02,  1.1431e-01,
         -3.6038e-02, -9.0973e-02,  1.4866e-01, -4.2437e-02, -3.4155e-03,
         -1.1735e-01, -1.0674e-01,  1.2998e-01,  6.9350e-02, -1.1162e-01,
         -8.8670e-02,  1.2014e-01, -8.3271e-02,  4.5390e-02,  1.3647e-01,
         -6.3892e-02,  1.1874e-01, -6.6072e-02, -1.0105e-01, -5.0744e-02,
          7.2719e-02,  9.8139e-02, -6.9785e-02, -1.0168e-01, -8.0064e-02,
          5.2989e-03, -4.8367e-02, -6.4080e-02,  1.1508e-01,  1.5129e-01,
          1.1141e-01, -2.4285e-02,  1.2026e-01,  3.8405e-03, -1.1174e-01,
         -1.9518e-02, -5.3688e-02, -8.1795e-02, -4.8794e-02, -2.4567e-02,
         -2.9453e-02,  8.5444e-02,  1.2819e-01, -1.1579e-01, -1.3071e-01,
          1.0227e-01]], device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[-0.0536,  0.0744,  0.1196,  ..., -0.0208, -0.1129,  0.0396],
        [ 0.1122,  0.0884, -0.0736,  ...,  0.1176, -0.1055,  0.0623],
        [-0.1091,  0.0566,  0.0280,  ...,  0.0187,  0.0989,  0.1062],
        ...,
        [ 0.0420, -0.0400,  0.0425,  ...,  0.0569,  0.0491, -0.0741],
        [-0.1079, -0.0310,  0.0685,  ..., -0.1126,  0.0336, -0.0482],
        [ 0.0359, -0.0851,  0.0086,  ...,  0.0949, -0.0958,  0.0366]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0536,  0.0744,  0.1196,  ..., -0.0208, -0.1129,  0.0396],
        [ 0.1122,  0.0884, -0.0736,  ...,  0.1176, -0.1055,  0.0623],
        [-0.1091,  0.0566,  0.0280,  ...,  0.0187,  0.0989,  0.1062],
        ...,
        [ 0.0420, -0.0400,  0.0425,  ...,  0.0569,  0.0491, -0.0741],
        [-0.1079, -0.0310,  0.0685,  ..., -0.1126,  0.0336, -0.0482],
        [ 0.0359, -0.0851,  0.0086,  ...,  0.0949, -0.0958,  0.0366]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.1521,  0.0197,  0.0236,  ..., -0.0094, -0.0403, -0.1413],
        [-0.0046,  0.0162,  0.0932,  ..., -0.1084, -0.1249, -0.1406],
        [ 0.0838,  0.0050,  0.1616,  ...,  0.0556, -0.0161,  0.0394],
        ...,
        [-0.0665, -0.0458,  0.0241,  ..., -0.1146,  0.1622, -0.0722],
        [-0.0501,  0.1686,  0.1236,  ..., -0.0618,  0.1311, -0.1275],
        [ 0.0204,  0.1296, -0.0868,  ...,  0.0304, -0.1119,  0.0212]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1521,  0.0197,  0.0236,  ..., -0.0094, -0.0403, -0.1413],
        [-0.0046,  0.0162,  0.0932,  ..., -0.1084, -0.1249, -0.1406],
        [ 0.0838,  0.0050,  0.1616,  ...,  0.0556, -0.0161,  0.0394],
        ...,
        [-0.0665, -0.0458,  0.0241,  ..., -0.1146,  0.1622, -0.0722],
        [-0.0501,  0.1686,  0.1236,  ..., -0.0618,  0.1311, -0.1275],
        [ 0.0204,  0.1296, -0.0868,  ...,  0.0304, -0.1119,  0.0212]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.2342,  0.1523,  0.1843,  ...,  0.1140, -0.1383, -0.0037],
        [ 0.1902,  0.0822, -0.2108,  ...,  0.1999, -0.0948,  0.1019],
        [ 0.0110,  0.1206, -0.1026,  ...,  0.0865, -0.1741, -0.0466],
        ...,
        [-0.2115,  0.0996, -0.0179,  ..., -0.1938,  0.1937,  0.0857],
        [ 0.1727,  0.1219, -0.2445,  ..., -0.1691,  0.1999, -0.0165],
        [ 0.0765,  0.1820, -0.1749,  ...,  0.0351,  0.2096, -0.1458]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.2342,  0.1523,  0.1843,  ...,  0.1140, -0.1383, -0.0037],
        [ 0.1902,  0.0822, -0.2108,  ...,  0.1999, -0.0948,  0.1019],
        [ 0.0110,  0.1206, -0.1026,  ...,  0.0865, -0.1741, -0.0466],
        ...,
        [-0.2115,  0.0996, -0.0179,  ..., -0.1938,  0.1937,  0.0857],
        [ 0.1727,  0.1219, -0.2445,  ..., -0.1691,  0.1999, -0.0165],
        [ 0.0765,  0.1820, -0.1749,  ...,  0.0351,  0.2096, -0.1458]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.4071],
        [ 0.0342],
        [-0.4170],
        [-0.1546],
        [ 0.1348],
        [-0.0418],
        [-0.2989],
        [-0.2315],
        [ 0.1173],
        [-0.4138],
        [ 0.2499],
        [-0.2348],
        [-0.1750],
        [-0.0401],
        [-0.2692],
        [ 0.1863],
        [ 0.3287],
        [-0.2476],
        [ 0.0308],
        [-0.0683],
        [-0.1997],
        [ 0.2230],
        [-0.1522],
        [ 0.1967],
        [ 0.3088],
        [-0.3914],
        [ 0.1215],
        [ 0.0511],
        [-0.1521],
        [ 0.3092],
        [ 0.0039],
        [ 0.1994]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.4071],
        [ 0.0342],
        [-0.4170],
        [-0.1546],
        [ 0.1348],
        [-0.0418],
        [-0.2989],
        [-0.2315],
        [ 0.1173],
        [-0.4138],
        [ 0.2499],
        [-0.2348],
        [-0.1750],
        [-0.0401],
        [-0.2692],
        [ 0.1863],
        [ 0.3287],
        [-0.2476],
        [ 0.0308],
        [-0.0683],
        [-0.1997],
        [ 0.2230],
        [-0.1522],
        [ 0.1967],
        [ 0.3088],
        [-0.3914],
        [ 0.1215],
        [ 0.0511],
        [-0.1521],
        [ 0.3092],
        [ 0.0039],
        [ 0.1994]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 0.1448, -0.1333,  0.1099, -0.1054,  0.0147, -0.0406,  0.1163,  0.1259,
         -0.1080, -0.0867,  0.0017, -0.0319, -0.1510,  0.1280,  0.0328, -0.0454,
         -0.1074,  0.1254,  0.0341,  0.1385,  0.0052, -0.0104,  0.1483,  0.0293,
          0.0602,  0.0414, -0.1214, -0.1251,  0.1504,  0.0351,  0.0103, -0.0026,
          0.0346,  0.0671, -0.0427,  0.0828,  0.0354, -0.0366,  0.0933, -0.0133,
          0.1033,  0.0587,  0.0142, -0.0290,  0.1432,  0.0399,  0.1156,  0.0792,
          0.0726, -0.0812, -0.0570, -0.0289,  0.0357, -0.0307,  0.0223, -0.0075,
          0.1118,  0.0244,  0.0930, -0.0542,  0.0287, -0.0455,  0.0565, -0.1338,
         -0.1452,  0.0955, -0.0472,  0.0914, -0.1025, -0.0887,  0.0384,  0.0085,
         -0.1480,  0.0105,  0.0045,  0.0782,  0.0420,  0.1103,  0.0410,  0.0832,
          0.1230,  0.1255, -0.1397, -0.1042, -0.0815,  0.0862, -0.1240, -0.0122,
         -0.1310,  0.0314,  0.1235, -0.0319,  0.1392,  0.0177,  0.1204,  0.1174,
          0.1509, -0.1442,  0.0122, -0.0143, -0.0882,  0.0060, -0.1500, -0.0205,
          0.0703, -0.0358, -0.0550,  0.1052,  0.0155, -0.0677, -0.1223,  0.0619,
         -0.0540,  0.0074,  0.0159,  0.1359,  0.0834,  0.0553,  0.0620, -0.0759,
         -0.0242,  0.0985, -0.1269, -0.0798, -0.0705,  0.1117, -0.0963,  0.0371,
          0.0868,  0.0445, -0.0375, -0.0208,  0.0594, -0.1469,  0.0364,  0.0359,
          0.0832,  0.1302, -0.0946, -0.0741, -0.1440, -0.0794, -0.0568,  0.0983,
          0.1305, -0.0569, -0.1110,  0.0358,  0.0522, -0.0201,  0.1348, -0.0885,
         -0.0797, -0.0299,  0.0052,  0.0006, -0.0227, -0.1394, -0.0591,  0.1190,
         -0.1474, -0.0020,  0.0466, -0.0849, -0.0679, -0.1008, -0.1524,  0.0994,
          0.0410, -0.0222,  0.0915,  0.1325,  0.0549, -0.1455, -0.1204, -0.1175,
         -0.0622, -0.1253,  0.0858,  0.1244, -0.0097, -0.1514, -0.1489, -0.1160,
         -0.0749,  0.0165, -0.0103,  0.1461,  0.1390, -0.0741,  0.0956, -0.1405,
          0.0895, -0.0199, -0.0883,  0.1422, -0.0393, -0.0485, -0.0589, -0.0082,
         -0.1309, -0.0191,  0.1041,  0.1481,  0.1192,  0.0624, -0.0845,  0.0774,
          0.0557,  0.0174,  0.0589,  0.0574,  0.0614, -0.0007,  0.1497,  0.0852,
         -0.1324, -0.1485,  0.0681, -0.0744, -0.0966, -0.0111,  0.0931,  0.1348,
         -0.0583, -0.0688,  0.1342, -0.0569, -0.1160,  0.0985, -0.0352, -0.0674,
         -0.0635,  0.0192,  0.0028, -0.0813, -0.1521, -0.1133, -0.0257,  0.1170,
         -0.0335,  0.0362, -0.0091, -0.0194,  0.0660,  0.0133,  0.0489,  0.1163,
          0.0104,  0.0525, -0.0274,  0.0862, -0.0685,  0.0147, -0.0154,  0.0305]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1448, -0.1333,  0.1099, -0.1054,  0.0147, -0.0406,  0.1163,  0.1259,
         -0.1080, -0.0867,  0.0017, -0.0319, -0.1510,  0.1280,  0.0328, -0.0454,
         -0.1074,  0.1254,  0.0341,  0.1385,  0.0052, -0.0104,  0.1483,  0.0293,
          0.0602,  0.0414, -0.1214, -0.1251,  0.1504,  0.0351,  0.0103, -0.0026,
          0.0346,  0.0671, -0.0427,  0.0828,  0.0354, -0.0366,  0.0933, -0.0133,
          0.1033,  0.0587,  0.0142, -0.0290,  0.1432,  0.0399,  0.1156,  0.0792,
          0.0726, -0.0812, -0.0570, -0.0289,  0.0357, -0.0307,  0.0223, -0.0075,
          0.1118,  0.0244,  0.0930, -0.0542,  0.0287, -0.0455,  0.0565, -0.1338,
         -0.1452,  0.0955, -0.0472,  0.0914, -0.1025, -0.0887,  0.0384,  0.0085,
         -0.1480,  0.0105,  0.0045,  0.0782,  0.0420,  0.1103,  0.0410,  0.0832,
          0.1230,  0.1255, -0.1397, -0.1042, -0.0815,  0.0862, -0.1240, -0.0122,
         -0.1310,  0.0314,  0.1235, -0.0319,  0.1392,  0.0177,  0.1204,  0.1174,
          0.1509, -0.1442,  0.0122, -0.0143, -0.0882,  0.0060, -0.1500, -0.0205,
          0.0703, -0.0358, -0.0550,  0.1052,  0.0155, -0.0677, -0.1223,  0.0619,
         -0.0540,  0.0074,  0.0159,  0.1359,  0.0834,  0.0553,  0.0620, -0.0759,
         -0.0242,  0.0985, -0.1269, -0.0798, -0.0705,  0.1117, -0.0963,  0.0371,
          0.0868,  0.0445, -0.0375, -0.0208,  0.0594, -0.1469,  0.0364,  0.0359,
          0.0832,  0.1302, -0.0946, -0.0741, -0.1440, -0.0794, -0.0568,  0.0983,
          0.1305, -0.0569, -0.1110,  0.0358,  0.0522, -0.0201,  0.1348, -0.0885,
         -0.0797, -0.0299,  0.0052,  0.0006, -0.0227, -0.1394, -0.0591,  0.1190,
         -0.1474, -0.0020,  0.0466, -0.0849, -0.0679, -0.1008, -0.1524,  0.0994,
          0.0410, -0.0222,  0.0915,  0.1325,  0.0549, -0.1455, -0.1204, -0.1175,
         -0.0622, -0.1253,  0.0858,  0.1244, -0.0097, -0.1514, -0.1489, -0.1160,
         -0.0749,  0.0165, -0.0103,  0.1461,  0.1390, -0.0741,  0.0956, -0.1405,
          0.0895, -0.0199, -0.0883,  0.1422, -0.0393, -0.0485, -0.0589, -0.0082,
         -0.1309, -0.0191,  0.1041,  0.1481,  0.1192,  0.0624, -0.0845,  0.0774,
          0.0557,  0.0174,  0.0589,  0.0574,  0.0614, -0.0007,  0.1497,  0.0852,
         -0.1324, -0.1485,  0.0681, -0.0744, -0.0966, -0.0111,  0.0931,  0.1348,
         -0.0583, -0.0688,  0.1342, -0.0569, -0.1160,  0.0985, -0.0352, -0.0674,
         -0.0635,  0.0192,  0.0028, -0.0813, -0.1521, -0.1133, -0.0257,  0.1170,
         -0.0335,  0.0362, -0.0091, -0.0194,  0.0660,  0.0133,  0.0489,  0.1163,
          0.0104,  0.0525, -0.0274,  0.0862, -0.0685,  0.0147, -0.0154,  0.0305]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0969,  0.0147,  0.0790,  ..., -0.0559, -0.0072, -0.0230],
        [ 0.0352, -0.0596,  0.0419,  ..., -0.1191, -0.0633, -0.0830],
        [-0.0250,  0.1222, -0.0308,  ...,  0.0384, -0.1020, -0.0817],
        ...,
        [ 0.1105,  0.0246,  0.0033,  ...,  0.0188,  0.1207, -0.0404],
        [-0.0248, -0.0384, -0.1092,  ..., -0.1205,  0.0015, -0.0777],
        [ 0.0752,  0.0165,  0.0204,  ...,  0.1168,  0.0306, -0.0224]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0969,  0.0147,  0.0790,  ..., -0.0559, -0.0072, -0.0230],
        [ 0.0352, -0.0596,  0.0419,  ..., -0.1191, -0.0633, -0.0830],
        [-0.0250,  0.1222, -0.0308,  ...,  0.0384, -0.1020, -0.0817],
        ...,
        [ 0.1105,  0.0246,  0.0033,  ...,  0.0188,  0.1207, -0.0404],
        [-0.0248, -0.0384, -0.1092,  ..., -0.1205,  0.0015, -0.0777],
        [ 0.0752,  0.0165,  0.0204,  ...,  0.1168,  0.0306, -0.0224]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.0999,  0.0952, -0.0131,  ..., -0.1482,  0.1379,  0.0323],
        [ 0.0741,  0.0468, -0.0334,  ..., -0.0432, -0.0950,  0.1649],
        [ 0.0087,  0.0534, -0.1494,  ..., -0.0104,  0.1318,  0.1523],
        ...,
        [ 0.0925,  0.1729,  0.1552,  ...,  0.0341,  0.1196,  0.0929],
        [ 0.0070, -0.1749, -0.0258,  ..., -0.0147,  0.1540, -0.1185],
        [-0.0766,  0.1393, -0.1131,  ...,  0.1602, -0.0392, -0.0979]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0999,  0.0952, -0.0131,  ..., -0.1482,  0.1379,  0.0323],
        [ 0.0741,  0.0468, -0.0334,  ..., -0.0432, -0.0950,  0.1649],
        [ 0.0087,  0.0534, -0.1494,  ..., -0.0104,  0.1318,  0.1523],
        ...,
        [ 0.0925,  0.1729,  0.1552,  ...,  0.0341,  0.1196,  0.0929],
        [ 0.0070, -0.1749, -0.0258,  ..., -0.0147,  0.1540, -0.1185],
        [-0.0766,  0.1393, -0.1131,  ...,  0.1602, -0.0392, -0.0979]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[ 0.2386,  0.0559, -0.0508,  ..., -0.1614,  0.1357,  0.0651],
        [-0.0187, -0.1758,  0.2419,  ...,  0.0560, -0.0376,  0.0552],
        [-0.2478,  0.0555,  0.1929,  ..., -0.0787, -0.2405, -0.1728],
        ...,
        [ 0.1799,  0.1842, -0.1561,  ...,  0.1413, -0.2329,  0.1681],
        [ 0.0824,  0.0190,  0.0896,  ...,  0.1179, -0.2438,  0.2297],
        [ 0.0534, -0.0878,  0.1375,  ..., -0.1421, -0.1366,  0.0328]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.2386,  0.0559, -0.0508,  ..., -0.1614,  0.1357,  0.0651],
        [-0.0187, -0.1758,  0.2419,  ...,  0.0560, -0.0376,  0.0552],
        [-0.2478,  0.0555,  0.1929,  ..., -0.0787, -0.2405, -0.1728],
        ...,
        [ 0.1799,  0.1842, -0.1561,  ...,  0.1413, -0.2329,  0.1681],
        [ 0.0824,  0.0190,  0.0896,  ...,  0.1179, -0.2438,  0.2297],
        [ 0.0534, -0.0878,  0.1375,  ..., -0.1421, -0.1366,  0.0328]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.1614],
        [ 0.0975],
        [ 0.1393],
        [-0.0465],
        [ 0.2511],
        [ 0.0491],
        [ 0.1294],
        [-0.1227],
        [ 0.1310],
        [ 0.0089],
        [-0.2415],
        [-0.0382],
        [ 0.1818],
        [-0.3594],
        [ 0.2053],
        [ 0.3728],
        [ 0.0178],
        [-0.0466],
        [-0.3285],
        [ 0.2079],
        [-0.4023],
        [-0.3722],
        [-0.1693],
        [-0.2699],
        [-0.2855],
        [-0.2707],
        [ 0.0681],
        [ 0.1016],
        [ 0.0420],
        [ 0.0339],
        [ 0.3283],
        [-0.2250]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.1614],
        [ 0.0975],
        [ 0.1393],
        [-0.0465],
        [ 0.2511],
        [ 0.0491],
        [ 0.1294],
        [-0.1227],
        [ 0.1310],
        [ 0.0089],
        [-0.2415],
        [-0.0382],
        [ 0.1818],
        [-0.3594],
        [ 0.2053],
        [ 0.3728],
        [ 0.0178],
        [-0.0466],
        [-0.3285],
        [ 0.2079],
        [-0.4023],
        [-0.3722],
        [-0.1693],
        [-0.2699],
        [-0.2855],
        [-0.2707],
        [ 0.0681],
        [ 0.1016],
        [ 0.0420],
        [ 0.0339],
        [ 0.3283],
        [-0.2250]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(33.1882, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-30.7559, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(1.8893, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(1.9391, device='cuda:0')



h[100].sum tensor(1.4893, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(1.5285, device='cuda:0')



h[200].sum tensor(-4.2580, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-4.3701, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(2707.2393, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0009,  ..., 0.0000, 0.0010, 0.0016],
        [0.0000, 0.0000, 0.0045,  ..., 0.0000, 0.0053, 0.0084],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(12744.7129, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-23.3045, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(15.3742, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(1.2313, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(382.5269, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(30.6007, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0038],
        [0.0047],
        [0.0067],
        ...,
        [0.0011],
        [0.0011],
        [0.0009]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(96.6285, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[0.0038],
        [0.0047],
        [0.0067],
        ...,
        [0.0011],
        [0.0011],
        [0.0009]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(132.4834, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(-89.0720, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(11.7117, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(11.6168, device='cuda:0')



h[100].sum tensor(-5.0605, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-5.0195, device='cuda:0')



h[200].sum tensor(-0.3761, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-0.3730, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(14298.4414, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0057, 0.0000, 0.0000,  ..., 0.0000, 0.0195, 0.0000],
        [0.0012, 0.0000, 0.0000,  ..., 0.0000, 0.0041, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(68496.0781, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(458.5927, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(32.2485, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(582.8369, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(41.0037, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-154.6283, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.2718],
        [0.1667],
        [0.1020],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(15966.9502, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[0.0038],
        [0.0047],
        [0.0067],
        ...,
        [0.0011],
        [0.0011],
        [0.0009]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0. 0. 0. ... 0. 0. 0.]
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/saved_checkpoint.pth.tar



load_model True 
TraEvN 30001 
BatchSize 5 
EpochNum 50 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[-0.0174, -0.1397,  0.0905,  0.0242,  0.0649, -0.0421, -0.0068,  0.1005,
          0.0306,  0.1241,  0.0910,  0.1260, -0.0593,  0.0356,  0.1313,  0.1315,
          0.1342, -0.1521, -0.0073, -0.0375, -0.0313,  0.1280,  0.0359,  0.0974,
          0.1085,  0.0271, -0.0194,  0.0477, -0.0006, -0.1473,  0.1079, -0.1273,
          0.0082, -0.0142,  0.1046, -0.0038,  0.0639,  0.0011, -0.0299, -0.0969,
          0.0702,  0.1484, -0.0713, -0.0202,  0.0650,  0.1327,  0.0898,  0.0311,
          0.0997,  0.1104,  0.0857, -0.0554, -0.1027, -0.0253, -0.0178, -0.1501,
         -0.1355, -0.0246,  0.0326,  0.0706,  0.0013,  0.0575, -0.1025, -0.1069,
          0.0326, -0.0440,  0.1277, -0.0641, -0.0735, -0.0767,  0.0593, -0.0213,
         -0.1177,  0.1290,  0.0355,  0.0101, -0.0747, -0.1051,  0.0229,  0.1088,
         -0.0269, -0.1134,  0.0334, -0.0423,  0.0829, -0.0673,  0.1375,  0.0129,
         -0.1376,  0.0820,  0.1212,  0.0307,  0.0672, -0.0817,  0.0940, -0.0754,
          0.1379, -0.1433,  0.0217, -0.0487,  0.0937, -0.0379, -0.1303,  0.0511,
          0.0065, -0.1241,  0.1075, -0.0424, -0.0772,  0.1418,  0.1397, -0.0267,
          0.1339,  0.0370, -0.0819,  0.0489, -0.0342, -0.0364, -0.0217,  0.1271,
         -0.0355, -0.0066, -0.0406, -0.1152, -0.1059, -0.0281, -0.1333,  0.0502,
         -0.0004, -0.0504,  0.0291,  0.0730,  0.0384,  0.0290, -0.0381, -0.0060,
         -0.0847, -0.0443, -0.0513, -0.0416, -0.0374,  0.0517,  0.0509,  0.0824,
         -0.0345, -0.0883,  0.0494, -0.1198, -0.1347,  0.0616,  0.0840, -0.0138,
         -0.0378, -0.1415, -0.0493,  0.0388,  0.0196,  0.1245,  0.0870, -0.0357,
          0.0724,  0.1087, -0.0681, -0.0854,  0.0805,  0.1143,  0.0812, -0.0336,
         -0.0503,  0.1177, -0.0217,  0.1173,  0.0672, -0.0050,  0.0777,  0.0749,
          0.0533, -0.1160, -0.0907,  0.0844, -0.1289,  0.0431, -0.0265,  0.0156,
         -0.0268,  0.0946,  0.1054, -0.1238, -0.1477, -0.0688, -0.1419,  0.1167,
         -0.1506, -0.1477, -0.0644, -0.0616,  0.0346, -0.1415,  0.0898,  0.0826,
          0.1385,  0.1055,  0.0532, -0.0759, -0.1460,  0.0211,  0.0508,  0.0174,
          0.1233, -0.0883, -0.1137,  0.0257, -0.0330,  0.1197, -0.1251, -0.0246,
          0.0334,  0.0333,  0.0991,  0.1371, -0.1008, -0.1270,  0.0082, -0.0390,
          0.0921, -0.1470, -0.1356, -0.1116, -0.0847, -0.0858, -0.1269,  0.1507,
         -0.1058,  0.1373,  0.0230, -0.1385,  0.0419, -0.0626,  0.0603, -0.0271,
          0.0111, -0.1404,  0.0874, -0.0205, -0.1275,  0.1421, -0.0292,  0.1416,
         -0.1498, -0.0957, -0.1228, -0.0498,  0.1486,  0.0433,  0.0780,  0.1033]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0222, -0.0041,  0.0428,  ...,  0.0198, -0.0100, -0.0801],
        [ 0.1070, -0.0081, -0.0760,  ..., -0.0281, -0.0009, -0.0907],
        [-0.0520,  0.1190,  0.1146,  ..., -0.0750,  0.0088, -0.1112],
        ...,
        [ 0.0364,  0.0103, -0.0538,  ..., -0.0222, -0.1014,  0.0712],
        [ 0.1162, -0.0882,  0.0936,  ...,  0.0148, -0.0546,  0.0406],
        [ 0.1067, -0.0308,  0.0574,  ...,  0.0368, -0.0772, -0.0397]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0225,  0.0109, -0.1145,  ...,  0.0128,  0.1275,  0.0821],
        [ 0.0261,  0.0600, -0.1159,  ...,  0.1631, -0.1761, -0.0424],
        [-0.1135, -0.1411, -0.0980,  ..., -0.0723, -0.1406, -0.1183],
        ...,
        [-0.0075,  0.1457, -0.1164,  ...,  0.1670,  0.1423, -0.1281],
        [ 0.0937,  0.0722,  0.0543,  ..., -0.0261, -0.1073, -0.1449],
        [-0.1375,  0.1532, -0.1233,  ..., -0.0888,  0.0411,  0.1001]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.1799,  0.0139,  0.2044,  ...,  0.0747, -0.1164,  0.1483],
        [-0.2027,  0.0046, -0.0016,  ...,  0.1836,  0.2465,  0.2352],
        [ 0.2329,  0.2066,  0.1637,  ..., -0.1540,  0.1485,  0.2196],
        ...,
        [ 0.0182,  0.1935,  0.2471,  ..., -0.2154, -0.1618, -0.2438],
        [-0.0274,  0.1725,  0.0911,  ...,  0.2271,  0.0468, -0.0407],
        [ 0.2188, -0.0594,  0.1306,  ..., -0.1344,  0.1421, -0.0876]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.4239],
        [-0.2729],
        [-0.2407],
        [ 0.1368],
        [ 0.3656],
        [ 0.2736],
        [-0.3497],
        [ 0.0700],
        [-0.1899],
        [ 0.0398],
        [-0.0917],
        [-0.0447],
        [-0.2548],
        [-0.1933],
        [ 0.3775],
        [ 0.1597],
        [ 0.2147],
        [-0.1108],
        [-0.3998],
        [-0.3878],
        [-0.4056],
        [ 0.2794],
        [-0.2342],
        [-0.3114],
        [-0.0182],
        [-0.0332],
        [-0.2083],
        [-0.1704],
        [ 0.0379],
        [ 0.0674],
        [ 0.0584],
        [-0.1303]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': array(0.0001), 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': array(5.e-05), 'amsgrad': False}]



optimizer.param_groups [{'params': [Parameter containing:
tensor([[-0.0174, -0.1397,  0.0905,  0.0242,  0.0649, -0.0421, -0.0068,  0.1005,
          0.0306,  0.1241,  0.0910,  0.1260, -0.0593,  0.0356,  0.1313,  0.1315,
          0.1342, -0.1521, -0.0073, -0.0375, -0.0313,  0.1280,  0.0359,  0.0974,
          0.1085,  0.0271, -0.0194,  0.0477, -0.0006, -0.1473,  0.1079, -0.1273,
          0.0082, -0.0142,  0.1046, -0.0038,  0.0639,  0.0011, -0.0299, -0.0969,
          0.0702,  0.1484, -0.0713, -0.0202,  0.0650,  0.1327,  0.0898,  0.0311,
          0.0997,  0.1104,  0.0857, -0.0554, -0.1027, -0.0253, -0.0178, -0.1501,
         -0.1355, -0.0246,  0.0326,  0.0706,  0.0013,  0.0575, -0.1025, -0.1069,
          0.0326, -0.0440,  0.1277, -0.0641, -0.0735, -0.0767,  0.0593, -0.0213,
         -0.1177,  0.1290,  0.0355,  0.0101, -0.0747, -0.1051,  0.0229,  0.1088,
         -0.0269, -0.1134,  0.0334, -0.0423,  0.0829, -0.0673,  0.1375,  0.0129,
         -0.1376,  0.0820,  0.1212,  0.0307,  0.0672, -0.0817,  0.0940, -0.0754,
          0.1379, -0.1433,  0.0217, -0.0487,  0.0937, -0.0379, -0.1303,  0.0511,
          0.0065, -0.1241,  0.1075, -0.0424, -0.0772,  0.1418,  0.1397, -0.0267,
          0.1339,  0.0370, -0.0819,  0.0489, -0.0342, -0.0364, -0.0217,  0.1271,
         -0.0355, -0.0066, -0.0406, -0.1152, -0.1059, -0.0281, -0.1333,  0.0502,
         -0.0004, -0.0504,  0.0291,  0.0730,  0.0384,  0.0290, -0.0381, -0.0060,
         -0.0847, -0.0443, -0.0513, -0.0416, -0.0374,  0.0517,  0.0509,  0.0824,
         -0.0345, -0.0883,  0.0494, -0.1198, -0.1347,  0.0616,  0.0840, -0.0138,
         -0.0378, -0.1415, -0.0493,  0.0388,  0.0196,  0.1245,  0.0870, -0.0357,
          0.0724,  0.1087, -0.0681, -0.0854,  0.0805,  0.1143,  0.0812, -0.0336,
         -0.0503,  0.1177, -0.0217,  0.1173,  0.0672, -0.0050,  0.0777,  0.0749,
          0.0533, -0.1160, -0.0907,  0.0844, -0.1289,  0.0431, -0.0265,  0.0156,
         -0.0268,  0.0946,  0.1054, -0.1238, -0.1477, -0.0688, -0.1419,  0.1167,
         -0.1506, -0.1477, -0.0644, -0.0616,  0.0346, -0.1415,  0.0898,  0.0826,
          0.1385,  0.1055,  0.0532, -0.0759, -0.1460,  0.0211,  0.0508,  0.0174,
          0.1233, -0.0883, -0.1137,  0.0257, -0.0330,  0.1197, -0.1251, -0.0246,
          0.0334,  0.0333,  0.0991,  0.1371, -0.1008, -0.1270,  0.0082, -0.0390,
          0.0921, -0.1470, -0.1356, -0.1116, -0.0847, -0.0858, -0.1269,  0.1507,
         -0.1058,  0.1373,  0.0230, -0.1385,  0.0419, -0.0626,  0.0603, -0.0271,
          0.0111, -0.1404,  0.0874, -0.0205, -0.1275,  0.1421, -0.0292,  0.1416,
         -0.1498, -0.0957, -0.1228, -0.0498,  0.1486,  0.0433,  0.0780,  0.1033]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0222, -0.0041,  0.0428,  ...,  0.0198, -0.0100, -0.0801],
        [ 0.1070, -0.0081, -0.0760,  ..., -0.0281, -0.0009, -0.0907],
        [-0.0520,  0.1190,  0.1146,  ..., -0.0750,  0.0088, -0.1112],
        ...,
        [ 0.0364,  0.0103, -0.0538,  ..., -0.0222, -0.1014,  0.0712],
        [ 0.1162, -0.0882,  0.0936,  ...,  0.0148, -0.0546,  0.0406],
        [ 0.1067, -0.0308,  0.0574,  ...,  0.0368, -0.0772, -0.0397]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0225,  0.0109, -0.1145,  ...,  0.0128,  0.1275,  0.0821],
        [ 0.0261,  0.0600, -0.1159,  ...,  0.1631, -0.1761, -0.0424],
        [-0.1135, -0.1411, -0.0980,  ..., -0.0723, -0.1406, -0.1183],
        ...,
        [-0.0075,  0.1457, -0.1164,  ...,  0.1670,  0.1423, -0.1281],
        [ 0.0937,  0.0722,  0.0543,  ..., -0.0261, -0.1073, -0.1449],
        [-0.1375,  0.1532, -0.1233,  ..., -0.0888,  0.0411,  0.1001]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.1799,  0.0139,  0.2044,  ...,  0.0747, -0.1164,  0.1483],
        [-0.2027,  0.0046, -0.0016,  ...,  0.1836,  0.2465,  0.2352],
        [ 0.2329,  0.2066,  0.1637,  ..., -0.1540,  0.1485,  0.2196],
        ...,
        [ 0.0182,  0.1935,  0.2471,  ..., -0.2154, -0.1618, -0.2438],
        [-0.0274,  0.1725,  0.0911,  ...,  0.2271,  0.0468, -0.0407],
        [ 0.2188, -0.0594,  0.1306,  ..., -0.1344,  0.1421, -0.0876]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.4239],
        [-0.2729],
        [-0.2407],
        [ 0.1368],
        [ 0.3656],
        [ 0.2736],
        [-0.3497],
        [ 0.0700],
        [-0.1899],
        [ 0.0398],
        [-0.0917],
        [-0.0447],
        [-0.2548],
        [-0.1933],
        [ 0.3775],
        [ 0.1597],
        [ 0.2147],
        [-0.1108],
        [-0.3998],
        [-0.3878],
        [-0.4056],
        [ 0.2794],
        [-0.2342],
        [-0.3114],
        [-0.0182],
        [-0.0332],
        [-0.2083],
        [-0.1704],
        [ 0.0379],
        [ 0.0674],
        [ 0.0584],
        [-0.1303]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': array(0.0001), 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': array(5.e-05), 'amsgrad': False}, {'params': [tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True)], 'lr': array(0.0001), 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': array(5.e-05), 'amsgrad': False}]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N2/./TrainingBha.py", line 77, in <module>
    featbatch = TraTen[i : i + BatchSize].reshape(int(BatchSize * 6796), 1)
TypeError: slice indices must be integers or None or have an __index__ method

real	0m23.777s
user	0m14.029s
sys	0m6.721s
