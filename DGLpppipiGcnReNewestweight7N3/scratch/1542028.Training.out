0: gpu034.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-07f659b6-fc78-8e02-1667-20934fa516c9)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        450.36.06
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.8
srcversion:     BB5CB243542347D4EB0C79C
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_MapRegistersEarly:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_EnableBacklightHandler:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_AssignGpus:charp

nvidia-smi:
Sun Aug 14 01:43:44 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
| N/A   33C    P0    43W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089730048

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2ad3ca39d8e0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m3.503s
user	0m1.824s
sys	0m0.594s
[01:43:49] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.10.2.so: cannot open shared object file: No such file or directory
Using backend: pytorch
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 4907, 4907, 4907],
        [   1,    2,    3,  ..., 4918, 4919, 4920]]) 

edge_index shape
 torch.Size([2, 36593])
graph: Graph(num_nodes=6796, num_edges=36593,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 4907, 4907, 4907], device='cuda:0'), tensor([   1,    2,    3,  ..., 4918, 4919, 4920], device='cuda:0')) 
edges shae:

number of nodes: 6796

number of edges: 73186

node features (random input): tensor([[-2.2792],
        [ 0.3149],
        [ 0.0859],
        ...,
        [ 1.6620],
        [ 0.2430],
        [ 1.1770]], device='cuda:0', requires_grad=True) 
node features sum: tensor(61.8937, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 14

In degrees of node 234: 14





 Loading data ... 


shape (2000, 6796) (2000, 6796)
sum 189931 265535
shape torch.Size([2000, 6796]) torch.Size([2000, 6796])
Model name: DGLpppipiGcnReNewestweight7N3
net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[-0.0448, -0.1491, -0.0595,  0.0446, -0.0401,  0.0605,  0.0426,  0.1269,
         -0.0034, -0.1501,  0.1312, -0.0349, -0.1485, -0.0265,  0.1002,  0.0325,
         -0.0760, -0.0581, -0.0113,  0.0060,  0.1523, -0.0247,  0.1053, -0.1519,
         -0.0089,  0.0501,  0.0808, -0.1181,  0.0271, -0.1351, -0.0804, -0.0992,
          0.0506, -0.0101,  0.0522, -0.0422, -0.0367,  0.0375, -0.1023,  0.1123,
         -0.0223,  0.1511, -0.0829, -0.1405, -0.1362,  0.1312,  0.0862,  0.0862,
         -0.1411,  0.1493,  0.0646, -0.0007,  0.0594, -0.1102, -0.1356,  0.0219,
         -0.0077,  0.1264,  0.0288, -0.1259, -0.1112, -0.0253,  0.0357,  0.0117,
         -0.0139, -0.0775,  0.1362, -0.1372,  0.0907,  0.1385,  0.1335, -0.0018,
         -0.0254,  0.0224, -0.0972, -0.0593, -0.0900,  0.1375, -0.1201,  0.0357,
         -0.1061, -0.0685, -0.0087,  0.1377,  0.0423, -0.1488,  0.0147, -0.0622,
         -0.0425,  0.0128, -0.0574, -0.0786, -0.1092,  0.1306,  0.0530, -0.0237,
          0.0680,  0.1507, -0.0160,  0.1244, -0.0675,  0.0984, -0.1274, -0.0567,
          0.0693, -0.0095,  0.1457, -0.0606, -0.1199, -0.0993,  0.0449,  0.1074,
         -0.1061, -0.0996,  0.0848,  0.0019, -0.1242, -0.0215,  0.0158, -0.1032,
          0.0464, -0.0408, -0.0205, -0.0101,  0.0616, -0.0647,  0.0053, -0.1503,
         -0.1328, -0.1249, -0.1389,  0.0386, -0.1228, -0.1417, -0.0680,  0.0276,
         -0.1484, -0.1342, -0.0866, -0.1311, -0.0988, -0.0550,  0.0545, -0.0224,
          0.0889, -0.1518, -0.1450, -0.1033,  0.0482, -0.1176, -0.0398, -0.0298,
          0.0511, -0.0870,  0.0710,  0.0722, -0.0348,  0.0614, -0.0072, -0.1222,
          0.0172, -0.1336, -0.1523,  0.0367, -0.0594,  0.1235, -0.0066,  0.1214,
         -0.0835,  0.1151, -0.0092,  0.0029, -0.0143,  0.0360,  0.0508,  0.0901,
          0.1401, -0.0615,  0.0265, -0.0660,  0.0720,  0.0628,  0.1238, -0.1341,
         -0.0858,  0.1087, -0.0922,  0.0593,  0.0577,  0.1383, -0.1264, -0.0041,
         -0.1399,  0.1412, -0.0359,  0.0400, -0.0624, -0.0926,  0.0400,  0.0775,
          0.1332,  0.1303,  0.0668,  0.0725, -0.0034,  0.0288,  0.0746,  0.1241,
          0.1257,  0.1194, -0.0756,  0.0101,  0.0647, -0.1212,  0.1148,  0.0230,
         -0.0884,  0.1330,  0.0121,  0.1436, -0.0743,  0.0984,  0.1300,  0.0129,
          0.1122,  0.0195, -0.0451,  0.0390,  0.1158, -0.0379, -0.0163,  0.1411,
         -0.1318, -0.1431,  0.0403,  0.0040,  0.0198, -0.1398,  0.1267, -0.0855,
         -0.0837, -0.0961, -0.1271,  0.0405,  0.1482,  0.1277,  0.0221, -0.0788,
         -0.0296,  0.1202,  0.0257, -0.0464, -0.1457, -0.0189,  0.0493, -0.1091]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0448, -0.1491, -0.0595,  0.0446, -0.0401,  0.0605,  0.0426,  0.1269,
         -0.0034, -0.1501,  0.1312, -0.0349, -0.1485, -0.0265,  0.1002,  0.0325,
         -0.0760, -0.0581, -0.0113,  0.0060,  0.1523, -0.0247,  0.1053, -0.1519,
         -0.0089,  0.0501,  0.0808, -0.1181,  0.0271, -0.1351, -0.0804, -0.0992,
          0.0506, -0.0101,  0.0522, -0.0422, -0.0367,  0.0375, -0.1023,  0.1123,
         -0.0223,  0.1511, -0.0829, -0.1405, -0.1362,  0.1312,  0.0862,  0.0862,
         -0.1411,  0.1493,  0.0646, -0.0007,  0.0594, -0.1102, -0.1356,  0.0219,
         -0.0077,  0.1264,  0.0288, -0.1259, -0.1112, -0.0253,  0.0357,  0.0117,
         -0.0139, -0.0775,  0.1362, -0.1372,  0.0907,  0.1385,  0.1335, -0.0018,
         -0.0254,  0.0224, -0.0972, -0.0593, -0.0900,  0.1375, -0.1201,  0.0357,
         -0.1061, -0.0685, -0.0087,  0.1377,  0.0423, -0.1488,  0.0147, -0.0622,
         -0.0425,  0.0128, -0.0574, -0.0786, -0.1092,  0.1306,  0.0530, -0.0237,
          0.0680,  0.1507, -0.0160,  0.1244, -0.0675,  0.0984, -0.1274, -0.0567,
          0.0693, -0.0095,  0.1457, -0.0606, -0.1199, -0.0993,  0.0449,  0.1074,
         -0.1061, -0.0996,  0.0848,  0.0019, -0.1242, -0.0215,  0.0158, -0.1032,
          0.0464, -0.0408, -0.0205, -0.0101,  0.0616, -0.0647,  0.0053, -0.1503,
         -0.1328, -0.1249, -0.1389,  0.0386, -0.1228, -0.1417, -0.0680,  0.0276,
         -0.1484, -0.1342, -0.0866, -0.1311, -0.0988, -0.0550,  0.0545, -0.0224,
          0.0889, -0.1518, -0.1450, -0.1033,  0.0482, -0.1176, -0.0398, -0.0298,
          0.0511, -0.0870,  0.0710,  0.0722, -0.0348,  0.0614, -0.0072, -0.1222,
          0.0172, -0.1336, -0.1523,  0.0367, -0.0594,  0.1235, -0.0066,  0.1214,
         -0.0835,  0.1151, -0.0092,  0.0029, -0.0143,  0.0360,  0.0508,  0.0901,
          0.1401, -0.0615,  0.0265, -0.0660,  0.0720,  0.0628,  0.1238, -0.1341,
         -0.0858,  0.1087, -0.0922,  0.0593,  0.0577,  0.1383, -0.1264, -0.0041,
         -0.1399,  0.1412, -0.0359,  0.0400, -0.0624, -0.0926,  0.0400,  0.0775,
          0.1332,  0.1303,  0.0668,  0.0725, -0.0034,  0.0288,  0.0746,  0.1241,
          0.1257,  0.1194, -0.0756,  0.0101,  0.0647, -0.1212,  0.1148,  0.0230,
         -0.0884,  0.1330,  0.0121,  0.1436, -0.0743,  0.0984,  0.1300,  0.0129,
          0.1122,  0.0195, -0.0451,  0.0390,  0.1158, -0.0379, -0.0163,  0.1411,
         -0.1318, -0.1431,  0.0403,  0.0040,  0.0198, -0.1398,  0.1267, -0.0855,
         -0.0837, -0.0961, -0.1271,  0.0405,  0.1482,  0.1277,  0.0221, -0.0788,
         -0.0296,  0.1202,  0.0257, -0.0464, -0.1457, -0.0189,  0.0493, -0.1091]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[-0.0589,  0.0900, -0.1221,  ...,  0.1136, -0.0800,  0.0268],
        [-0.0119,  0.1049, -0.0556,  ..., -0.1189, -0.0246,  0.0467],
        [ 0.0736,  0.0606, -0.0053,  ...,  0.1242, -0.0269, -0.0479],
        ...,
        [ 0.1110, -0.0273,  0.0603,  ..., -0.0497, -0.0788, -0.0181],
        [-0.0421, -0.0844,  0.1165,  ..., -0.0421,  0.1027, -0.0990],
        [-0.1007, -0.1009,  0.0880,  ..., -0.0241,  0.1187, -0.0868]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.0589,  0.0900, -0.1221,  ...,  0.1136, -0.0800,  0.0268],
        [-0.0119,  0.1049, -0.0556,  ..., -0.1189, -0.0246,  0.0467],
        [ 0.0736,  0.0606, -0.0053,  ...,  0.1242, -0.0269, -0.0479],
        ...,
        [ 0.1110, -0.0273,  0.0603,  ..., -0.0497, -0.0788, -0.0181],
        [-0.0421, -0.0844,  0.1165,  ..., -0.0421,  0.1027, -0.0990],
        [-0.1007, -0.1009,  0.0880,  ..., -0.0241,  0.1187, -0.0868]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[ 0.1512,  0.1174, -0.0594,  ..., -0.1739,  0.0990, -0.1266],
        [-0.0697, -0.1450,  0.0682,  ..., -0.0617,  0.1227,  0.1163],
        [-0.0450, -0.1694,  0.0782,  ...,  0.1501,  0.1367, -0.0413],
        ...,
        [-0.1364, -0.0722,  0.1079,  ...,  0.0492,  0.1738,  0.1529],
        [ 0.1226,  0.1111, -0.1175,  ...,  0.1277, -0.0705,  0.1647],
        [ 0.1690, -0.1677, -0.0967,  ..., -0.1076, -0.0513,  0.1412]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.1512,  0.1174, -0.0594,  ..., -0.1739,  0.0990, -0.1266],
        [-0.0697, -0.1450,  0.0682,  ..., -0.0617,  0.1227,  0.1163],
        [-0.0450, -0.1694,  0.0782,  ...,  0.1501,  0.1367, -0.0413],
        ...,
        [-0.1364, -0.0722,  0.1079,  ...,  0.0492,  0.1738,  0.1529],
        [ 0.1226,  0.1111, -0.1175,  ...,  0.1277, -0.0705,  0.1647],
        [ 0.1690, -0.1677, -0.0967,  ..., -0.1076, -0.0513,  0.1412]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[-0.2078, -0.1484, -0.0924,  ...,  0.0083,  0.1113,  0.1638],
        [-0.1081, -0.0465, -0.0221,  ..., -0.1975,  0.0970,  0.0170],
        [-0.0625, -0.1872,  0.1140,  ...,  0.0774,  0.1524,  0.1816],
        ...,
        [-0.1331, -0.0393,  0.0989,  ...,  0.0363,  0.1325, -0.1161],
        [ 0.1848, -0.0447, -0.2148,  ..., -0.0874,  0.0840,  0.1780],
        [-0.2409, -0.1053,  0.1188,  ..., -0.1317,  0.0512,  0.1562]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.2078, -0.1484, -0.0924,  ...,  0.0083,  0.1113,  0.1638],
        [-0.1081, -0.0465, -0.0221,  ..., -0.1975,  0.0970,  0.0170],
        [-0.0625, -0.1872,  0.1140,  ...,  0.0774,  0.1524,  0.1816],
        ...,
        [-0.1331, -0.0393,  0.0989,  ...,  0.0363,  0.1325, -0.1161],
        [ 0.1848, -0.0447, -0.2148,  ..., -0.0874,  0.0840,  0.1780],
        [-0.2409, -0.1053,  0.1188,  ..., -0.1317,  0.0512,  0.1562]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[ 0.3548],
        [ 0.3438],
        [-0.1414],
        [ 0.4038],
        [ 0.1647],
        [-0.2556],
        [ 0.0896],
        [-0.4157],
        [ 0.3158],
        [-0.2170],
        [-0.1443],
        [-0.1534],
        [-0.1916],
        [ 0.0842],
        [-0.0071],
        [ 0.1444],
        [-0.3669],
        [-0.2829],
        [ 0.2424],
        [ 0.0972],
        [ 0.1461],
        [ 0.2403],
        [-0.2807],
        [ 0.2417],
        [ 0.2454],
        [ 0.3898],
        [ 0.2519],
        [-0.4243],
        [-0.0253],
        [ 0.3958],
        [ 0.2133],
        [ 0.1813]], device='cuda:0') 
 Parameter containing:
tensor([[ 0.3548],
        [ 0.3438],
        [-0.1414],
        [ 0.4038],
        [ 0.1647],
        [-0.2556],
        [ 0.0896],
        [-0.4157],
        [ 0.3158],
        [-0.2170],
        [-0.1443],
        [-0.1534],
        [-0.1916],
        [ 0.0842],
        [-0.0071],
        [ 0.1444],
        [-0.3669],
        [-0.2829],
        [ 0.2424],
        [ 0.0972],
        [ 0.1461],
        [ 0.2403],
        [-0.2807],
        [ 0.2417],
        [ 0.2454],
        [ 0.3898],
        [ 0.2519],
        [-0.4243],
        [-0.0253],
        [ 0.3958],
        [ 0.2133],
        [ 0.1813]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
conv1.weight 
 torch.Size([1, 256]) 
 True 
 tensor([[ 0.0759, -0.1391, -0.0214,  0.0307,  0.1250,  0.0336, -0.0405, -0.1430,
         -0.0197,  0.1501, -0.0530,  0.0545,  0.1302, -0.0346,  0.0220, -0.1399,
          0.1323, -0.0356, -0.0411,  0.1468, -0.0373,  0.0402,  0.1254,  0.0026,
         -0.0020, -0.0861, -0.1079,  0.0571,  0.1253, -0.1243,  0.1085, -0.0361,
         -0.1317, -0.1359,  0.0628,  0.0047, -0.0898, -0.0085, -0.0211,  0.0337,
         -0.0345,  0.0734,  0.0304,  0.0942, -0.0455,  0.0853,  0.1482, -0.0204,
         -0.0097,  0.1302,  0.0423, -0.0784, -0.0777,  0.0967, -0.1427,  0.0887,
         -0.1079,  0.0096, -0.1387,  0.0618, -0.1227,  0.0452,  0.0869, -0.1406,
         -0.0750, -0.0060,  0.0847, -0.0156,  0.0782,  0.0844, -0.0867,  0.1414,
          0.1407,  0.1333,  0.0977, -0.0400,  0.1505, -0.0172, -0.1013, -0.1076,
          0.0865,  0.0237, -0.0780,  0.0700,  0.0953,  0.0971,  0.0842,  0.0032,
          0.1495,  0.0191, -0.0092, -0.0460,  0.1170, -0.0685, -0.0124, -0.0208,
         -0.0489, -0.0909,  0.0480,  0.0472,  0.0025,  0.0090,  0.0488,  0.1453,
         -0.0795,  0.0892, -0.0398,  0.0853,  0.1209,  0.0756,  0.0096,  0.0359,
          0.1110,  0.1347,  0.0693, -0.0070,  0.1339, -0.1407, -0.0774, -0.1413,
         -0.0346, -0.0775, -0.0275, -0.0048, -0.0435,  0.1442,  0.1357,  0.1406,
          0.1205, -0.1488, -0.0881,  0.1157, -0.0176,  0.0581, -0.0579,  0.0310,
         -0.0730,  0.0755, -0.0984, -0.0936, -0.1060, -0.0176,  0.1156, -0.0325,
          0.1299, -0.0802,  0.0711,  0.0629,  0.1095, -0.0605,  0.0938, -0.1136,
          0.0703,  0.1050,  0.1486,  0.1216,  0.1116, -0.0047,  0.0904, -0.0307,
         -0.1333, -0.1109, -0.1246,  0.0765, -0.0749,  0.0904, -0.1170,  0.1051,
         -0.1224,  0.0350,  0.0693,  0.0259, -0.0812,  0.0359,  0.0211,  0.0156,
         -0.0526,  0.0545, -0.0510,  0.0850, -0.1078, -0.0996,  0.1177, -0.0312,
          0.0532, -0.0186,  0.1223,  0.1246, -0.1277, -0.1052, -0.0162,  0.0399,
          0.0211, -0.0203, -0.1158, -0.1465, -0.0754, -0.1476,  0.0419, -0.1275,
         -0.0483,  0.1019,  0.1042,  0.0588, -0.1507, -0.0069, -0.0030,  0.1098,
          0.0791, -0.1115, -0.0783,  0.0200, -0.0532,  0.1415,  0.1125,  0.1147,
         -0.0943,  0.1467, -0.0356,  0.1348,  0.1468, -0.0105,  0.1456,  0.1401,
         -0.0578,  0.0313, -0.0766, -0.0491, -0.1226, -0.0064, -0.0054, -0.0872,
          0.1350, -0.0059, -0.1435, -0.0550, -0.1489, -0.0201,  0.0886, -0.0315,
          0.0411,  0.0293,  0.0931, -0.0408,  0.1524,  0.1381, -0.1278,  0.0558,
         -0.0678, -0.0855, -0.1007,  0.0206, -0.0098,  0.0292,  0.0774,  0.1526]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0759, -0.1391, -0.0214,  0.0307,  0.1250,  0.0336, -0.0405, -0.1430,
         -0.0197,  0.1501, -0.0530,  0.0545,  0.1302, -0.0346,  0.0220, -0.1399,
          0.1323, -0.0356, -0.0411,  0.1468, -0.0373,  0.0402,  0.1254,  0.0026,
         -0.0020, -0.0861, -0.1079,  0.0571,  0.1253, -0.1243,  0.1085, -0.0361,
         -0.1317, -0.1359,  0.0628,  0.0047, -0.0898, -0.0085, -0.0211,  0.0337,
         -0.0345,  0.0734,  0.0304,  0.0942, -0.0455,  0.0853,  0.1482, -0.0204,
         -0.0097,  0.1302,  0.0423, -0.0784, -0.0777,  0.0967, -0.1427,  0.0887,
         -0.1079,  0.0096, -0.1387,  0.0618, -0.1227,  0.0452,  0.0869, -0.1406,
         -0.0750, -0.0060,  0.0847, -0.0156,  0.0782,  0.0844, -0.0867,  0.1414,
          0.1407,  0.1333,  0.0977, -0.0400,  0.1505, -0.0172, -0.1013, -0.1076,
          0.0865,  0.0237, -0.0780,  0.0700,  0.0953,  0.0971,  0.0842,  0.0032,
          0.1495,  0.0191, -0.0092, -0.0460,  0.1170, -0.0685, -0.0124, -0.0208,
         -0.0489, -0.0909,  0.0480,  0.0472,  0.0025,  0.0090,  0.0488,  0.1453,
         -0.0795,  0.0892, -0.0398,  0.0853,  0.1209,  0.0756,  0.0096,  0.0359,
          0.1110,  0.1347,  0.0693, -0.0070,  0.1339, -0.1407, -0.0774, -0.1413,
         -0.0346, -0.0775, -0.0275, -0.0048, -0.0435,  0.1442,  0.1357,  0.1406,
          0.1205, -0.1488, -0.0881,  0.1157, -0.0176,  0.0581, -0.0579,  0.0310,
         -0.0730,  0.0755, -0.0984, -0.0936, -0.1060, -0.0176,  0.1156, -0.0325,
          0.1299, -0.0802,  0.0711,  0.0629,  0.1095, -0.0605,  0.0938, -0.1136,
          0.0703,  0.1050,  0.1486,  0.1216,  0.1116, -0.0047,  0.0904, -0.0307,
         -0.1333, -0.1109, -0.1246,  0.0765, -0.0749,  0.0904, -0.1170,  0.1051,
         -0.1224,  0.0350,  0.0693,  0.0259, -0.0812,  0.0359,  0.0211,  0.0156,
         -0.0526,  0.0545, -0.0510,  0.0850, -0.1078, -0.0996,  0.1177, -0.0312,
          0.0532, -0.0186,  0.1223,  0.1246, -0.1277, -0.1052, -0.0162,  0.0399,
          0.0211, -0.0203, -0.1158, -0.1465, -0.0754, -0.1476,  0.0419, -0.1275,
         -0.0483,  0.1019,  0.1042,  0.0588, -0.1507, -0.0069, -0.0030,  0.1098,
          0.0791, -0.1115, -0.0783,  0.0200, -0.0532,  0.1415,  0.1125,  0.1147,
         -0.0943,  0.1467, -0.0356,  0.1348,  0.1468, -0.0105,  0.1456,  0.1401,
         -0.0578,  0.0313, -0.0766, -0.0491, -0.1226, -0.0064, -0.0054, -0.0872,
          0.1350, -0.0059, -0.1435, -0.0550, -0.1489, -0.0201,  0.0886, -0.0315,
          0.0411,  0.0293,  0.0931, -0.0408,  0.1524,  0.1381, -0.1278,  0.0558,
         -0.0678, -0.0855, -0.1007,  0.0206, -0.0098,  0.0292,  0.0774,  0.1526]],
       device='cuda:0', requires_grad=True)
conv1.bias 
 torch.Size([256]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv2.weight 
 torch.Size([256, 128]) 
 True 
 tensor([[ 0.0687,  0.0019,  0.0056,  ...,  0.0400, -0.1220,  0.0284],
        [-0.0292,  0.0452,  0.0986,  ..., -0.0826,  0.1131, -0.0914],
        [ 0.0557, -0.0686,  0.1109,  ..., -0.1152,  0.0478, -0.0695],
        ...,
        [-0.0048, -0.0320,  0.0194,  ...,  0.1232, -0.0500,  0.1000],
        [-0.0758,  0.0274,  0.0624,  ..., -0.1167, -0.0931, -0.0619],
        [ 0.0080, -0.0066, -0.1148,  ..., -0.0894, -0.0310, -0.0490]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0687,  0.0019,  0.0056,  ...,  0.0400, -0.1220,  0.0284],
        [-0.0292,  0.0452,  0.0986,  ..., -0.0826,  0.1131, -0.0914],
        [ 0.0557, -0.0686,  0.1109,  ..., -0.1152,  0.0478, -0.0695],
        ...,
        [-0.0048, -0.0320,  0.0194,  ...,  0.1232, -0.0500,  0.1000],
        [-0.0758,  0.0274,  0.0624,  ..., -0.1167, -0.0931, -0.0619],
        [ 0.0080, -0.0066, -0.1148,  ..., -0.0894, -0.0310, -0.0490]],
       device='cuda:0', requires_grad=True)
conv2.bias 
 torch.Size([128]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv3.weight 
 torch.Size([128, 64]) 
 True 
 tensor([[-0.1698,  0.1416,  0.0228,  ..., -0.0507, -0.0543,  0.1298],
        [ 0.0858, -0.0794,  0.0519,  ..., -0.1274, -0.1750, -0.1454],
        [ 0.1436,  0.0799, -0.0222,  ...,  0.0531, -0.1502, -0.1250],
        ...,
        [ 0.1546, -0.0886,  0.0410,  ..., -0.1440, -0.0041,  0.1577],
        [-0.0948,  0.1258, -0.0637,  ...,  0.0322,  0.1724, -0.1265],
        [-0.0234, -0.0225,  0.1201,  ..., -0.1703,  0.0083,  0.1485]],
       device='cuda:0') 
 Parameter containing:
tensor([[-0.1698,  0.1416,  0.0228,  ..., -0.0507, -0.0543,  0.1298],
        [ 0.0858, -0.0794,  0.0519,  ..., -0.1274, -0.1750, -0.1454],
        [ 0.1436,  0.0799, -0.0222,  ...,  0.0531, -0.1502, -0.1250],
        ...,
        [ 0.1546, -0.0886,  0.0410,  ..., -0.1440, -0.0041,  0.1577],
        [-0.0948,  0.1258, -0.0637,  ...,  0.0322,  0.1724, -0.1265],
        [-0.0234, -0.0225,  0.1201,  ..., -0.1703,  0.0083,  0.1485]],
       device='cuda:0', requires_grad=True)
conv3.bias 
 torch.Size([64]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)
conv4.weight 
 torch.Size([64, 32]) 
 True 
 tensor([[ 0.0359,  0.1258, -0.1647,  ...,  0.2252,  0.0045,  0.2469],
        [ 0.2085,  0.0538,  0.1771,  ..., -0.1319,  0.0277,  0.0910],
        [-0.2132, -0.1890, -0.0976,  ...,  0.1360, -0.0151, -0.2490],
        ...,
        [ 0.1737, -0.0243,  0.0344,  ..., -0.2449,  0.2490,  0.0758],
        [ 0.0962,  0.0090,  0.0236,  ...,  0.2001,  0.2365,  0.0535],
        [ 0.0735,  0.1947, -0.1346,  ..., -0.0477, -0.1975,  0.1914]],
       device='cuda:0') 
 Parameter containing:
tensor([[ 0.0359,  0.1258, -0.1647,  ...,  0.2252,  0.0045,  0.2469],
        [ 0.2085,  0.0538,  0.1771,  ..., -0.1319,  0.0277,  0.0910],
        [-0.2132, -0.1890, -0.0976,  ...,  0.1360, -0.0151, -0.2490],
        ...,
        [ 0.1737, -0.0243,  0.0344,  ..., -0.2449,  0.2490,  0.0758],
        [ 0.0962,  0.0090,  0.0236,  ...,  0.2001,  0.2365,  0.0535],
        [ 0.0735,  0.1947, -0.1346,  ..., -0.0477, -0.1975,  0.1914]],
       device='cuda:0', requires_grad=True)
conv4.bias 
 torch.Size([32]) 
 True 
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)
conv5.weight 
 torch.Size([32, 1]) 
 True 
 tensor([[-0.2838],
        [-0.2710],
        [-0.1366],
        [ 0.2826],
        [-0.1525],
        [-0.3283],
        [-0.0499],
        [ 0.0403],
        [-0.4004],
        [-0.2181],
        [ 0.2254],
        [ 0.3810],
        [-0.3667],
        [-0.3107],
        [-0.2924],
        [-0.3163],
        [-0.1451],
        [ 0.0319],
        [ 0.0815],
        [-0.0668],
        [ 0.0647],
        [ 0.2803],
        [-0.2827],
        [ 0.2013],
        [ 0.1766],
        [-0.2050],
        [ 0.1581],
        [ 0.3750],
        [-0.2752],
        [-0.3448],
        [-0.2981],
        [-0.1504]], device='cuda:0') 
 Parameter containing:
tensor([[-0.2838],
        [-0.2710],
        [-0.1366],
        [ 0.2826],
        [-0.1525],
        [-0.3283],
        [-0.0499],
        [ 0.0403],
        [-0.4004],
        [-0.2181],
        [ 0.2254],
        [ 0.3810],
        [-0.3667],
        [-0.3107],
        [-0.2924],
        [-0.3163],
        [-0.1451],
        [ 0.0319],
        [ 0.0815],
        [-0.0668],
        [ 0.0647],
        [ 0.2803],
        [-0.2827],
        [ 0.2013],
        [ 0.1766],
        [-0.2050],
        [ 0.1581],
        [ 0.3750],
        [-0.2752],
        [-0.3448],
        [-0.2981],
        [-0.1504]], device='cuda:0', requires_grad=True)
conv5.bias 
 torch.Size([1]) 
 True 
 tensor([0.], device='cuda:0') 
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.0000],
        [0.0000],
        [0.2988],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(173.1525, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.0000],
        [0.0000],
        [0.2988],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].sum tensor(173.1525, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[ 7.0796e-03, -4.6246e-03, -5.0429e-03,  ...,  2.7196e-03,
         -8.8336e-03,  9.0844e-05],
        [ 2.3442e-02, -1.5313e-02, -1.6699e-02,  ...,  9.0054e-03,
         -2.9251e-02,  3.0081e-04],
        [ 1.5550e-02, -1.0158e-02, -1.1076e-02,  ...,  5.9734e-03,
         -1.9402e-02,  1.9953e-04],
        ...,
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,
          0.0000e+00,  0.0000e+00]], device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-308.4146, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(19.6485, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(20.4133, device='cuda:0')



h[100].sum tensor(-6.7924, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-7.0567, device='cuda:0')



h[200].sum tensor(-14.6953, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-15.2673, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0538, 0.0000, 0.0000,  ..., 0.0207, 0.0000, 0.0007],
        [0.0474, 0.0000, 0.0000,  ..., 0.0182, 0.0000, 0.0006],
        [0.0651, 0.0000, 0.0000,  ..., 0.0250, 0.0000, 0.0008],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(18647.1680, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0990, 0.1223, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0971, 0.1200, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0976, 0.1205, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(117769.5938, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(1591.6885, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(101.5474, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-101.0983, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-295.5370, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=73186,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.0522],
        [0.0503],
        [0.0452],
        ...,
        [0.0004],
        [0.0004],
        [0.0004]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(2685.6191, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([73186, 1]) 
g.edata[efet].sum tensor(73186., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 20 from the network before training 
result1: tensor([[0.0522],
        [0.0503],
        [0.0452],
        ...,
        [0.0004],
        [0.0004],
        [0.0004]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0.     0.     0.2988 ... 0.     0.     0.    ]



input node feature: 
g.ndata[nfet] tensor([[0.5166],
        [0.0000],
        [0.0000],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet].sum tensor(273.5499, device='cuda:0')



input graph: 
g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([13592, 1]) 
g.ndata[nfet] tensor([[0.5166],
        [0.0000],
        [0.0000],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].sum tensor(273.5499, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[ 0.0065, -0.0030, -0.0004,  ..., -0.0073,  0.0118, -0.0111],
        [ 0.0145, -0.0067, -0.0008,  ..., -0.0163,  0.0263, -0.0247],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(-242.5426, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(16.5162, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(16.8684, device='cuda:0')



h[100].sum tensor(-28.9287, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-29.5456, device='cuda:0')



h[200].sum tensor(-16.4066, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-16.7565, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0579, 0.0000, 0.0000,  ..., 0.0000, 0.1050, 0.0000],
        [0.0291, 0.0000, 0.0000,  ..., 0.0000, 0.0528, 0.0000],
        [0.0327, 0.0000, 0.0000,  ..., 0.0000, 0.0594, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([13592, 256]) 
h.sum tensor(27108.9043, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.1991,  ..., 0.0000, 0.0888, 0.0000],
        [0.0000, 0.0000, 0.1520,  ..., 0.0000, 0.0678, 0.0000],
        [0.0000, 0.0000, 0.1400,  ..., 0.0000, 0.0624, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([13592, 128]) 
h2.sum tensor(147773.9531, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-215.9801, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-460.3464, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(1531.3052, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(105.4896, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=13592, num_edges=146372,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[1.3190e+00],
        [1.1408e+00],
        [9.9524e-01],
        ...,
        [1.6184e-05],
        [2.6907e-05],
        [3.8463e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([13592, 1]) 
h5.sum tensor(28439.4062, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([146372, 1]) 
g.edata[efet].sum tensor(146372., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[0.0522],
        [0.0503],
        [0.0452],
        ...,
        [0.0004],
        [0.0004],
        [0.0004]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: [0.     0.     0.2988 ... 0.     0.     0.    ]



load_model False 
TraEvN 3001 
BatchSize 30 
EpochNum 60 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 
startmesh 284 
endmesh 285 






optimizer.param_groups [{'params': [Parameter containing:
tensor([[ 7.9210e-02,  8.5339e-02, -7.5192e-03, -5.5734e-02, -7.7393e-02,
          5.7967e-02,  8.3265e-02, -1.2049e-01, -7.1654e-02, -1.2036e-02,
          1.5126e-01,  1.1023e-01, -1.4481e-01,  9.4421e-03, -2.8893e-02,
          5.7062e-02, -2.6251e-02, -1.2934e-01, -1.8562e-02, -1.1155e-01,
          5.0560e-02,  4.3384e-02,  1.0998e-02, -1.4198e-01,  1.3841e-01,
         -6.8480e-02, -4.8048e-02, -1.2662e-01, -1.4964e-01, -3.4455e-02,
          4.5086e-02,  1.1847e-01, -6.7907e-02,  3.9262e-02, -8.5269e-02,
          1.3602e-01,  8.7272e-02,  8.8757e-03,  4.2025e-02, -1.3282e-02,
          1.1391e-01, -1.7862e-02, -3.6621e-02,  1.2616e-02, -8.1277e-02,
          7.3720e-02,  6.5683e-02, -3.6623e-02, -8.2103e-02, -2.0833e-02,
          7.5098e-02,  7.6411e-02, -4.0172e-02,  7.2491e-02, -1.0611e-02,
         -1.4090e-01, -1.0910e-01,  1.5218e-01, -4.9781e-03, -4.4408e-02,
         -7.5246e-02, -9.7927e-02,  3.6430e-02,  1.1715e-01, -5.2528e-02,
         -1.3614e-01, -7.7574e-02,  9.0521e-02,  3.1971e-02, -3.1280e-02,
         -1.3293e-02,  6.9342e-02, -1.3720e-01, -9.2983e-02,  6.5076e-02,
         -6.2484e-02, -1.0382e-04,  1.6793e-02, -2.9041e-02,  5.3861e-02,
         -1.9526e-02, -1.4339e-01, -1.4533e-01, -1.4134e-01, -3.0746e-02,
          1.2862e-01,  7.2254e-02, -2.0209e-02,  8.3854e-02, -7.4271e-02,
         -9.1149e-02, -8.0865e-03,  4.2356e-02,  1.2749e-01, -3.2289e-03,
         -9.6283e-03,  2.9487e-02,  1.1934e-01, -1.3391e-01,  1.3334e-01,
         -6.0436e-02, -2.5046e-03, -8.9882e-03,  2.5881e-02,  6.7201e-02,
         -1.0108e-01,  7.1497e-02, -7.8256e-02,  6.1796e-02, -1.0294e-01,
         -2.2233e-02,  4.0628e-02,  5.7783e-02, -9.1344e-03, -1.2794e-01,
         -9.6776e-02, -2.1463e-02, -2.3630e-02, -1.0431e-01,  9.6941e-02,
         -3.6354e-03, -3.1423e-02,  1.2098e-01,  1.5467e-02, -4.4615e-02,
         -1.9975e-02, -1.1178e-01, -1.5180e-01,  3.3407e-02,  2.2387e-02,
          3.8492e-02, -2.0640e-02, -3.7559e-02,  3.9787e-02, -7.2610e-02,
         -3.3306e-02, -3.0139e-02, -8.8803e-02,  9.2340e-02, -4.1053e-03,
          5.0970e-02,  1.3662e-01, -5.3162e-02, -4.0612e-02, -1.1003e-01,
         -1.1785e-01, -1.3152e-01,  6.4211e-03,  5.9456e-02,  1.2073e-01,
          9.1351e-03, -3.4901e-02,  5.1211e-02,  1.1827e-01,  9.7311e-02,
          1.4139e-01,  1.1228e-01,  1.1282e-01,  3.1938e-02,  3.3314e-02,
          1.2261e-01,  6.8933e-02, -1.1510e-01, -1.4541e-01,  8.6561e-02,
          4.9197e-02, -1.1283e-01,  1.3685e-01, -3.6270e-02, -3.8328e-02,
          7.5050e-02, -5.2200e-02,  5.6043e-02,  1.4844e-01, -3.3412e-02,
         -2.8401e-03,  6.7230e-02, -3.6108e-02,  5.3740e-02,  1.4804e-01,
          4.6958e-02, -1.3059e-01,  1.2341e-01,  9.8455e-02, -1.3843e-02,
         -1.3528e-02,  5.1615e-02, -9.9667e-02, -5.0565e-02, -1.2179e-01,
         -2.4923e-03, -1.4966e-01,  8.8828e-03,  1.4614e-01, -4.5185e-02,
          1.0772e-01, -5.5841e-03,  8.2059e-02, -8.6044e-02,  5.1226e-02,
          3.1941e-02, -6.6045e-02, -8.2783e-03, -1.1672e-01, -7.6482e-02,
         -7.0383e-02,  2.4937e-02, -8.3994e-02, -3.4964e-02,  3.3811e-03,
         -7.1848e-02,  1.9970e-02, -8.7555e-02, -7.0610e-02,  1.4715e-01,
          4.7783e-02, -1.3421e-01,  9.1073e-02, -3.4613e-02, -1.0770e-01,
          1.0907e-02, -2.1010e-02, -1.4233e-01, -5.3060e-02,  4.6826e-02,
          1.2303e-02,  5.8991e-02,  6.5428e-02,  9.4892e-02, -1.5268e-01,
          1.0011e-01, -9.0377e-02, -5.3515e-02,  1.4322e-02,  1.1798e-01,
         -1.4905e-01, -1.0934e-01, -1.5035e-02, -1.4834e-01,  1.5079e-01,
         -1.4886e-01, -1.3412e-01,  9.1298e-02, -1.3596e-01, -6.9484e-02,
          1.4495e-01,  6.4226e-02,  1.4112e-01, -3.9029e-02, -1.4379e-01,
         -1.1940e-01,  1.7564e-02, -7.7345e-03, -6.0576e-02,  1.0863e-02,
          1.1716e-01]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0799, -0.0572,  0.0721,  ...,  0.0244, -0.1010, -0.1149],
        [-0.0354,  0.1196,  0.0802,  ..., -0.0509,  0.0838,  0.0309],
        [ 0.0367,  0.0974, -0.1187,  ...,  0.0738, -0.1235, -0.0523],
        ...,
        [-0.1104, -0.0517,  0.0728,  ..., -0.0705,  0.0241, -0.0863],
        [ 0.1082, -0.0280,  0.1184,  ..., -0.0859, -0.0114,  0.0866],
        [ 0.0473,  0.0338,  0.0251,  ...,  0.0985,  0.1210, -0.0670]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1762,  0.1143,  0.0661,  ..., -0.1621, -0.1666, -0.1030],
        [ 0.1398,  0.0372,  0.0962,  ..., -0.0039, -0.0211,  0.0549],
        [ 0.0237, -0.0125,  0.1409,  ...,  0.1640,  0.0741,  0.0347],
        ...,
        [ 0.0384, -0.0325, -0.0935,  ..., -0.1442, -0.0410, -0.1181],
        [-0.0274, -0.1340,  0.1191,  ...,  0.0889,  0.1592,  0.0290],
        [ 0.1168,  0.1046, -0.1727,  ...,  0.0562, -0.1346,  0.1336]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0462, -0.0547, -0.1428,  ..., -0.2500, -0.2094,  0.2415],
        [-0.0503, -0.0815,  0.1840,  ..., -0.0365,  0.1957,  0.1044],
        [-0.2066,  0.1402,  0.1794,  ..., -0.1797, -0.2287,  0.0622],
        ...,
        [ 0.0345, -0.0026, -0.0538,  ..., -0.2478,  0.1890,  0.1995],
        [ 0.2413, -0.2012, -0.1282,  ..., -0.0747,  0.1555,  0.1278],
        [ 0.2310,  0.0925,  0.0436,  ...,  0.0404,  0.0761,  0.0576]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0133],
        [ 0.0373],
        [-0.1271],
        [-0.2663],
        [ 0.2779],
        [ 0.3379],
        [ 0.1982],
        [ 0.0113],
        [ 0.0346],
        [ 0.4093],
        [-0.2058],
        [ 0.0192],
        [ 0.0650],
        [ 0.0319],
        [ 0.1723],
        [-0.1452],
        [ 0.4027],
        [-0.0016],
        [-0.3058],
        [-0.2606],
        [-0.3258],
        [-0.3861],
        [-0.2629],
        [ 0.0497],
        [ 0.0923],
        [ 0.0063],
        [ 0.0546],
        [-0.3064],
        [ 0.3501],
        [-0.0601],
        [ 0.3896],
        [ 0.4051]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]



optimizer.param_groups [{'params': [Parameter containing:
tensor([[ 7.9210e-02,  8.5339e-02, -7.5192e-03, -5.5734e-02, -7.7393e-02,
          5.7967e-02,  8.3265e-02, -1.2049e-01, -7.1654e-02, -1.2036e-02,
          1.5126e-01,  1.1023e-01, -1.4481e-01,  9.4421e-03, -2.8893e-02,
          5.7062e-02, -2.6251e-02, -1.2934e-01, -1.8562e-02, -1.1155e-01,
          5.0560e-02,  4.3384e-02,  1.0998e-02, -1.4198e-01,  1.3841e-01,
         -6.8480e-02, -4.8048e-02, -1.2662e-01, -1.4964e-01, -3.4455e-02,
          4.5086e-02,  1.1847e-01, -6.7907e-02,  3.9262e-02, -8.5269e-02,
          1.3602e-01,  8.7272e-02,  8.8757e-03,  4.2025e-02, -1.3282e-02,
          1.1391e-01, -1.7862e-02, -3.6621e-02,  1.2616e-02, -8.1277e-02,
          7.3720e-02,  6.5683e-02, -3.6623e-02, -8.2103e-02, -2.0833e-02,
          7.5098e-02,  7.6411e-02, -4.0172e-02,  7.2491e-02, -1.0611e-02,
         -1.4090e-01, -1.0910e-01,  1.5218e-01, -4.9781e-03, -4.4408e-02,
         -7.5246e-02, -9.7927e-02,  3.6430e-02,  1.1715e-01, -5.2528e-02,
         -1.3614e-01, -7.7574e-02,  9.0521e-02,  3.1971e-02, -3.1280e-02,
         -1.3293e-02,  6.9342e-02, -1.3720e-01, -9.2983e-02,  6.5076e-02,
         -6.2484e-02, -1.0382e-04,  1.6793e-02, -2.9041e-02,  5.3861e-02,
         -1.9526e-02, -1.4339e-01, -1.4533e-01, -1.4134e-01, -3.0746e-02,
          1.2862e-01,  7.2254e-02, -2.0209e-02,  8.3854e-02, -7.4271e-02,
         -9.1149e-02, -8.0865e-03,  4.2356e-02,  1.2749e-01, -3.2289e-03,
         -9.6283e-03,  2.9487e-02,  1.1934e-01, -1.3391e-01,  1.3334e-01,
         -6.0436e-02, -2.5046e-03, -8.9882e-03,  2.5881e-02,  6.7201e-02,
         -1.0108e-01,  7.1497e-02, -7.8256e-02,  6.1796e-02, -1.0294e-01,
         -2.2233e-02,  4.0628e-02,  5.7783e-02, -9.1344e-03, -1.2794e-01,
         -9.6776e-02, -2.1463e-02, -2.3630e-02, -1.0431e-01,  9.6941e-02,
         -3.6354e-03, -3.1423e-02,  1.2098e-01,  1.5467e-02, -4.4615e-02,
         -1.9975e-02, -1.1178e-01, -1.5180e-01,  3.3407e-02,  2.2387e-02,
          3.8492e-02, -2.0640e-02, -3.7559e-02,  3.9787e-02, -7.2610e-02,
         -3.3306e-02, -3.0139e-02, -8.8803e-02,  9.2340e-02, -4.1053e-03,
          5.0970e-02,  1.3662e-01, -5.3162e-02, -4.0612e-02, -1.1003e-01,
         -1.1785e-01, -1.3152e-01,  6.4211e-03,  5.9456e-02,  1.2073e-01,
          9.1351e-03, -3.4901e-02,  5.1211e-02,  1.1827e-01,  9.7311e-02,
          1.4139e-01,  1.1228e-01,  1.1282e-01,  3.1938e-02,  3.3314e-02,
          1.2261e-01,  6.8933e-02, -1.1510e-01, -1.4541e-01,  8.6561e-02,
          4.9197e-02, -1.1283e-01,  1.3685e-01, -3.6270e-02, -3.8328e-02,
          7.5050e-02, -5.2200e-02,  5.6043e-02,  1.4844e-01, -3.3412e-02,
         -2.8401e-03,  6.7230e-02, -3.6108e-02,  5.3740e-02,  1.4804e-01,
          4.6958e-02, -1.3059e-01,  1.2341e-01,  9.8455e-02, -1.3843e-02,
         -1.3528e-02,  5.1615e-02, -9.9667e-02, -5.0565e-02, -1.2179e-01,
         -2.4923e-03, -1.4966e-01,  8.8828e-03,  1.4614e-01, -4.5185e-02,
          1.0772e-01, -5.5841e-03,  8.2059e-02, -8.6044e-02,  5.1226e-02,
          3.1941e-02, -6.6045e-02, -8.2783e-03, -1.1672e-01, -7.6482e-02,
         -7.0383e-02,  2.4937e-02, -8.3994e-02, -3.4964e-02,  3.3811e-03,
         -7.1848e-02,  1.9970e-02, -8.7555e-02, -7.0610e-02,  1.4715e-01,
          4.7783e-02, -1.3421e-01,  9.1073e-02, -3.4613e-02, -1.0770e-01,
          1.0907e-02, -2.1010e-02, -1.4233e-01, -5.3060e-02,  4.6826e-02,
          1.2303e-02,  5.8991e-02,  6.5428e-02,  9.4892e-02, -1.5268e-01,
          1.0011e-01, -9.0377e-02, -5.3515e-02,  1.4322e-02,  1.1798e-01,
         -1.4905e-01, -1.0934e-01, -1.5035e-02, -1.4834e-01,  1.5079e-01,
         -1.4886e-01, -1.3412e-01,  9.1298e-02, -1.3596e-01, -6.9484e-02,
          1.4495e-01,  6.4226e-02,  1.4112e-01, -3.9029e-02, -1.4379e-01,
         -1.1940e-01,  1.7564e-02, -7.7345e-03, -6.0576e-02,  1.0863e-02,
          1.1716e-01]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0799, -0.0572,  0.0721,  ...,  0.0244, -0.1010, -0.1149],
        [-0.0354,  0.1196,  0.0802,  ..., -0.0509,  0.0838,  0.0309],
        [ 0.0367,  0.0974, -0.1187,  ...,  0.0738, -0.1235, -0.0523],
        ...,
        [-0.1104, -0.0517,  0.0728,  ..., -0.0705,  0.0241, -0.0863],
        [ 0.1082, -0.0280,  0.1184,  ..., -0.0859, -0.0114,  0.0866],
        [ 0.0473,  0.0338,  0.0251,  ...,  0.0985,  0.1210, -0.0670]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1762,  0.1143,  0.0661,  ..., -0.1621, -0.1666, -0.1030],
        [ 0.1398,  0.0372,  0.0962,  ..., -0.0039, -0.0211,  0.0549],
        [ 0.0237, -0.0125,  0.1409,  ...,  0.1640,  0.0741,  0.0347],
        ...,
        [ 0.0384, -0.0325, -0.0935,  ..., -0.1442, -0.0410, -0.1181],
        [-0.0274, -0.1340,  0.1191,  ...,  0.0889,  0.1592,  0.0290],
        [ 0.1168,  0.1046, -0.1727,  ...,  0.0562, -0.1346,  0.1336]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0462, -0.0547, -0.1428,  ..., -0.2500, -0.2094,  0.2415],
        [-0.0503, -0.0815,  0.1840,  ..., -0.0365,  0.1957,  0.1044],
        [-0.2066,  0.1402,  0.1794,  ..., -0.1797, -0.2287,  0.0622],
        ...,
        [ 0.0345, -0.0026, -0.0538,  ..., -0.2478,  0.1890,  0.1995],
        [ 0.2413, -0.2012, -0.1282,  ..., -0.0747,  0.1555,  0.1278],
        [ 0.2310,  0.0925,  0.0436,  ...,  0.0404,  0.0761,  0.0576]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0133],
        [ 0.0373],
        [-0.1271],
        [-0.2663],
        [ 0.2779],
        [ 0.3379],
        [ 0.1982],
        [ 0.0113],
        [ 0.0346],
        [ 0.4093],
        [-0.2058],
        [ 0.0192],
        [ 0.0650],
        [ 0.0319],
        [ 0.1723],
        [-0.1452],
        [ 0.4027],
        [-0.0016],
        [-0.3058],
        [-0.2606],
        [-0.3258],
        [-0.3861],
        [-0.2629],
        [ 0.0497],
        [ 0.0923],
        [ 0.0063],
        [ 0.0546],
        [-0.3064],
        [ 0.3501],
        [-0.0601],
        [ 0.3896],
        [ 0.4051]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}, {'params': [tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLpppipiGcnReNewestweight7N3/./Training.py", line 78, in <module>
    featbatch = TraTen[i : i + BatchSize].reshape(BatchSize * 6796, 1)
RuntimeError: shape '[203880, 1]' is invalid for input of size 0

real	0m33.865s
user	0m8.090s
sys	0m3.703s
