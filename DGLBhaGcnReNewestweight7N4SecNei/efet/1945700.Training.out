0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.80.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.80.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        9B:9E:55:A9:86:D9:50:0B:6D:2D:9F:BA:A7:E6:45:39:D4:DD:5F:C6
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Jan  9 17:13:15 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   27C    P0    33W / 250W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.358472704

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2afce91dc880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m23.516s
user	0m3.555s
sys	0m3.037s




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[ 0.6966],
        [ 1.3198],
        [ 1.1981],
        ...,
        [-0.2404],
        [ 0.2307],
        [ 0.2058]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-42.0497, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (linear1): Linear(in_features=2350554, out_features=32, bias=True)
  (linear2): Linear(in_features=32, out_features=2350554, bias=True)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 152829819

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-0.1203, -0.1334, -0.1372, -0.0171,  0.1186, -0.0259,  0.1325,  0.0404,
         -0.1453,  0.0367, -0.1126,  0.1417,  0.1458, -0.1145, -0.0231,  0.1454,
          0.1021,  0.0141, -0.1503, -0.0314,  0.0004, -0.0055, -0.0054,  0.1305,
          0.1223,  0.0867, -0.0614, -0.0591, -0.0130,  0.0336, -0.0061,  0.0030,
          0.0307,  0.1055, -0.0357,  0.0055, -0.1137, -0.0521, -0.0759, -0.0458,
          0.0406, -0.1511, -0.1510,  0.0455,  0.1325, -0.1323, -0.0569,  0.0378,
         -0.1128, -0.1331,  0.0360,  0.0399, -0.1297, -0.0933, -0.1005,  0.0630,
         -0.0051, -0.0035,  0.0582, -0.0962, -0.0674, -0.0656, -0.1223,  0.0715,
          0.0818,  0.0753,  0.1511,  0.1287,  0.0101, -0.1330,  0.0186,  0.0905,
          0.1241, -0.0414, -0.1312, -0.1382, -0.1089,  0.1407,  0.1128, -0.1041,
         -0.1030, -0.1019, -0.0823,  0.0011,  0.1320, -0.0554,  0.1341, -0.0284,
          0.1273,  0.0830,  0.0687,  0.0044,  0.0112, -0.1389,  0.1519, -0.0799,
         -0.0297, -0.1395,  0.1453, -0.1189, -0.0559, -0.0159,  0.0457,  0.0715,
          0.1413, -0.1128,  0.0090,  0.0306,  0.1375,  0.0901,  0.1023, -0.0657,
         -0.0228,  0.1430, -0.0176, -0.0472,  0.1018,  0.0171, -0.0124,  0.1350,
         -0.0915, -0.0435,  0.0271, -0.0547, -0.0316, -0.1489, -0.0868,  0.0600,
          0.0580,  0.0470,  0.0037, -0.1396, -0.0242,  0.0988, -0.0846, -0.0619,
          0.0244, -0.1081,  0.0448, -0.1160, -0.0348, -0.0535, -0.0038,  0.0544,
          0.1335, -0.0132, -0.0682, -0.1052,  0.0827,  0.1274,  0.0842, -0.0922,
          0.0771, -0.0734, -0.0927,  0.0052,  0.0714, -0.0793,  0.0831,  0.0207,
         -0.0441,  0.1143,  0.1391, -0.0720,  0.1291,  0.0342,  0.1144,  0.0358,
          0.0283, -0.1050,  0.0428, -0.0358, -0.1302, -0.0786,  0.0457, -0.1287,
         -0.1000, -0.0281,  0.1208,  0.0466,  0.0411,  0.0097, -0.0108, -0.0272,
         -0.0786,  0.1000,  0.1515, -0.0696,  0.0237, -0.0571, -0.0177,  0.0383,
         -0.0550,  0.0458, -0.0626,  0.0778,  0.0174, -0.0387, -0.0601,  0.1374,
         -0.1381, -0.1428,  0.1080, -0.0692,  0.0804, -0.0728, -0.0836, -0.1080,
         -0.0153, -0.0436,  0.0569, -0.0437, -0.1295, -0.1458, -0.0905,  0.0204,
         -0.0280, -0.0148, -0.0808,  0.0229,  0.0570, -0.1126,  0.0095,  0.0606,
          0.0923, -0.1288, -0.0283, -0.1451,  0.1434,  0.1203, -0.1474,  0.1267,
          0.1453, -0.0823, -0.0402,  0.0311,  0.1014,  0.0253, -0.1184, -0.0556,
          0.1404, -0.0304,  0.1093, -0.1088, -0.0237,  0.0885, -0.0927, -0.0670,
          0.1277,  0.0575,  0.0256,  0.0065,  0.0159,  0.0738, -0.0163, -0.0593]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1203, -0.1334, -0.1372, -0.0171,  0.1186, -0.0259,  0.1325,  0.0404,
         -0.1453,  0.0367, -0.1126,  0.1417,  0.1458, -0.1145, -0.0231,  0.1454,
          0.1021,  0.0141, -0.1503, -0.0314,  0.0004, -0.0055, -0.0054,  0.1305,
          0.1223,  0.0867, -0.0614, -0.0591, -0.0130,  0.0336, -0.0061,  0.0030,
          0.0307,  0.1055, -0.0357,  0.0055, -0.1137, -0.0521, -0.0759, -0.0458,
          0.0406, -0.1511, -0.1510,  0.0455,  0.1325, -0.1323, -0.0569,  0.0378,
         -0.1128, -0.1331,  0.0360,  0.0399, -0.1297, -0.0933, -0.1005,  0.0630,
         -0.0051, -0.0035,  0.0582, -0.0962, -0.0674, -0.0656, -0.1223,  0.0715,
          0.0818,  0.0753,  0.1511,  0.1287,  0.0101, -0.1330,  0.0186,  0.0905,
          0.1241, -0.0414, -0.1312, -0.1382, -0.1089,  0.1407,  0.1128, -0.1041,
         -0.1030, -0.1019, -0.0823,  0.0011,  0.1320, -0.0554,  0.1341, -0.0284,
          0.1273,  0.0830,  0.0687,  0.0044,  0.0112, -0.1389,  0.1519, -0.0799,
         -0.0297, -0.1395,  0.1453, -0.1189, -0.0559, -0.0159,  0.0457,  0.0715,
          0.1413, -0.1128,  0.0090,  0.0306,  0.1375,  0.0901,  0.1023, -0.0657,
         -0.0228,  0.1430, -0.0176, -0.0472,  0.1018,  0.0171, -0.0124,  0.1350,
         -0.0915, -0.0435,  0.0271, -0.0547, -0.0316, -0.1489, -0.0868,  0.0600,
          0.0580,  0.0470,  0.0037, -0.1396, -0.0242,  0.0988, -0.0846, -0.0619,
          0.0244, -0.1081,  0.0448, -0.1160, -0.0348, -0.0535, -0.0038,  0.0544,
          0.1335, -0.0132, -0.0682, -0.1052,  0.0827,  0.1274,  0.0842, -0.0922,
          0.0771, -0.0734, -0.0927,  0.0052,  0.0714, -0.0793,  0.0831,  0.0207,
         -0.0441,  0.1143,  0.1391, -0.0720,  0.1291,  0.0342,  0.1144,  0.0358,
          0.0283, -0.1050,  0.0428, -0.0358, -0.1302, -0.0786,  0.0457, -0.1287,
         -0.1000, -0.0281,  0.1208,  0.0466,  0.0411,  0.0097, -0.0108, -0.0272,
         -0.0786,  0.1000,  0.1515, -0.0696,  0.0237, -0.0571, -0.0177,  0.0383,
         -0.0550,  0.0458, -0.0626,  0.0778,  0.0174, -0.0387, -0.0601,  0.1374,
         -0.1381, -0.1428,  0.1080, -0.0692,  0.0804, -0.0728, -0.0836, -0.1080,
         -0.0153, -0.0436,  0.0569, -0.0437, -0.1295, -0.1458, -0.0905,  0.0204,
         -0.0280, -0.0148, -0.0808,  0.0229,  0.0570, -0.1126,  0.0095,  0.0606,
          0.0923, -0.1288, -0.0283, -0.1451,  0.1434,  0.1203, -0.1474,  0.1267,
          0.1453, -0.0823, -0.0402,  0.0311,  0.1014,  0.0253, -0.1184, -0.0556,
          0.1404, -0.0304,  0.1093, -0.1088, -0.0237,  0.0885, -0.0927, -0.0670,
          0.1277,  0.0575,  0.0256,  0.0065,  0.0159,  0.0738, -0.0163, -0.0593]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name linear1.weight 
shape:
 torch.Size([32, 2350554]) 
grad:
 True 
date:
 tensor([[-5.6888e-04,  4.0615e-04, -2.4351e-04,  ...,  5.4126e-04,
          4.9910e-04, -5.3235e-04],
        [-4.4596e-04, -4.8235e-04,  6.1206e-04,  ...,  9.2104e-05,
          4.1487e-04, -6.8862e-05],
        [ 1.1499e-04, -3.2122e-04, -2.8993e-04,  ..., -6.3941e-04,
          2.3925e-04,  3.9291e-04],
        ...,
        [ 6.1341e-05,  5.7326e-04, -5.5750e-04,  ...,  6.0965e-04,
          2.7488e-04,  1.2022e-04],
        [-3.8911e-04,  3.2242e-04,  2.9652e-04,  ..., -5.9934e-05,
          1.7874e-04,  8.8774e-05],
        [-4.6015e-04, -1.8089e-04, -5.5390e-04,  ..., -5.2872e-04,
         -5.7992e-04, -3.0253e-04]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-5.6888e-04,  4.0615e-04, -2.4351e-04,  ...,  5.4126e-04,
          4.9910e-04, -5.3235e-04],
        [-4.4596e-04, -4.8235e-04,  6.1206e-04,  ...,  9.2104e-05,
          4.1487e-04, -6.8862e-05],
        [ 1.1499e-04, -3.2122e-04, -2.8993e-04,  ..., -6.3941e-04,
          2.3925e-04,  3.9291e-04],
        ...,
        [ 6.1341e-05,  5.7326e-04, -5.5750e-04,  ...,  6.0965e-04,
          2.7488e-04,  1.2022e-04],
        [-3.8911e-04,  3.2242e-04,  2.9652e-04,  ..., -5.9934e-05,
          1.7874e-04,  8.8774e-05],
        [-4.6015e-04, -1.8089e-04, -5.5390e-04,  ..., -5.2872e-04,
         -5.7992e-04, -3.0253e-04]], device='cuda:0', requires_grad=True)

name linear1.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([ 4.5122e-05,  6.8048e-05, -6.4964e-04,  5.9148e-04,  2.8614e-04,
        -3.8405e-04, -3.2328e-04, -3.4524e-04,  5.5665e-05, -6.6140e-05,
         3.8312e-04, -3.6896e-04,  6.4354e-04,  2.0566e-05,  6.0103e-05,
         2.1420e-04,  1.5174e-04, -2.7051e-04, -4.3698e-04,  6.1135e-04,
         4.2830e-04,  5.3136e-04, -1.3448e-04, -5.8566e-05, -2.4067e-04,
        -5.7209e-04,  5.5694e-04, -5.0010e-04,  6.8827e-05, -6.0861e-04,
         1.6290e-04,  2.8802e-04], device='cuda:0') 
parameter:
 Parameter containing:
tensor([ 4.5122e-05,  6.8048e-05, -6.4964e-04,  5.9148e-04,  2.8614e-04,
        -3.8405e-04, -3.2328e-04, -3.4524e-04,  5.5665e-05, -6.6140e-05,
         3.8312e-04, -3.6896e-04,  6.4354e-04,  2.0566e-05,  6.0103e-05,
         2.1420e-04,  1.5174e-04, -2.7051e-04, -4.3698e-04,  6.1135e-04,
         4.2830e-04,  5.3136e-04, -1.3448e-04, -5.8566e-05, -2.4067e-04,
        -5.7209e-04,  5.5694e-04, -5.0010e-04,  6.8827e-05, -6.0861e-04,
         1.6290e-04,  2.8802e-04], device='cuda:0', requires_grad=True)

name linear2.weight 
shape:
 torch.Size([2350554, 32]) 
grad:
 True 
date:
 tensor([[ 4.7311e-02,  1.5281e-01, -1.4892e-01,  ...,  7.7757e-02,
         -7.6286e-02, -1.4430e-01],
        [-1.2612e-01,  1.3882e-01, -1.8638e-02,  ...,  7.4905e-02,
         -2.4156e-02, -2.9877e-02],
        [ 4.3695e-02,  1.5141e-02, -1.4854e-01,  ..., -3.6459e-02,
         -1.3838e-01, -1.2836e-01],
        ...,
        [-4.5299e-02,  1.4134e-01,  1.2724e-01,  ...,  7.2116e-02,
         -8.9536e-02,  1.1898e-01],
        [ 9.4219e-02,  1.4263e-01,  1.4692e-04,  ..., -1.1729e-01,
         -9.6811e-02, -7.8833e-02],
        [ 7.8211e-02,  8.3779e-02, -1.2064e-01,  ...,  9.3175e-03,
         -9.7934e-02,  1.6776e-01]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 4.7311e-02,  1.5281e-01, -1.4892e-01,  ...,  7.7757e-02,
         -7.6286e-02, -1.4430e-01],
        [-1.2612e-01,  1.3882e-01, -1.8638e-02,  ...,  7.4905e-02,
         -2.4156e-02, -2.9877e-02],
        [ 4.3695e-02,  1.5141e-02, -1.4854e-01,  ..., -3.6459e-02,
         -1.3838e-01, -1.2836e-01],
        ...,
        [-4.5299e-02,  1.4134e-01,  1.2724e-01,  ...,  7.2116e-02,
         -8.9536e-02,  1.1898e-01],
        [ 9.4219e-02,  1.4263e-01,  1.4692e-04,  ..., -1.1729e-01,
         -9.6811e-02, -7.8833e-02],
        [ 7.8211e-02,  8.3779e-02, -1.2064e-01,  ...,  9.3175e-03,
         -9.7934e-02,  1.6776e-01]], device='cuda:0', requires_grad=True)

name linear2.bias 
shape:
 torch.Size([2350554]) 
grad:
 True 
date:
 tensor([ 0.0512, -0.1093,  0.0663,  ..., -0.0814, -0.0989, -0.0588],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([ 0.0512, -0.1093,  0.0663,  ..., -0.0814, -0.0989, -0.0588],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.1035, -0.0572,  0.1048,  ...,  0.0526, -0.0924,  0.0395],
        [-0.0543,  0.0611, -0.0727,  ..., -0.0020,  0.0107, -0.0760],
        [ 0.0224,  0.0793, -0.0722,  ...,  0.0087,  0.0304,  0.1103],
        ...,
        [-0.0503, -0.1244,  0.0109,  ...,  0.1033,  0.0398, -0.0744],
        [ 0.1057, -0.0116, -0.0827,  ...,  0.1155,  0.1122,  0.1016],
        [-0.0885,  0.0291,  0.1142,  ...,  0.0190,  0.0049,  0.1037]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1035, -0.0572,  0.1048,  ...,  0.0526, -0.0924,  0.0395],
        [-0.0543,  0.0611, -0.0727,  ..., -0.0020,  0.0107, -0.0760],
        [ 0.0224,  0.0793, -0.0722,  ...,  0.0087,  0.0304,  0.1103],
        ...,
        [-0.0503, -0.1244,  0.0109,  ...,  0.1033,  0.0398, -0.0744],
        [ 0.1057, -0.0116, -0.0827,  ...,  0.1155,  0.1122,  0.1016],
        [-0.0885,  0.0291,  0.1142,  ...,  0.0190,  0.0049,  0.1037]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.1375, -0.1287,  0.1181,  ...,  0.0751, -0.0816, -0.1098],
        [-0.0568, -0.0309,  0.0612,  ..., -0.0384, -0.0743, -0.0219],
        [ 0.1580,  0.0395, -0.0161,  ..., -0.0790, -0.1642, -0.0299],
        ...,
        [ 0.0211, -0.0086, -0.1096,  ...,  0.0426, -0.0491, -0.1520],
        [-0.0789,  0.0869,  0.0952,  ...,  0.0843, -0.1079,  0.0664],
        [-0.0433, -0.0497,  0.1583,  ..., -0.1182, -0.1320, -0.1465]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1375, -0.1287,  0.1181,  ...,  0.0751, -0.0816, -0.1098],
        [-0.0568, -0.0309,  0.0612,  ..., -0.0384, -0.0743, -0.0219],
        [ 0.1580,  0.0395, -0.0161,  ..., -0.0790, -0.1642, -0.0299],
        ...,
        [ 0.0211, -0.0086, -0.1096,  ...,  0.0426, -0.0491, -0.1520],
        [-0.0789,  0.0869,  0.0952,  ...,  0.0843, -0.1079,  0.0664],
        [-0.0433, -0.0497,  0.1583,  ..., -0.1182, -0.1320, -0.1465]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-0.0693, -0.1471,  0.1304,  ..., -0.0298, -0.0523, -0.1510],
        [ 0.1201, -0.0178,  0.0599,  ..., -0.2442, -0.2279, -0.0240],
        [-0.2020, -0.1866, -0.0290,  ..., -0.0475, -0.0897,  0.1900],
        ...,
        [ 0.1887,  0.0735, -0.0613,  ...,  0.1743,  0.0486,  0.0867],
        [-0.0681,  0.0869,  0.2327,  ...,  0.1850,  0.1387, -0.1376],
        [ 0.1293, -0.1006,  0.0166,  ..., -0.0722,  0.1329, -0.0771]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0693, -0.1471,  0.1304,  ..., -0.0298, -0.0523, -0.1510],
        [ 0.1201, -0.0178,  0.0599,  ..., -0.2442, -0.2279, -0.0240],
        [-0.2020, -0.1866, -0.0290,  ..., -0.0475, -0.0897,  0.1900],
        ...,
        [ 0.1887,  0.0735, -0.0613,  ...,  0.1743,  0.0486,  0.0867],
        [-0.0681,  0.0869,  0.2327,  ...,  0.1850,  0.1387, -0.1376],
        [ 0.1293, -0.1006,  0.0166,  ..., -0.0722,  0.1329, -0.0771]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.2423],
        [-0.1779],
        [ 0.0705],
        [-0.3322],
        [-0.2647],
        [-0.0554],
        [ 0.4003],
        [-0.1522],
        [-0.2078],
        [ 0.3459],
        [-0.2273],
        [-0.2188],
        [-0.1426],
        [ 0.1603],
        [ 0.3140],
        [ 0.0311],
        [-0.0755],
        [ 0.3241],
        [-0.1157],
        [-0.2048],
        [ 0.1551],
        [-0.2224],
        [-0.2469],
        [-0.1363],
        [-0.4039],
        [ 0.1538],
        [-0.3091],
        [ 0.1441],
        [ 0.2866],
        [-0.3813],
        [-0.3013],
        [-0.2367]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.2423],
        [-0.1779],
        [ 0.0705],
        [-0.3322],
        [-0.2647],
        [-0.0554],
        [ 0.4003],
        [-0.1522],
        [-0.2078],
        [ 0.3459],
        [-0.2273],
        [-0.2188],
        [-0.1426],
        [ 0.1603],
        [ 0.3140],
        [ 0.0311],
        [-0.0755],
        [ 0.3241],
        [-0.1157],
        [-0.2048],
        [ 0.1551],
        [-0.2224],
        [-0.2469],
        [-0.1363],
        [-0.4039],
        [ 0.1538],
        [-0.3091],
        [ 0.1441],
        [ 0.2866],
        [-0.3813],
        [-0.3013],
        [-0.2367]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)





 shepe: torch.Size([2350554, 1]) 









input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet] tensor([[0.0000],
        [0.0402],
        [0.0000],
        ...,
        [0.0000],
        [0.1455],
        [0.2742]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(212265.3281, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(140.1520, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-10.7467, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-11.4973, device='cuda:0')



h[100].sum tensor(-10.0036, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-10.7024, device='cuda:0')



h[200].sum tensor(6.5401, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(6.9969, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(34638.2266, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0118, 0.0000, 0.0125,  ..., 0.0000, 0.0237, 0.0094],
        [0.0046, 0.0000, 0.0049,  ..., 0.0000, 0.0093, 0.0037],
        [0.0020, 0.0000, 0.0022,  ..., 0.0000, 0.0041, 0.0016],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(837633.1875, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(14708.3281, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(236.5439, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[2.9483],
        [2.1715],
        [1.7370],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(1034750.1250, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.0000],
        [0.0402],
        [0.0000],
        ...,
        [0.0000],
        [0.1455],
        [0.2742]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet].sum tensor(212265.3281, device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[2.9483],
        [2.1715],
        [1.7370],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])





 shepe: torch.Size([47011080, 1]) 









input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet] tensor([[0.0900],
        [0.0000],
        [0.0000],
        ...,
        [0.0671],
        [0.0000],
        [0.4233]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(5450836.5000, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0197,  0.0054,  0.0014,  ..., -0.0112, -0.0027, -0.0170],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(486.3343, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-137.4819, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-147.6638, device='cuda:0')



h[100].sum tensor(21.0060, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(22.5617, device='cuda:0')



h[200].sum tensor(53.1770, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(57.1153, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0299, 0.0079,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0140, 0.0037,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0041, 0.0011,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(369703.3125, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0933, 0.0189],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0594, 0.0120],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0473, 0.0095],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(7948549.5000, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-2409.1431, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[1.6727e+00],
        [1.7754e+00],
        [2.0419e+00],
        ...,
        [1.7066e-05],
        [3.1928e-05],
        [4.0200e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(911906.8750, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.0900],
        [0.0000],
        [0.0000],
        ...,
        [0.0671],
        [0.0000],
        [0.4233]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet].sum tensor(5450836.5000, device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[2.9483],
        [2.1715],
        [1.7370],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndneiefet.py", line 13, in <module>
    writer = SummaryWriter()
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py", line 220, in __init__
    self._get_file_writer()
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py", line 250, in _get_file_writer
    self.file_writer = FileWriter(self.log_dir, self.max_queue,
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py", line 60, in __init__
    self.event_writer = EventFileWriter(
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/tensorboard/summary/writer/event_file_writer.py", line 72, in __init__
    tf.io.gfile.makedirs(logdir)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 900, in makedirs
    return get_filesystem(path).makedirs(path)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/tensorboard/compat/tensorflow_stub/io/gfile.py", line 201, in makedirs
    os.makedirs(path, exist_ok=True)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/os.py", line 225, in makedirs
    mkdir(name, mode)
OSError: [Errno 122] Disk quota exceeded: 'runs/Jan09_17-14-27_cmsgpu001.ihep.ac.cn'

real	0m50.607s
user	0m22.768s
sys	0m10.075s
