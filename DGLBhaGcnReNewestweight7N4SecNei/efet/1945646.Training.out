0: gpu015.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-27e5e31d-508e-9b8c-456d-09df29fc7d98)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        1A:4C:BC:79:AC:F4:80:9B:25:8E:21:10:C0:C4:44:9C:1F:5B:BD:6E
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Jan  9 16:43:03 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1F:00.0 Off |                    0 |
| N/A   31C    P0    42W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b3e8a10e880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m4.894s
user	0m2.863s
sys	0m0.816s




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[-1.7069],
        [-0.2922],
        [-1.7220],
        ...,
        [ 0.8680],
        [-0.5536],
        [ 1.5125]], device='cuda:0', requires_grad=True) 
node features sum: tensor(48.1143, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (linear1): Linear(in_features=2350554, out_features=256, bias=True)
  (linear2): Linear(in_features=256, out_features=2350554, bias=True)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 1205878235

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.0375,  0.1148,  0.1370,  0.0504, -0.1276, -0.0088,  0.0556,  0.0010,
          0.1430,  0.0667,  0.1442,  0.0034,  0.0081, -0.1375,  0.1232, -0.1508,
          0.0543, -0.0041,  0.0300,  0.1084,  0.0684, -0.1315,  0.0270, -0.1505,
          0.0642,  0.0167, -0.1040, -0.1034,  0.0476, -0.0873, -0.0093,  0.0465,
         -0.0290,  0.0543,  0.1164, -0.0631, -0.1443,  0.0356, -0.0598,  0.0716,
          0.0207, -0.0807,  0.0113, -0.0559, -0.1114,  0.0543,  0.0495, -0.0348,
          0.1381,  0.1084, -0.1275,  0.0379,  0.1146,  0.0122, -0.0663, -0.0462,
          0.1201,  0.1431,  0.1165,  0.0989, -0.1332, -0.0465, -0.0990, -0.0131,
         -0.0691, -0.0476, -0.0954,  0.0918, -0.1204, -0.0206, -0.0835,  0.0335,
          0.0672, -0.0945, -0.1313,  0.1451,  0.0243, -0.0434,  0.0049,  0.0595,
         -0.0355, -0.0058,  0.0139, -0.1046,  0.0196,  0.1378, -0.0592, -0.0052,
          0.0171,  0.0076,  0.0891,  0.0427,  0.0666, -0.0520, -0.0250, -0.0440,
         -0.0561, -0.0925, -0.0285,  0.0143, -0.1029, -0.0765, -0.0247,  0.0935,
         -0.0670,  0.0331, -0.0037, -0.1342, -0.0815,  0.0020, -0.1165, -0.1019,
         -0.0309, -0.1200, -0.0786,  0.0491, -0.0139,  0.0889,  0.0687, -0.1489,
          0.0271,  0.0242, -0.0206, -0.1117,  0.1387, -0.0043, -0.0312,  0.0159,
          0.1498,  0.1289, -0.0362, -0.1027, -0.0412, -0.0468, -0.1333, -0.0016,
          0.0812,  0.1063, -0.0436, -0.0396,  0.0319, -0.0246, -0.1242,  0.0011,
         -0.1347, -0.0511, -0.0621,  0.1492, -0.1210, -0.0791,  0.1480,  0.0806,
         -0.0669, -0.1118,  0.0380,  0.0246, -0.0970,  0.0565, -0.0745,  0.1289,
         -0.0741,  0.0192, -0.0884,  0.1450, -0.0112,  0.1061,  0.0015,  0.0102,
         -0.0728, -0.1520,  0.1201, -0.1196,  0.1048, -0.0532,  0.0618,  0.1041,
         -0.1499,  0.0454,  0.0250, -0.1360,  0.0940, -0.1030, -0.0973, -0.0998,
         -0.1007,  0.0322, -0.1413,  0.0686,  0.0645, -0.1269, -0.1445, -0.0425,
          0.0281,  0.1120,  0.1288, -0.1337, -0.1382, -0.0431, -0.0070,  0.1337,
         -0.0051,  0.1266, -0.0876,  0.0068, -0.1077, -0.0700,  0.0007, -0.0088,
         -0.0646,  0.0088,  0.0590,  0.1404, -0.0914,  0.1179, -0.0217, -0.0290,
         -0.1294, -0.0375,  0.0400, -0.0248, -0.1015, -0.1291,  0.0746, -0.1179,
         -0.0413, -0.0846, -0.0263, -0.0491,  0.0717, -0.1035, -0.0902, -0.1183,
          0.0254,  0.0545, -0.1110,  0.0877,  0.1284,  0.1391,  0.0323,  0.0028,
         -0.0033,  0.1456, -0.0065, -0.0109,  0.0332,  0.0164, -0.1365, -0.0313,
         -0.0912, -0.0199,  0.1130, -0.0739, -0.1468,  0.0035,  0.0488,  0.0449]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0375,  0.1148,  0.1370,  0.0504, -0.1276, -0.0088,  0.0556,  0.0010,
          0.1430,  0.0667,  0.1442,  0.0034,  0.0081, -0.1375,  0.1232, -0.1508,
          0.0543, -0.0041,  0.0300,  0.1084,  0.0684, -0.1315,  0.0270, -0.1505,
          0.0642,  0.0167, -0.1040, -0.1034,  0.0476, -0.0873, -0.0093,  0.0465,
         -0.0290,  0.0543,  0.1164, -0.0631, -0.1443,  0.0356, -0.0598,  0.0716,
          0.0207, -0.0807,  0.0113, -0.0559, -0.1114,  0.0543,  0.0495, -0.0348,
          0.1381,  0.1084, -0.1275,  0.0379,  0.1146,  0.0122, -0.0663, -0.0462,
          0.1201,  0.1431,  0.1165,  0.0989, -0.1332, -0.0465, -0.0990, -0.0131,
         -0.0691, -0.0476, -0.0954,  0.0918, -0.1204, -0.0206, -0.0835,  0.0335,
          0.0672, -0.0945, -0.1313,  0.1451,  0.0243, -0.0434,  0.0049,  0.0595,
         -0.0355, -0.0058,  0.0139, -0.1046,  0.0196,  0.1378, -0.0592, -0.0052,
          0.0171,  0.0076,  0.0891,  0.0427,  0.0666, -0.0520, -0.0250, -0.0440,
         -0.0561, -0.0925, -0.0285,  0.0143, -0.1029, -0.0765, -0.0247,  0.0935,
         -0.0670,  0.0331, -0.0037, -0.1342, -0.0815,  0.0020, -0.1165, -0.1019,
         -0.0309, -0.1200, -0.0786,  0.0491, -0.0139,  0.0889,  0.0687, -0.1489,
          0.0271,  0.0242, -0.0206, -0.1117,  0.1387, -0.0043, -0.0312,  0.0159,
          0.1498,  0.1289, -0.0362, -0.1027, -0.0412, -0.0468, -0.1333, -0.0016,
          0.0812,  0.1063, -0.0436, -0.0396,  0.0319, -0.0246, -0.1242,  0.0011,
         -0.1347, -0.0511, -0.0621,  0.1492, -0.1210, -0.0791,  0.1480,  0.0806,
         -0.0669, -0.1118,  0.0380,  0.0246, -0.0970,  0.0565, -0.0745,  0.1289,
         -0.0741,  0.0192, -0.0884,  0.1450, -0.0112,  0.1061,  0.0015,  0.0102,
         -0.0728, -0.1520,  0.1201, -0.1196,  0.1048, -0.0532,  0.0618,  0.1041,
         -0.1499,  0.0454,  0.0250, -0.1360,  0.0940, -0.1030, -0.0973, -0.0998,
         -0.1007,  0.0322, -0.1413,  0.0686,  0.0645, -0.1269, -0.1445, -0.0425,
          0.0281,  0.1120,  0.1288, -0.1337, -0.1382, -0.0431, -0.0070,  0.1337,
         -0.0051,  0.1266, -0.0876,  0.0068, -0.1077, -0.0700,  0.0007, -0.0088,
         -0.0646,  0.0088,  0.0590,  0.1404, -0.0914,  0.1179, -0.0217, -0.0290,
         -0.1294, -0.0375,  0.0400, -0.0248, -0.1015, -0.1291,  0.0746, -0.1179,
         -0.0413, -0.0846, -0.0263, -0.0491,  0.0717, -0.1035, -0.0902, -0.1183,
          0.0254,  0.0545, -0.1110,  0.0877,  0.1284,  0.1391,  0.0323,  0.0028,
         -0.0033,  0.1456, -0.0065, -0.0109,  0.0332,  0.0164, -0.1365, -0.0313,
         -0.0912, -0.0199,  0.1130, -0.0739, -0.1468,  0.0035,  0.0488,  0.0449]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name linear1.weight 
shape:
 torch.Size([256, 2350554]) 
grad:
 True 
date:
 tensor([[ 6.0524e-04,  1.9096e-06, -5.9260e-04,  ...,  4.9942e-04,
         -4.1692e-04,  1.7526e-04],
        [-5.8360e-04,  6.3093e-04, -1.7846e-04,  ...,  3.5967e-04,
         -6.0741e-04, -6.2317e-04],
        [ 3.1474e-06, -3.2906e-04,  1.4913e-04,  ..., -4.3109e-04,
         -5.9669e-04, -6.1526e-04],
        ...,
        [ 4.7527e-04,  2.0932e-04, -4.8541e-04,  ..., -4.5999e-04,
          6.1096e-05,  7.0038e-05],
        [ 3.9604e-04, -3.2848e-04,  3.4399e-04,  ..., -2.8526e-04,
         -6.2034e-04,  2.1592e-04],
        [ 3.7265e-04,  3.1129e-04,  3.2049e-05,  ..., -1.1772e-04,
          2.8314e-04, -6.3364e-04]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 6.0524e-04,  1.9096e-06, -5.9260e-04,  ...,  4.9942e-04,
         -4.1692e-04,  1.7526e-04],
        [-5.8360e-04,  6.3093e-04, -1.7846e-04,  ...,  3.5967e-04,
         -6.0741e-04, -6.2317e-04],
        [ 3.1474e-06, -3.2906e-04,  1.4913e-04,  ..., -4.3109e-04,
         -5.9669e-04, -6.1526e-04],
        ...,
        [ 4.7527e-04,  2.0932e-04, -4.8541e-04,  ..., -4.5999e-04,
          6.1096e-05,  7.0038e-05],
        [ 3.9604e-04, -3.2848e-04,  3.4399e-04,  ..., -2.8526e-04,
         -6.2034e-04,  2.1592e-04],
        [ 3.7265e-04,  3.1129e-04,  3.2049e-05,  ..., -1.1772e-04,
          2.8314e-04, -6.3364e-04]], device='cuda:0', requires_grad=True)

name linear1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([-4.1477e-04, -1.5516e-04, -4.1084e-04,  1.6641e-04,  3.0040e-04,
         2.6220e-04, -1.2854e-04, -1.4319e-04,  5.3339e-04,  7.4982e-05,
         2.3550e-04, -2.0238e-04,  4.2403e-04, -1.9791e-04, -2.8325e-04,
        -3.1170e-04, -2.5490e-04,  6.1038e-04,  3.2007e-05,  1.7280e-04,
         2.3672e-04,  4.6135e-04, -1.3804e-04, -4.8748e-04, -1.6568e-04,
         3.3064e-04, -5.3937e-04, -3.8260e-04, -1.7547e-04, -3.5412e-04,
         1.4951e-04, -2.9829e-04, -4.9558e-04, -5.5343e-04,  2.6693e-04,
        -9.5117e-05, -3.5474e-04,  2.4211e-04, -5.5139e-05, -9.3551e-05,
        -8.6617e-05, -3.4072e-04, -1.6431e-04, -5.7467e-04,  5.3804e-04,
         5.7391e-04,  3.3349e-04,  2.4684e-04, -7.9184e-06, -4.5205e-04,
        -1.9000e-05, -1.8654e-04,  4.7596e-04,  1.5437e-04,  4.2911e-04,
        -2.5662e-04,  3.4280e-04,  2.7861e-04, -6.4966e-04, -3.7998e-04,
         2.5308e-04,  3.6653e-04,  3.2728e-04,  3.2656e-04, -5.3444e-04,
        -6.3588e-04, -6.3366e-04, -1.7825e-04, -1.4788e-04,  6.3531e-04,
         4.7006e-04, -6.5035e-04, -2.0714e-05, -1.7471e-04,  2.8038e-04,
         2.8522e-04,  5.7936e-04, -1.8775e-04,  2.3422e-04,  6.4301e-04,
        -1.2400e-04,  1.5047e-05, -2.5226e-04,  4.3116e-04,  1.3033e-04,
        -6.4411e-04, -1.7671e-04, -4.5293e-04,  4.5751e-04, -2.3774e-04,
        -4.5301e-04, -2.6953e-04, -1.4758e-04,  1.1219e-04,  1.7688e-04,
        -3.7784e-04, -1.3597e-04, -2.5003e-04,  6.2888e-04,  8.4062e-05,
        -9.8701e-05, -1.5633e-04, -3.7724e-04,  4.6784e-04,  5.0510e-04,
        -4.4990e-04,  3.9081e-04,  6.0022e-04, -3.8359e-04, -4.6930e-04,
        -2.3461e-04,  2.0488e-04, -2.1724e-04,  1.9465e-04,  2.7659e-04,
        -4.3496e-04,  1.5986e-04,  4.0294e-04, -2.0087e-04, -4.1976e-04,
         4.7813e-04, -5.7488e-04,  4.6640e-04, -2.1707e-04,  5.1376e-04,
         6.5119e-04,  2.5391e-04, -3.5565e-04, -3.5610e-04, -6.4495e-04,
         5.9613e-04,  4.0472e-04,  1.9857e-04, -6.1318e-04,  9.4733e-05,
        -4.1662e-04,  1.3968e-04, -5.2059e-04,  6.0143e-04, -2.8717e-04,
        -5.1912e-04, -5.1279e-05,  3.1226e-04, -6.5105e-04, -2.3661e-04,
        -6.6837e-05,  5.8999e-04, -2.1005e-04, -2.2915e-04,  2.0968e-04,
        -1.3515e-04, -2.3138e-04,  3.7347e-04,  4.3683e-05, -3.5019e-05,
         3.9915e-05, -4.1421e-04,  1.3651e-04,  4.2589e-04,  6.1181e-04,
        -5.2771e-04,  1.5448e-04, -9.4731e-05, -1.1664e-04,  4.4559e-05,
         1.0111e-04, -2.1514e-04,  1.7797e-04, -1.6691e-04, -1.5431e-05,
        -1.9011e-04, -6.2582e-04, -4.5455e-04, -5.7560e-04, -4.4763e-04,
         2.9921e-05, -5.8972e-04, -1.4589e-04, -1.7741e-04,  1.3346e-04,
         4.1610e-04,  3.6849e-04, -3.6075e-04,  4.6643e-04, -6.6332e-05,
        -6.3529e-04,  1.8120e-06, -3.4971e-04,  5.6911e-04, -5.3378e-04,
        -6.2817e-04,  4.8111e-04,  4.3666e-05, -3.3797e-04, -5.6692e-04,
        -6.1734e-04, -3.5731e-04, -6.4979e-04, -2.4362e-04, -3.7267e-04,
        -4.2819e-04,  5.2176e-06, -5.9332e-04,  4.7639e-04, -3.3998e-05,
         3.7441e-04, -7.1798e-05, -5.8389e-04,  2.4822e-04, -4.0011e-05,
        -3.6945e-04,  3.6977e-04, -4.1983e-04,  5.3036e-04, -5.4318e-04,
        -1.8851e-04,  6.4804e-04,  4.5474e-04,  4.3990e-06, -4.6177e-04,
         1.0605e-04, -1.1633e-04,  2.9263e-04, -2.1084e-04, -1.2517e-04,
         3.1690e-04, -2.4320e-04,  2.2736e-04,  4.8639e-04,  1.6951e-04,
         1.2017e-04, -4.5292e-05,  3.4263e-04, -5.4065e-04,  3.0896e-04,
         2.2271e-04,  4.6783e-04,  1.2986e-04,  1.1930e-04,  6.3176e-04,
        -3.4763e-04,  4.1345e-05, -4.2849e-04, -3.1080e-04,  3.3111e-04,
        -3.9276e-04, -2.5967e-04,  5.2343e-04,  2.1367e-04,  5.9928e-04,
        -5.8953e-04,  3.8592e-04, -4.6856e-04,  4.8410e-04, -2.1462e-04,
         4.2445e-04], device='cuda:0') 
parameter:
 Parameter containing:
tensor([-4.1477e-04, -1.5516e-04, -4.1084e-04,  1.6641e-04,  3.0040e-04,
         2.6220e-04, -1.2854e-04, -1.4319e-04,  5.3339e-04,  7.4982e-05,
         2.3550e-04, -2.0238e-04,  4.2403e-04, -1.9791e-04, -2.8325e-04,
        -3.1170e-04, -2.5490e-04,  6.1038e-04,  3.2007e-05,  1.7280e-04,
         2.3672e-04,  4.6135e-04, -1.3804e-04, -4.8748e-04, -1.6568e-04,
         3.3064e-04, -5.3937e-04, -3.8260e-04, -1.7547e-04, -3.5412e-04,
         1.4951e-04, -2.9829e-04, -4.9558e-04, -5.5343e-04,  2.6693e-04,
        -9.5117e-05, -3.5474e-04,  2.4211e-04, -5.5139e-05, -9.3551e-05,
        -8.6617e-05, -3.4072e-04, -1.6431e-04, -5.7467e-04,  5.3804e-04,
         5.7391e-04,  3.3349e-04,  2.4684e-04, -7.9184e-06, -4.5205e-04,
        -1.9000e-05, -1.8654e-04,  4.7596e-04,  1.5437e-04,  4.2911e-04,
        -2.5662e-04,  3.4280e-04,  2.7861e-04, -6.4966e-04, -3.7998e-04,
         2.5308e-04,  3.6653e-04,  3.2728e-04,  3.2656e-04, -5.3444e-04,
        -6.3588e-04, -6.3366e-04, -1.7825e-04, -1.4788e-04,  6.3531e-04,
         4.7006e-04, -6.5035e-04, -2.0714e-05, -1.7471e-04,  2.8038e-04,
         2.8522e-04,  5.7936e-04, -1.8775e-04,  2.3422e-04,  6.4301e-04,
        -1.2400e-04,  1.5047e-05, -2.5226e-04,  4.3116e-04,  1.3033e-04,
        -6.4411e-04, -1.7671e-04, -4.5293e-04,  4.5751e-04, -2.3774e-04,
        -4.5301e-04, -2.6953e-04, -1.4758e-04,  1.1219e-04,  1.7688e-04,
        -3.7784e-04, -1.3597e-04, -2.5003e-04,  6.2888e-04,  8.4062e-05,
        -9.8701e-05, -1.5633e-04, -3.7724e-04,  4.6784e-04,  5.0510e-04,
        -4.4990e-04,  3.9081e-04,  6.0022e-04, -3.8359e-04, -4.6930e-04,
        -2.3461e-04,  2.0488e-04, -2.1724e-04,  1.9465e-04,  2.7659e-04,
        -4.3496e-04,  1.5986e-04,  4.0294e-04, -2.0087e-04, -4.1976e-04,
         4.7813e-04, -5.7488e-04,  4.6640e-04, -2.1707e-04,  5.1376e-04,
         6.5119e-04,  2.5391e-04, -3.5565e-04, -3.5610e-04, -6.4495e-04,
         5.9613e-04,  4.0472e-04,  1.9857e-04, -6.1318e-04,  9.4733e-05,
        -4.1662e-04,  1.3968e-04, -5.2059e-04,  6.0143e-04, -2.8717e-04,
        -5.1912e-04, -5.1279e-05,  3.1226e-04, -6.5105e-04, -2.3661e-04,
        -6.6837e-05,  5.8999e-04, -2.1005e-04, -2.2915e-04,  2.0968e-04,
        -1.3515e-04, -2.3138e-04,  3.7347e-04,  4.3683e-05, -3.5019e-05,
         3.9915e-05, -4.1421e-04,  1.3651e-04,  4.2589e-04,  6.1181e-04,
        -5.2771e-04,  1.5448e-04, -9.4731e-05, -1.1664e-04,  4.4559e-05,
         1.0111e-04, -2.1514e-04,  1.7797e-04, -1.6691e-04, -1.5431e-05,
        -1.9011e-04, -6.2582e-04, -4.5455e-04, -5.7560e-04, -4.4763e-04,
         2.9921e-05, -5.8972e-04, -1.4589e-04, -1.7741e-04,  1.3346e-04,
         4.1610e-04,  3.6849e-04, -3.6075e-04,  4.6643e-04, -6.6332e-05,
        -6.3529e-04,  1.8120e-06, -3.4971e-04,  5.6911e-04, -5.3378e-04,
        -6.2817e-04,  4.8111e-04,  4.3666e-05, -3.3797e-04, -5.6692e-04,
        -6.1734e-04, -3.5731e-04, -6.4979e-04, -2.4362e-04, -3.7267e-04,
        -4.2819e-04,  5.2176e-06, -5.9332e-04,  4.7639e-04, -3.3998e-05,
         3.7441e-04, -7.1798e-05, -5.8389e-04,  2.4822e-04, -4.0011e-05,
        -3.6945e-04,  3.6977e-04, -4.1983e-04,  5.3036e-04, -5.4318e-04,
        -1.8851e-04,  6.4804e-04,  4.5474e-04,  4.3990e-06, -4.6177e-04,
         1.0605e-04, -1.1633e-04,  2.9263e-04, -2.1084e-04, -1.2517e-04,
         3.1690e-04, -2.4320e-04,  2.2736e-04,  4.8639e-04,  1.6951e-04,
         1.2017e-04, -4.5292e-05,  3.4263e-04, -5.4065e-04,  3.0896e-04,
         2.2271e-04,  4.6783e-04,  1.2986e-04,  1.1930e-04,  6.3176e-04,
        -3.4763e-04,  4.1345e-05, -4.2849e-04, -3.1080e-04,  3.3111e-04,
        -3.9276e-04, -2.5967e-04,  5.2343e-04,  2.1367e-04,  5.9928e-04,
        -5.8953e-04,  3.8592e-04, -4.6856e-04,  4.8410e-04, -2.1462e-04,
         4.2445e-04], device='cuda:0', requires_grad=True)

name linear2.weight 
shape:
 torch.Size([2350554, 256]) 
grad:
 True 
date:
 tensor([[ 0.0618, -0.0334, -0.0607,  ...,  0.0512, -0.0518,  0.0528],
        [ 0.0553,  0.0532,  0.0449,  ..., -0.0395, -0.0153,  0.0481],
        [ 0.0372,  0.0520,  0.0162,  ..., -0.0146, -0.0065, -0.0482],
        ...,
        [-0.0426, -0.0356, -0.0239,  ..., -0.0249, -0.0424,  0.0490],
        [-0.0401, -0.0214, -0.0230,  ..., -0.0240, -0.0454, -0.0469],
        [ 0.0224,  0.0430, -0.0501,  ..., -0.0103,  0.0437, -0.0159]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0618, -0.0334, -0.0607,  ...,  0.0512, -0.0518,  0.0528],
        [ 0.0553,  0.0532,  0.0449,  ..., -0.0395, -0.0153,  0.0481],
        [ 0.0372,  0.0520,  0.0162,  ..., -0.0146, -0.0065, -0.0482],
        ...,
        [-0.0426, -0.0356, -0.0239,  ..., -0.0249, -0.0424,  0.0490],
        [-0.0401, -0.0214, -0.0230,  ..., -0.0240, -0.0454, -0.0469],
        [ 0.0224,  0.0430, -0.0501,  ..., -0.0103,  0.0437, -0.0159]],
       device='cuda:0', requires_grad=True)

name linear2.bias 
shape:
 torch.Size([2350554]) 
grad:
 True 
date:
 tensor([-2.8783e-03, -5.9731e-02, -4.7244e-02,  ..., -6.3717e-05,
         3.8705e-02,  5.0641e-02], device='cuda:0') 
parameter:
 Parameter containing:
tensor([-2.8783e-03, -5.9731e-02, -4.7244e-02,  ..., -6.3717e-05,
         3.8705e-02,  5.0641e-02], device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.1011,  0.0858,  0.1024,  ..., -0.0301,  0.0013,  0.0195],
        [ 0.0846,  0.0993,  0.0344,  ...,  0.0637, -0.0472,  0.0539],
        [ 0.1234,  0.0898,  0.1152,  ..., -0.1138,  0.0232, -0.1137],
        ...,
        [-0.0189,  0.1242, -0.1161,  ...,  0.0377, -0.1044, -0.1232],
        [-0.0122,  0.0929, -0.0506,  ..., -0.1213, -0.0256,  0.0595],
        [ 0.0613,  0.0561,  0.0566,  ...,  0.1237,  0.1017,  0.0537]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1011,  0.0858,  0.1024,  ..., -0.0301,  0.0013,  0.0195],
        [ 0.0846,  0.0993,  0.0344,  ...,  0.0637, -0.0472,  0.0539],
        [ 0.1234,  0.0898,  0.1152,  ..., -0.1138,  0.0232, -0.1137],
        ...,
        [-0.0189,  0.1242, -0.1161,  ...,  0.0377, -0.1044, -0.1232],
        [-0.0122,  0.0929, -0.0506,  ..., -0.1213, -0.0256,  0.0595],
        [ 0.0613,  0.0561,  0.0566,  ...,  0.1237,  0.1017,  0.0537]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.1033, -0.0022, -0.0071,  ...,  0.1331, -0.0025, -0.0568],
        [-0.0288,  0.0854, -0.1165,  ..., -0.1452,  0.1421, -0.1422],
        [-0.1262, -0.1440, -0.0720,  ..., -0.0094,  0.0883,  0.0207],
        ...,
        [-0.0010, -0.0887,  0.0608,  ..., -0.0234, -0.0912, -0.0171],
        [-0.1160, -0.0732, -0.1480,  ...,  0.0150, -0.0467,  0.0240],
        [-0.0837, -0.1220, -0.0536,  ...,  0.1391, -0.0993,  0.1017]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1033, -0.0022, -0.0071,  ...,  0.1331, -0.0025, -0.0568],
        [-0.0288,  0.0854, -0.1165,  ..., -0.1452,  0.1421, -0.1422],
        [-0.1262, -0.1440, -0.0720,  ..., -0.0094,  0.0883,  0.0207],
        ...,
        [-0.0010, -0.0887,  0.0608,  ..., -0.0234, -0.0912, -0.0171],
        [-0.1160, -0.0732, -0.1480,  ...,  0.0150, -0.0467,  0.0240],
        [-0.0837, -0.1220, -0.0536,  ...,  0.1391, -0.0993,  0.1017]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.1387, -0.1399,  0.1593,  ...,  0.0511, -0.1973, -0.2449],
        [-0.0387,  0.2240, -0.0696,  ..., -0.2409,  0.0116,  0.2430],
        [ 0.1110, -0.0592,  0.0464,  ...,  0.0967,  0.1368, -0.1347],
        ...,
        [-0.0348, -0.0787, -0.0529,  ...,  0.1194, -0.1189,  0.0050],
        [-0.1617, -0.1230,  0.1245,  ...,  0.0812,  0.0062,  0.2276],
        [-0.0181, -0.2269, -0.1723,  ..., -0.1288, -0.0041,  0.2408]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1387, -0.1399,  0.1593,  ...,  0.0511, -0.1973, -0.2449],
        [-0.0387,  0.2240, -0.0696,  ..., -0.2409,  0.0116,  0.2430],
        [ 0.1110, -0.0592,  0.0464,  ...,  0.0967,  0.1368, -0.1347],
        ...,
        [-0.0348, -0.0787, -0.0529,  ...,  0.1194, -0.1189,  0.0050],
        [-0.1617, -0.1230,  0.1245,  ...,  0.0812,  0.0062,  0.2276],
        [-0.0181, -0.2269, -0.1723,  ..., -0.1288, -0.0041,  0.2408]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.1579],
        [ 0.0247],
        [-0.3699],
        [ 0.1035],
        [-0.2290],
        [ 0.2350],
        [-0.0330],
        [ 0.3186],
        [ 0.0323],
        [-0.1807],
        [ 0.1222],
        [-0.3358],
        [-0.0321],
        [ 0.3417],
        [ 0.2699],
        [ 0.3341],
        [ 0.3368],
        [-0.1064],
        [-0.0993],
        [ 0.4015],
        [ 0.4176],
        [-0.0571],
        [ 0.4156],
        [-0.3580],
        [ 0.2232],
        [ 0.3356],
        [ 0.3324],
        [-0.0750],
        [-0.1499],
        [ 0.0297],
        [-0.2467],
        [ 0.2037]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1579],
        [ 0.0247],
        [-0.3699],
        [ 0.1035],
        [-0.2290],
        [ 0.2350],
        [-0.0330],
        [ 0.3186],
        [ 0.0323],
        [-0.1807],
        [ 0.1222],
        [-0.3358],
        [-0.0321],
        [ 0.3417],
        [ 0.2699],
        [ 0.3341],
        [ 0.3368],
        [-0.1064],
        [-0.0993],
        [ 0.4015],
        [ 0.4176],
        [-0.0571],
        [ 0.4156],
        [-0.3580],
        [ 0.2232],
        [ 0.3356],
        [ 0.3324],
        [-0.0750],
        [-0.1499],
        [ 0.0297],
        [-0.2467],
        [ 0.2037]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)





 shepe: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 









input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet] tensor([[0.1325],
        [0.1154],
        [0.0000],
        ...,
        [0.0142],
        [0.0000],
        [0.1705]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(203267.8750, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-1.8780, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(2.5998, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(2.7814, device='cuda:0')



h[100].sum tensor(-8.0795, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-8.6439, device='cuda:0')



h[200].sum tensor(5.9147, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(6.3278, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(31166.3145, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0057, 0.0042, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0020, 0.0015, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0013, 0.0009, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(734607.6250, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-13.5761, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(3538.0752, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(59.5210, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-108.8535, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[1.5046],
        [1.0877],
        [0.8348],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(525212.7500, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.1325],
        [0.1154],
        [0.0000],
        ...,
        [0.0142],
        [0.0000],
        [0.1705]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet].sum tensor(203267.8750, device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[1.5046],
        [1.0877],
        [0.8348],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])





 shepe: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 






Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndneiefet.py", line 5, in <module>
    from ModelBha2ndneiefet import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 209, in <module>
    result2 = net(batcheddglgraph, batten)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 64, in forward
    he = self.linear1(g.edata['efet'].reshape(1, 2350554))
RuntimeError: shape '[1, 2350554]' is invalid for input of size 47011080

real	0m52.531s
user	0m44.382s
sys	0m7.596s
