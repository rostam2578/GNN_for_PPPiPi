0: gpu015.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-27e5e31d-508e-9b8c-456d-09df29fc7d98)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        1A:4C:BC:79:AC:F4:80:9B:25:8E:21:10:C0:C4:44:9C:1F:5B:BD:6E
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Jan  9 16:45:40 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1F:00.0 Off |                    0 |
| N/A   31C    P0    42W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b5fcc29f880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m4.886s
user	0m2.837s
sys	0m0.892s




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[-0.9069],
        [ 0.7117],
        [-2.9680],
        ...,
        [-1.7786],
        [-0.4690],
        [-1.2724]], device='cuda:0', requires_grad=True) 
node features sum: tensor(-1.6379, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (linear1): Linear(in_features=2350554, out_features=256, bias=True)
  (linear2): Linear(in_features=256, out_features=2350554, bias=True)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 1205878235

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-0.0482,  0.0553, -0.1029, -0.0441,  0.0819,  0.0383,  0.0453,  0.0218,
          0.0338, -0.0894,  0.0368,  0.0789, -0.1111, -0.0711,  0.0518,  0.1183,
          0.1501, -0.0428, -0.0740, -0.0958,  0.0993, -0.0448, -0.1214, -0.1205,
         -0.0701, -0.1156,  0.0653, -0.1182, -0.0361,  0.0097,  0.1110,  0.0560,
          0.1420, -0.0461, -0.0768, -0.0322, -0.1265, -0.0603, -0.0724, -0.0959,
          0.1250,  0.0024, -0.0872,  0.0820,  0.1489,  0.0150, -0.1040,  0.0208,
          0.0444,  0.1020, -0.1218, -0.0247,  0.0432,  0.1092, -0.0487, -0.1501,
         -0.0721, -0.0835,  0.0019, -0.1090, -0.1015, -0.0640,  0.0876, -0.1253,
         -0.1291, -0.1106,  0.1349, -0.1370,  0.1001, -0.1438,  0.1189, -0.0585,
          0.0696,  0.0401,  0.1306, -0.0685,  0.1151,  0.0655, -0.1495,  0.1417,
          0.1240,  0.0971, -0.1070,  0.0326,  0.0884,  0.1353, -0.1094, -0.0372,
          0.0055,  0.0207,  0.0582,  0.0929,  0.1489,  0.0064,  0.0036,  0.1231,
         -0.1207,  0.1380,  0.0253,  0.0660,  0.0909, -0.1273,  0.1513,  0.0088,
          0.1492,  0.1387, -0.0786, -0.1097, -0.0225,  0.0547, -0.1139, -0.0693,
         -0.0100, -0.1146,  0.0634, -0.1341, -0.0138,  0.0832,  0.0443, -0.0168,
          0.0979, -0.0161, -0.0892, -0.0422, -0.0200, -0.0982,  0.1444,  0.0516,
         -0.0612, -0.0141,  0.1049,  0.1357, -0.0039, -0.1015, -0.1074, -0.1278,
          0.1473, -0.1167,  0.1102,  0.1103,  0.1111, -0.0721, -0.0154, -0.0113,
          0.0492,  0.0543, -0.0939,  0.1226, -0.1240,  0.0727, -0.1006, -0.1511,
         -0.0103, -0.0392,  0.1342, -0.0620,  0.0972, -0.0661, -0.0086, -0.0803,
          0.0379,  0.0692,  0.1513,  0.1063, -0.1430,  0.0676,  0.0207,  0.0931,
          0.0959,  0.0192, -0.0838, -0.0123, -0.0743, -0.0454, -0.0985,  0.1493,
          0.0756,  0.0323, -0.1303,  0.0870,  0.1451, -0.0102,  0.1127,  0.0299,
          0.0617, -0.1148,  0.0011, -0.0400,  0.0504, -0.0609, -0.0103,  0.0417,
          0.0811, -0.0248,  0.0879, -0.0865,  0.0156, -0.1011,  0.1147, -0.0429,
          0.0804,  0.1069, -0.0285,  0.0197, -0.0910, -0.0740,  0.0125,  0.1047,
          0.1183,  0.0381,  0.0882,  0.1200, -0.0070,  0.0770, -0.1415,  0.0771,
         -0.1093,  0.0436, -0.0289,  0.0131,  0.0191, -0.1388, -0.0138,  0.0263,
          0.0205,  0.0704, -0.0173, -0.1505, -0.0258, -0.0470, -0.0815,  0.1362,
         -0.0751,  0.0815, -0.0572,  0.0101, -0.0375, -0.0617,  0.0626,  0.0468,
          0.0722, -0.1315,  0.0446, -0.0766, -0.0631,  0.1514,  0.1398, -0.0478,
          0.0783, -0.0207,  0.1351,  0.0531,  0.0189, -0.0194, -0.1357,  0.0038]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0482,  0.0553, -0.1029, -0.0441,  0.0819,  0.0383,  0.0453,  0.0218,
          0.0338, -0.0894,  0.0368,  0.0789, -0.1111, -0.0711,  0.0518,  0.1183,
          0.1501, -0.0428, -0.0740, -0.0958,  0.0993, -0.0448, -0.1214, -0.1205,
         -0.0701, -0.1156,  0.0653, -0.1182, -0.0361,  0.0097,  0.1110,  0.0560,
          0.1420, -0.0461, -0.0768, -0.0322, -0.1265, -0.0603, -0.0724, -0.0959,
          0.1250,  0.0024, -0.0872,  0.0820,  0.1489,  0.0150, -0.1040,  0.0208,
          0.0444,  0.1020, -0.1218, -0.0247,  0.0432,  0.1092, -0.0487, -0.1501,
         -0.0721, -0.0835,  0.0019, -0.1090, -0.1015, -0.0640,  0.0876, -0.1253,
         -0.1291, -0.1106,  0.1349, -0.1370,  0.1001, -0.1438,  0.1189, -0.0585,
          0.0696,  0.0401,  0.1306, -0.0685,  0.1151,  0.0655, -0.1495,  0.1417,
          0.1240,  0.0971, -0.1070,  0.0326,  0.0884,  0.1353, -0.1094, -0.0372,
          0.0055,  0.0207,  0.0582,  0.0929,  0.1489,  0.0064,  0.0036,  0.1231,
         -0.1207,  0.1380,  0.0253,  0.0660,  0.0909, -0.1273,  0.1513,  0.0088,
          0.1492,  0.1387, -0.0786, -0.1097, -0.0225,  0.0547, -0.1139, -0.0693,
         -0.0100, -0.1146,  0.0634, -0.1341, -0.0138,  0.0832,  0.0443, -0.0168,
          0.0979, -0.0161, -0.0892, -0.0422, -0.0200, -0.0982,  0.1444,  0.0516,
         -0.0612, -0.0141,  0.1049,  0.1357, -0.0039, -0.1015, -0.1074, -0.1278,
          0.1473, -0.1167,  0.1102,  0.1103,  0.1111, -0.0721, -0.0154, -0.0113,
          0.0492,  0.0543, -0.0939,  0.1226, -0.1240,  0.0727, -0.1006, -0.1511,
         -0.0103, -0.0392,  0.1342, -0.0620,  0.0972, -0.0661, -0.0086, -0.0803,
          0.0379,  0.0692,  0.1513,  0.1063, -0.1430,  0.0676,  0.0207,  0.0931,
          0.0959,  0.0192, -0.0838, -0.0123, -0.0743, -0.0454, -0.0985,  0.1493,
          0.0756,  0.0323, -0.1303,  0.0870,  0.1451, -0.0102,  0.1127,  0.0299,
          0.0617, -0.1148,  0.0011, -0.0400,  0.0504, -0.0609, -0.0103,  0.0417,
          0.0811, -0.0248,  0.0879, -0.0865,  0.0156, -0.1011,  0.1147, -0.0429,
          0.0804,  0.1069, -0.0285,  0.0197, -0.0910, -0.0740,  0.0125,  0.1047,
          0.1183,  0.0381,  0.0882,  0.1200, -0.0070,  0.0770, -0.1415,  0.0771,
         -0.1093,  0.0436, -0.0289,  0.0131,  0.0191, -0.1388, -0.0138,  0.0263,
          0.0205,  0.0704, -0.0173, -0.1505, -0.0258, -0.0470, -0.0815,  0.1362,
         -0.0751,  0.0815, -0.0572,  0.0101, -0.0375, -0.0617,  0.0626,  0.0468,
          0.0722, -0.1315,  0.0446, -0.0766, -0.0631,  0.1514,  0.1398, -0.0478,
          0.0783, -0.0207,  0.1351,  0.0531,  0.0189, -0.0194, -0.1357,  0.0038]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name linear1.weight 
shape:
 torch.Size([256, 2350554]) 
grad:
 True 
date:
 tensor([[-5.1536e-04,  2.3899e-04,  1.8004e-04,  ..., -5.5422e-05,
         -3.8429e-04,  4.2693e-04],
        [-2.9754e-04,  3.0003e-04, -3.3505e-04,  ..., -6.1683e-04,
         -2.7979e-04, -8.2650e-05],
        [-5.7396e-04,  3.3973e-04, -2.4932e-05,  ...,  3.9676e-04,
          3.8947e-05,  2.4592e-05],
        ...,
        [-2.6947e-04, -2.4065e-04,  6.2562e-04,  ...,  5.3321e-04,
         -2.1734e-04,  3.0692e-04],
        [ 4.0678e-04, -7.7258e-05, -3.5094e-04,  ...,  5.1390e-04,
          9.4199e-05, -1.4896e-04],
        [ 2.2337e-04,  5.9625e-04, -2.1191e-04,  ...,  3.4951e-04,
          4.3108e-04, -4.0069e-04]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-5.1536e-04,  2.3899e-04,  1.8004e-04,  ..., -5.5422e-05,
         -3.8429e-04,  4.2693e-04],
        [-2.9754e-04,  3.0003e-04, -3.3505e-04,  ..., -6.1683e-04,
         -2.7979e-04, -8.2650e-05],
        [-5.7396e-04,  3.3973e-04, -2.4932e-05,  ...,  3.9676e-04,
          3.8947e-05,  2.4592e-05],
        ...,
        [-2.6947e-04, -2.4065e-04,  6.2562e-04,  ...,  5.3321e-04,
         -2.1734e-04,  3.0692e-04],
        [ 4.0678e-04, -7.7258e-05, -3.5094e-04,  ...,  5.1390e-04,
          9.4199e-05, -1.4896e-04],
        [ 2.2337e-04,  5.9625e-04, -2.1191e-04,  ...,  3.4951e-04,
          4.3108e-04, -4.0069e-04]], device='cuda:0', requires_grad=True)

name linear1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([ 4.2434e-04, -1.2967e-04, -2.9523e-04,  5.9580e-04, -4.4144e-04,
         4.2139e-04,  6.0890e-04,  5.8284e-04, -4.7531e-04, -5.4109e-04,
        -5.9380e-04,  1.9267e-04,  5.1674e-04, -6.4395e-05,  4.2563e-04,
         4.9162e-04, -4.9398e-04, -1.1526e-04,  5.8747e-05, -5.6758e-04,
         1.7680e-04,  5.9950e-04,  1.2536e-04,  3.7728e-04,  4.2401e-04,
        -1.8023e-04, -5.8140e-04, -4.4493e-04, -2.1693e-04, -6.3572e-04,
        -6.3571e-04, -6.4276e-04, -6.4386e-04, -5.2741e-04, -1.7481e-04,
        -5.5844e-04, -6.5047e-04, -4.1080e-04,  8.6717e-05,  4.1198e-04,
         4.3703e-04,  3.3334e-04, -2.7330e-04, -5.1541e-05, -1.7588e-04,
        -4.1318e-04,  4.1502e-04, -4.1905e-04, -8.5440e-05, -5.8892e-04,
         1.0496e-04,  3.4472e-04, -1.2563e-05, -3.0675e-04, -5.5969e-04,
        -1.8515e-05,  4.4344e-04,  5.7466e-04, -4.3853e-04, -2.4503e-05,
         1.3418e-04, -2.2202e-04, -6.5219e-05,  4.9255e-04, -2.3226e-04,
         1.5833e-04, -6.3923e-04,  3.4464e-04,  3.5627e-04,  4.9559e-04,
         5.2753e-04, -5.9453e-04, -3.3934e-04,  5.7479e-04,  5.1160e-04,
        -4.6297e-04,  1.7999e-04, -6.4152e-04,  4.8003e-05, -3.4124e-04,
        -1.7225e-04,  6.4977e-04, -4.5858e-04, -1.9613e-04, -3.1129e-04,
        -3.6812e-04,  3.0666e-04, -4.0022e-04,  3.7361e-04, -1.8870e-04,
         6.1545e-04,  3.3074e-04, -5.1528e-04,  5.2098e-04,  3.6909e-04,
         2.3637e-04, -4.6349e-04,  2.2623e-04,  3.2206e-04,  4.6611e-04,
         3.2617e-04,  1.1028e-04,  1.8450e-04, -1.2670e-04,  1.8156e-05,
         8.0952e-05,  4.2716e-04,  5.1135e-04,  2.8113e-04,  4.0069e-04,
        -1.7578e-04,  1.4958e-04, -4.2423e-04,  6.7315e-05,  4.8035e-04,
        -3.7133e-04,  4.9116e-06, -4.6867e-04, -5.0015e-04,  3.1829e-04,
         4.1843e-05,  1.0464e-04, -5.6660e-04,  1.7559e-04, -8.0601e-05,
         3.7862e-04, -5.0342e-04, -1.5305e-04,  3.2370e-04,  1.9844e-04,
         3.7852e-04,  5.8891e-04,  5.0975e-04, -1.3378e-04,  3.6316e-04,
        -3.8388e-04, -4.7447e-04,  3.0839e-04,  2.9653e-04,  6.3839e-06,
        -6.2164e-04,  1.0829e-04,  3.6339e-04,  1.6989e-04, -5.3005e-04,
         3.4353e-05,  5.2513e-04,  3.4256e-04,  6.0675e-04, -3.9688e-04,
         3.1433e-04, -4.4278e-05, -2.1833e-04,  3.2089e-04,  3.7225e-04,
         3.6287e-04,  6.0373e-04, -5.0798e-04, -2.7991e-04,  1.6583e-04,
         2.0298e-06,  2.4834e-04,  2.8940e-04, -4.3549e-05,  1.9298e-04,
         6.2101e-05, -5.5995e-04, -1.2826e-04,  2.5981e-04, -3.9678e-04,
        -2.4186e-04, -2.1729e-04, -9.6776e-05, -4.5187e-04, -3.4817e-05,
        -5.5010e-04, -3.1866e-04,  2.0541e-04, -6.0139e-04,  4.2272e-04,
        -3.9686e-04, -3.2861e-05,  5.5106e-04,  1.5027e-04, -9.9534e-05,
         2.8479e-04, -4.9447e-06,  2.2712e-05,  2.6055e-04, -3.7352e-06,
         4.0847e-05,  5.7648e-04, -3.5289e-04, -1.2632e-04, -5.2676e-04,
         4.8684e-04,  6.1789e-04,  5.0659e-04, -1.7847e-04,  2.3300e-04,
        -6.0005e-04,  3.1884e-04,  3.9708e-04, -1.9794e-05,  2.9023e-04,
         6.1054e-04,  2.5407e-04, -4.9155e-04,  6.3849e-05, -3.3703e-05,
        -4.4290e-04, -5.2048e-04, -5.4560e-04, -2.0252e-04, -2.5290e-04,
         5.7030e-04, -9.8877e-05,  6.2855e-04,  6.2098e-04, -3.6292e-04,
         3.2512e-04, -4.8147e-04, -5.3452e-05, -5.9648e-04,  7.3493e-05,
         2.2036e-04, -5.8984e-04, -3.0982e-04, -4.1448e-04,  5.3060e-04,
        -2.6575e-04, -2.7441e-04, -5.5873e-04,  4.5878e-04,  5.4539e-04,
        -6.1051e-06,  4.9130e-05, -6.4587e-04, -5.6386e-04, -1.3177e-04,
        -6.3453e-04, -2.6043e-04, -6.0268e-04,  7.2248e-05,  2.3756e-04,
        -8.1143e-05, -1.1405e-04, -5.8578e-05,  4.9769e-04,  3.3486e-04,
         2.9488e-04, -3.3901e-04, -3.2282e-04,  2.9320e-04,  2.8807e-05,
        -3.4171e-04], device='cuda:0') 
parameter:
 Parameter containing:
tensor([ 4.2434e-04, -1.2967e-04, -2.9523e-04,  5.9580e-04, -4.4144e-04,
         4.2139e-04,  6.0890e-04,  5.8284e-04, -4.7531e-04, -5.4109e-04,
        -5.9380e-04,  1.9267e-04,  5.1674e-04, -6.4395e-05,  4.2563e-04,
         4.9162e-04, -4.9398e-04, -1.1526e-04,  5.8747e-05, -5.6758e-04,
         1.7680e-04,  5.9950e-04,  1.2536e-04,  3.7728e-04,  4.2401e-04,
        -1.8023e-04, -5.8140e-04, -4.4493e-04, -2.1693e-04, -6.3572e-04,
        -6.3571e-04, -6.4276e-04, -6.4386e-04, -5.2741e-04, -1.7481e-04,
        -5.5844e-04, -6.5047e-04, -4.1080e-04,  8.6717e-05,  4.1198e-04,
         4.3703e-04,  3.3334e-04, -2.7330e-04, -5.1541e-05, -1.7588e-04,
        -4.1318e-04,  4.1502e-04, -4.1905e-04, -8.5440e-05, -5.8892e-04,
         1.0496e-04,  3.4472e-04, -1.2563e-05, -3.0675e-04, -5.5969e-04,
        -1.8515e-05,  4.4344e-04,  5.7466e-04, -4.3853e-04, -2.4503e-05,
         1.3418e-04, -2.2202e-04, -6.5219e-05,  4.9255e-04, -2.3226e-04,
         1.5833e-04, -6.3923e-04,  3.4464e-04,  3.5627e-04,  4.9559e-04,
         5.2753e-04, -5.9453e-04, -3.3934e-04,  5.7479e-04,  5.1160e-04,
        -4.6297e-04,  1.7999e-04, -6.4152e-04,  4.8003e-05, -3.4124e-04,
        -1.7225e-04,  6.4977e-04, -4.5858e-04, -1.9613e-04, -3.1129e-04,
        -3.6812e-04,  3.0666e-04, -4.0022e-04,  3.7361e-04, -1.8870e-04,
         6.1545e-04,  3.3074e-04, -5.1528e-04,  5.2098e-04,  3.6909e-04,
         2.3637e-04, -4.6349e-04,  2.2623e-04,  3.2206e-04,  4.6611e-04,
         3.2617e-04,  1.1028e-04,  1.8450e-04, -1.2670e-04,  1.8156e-05,
         8.0952e-05,  4.2716e-04,  5.1135e-04,  2.8113e-04,  4.0069e-04,
        -1.7578e-04,  1.4958e-04, -4.2423e-04,  6.7315e-05,  4.8035e-04,
        -3.7133e-04,  4.9116e-06, -4.6867e-04, -5.0015e-04,  3.1829e-04,
         4.1843e-05,  1.0464e-04, -5.6660e-04,  1.7559e-04, -8.0601e-05,
         3.7862e-04, -5.0342e-04, -1.5305e-04,  3.2370e-04,  1.9844e-04,
         3.7852e-04,  5.8891e-04,  5.0975e-04, -1.3378e-04,  3.6316e-04,
        -3.8388e-04, -4.7447e-04,  3.0839e-04,  2.9653e-04,  6.3839e-06,
        -6.2164e-04,  1.0829e-04,  3.6339e-04,  1.6989e-04, -5.3005e-04,
         3.4353e-05,  5.2513e-04,  3.4256e-04,  6.0675e-04, -3.9688e-04,
         3.1433e-04, -4.4278e-05, -2.1833e-04,  3.2089e-04,  3.7225e-04,
         3.6287e-04,  6.0373e-04, -5.0798e-04, -2.7991e-04,  1.6583e-04,
         2.0298e-06,  2.4834e-04,  2.8940e-04, -4.3549e-05,  1.9298e-04,
         6.2101e-05, -5.5995e-04, -1.2826e-04,  2.5981e-04, -3.9678e-04,
        -2.4186e-04, -2.1729e-04, -9.6776e-05, -4.5187e-04, -3.4817e-05,
        -5.5010e-04, -3.1866e-04,  2.0541e-04, -6.0139e-04,  4.2272e-04,
        -3.9686e-04, -3.2861e-05,  5.5106e-04,  1.5027e-04, -9.9534e-05,
         2.8479e-04, -4.9447e-06,  2.2712e-05,  2.6055e-04, -3.7352e-06,
         4.0847e-05,  5.7648e-04, -3.5289e-04, -1.2632e-04, -5.2676e-04,
         4.8684e-04,  6.1789e-04,  5.0659e-04, -1.7847e-04,  2.3300e-04,
        -6.0005e-04,  3.1884e-04,  3.9708e-04, -1.9794e-05,  2.9023e-04,
         6.1054e-04,  2.5407e-04, -4.9155e-04,  6.3849e-05, -3.3703e-05,
        -4.4290e-04, -5.2048e-04, -5.4560e-04, -2.0252e-04, -2.5290e-04,
         5.7030e-04, -9.8877e-05,  6.2855e-04,  6.2098e-04, -3.6292e-04,
         3.2512e-04, -4.8147e-04, -5.3452e-05, -5.9648e-04,  7.3493e-05,
         2.2036e-04, -5.8984e-04, -3.0982e-04, -4.1448e-04,  5.3060e-04,
        -2.6575e-04, -2.7441e-04, -5.5873e-04,  4.5878e-04,  5.4539e-04,
        -6.1051e-06,  4.9130e-05, -6.4587e-04, -5.6386e-04, -1.3177e-04,
        -6.3453e-04, -2.6043e-04, -6.0268e-04,  7.2248e-05,  2.3756e-04,
        -8.1143e-05, -1.1405e-04, -5.8578e-05,  4.9769e-04,  3.3486e-04,
         2.9488e-04, -3.3901e-04, -3.2282e-04,  2.9320e-04,  2.8807e-05,
        -3.4171e-04], device='cuda:0', requires_grad=True)

name linear2.weight 
shape:
 torch.Size([2350554, 256]) 
grad:
 True 
date:
 tensor([[ 0.0059, -0.0092, -0.0396,  ...,  0.0198,  0.0328, -0.0336],
        [ 0.0357, -0.0413,  0.0403,  ...,  0.0022,  0.0235, -0.0155],
        [-0.0238,  0.0435,  0.0228,  ..., -0.0040,  0.0063, -0.0387],
        ...,
        [-0.0299,  0.0377, -0.0059,  ..., -0.0251, -0.0211, -0.0208],
        [ 0.0464,  0.0614,  0.0539,  ...,  0.0587,  0.0174, -0.0180],
        [-0.0364,  0.0066, -0.0120,  ...,  0.0256, -0.0273,  0.0446]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0059, -0.0092, -0.0396,  ...,  0.0198,  0.0328, -0.0336],
        [ 0.0357, -0.0413,  0.0403,  ...,  0.0022,  0.0235, -0.0155],
        [-0.0238,  0.0435,  0.0228,  ..., -0.0040,  0.0063, -0.0387],
        ...,
        [-0.0299,  0.0377, -0.0059,  ..., -0.0251, -0.0211, -0.0208],
        [ 0.0464,  0.0614,  0.0539,  ...,  0.0587,  0.0174, -0.0180],
        [-0.0364,  0.0066, -0.0120,  ...,  0.0256, -0.0273,  0.0446]],
       device='cuda:0', requires_grad=True)

name linear2.bias 
shape:
 torch.Size([2350554]) 
grad:
 True 
date:
 tensor([ 0.0284, -0.0176, -0.0363,  ..., -0.0195,  0.0003, -0.0548],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([ 0.0284, -0.0176, -0.0363,  ..., -0.0195,  0.0003, -0.0548],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.1075, -0.0886,  0.0006,  ...,  0.1011, -0.0487, -0.0788],
        [ 0.1122,  0.1115,  0.0691,  ...,  0.1212,  0.0210,  0.0010],
        [-0.1077, -0.0912,  0.1050,  ...,  0.0349, -0.0599,  0.0557],
        ...,
        [-0.0267,  0.0793,  0.0994,  ...,  0.0959, -0.0796,  0.0377],
        [ 0.0532, -0.1138, -0.0279,  ..., -0.0384, -0.0984,  0.0156],
        [ 0.1140,  0.0861,  0.1169,  ..., -0.0107,  0.1085, -0.0866]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1075, -0.0886,  0.0006,  ...,  0.1011, -0.0487, -0.0788],
        [ 0.1122,  0.1115,  0.0691,  ...,  0.1212,  0.0210,  0.0010],
        [-0.1077, -0.0912,  0.1050,  ...,  0.0349, -0.0599,  0.0557],
        ...,
        [-0.0267,  0.0793,  0.0994,  ...,  0.0959, -0.0796,  0.0377],
        [ 0.0532, -0.1138, -0.0279,  ..., -0.0384, -0.0984,  0.0156],
        [ 0.1140,  0.0861,  0.1169,  ..., -0.0107,  0.1085, -0.0866]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0351, -0.0387,  0.1210,  ..., -0.1433, -0.1513, -0.1262],
        [ 0.0762, -0.1215,  0.0931,  ...,  0.0150, -0.0882,  0.0602],
        [-0.0926, -0.0203, -0.0032,  ..., -0.1343, -0.0675,  0.0063],
        ...,
        [-0.0823,  0.0945, -0.1751,  ..., -0.1529,  0.0472,  0.0391],
        [-0.1409, -0.0037, -0.0398,  ..., -0.1219, -0.1055, -0.1621],
        [-0.0593,  0.1746, -0.0225,  ..., -0.0383, -0.1295, -0.1642]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0351, -0.0387,  0.1210,  ..., -0.1433, -0.1513, -0.1262],
        [ 0.0762, -0.1215,  0.0931,  ...,  0.0150, -0.0882,  0.0602],
        [-0.0926, -0.0203, -0.0032,  ..., -0.1343, -0.0675,  0.0063],
        ...,
        [-0.0823,  0.0945, -0.1751,  ..., -0.1529,  0.0472,  0.0391],
        [-0.1409, -0.0037, -0.0398,  ..., -0.1219, -0.1055, -0.1621],
        [-0.0593,  0.1746, -0.0225,  ..., -0.0383, -0.1295, -0.1642]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.0165, -0.0838,  0.0619,  ..., -0.1736,  0.2169,  0.0148],
        [-0.0391,  0.1021, -0.1529,  ..., -0.0080, -0.1784, -0.1228],
        [-0.0426, -0.0846, -0.0760,  ..., -0.1961, -0.0329,  0.2232],
        ...,
        [ 0.0941, -0.0630,  0.0983,  ...,  0.2392, -0.2318, -0.0784],
        [ 0.2438, -0.0807,  0.0493,  ...,  0.0819, -0.1311, -0.1812],
        [-0.0102, -0.0104, -0.0094,  ..., -0.0697, -0.2202,  0.0904]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0165, -0.0838,  0.0619,  ..., -0.1736,  0.2169,  0.0148],
        [-0.0391,  0.1021, -0.1529,  ..., -0.0080, -0.1784, -0.1228],
        [-0.0426, -0.0846, -0.0760,  ..., -0.1961, -0.0329,  0.2232],
        ...,
        [ 0.0941, -0.0630,  0.0983,  ...,  0.2392, -0.2318, -0.0784],
        [ 0.2438, -0.0807,  0.0493,  ...,  0.0819, -0.1311, -0.1812],
        [-0.0102, -0.0104, -0.0094,  ..., -0.0697, -0.2202,  0.0904]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.3088],
        [-0.2605],
        [-0.0577],
        [-0.0955],
        [-0.2518],
        [-0.3020],
        [-0.1989],
        [ 0.1266],
        [ 0.2921],
        [ 0.0186],
        [-0.0981],
        [ 0.1488],
        [-0.0414],
        [-0.2199],
        [-0.4222],
        [ 0.0582],
        [-0.3517],
        [ 0.0036],
        [-0.2871],
        [-0.0228],
        [-0.2110],
        [-0.0688],
        [-0.0181],
        [ 0.1253],
        [-0.4239],
        [ 0.0667],
        [-0.0376],
        [ 0.0598],
        [ 0.2164],
        [ 0.2737],
        [ 0.3976],
        [ 0.3359]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.3088],
        [-0.2605],
        [-0.0577],
        [-0.0955],
        [-0.2518],
        [-0.3020],
        [-0.1989],
        [ 0.1266],
        [ 0.2921],
        [ 0.0186],
        [-0.0981],
        [ 0.1488],
        [-0.0414],
        [-0.2199],
        [-0.4222],
        [ 0.0582],
        [-0.3517],
        [ 0.0036],
        [-0.2871],
        [-0.0228],
        [-0.2110],
        [-0.0688],
        [-0.0181],
        [ 0.1253],
        [-0.4239],
        [ 0.0667],
        [-0.0376],
        [ 0.0598],
        [ 0.2164],
        [ 0.2737],
        [ 0.3976],
        [ 0.3359]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)





 shepe: torch.Size([2350554, 1]) 









input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet] tensor([[0.0000],
        [0.0000],
        [0.0000],
        ...,
        [0.0000],
        [0.3995],
        [0.3916]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(230251.7344, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-28.4996, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(6.3163, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(6.7575, device='cuda:0')



h[100].sum tensor(-0.6840, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-0.7317, device='cuda:0')



h[200].sum tensor(2.3665, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(2.5318, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(31865.7461, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0123, 0.0025, 0.0075,  ..., 0.0000, 0.0000, 0.0181],
        [0.0048, 0.0010, 0.0029,  ..., 0.0000, 0.0000, 0.0070],
        [0.0030, 0.0006, 0.0018,  ..., 0.0000, 0.0000, 0.0044],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(781004.4375, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(13736.3984, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(203.4978, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-224.4746, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(13625.5439, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(201.8556, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.5910],
        [0.4421],
        [0.3725],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(228450.2656, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.0000],
        [0.0000],
        [0.0000],
        ...,
        [0.0000],
        [0.3995],
        [0.3916]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet].sum tensor(230251.7344, device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[0.5910],
        [0.4421],
        [0.3725],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])





 shepe: torch.Size([47011080, 1]) 






Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndneiefet.py", line 5, in <module>
    from ModelBha2ndneiefet import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 209, in <module>
    result2 = net(batcheddglgraph, batten)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 64, in forward
    he = self.linear1(g.edata['efet'].reshape(1, 2350554))
RuntimeError: shape '[1, 2350554]' is invalid for input of size 47011080

real	0m52.837s
user	0m44.440s
sys	0m7.794s
