0: gpu035.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-8ac19b97-e996-d56f-26ed-caea68e1fcfc)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        70:B2:A7:DF:ED:82:78:26:9F:D8:28:A0:1D:52:CD:B5:3B:DF:C3:17
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Jan  9 16:47:56 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:16:00.0 Off |                    0 |
| N/A   43C    P0    40W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2adf058a2880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m4.218s
user	0m1.783s
sys	0m0.564s




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[ 0.0894],
        [ 1.4109],
        [-0.6530],
        ...,
        [ 1.1294],
        [ 0.4623],
        [-0.4924]], device='cuda:0', requires_grad=True) 
node features sum: tensor(40.8140, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (linear1): Linear(in_features=2350554, out_features=256, bias=True)
  (linear2): Linear(in_features=256, out_features=2350554, bias=True)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 1205878235

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.0023, -0.1208,  0.0913, -0.0758,  0.0477,  0.0033, -0.0845,  0.1306,
         -0.0278,  0.0203, -0.0075, -0.1286, -0.0086, -0.1365,  0.0050,  0.1079,
          0.0381,  0.0073, -0.0482,  0.1210, -0.1008,  0.0016,  0.0913, -0.0101,
          0.1435,  0.1498, -0.1026, -0.1282, -0.0987, -0.1154,  0.0432, -0.0772,
          0.1198, -0.0228,  0.0235,  0.0455,  0.0040, -0.1022,  0.1527, -0.1026,
         -0.0980,  0.0075,  0.0263, -0.0590, -0.0761, -0.1251,  0.0275,  0.0036,
         -0.0513,  0.0846, -0.0112, -0.0739,  0.0914,  0.0097,  0.1360,  0.1416,
          0.0820, -0.1089,  0.1209, -0.0671,  0.0488,  0.0129, -0.1035, -0.1185,
          0.0325,  0.0763, -0.0323,  0.1290,  0.1214,  0.1506, -0.0900,  0.0580,
         -0.0920, -0.1516,  0.0146, -0.1282,  0.1284, -0.0053, -0.0303, -0.0059,
          0.0148,  0.1137,  0.1174, -0.0705, -0.1520, -0.0226,  0.0833, -0.0040,
         -0.0508, -0.0704,  0.1070,  0.0406,  0.1191, -0.0013, -0.0073, -0.1083,
          0.1228,  0.0913, -0.0951,  0.0755,  0.1288, -0.0931, -0.0094,  0.0036,
         -0.0474, -0.0542, -0.0164,  0.0057,  0.0302, -0.0146, -0.1038, -0.0983,
         -0.1131, -0.0701,  0.0966, -0.0386, -0.0151, -0.0605, -0.1020, -0.1207,
         -0.0934,  0.0016, -0.0290, -0.0252, -0.1144, -0.0285,  0.0096, -0.0156,
         -0.1469,  0.0882,  0.0503,  0.1144,  0.0876, -0.1075, -0.0423,  0.0766,
         -0.0364, -0.1035,  0.0514, -0.1134,  0.1008,  0.1333, -0.1091, -0.1284,
         -0.1457, -0.0268, -0.1124, -0.0172, -0.1139, -0.0027,  0.0504,  0.0966,
          0.1355, -0.0314, -0.1417,  0.1457, -0.1253, -0.0313, -0.1162, -0.1476,
         -0.1281, -0.0399, -0.1009, -0.1184, -0.1075,  0.0798, -0.1005,  0.0537,
         -0.1083, -0.0059, -0.1173,  0.0194,  0.0537, -0.1167, -0.0170,  0.1065,
          0.0169, -0.0647,  0.1354,  0.0130,  0.0879, -0.1500,  0.0154, -0.0753,
          0.0745,  0.1070, -0.0500,  0.1098, -0.1435,  0.1420, -0.1496, -0.0086,
          0.1095,  0.1024, -0.0658,  0.0338, -0.0869, -0.0827, -0.0292, -0.1392,
          0.0961, -0.1420, -0.0800,  0.1428,  0.0629,  0.0819,  0.0700, -0.1352,
         -0.1061, -0.1359, -0.0624, -0.0577, -0.0388, -0.1027, -0.0560,  0.0848,
         -0.0938,  0.1314,  0.0543, -0.0722, -0.0426, -0.0677,  0.0830,  0.0788,
         -0.0068, -0.0357,  0.0552, -0.0015,  0.1032, -0.0736, -0.1404,  0.0251,
          0.0165, -0.1054, -0.0975, -0.0842, -0.0473,  0.1058, -0.1496,  0.0276,
          0.0734, -0.0251, -0.0359, -0.1207,  0.0070, -0.1013, -0.0401,  0.0072,
          0.0634, -0.0061,  0.0670, -0.0822,  0.0873,  0.1049, -0.1510,  0.1447]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0023, -0.1208,  0.0913, -0.0758,  0.0477,  0.0033, -0.0845,  0.1306,
         -0.0278,  0.0203, -0.0075, -0.1286, -0.0086, -0.1365,  0.0050,  0.1079,
          0.0381,  0.0073, -0.0482,  0.1210, -0.1008,  0.0016,  0.0913, -0.0101,
          0.1435,  0.1498, -0.1026, -0.1282, -0.0987, -0.1154,  0.0432, -0.0772,
          0.1198, -0.0228,  0.0235,  0.0455,  0.0040, -0.1022,  0.1527, -0.1026,
         -0.0980,  0.0075,  0.0263, -0.0590, -0.0761, -0.1251,  0.0275,  0.0036,
         -0.0513,  0.0846, -0.0112, -0.0739,  0.0914,  0.0097,  0.1360,  0.1416,
          0.0820, -0.1089,  0.1209, -0.0671,  0.0488,  0.0129, -0.1035, -0.1185,
          0.0325,  0.0763, -0.0323,  0.1290,  0.1214,  0.1506, -0.0900,  0.0580,
         -0.0920, -0.1516,  0.0146, -0.1282,  0.1284, -0.0053, -0.0303, -0.0059,
          0.0148,  0.1137,  0.1174, -0.0705, -0.1520, -0.0226,  0.0833, -0.0040,
         -0.0508, -0.0704,  0.1070,  0.0406,  0.1191, -0.0013, -0.0073, -0.1083,
          0.1228,  0.0913, -0.0951,  0.0755,  0.1288, -0.0931, -0.0094,  0.0036,
         -0.0474, -0.0542, -0.0164,  0.0057,  0.0302, -0.0146, -0.1038, -0.0983,
         -0.1131, -0.0701,  0.0966, -0.0386, -0.0151, -0.0605, -0.1020, -0.1207,
         -0.0934,  0.0016, -0.0290, -0.0252, -0.1144, -0.0285,  0.0096, -0.0156,
         -0.1469,  0.0882,  0.0503,  0.1144,  0.0876, -0.1075, -0.0423,  0.0766,
         -0.0364, -0.1035,  0.0514, -0.1134,  0.1008,  0.1333, -0.1091, -0.1284,
         -0.1457, -0.0268, -0.1124, -0.0172, -0.1139, -0.0027,  0.0504,  0.0966,
          0.1355, -0.0314, -0.1417,  0.1457, -0.1253, -0.0313, -0.1162, -0.1476,
         -0.1281, -0.0399, -0.1009, -0.1184, -0.1075,  0.0798, -0.1005,  0.0537,
         -0.1083, -0.0059, -0.1173,  0.0194,  0.0537, -0.1167, -0.0170,  0.1065,
          0.0169, -0.0647,  0.1354,  0.0130,  0.0879, -0.1500,  0.0154, -0.0753,
          0.0745,  0.1070, -0.0500,  0.1098, -0.1435,  0.1420, -0.1496, -0.0086,
          0.1095,  0.1024, -0.0658,  0.0338, -0.0869, -0.0827, -0.0292, -0.1392,
          0.0961, -0.1420, -0.0800,  0.1428,  0.0629,  0.0819,  0.0700, -0.1352,
         -0.1061, -0.1359, -0.0624, -0.0577, -0.0388, -0.1027, -0.0560,  0.0848,
         -0.0938,  0.1314,  0.0543, -0.0722, -0.0426, -0.0677,  0.0830,  0.0788,
         -0.0068, -0.0357,  0.0552, -0.0015,  0.1032, -0.0736, -0.1404,  0.0251,
          0.0165, -0.1054, -0.0975, -0.0842, -0.0473,  0.1058, -0.1496,  0.0276,
          0.0734, -0.0251, -0.0359, -0.1207,  0.0070, -0.1013, -0.0401,  0.0072,
          0.0634, -0.0061,  0.0670, -0.0822,  0.0873,  0.1049, -0.1510,  0.1447]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name linear1.weight 
shape:
 torch.Size([256, 2350554]) 
grad:
 True 
date:
 tensor([[-3.5926e-04,  8.8331e-05, -5.2546e-04,  ...,  2.4084e-04,
         -1.8317e-04, -5.4312e-05],
        [-4.7470e-04, -1.0121e-04,  6.4546e-04,  ..., -6.4749e-04,
          3.7772e-04, -6.3163e-04],
        [ 4.0760e-04, -5.8439e-05,  5.2709e-04,  ..., -3.2965e-04,
          1.9050e-04, -1.9903e-04],
        ...,
        [ 5.3568e-04,  1.8119e-04, -2.4039e-04,  ...,  3.0534e-05,
         -3.4165e-04, -1.1047e-04],
        [ 2.6654e-04, -1.4957e-04, -5.1413e-04,  ..., -4.3545e-04,
         -2.7108e-04, -5.9141e-04],
        [-1.5740e-04,  4.0812e-04,  1.0115e-04,  ..., -3.7953e-04,
         -5.5735e-04, -2.7593e-04]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-3.5926e-04,  8.8331e-05, -5.2546e-04,  ...,  2.4084e-04,
         -1.8317e-04, -5.4312e-05],
        [-4.7470e-04, -1.0121e-04,  6.4546e-04,  ..., -6.4749e-04,
          3.7772e-04, -6.3163e-04],
        [ 4.0760e-04, -5.8439e-05,  5.2709e-04,  ..., -3.2965e-04,
          1.9050e-04, -1.9903e-04],
        ...,
        [ 5.3568e-04,  1.8119e-04, -2.4039e-04,  ...,  3.0534e-05,
         -3.4165e-04, -1.1047e-04],
        [ 2.6654e-04, -1.4957e-04, -5.1413e-04,  ..., -4.3545e-04,
         -2.7108e-04, -5.9141e-04],
        [-1.5740e-04,  4.0812e-04,  1.0115e-04,  ..., -3.7953e-04,
         -5.5735e-04, -2.7593e-04]], device='cuda:0', requires_grad=True)

name linear1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([-1.4618e-04, -2.0503e-04,  3.7698e-04, -3.7905e-04,  1.6994e-04,
        -5.9180e-04, -3.6089e-04, -3.6743e-04,  3.9399e-05, -1.9201e-04,
         5.3967e-04,  4.9299e-04, -4.2394e-04,  3.7198e-04,  3.2128e-04,
        -1.3518e-04,  1.9680e-04,  1.4738e-04,  4.3812e-04, -4.3623e-04,
         4.3264e-04,  6.2212e-04, -1.8891e-04, -3.5262e-04,  1.2661e-04,
        -5.9520e-04,  3.0838e-04, -3.9354e-05,  3.2737e-04, -4.1844e-04,
        -5.1204e-05,  5.2262e-04,  3.0400e-04, -9.3157e-05,  5.8507e-04,
        -4.6533e-04,  5.2635e-04,  1.8077e-04,  2.8120e-04,  5.7321e-04,
         2.4986e-04,  4.6155e-04,  5.8881e-04, -5.9955e-04,  4.7583e-04,
         4.7701e-04, -1.0871e-04,  1.9488e-04, -4.0626e-04,  2.1087e-04,
         9.6359e-05,  5.2879e-04,  5.8506e-05, -2.3661e-04,  2.9731e-04,
        -2.6128e-04, -6.5351e-06,  4.6646e-04, -3.0747e-04, -2.5458e-04,
        -9.0043e-06,  8.6862e-05,  2.5241e-04, -3.6943e-04, -4.7398e-04,
        -5.7574e-04, -3.5142e-04, -4.9145e-04,  7.3887e-06, -5.0716e-04,
        -2.0211e-04, -1.5649e-04,  1.8443e-04,  3.2910e-04, -1.4241e-05,
        -6.0250e-04, -1.3102e-04, -4.5857e-04,  3.3031e-04, -4.0129e-04,
         3.7209e-05, -2.1638e-04, -5.1859e-04, -6.0301e-04, -2.7906e-04,
         2.4777e-04, -5.1505e-04,  3.2470e-04,  4.3685e-04, -7.2321e-06,
         4.6957e-05, -9.5710e-05,  3.1998e-04,  4.1636e-04,  1.7360e-04,
         4.8557e-04,  5.0943e-04,  6.1892e-05,  6.1835e-04, -6.5212e-04,
        -2.5541e-04,  1.7704e-06, -5.3853e-04, -1.4925e-04,  3.7942e-04,
        -2.7329e-04,  5.3239e-04, -2.8529e-04,  1.1911e-04, -2.5891e-04,
        -6.2334e-04, -8.6094e-05,  6.5667e-05, -2.7569e-04, -4.4721e-04,
        -6.2541e-04,  3.7873e-04, -5.5996e-04, -1.7519e-04, -2.7139e-04,
         2.3008e-04, -1.3494e-04,  5.2066e-04,  2.1244e-04, -2.2670e-05,
         1.0135e-04,  5.0650e-04, -2.2993e-04, -6.3423e-06, -2.4538e-04,
        -3.2106e-04, -1.0305e-04,  2.8811e-04,  6.1921e-04,  5.4239e-04,
        -2.8156e-04,  1.9039e-05, -6.5001e-04,  3.4164e-04, -2.4598e-04,
         1.7272e-04,  9.0888e-05, -8.8573e-05, -5.7803e-04,  2.8063e-04,
         5.9724e-04,  2.6848e-04, -5.3701e-04,  5.1210e-04, -6.1212e-05,
         9.3704e-05,  5.7834e-04, -2.0436e-04,  1.1583e-04,  3.3847e-04,
        -5.9772e-04,  1.1679e-04, -4.8047e-04,  4.7083e-04,  1.3112e-04,
        -3.5233e-04,  4.8153e-04, -2.3245e-04,  3.1721e-04, -4.0589e-04,
        -5.5078e-04,  1.1700e-06, -7.8418e-05, -4.4418e-05,  8.0100e-05,
         6.1610e-04, -1.7280e-04, -2.0076e-04, -2.2838e-04, -3.0923e-04,
        -2.3692e-04,  4.6178e-04,  6.1309e-04, -6.3696e-04,  5.3304e-04,
        -5.6984e-04, -2.9454e-05, -6.3345e-04, -2.2891e-04, -2.0533e-04,
         4.6660e-04, -3.3402e-04,  6.8883e-05, -1.3020e-04,  1.7228e-04,
        -3.6883e-04, -4.5417e-04,  2.7145e-04,  5.7768e-05, -2.1936e-04,
        -2.9338e-04, -4.6932e-04,  6.1487e-04, -5.0439e-04, -3.4121e-04,
         4.4968e-05,  4.4728e-04, -4.9521e-04, -3.8749e-04, -2.2022e-04,
         1.0465e-04, -6.1590e-04,  3.0970e-04,  6.1411e-04,  7.9336e-05,
         3.6565e-04, -4.6485e-04, -5.0315e-04,  2.9122e-04, -5.6673e-04,
        -5.3070e-04, -3.8395e-04, -5.1177e-04,  5.3749e-04, -3.6114e-04,
        -4.3562e-04,  4.5886e-04,  4.1321e-05, -1.6794e-04, -3.9930e-04,
         4.3768e-04, -3.1863e-04, -5.5405e-04, -2.5084e-04,  5.1323e-06,
         4.5123e-04, -1.1892e-04,  5.2257e-04, -4.2666e-04,  6.1637e-04,
        -5.6243e-04,  4.5958e-04,  9.3202e-05,  8.8635e-05, -5.4021e-05,
         2.4791e-04,  1.2676e-04, -6.3559e-04, -6.2017e-04, -2.3084e-04,
         1.6434e-04, -5.8862e-04, -6.5052e-04, -1.5826e-04,  7.1299e-05,
         5.7340e-04,  6.2033e-04, -3.2279e-04,  4.7532e-04,  4.1079e-04,
        -3.1971e-04], device='cuda:0') 
parameter:
 Parameter containing:
tensor([-1.4618e-04, -2.0503e-04,  3.7698e-04, -3.7905e-04,  1.6994e-04,
        -5.9180e-04, -3.6089e-04, -3.6743e-04,  3.9399e-05, -1.9201e-04,
         5.3967e-04,  4.9299e-04, -4.2394e-04,  3.7198e-04,  3.2128e-04,
        -1.3518e-04,  1.9680e-04,  1.4738e-04,  4.3812e-04, -4.3623e-04,
         4.3264e-04,  6.2212e-04, -1.8891e-04, -3.5262e-04,  1.2661e-04,
        -5.9520e-04,  3.0838e-04, -3.9354e-05,  3.2737e-04, -4.1844e-04,
        -5.1204e-05,  5.2262e-04,  3.0400e-04, -9.3157e-05,  5.8507e-04,
        -4.6533e-04,  5.2635e-04,  1.8077e-04,  2.8120e-04,  5.7321e-04,
         2.4986e-04,  4.6155e-04,  5.8881e-04, -5.9955e-04,  4.7583e-04,
         4.7701e-04, -1.0871e-04,  1.9488e-04, -4.0626e-04,  2.1087e-04,
         9.6359e-05,  5.2879e-04,  5.8506e-05, -2.3661e-04,  2.9731e-04,
        -2.6128e-04, -6.5351e-06,  4.6646e-04, -3.0747e-04, -2.5458e-04,
        -9.0043e-06,  8.6862e-05,  2.5241e-04, -3.6943e-04, -4.7398e-04,
        -5.7574e-04, -3.5142e-04, -4.9145e-04,  7.3887e-06, -5.0716e-04,
        -2.0211e-04, -1.5649e-04,  1.8443e-04,  3.2910e-04, -1.4241e-05,
        -6.0250e-04, -1.3102e-04, -4.5857e-04,  3.3031e-04, -4.0129e-04,
         3.7209e-05, -2.1638e-04, -5.1859e-04, -6.0301e-04, -2.7906e-04,
         2.4777e-04, -5.1505e-04,  3.2470e-04,  4.3685e-04, -7.2321e-06,
         4.6957e-05, -9.5710e-05,  3.1998e-04,  4.1636e-04,  1.7360e-04,
         4.8557e-04,  5.0943e-04,  6.1892e-05,  6.1835e-04, -6.5212e-04,
        -2.5541e-04,  1.7704e-06, -5.3853e-04, -1.4925e-04,  3.7942e-04,
        -2.7329e-04,  5.3239e-04, -2.8529e-04,  1.1911e-04, -2.5891e-04,
        -6.2334e-04, -8.6094e-05,  6.5667e-05, -2.7569e-04, -4.4721e-04,
        -6.2541e-04,  3.7873e-04, -5.5996e-04, -1.7519e-04, -2.7139e-04,
         2.3008e-04, -1.3494e-04,  5.2066e-04,  2.1244e-04, -2.2670e-05,
         1.0135e-04,  5.0650e-04, -2.2993e-04, -6.3423e-06, -2.4538e-04,
        -3.2106e-04, -1.0305e-04,  2.8811e-04,  6.1921e-04,  5.4239e-04,
        -2.8156e-04,  1.9039e-05, -6.5001e-04,  3.4164e-04, -2.4598e-04,
         1.7272e-04,  9.0888e-05, -8.8573e-05, -5.7803e-04,  2.8063e-04,
         5.9724e-04,  2.6848e-04, -5.3701e-04,  5.1210e-04, -6.1212e-05,
         9.3704e-05,  5.7834e-04, -2.0436e-04,  1.1583e-04,  3.3847e-04,
        -5.9772e-04,  1.1679e-04, -4.8047e-04,  4.7083e-04,  1.3112e-04,
        -3.5233e-04,  4.8153e-04, -2.3245e-04,  3.1721e-04, -4.0589e-04,
        -5.5078e-04,  1.1700e-06, -7.8418e-05, -4.4418e-05,  8.0100e-05,
         6.1610e-04, -1.7280e-04, -2.0076e-04, -2.2838e-04, -3.0923e-04,
        -2.3692e-04,  4.6178e-04,  6.1309e-04, -6.3696e-04,  5.3304e-04,
        -5.6984e-04, -2.9454e-05, -6.3345e-04, -2.2891e-04, -2.0533e-04,
         4.6660e-04, -3.3402e-04,  6.8883e-05, -1.3020e-04,  1.7228e-04,
        -3.6883e-04, -4.5417e-04,  2.7145e-04,  5.7768e-05, -2.1936e-04,
        -2.9338e-04, -4.6932e-04,  6.1487e-04, -5.0439e-04, -3.4121e-04,
         4.4968e-05,  4.4728e-04, -4.9521e-04, -3.8749e-04, -2.2022e-04,
         1.0465e-04, -6.1590e-04,  3.0970e-04,  6.1411e-04,  7.9336e-05,
         3.6565e-04, -4.6485e-04, -5.0315e-04,  2.9122e-04, -5.6673e-04,
        -5.3070e-04, -3.8395e-04, -5.1177e-04,  5.3749e-04, -3.6114e-04,
        -4.3562e-04,  4.5886e-04,  4.1321e-05, -1.6794e-04, -3.9930e-04,
         4.3768e-04, -3.1863e-04, -5.5405e-04, -2.5084e-04,  5.1323e-06,
         4.5123e-04, -1.1892e-04,  5.2257e-04, -4.2666e-04,  6.1637e-04,
        -5.6243e-04,  4.5958e-04,  9.3202e-05,  8.8635e-05, -5.4021e-05,
         2.4791e-04,  1.2676e-04, -6.3559e-04, -6.2017e-04, -2.3084e-04,
         1.6434e-04, -5.8862e-04, -6.5052e-04, -1.5826e-04,  7.1299e-05,
         5.7340e-04,  6.2033e-04, -3.2279e-04,  4.7532e-04,  4.1079e-04,
        -3.1971e-04], device='cuda:0', requires_grad=True)

name linear2.weight 
shape:
 torch.Size([2350554, 256]) 
grad:
 True 
date:
 tensor([[ 0.0094, -0.0576, -0.0336,  ..., -0.0411,  0.0598,  0.0069],
        [ 0.0239, -0.0620, -0.0505,  ..., -0.0540,  0.0422,  0.0500],
        [-0.0291, -0.0291, -0.0155,  ..., -0.0484,  0.0250, -0.0573],
        ...,
        [ 0.0539,  0.0262,  0.0574,  ..., -0.0227,  0.0439, -0.0158],
        [ 0.0402,  0.0437,  0.0067,  ...,  0.0019,  0.0508,  0.0039],
        [ 0.0417, -0.0071, -0.0366,  ..., -0.0530,  0.0445,  0.0182]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0094, -0.0576, -0.0336,  ..., -0.0411,  0.0598,  0.0069],
        [ 0.0239, -0.0620, -0.0505,  ..., -0.0540,  0.0422,  0.0500],
        [-0.0291, -0.0291, -0.0155,  ..., -0.0484,  0.0250, -0.0573],
        ...,
        [ 0.0539,  0.0262,  0.0574,  ..., -0.0227,  0.0439, -0.0158],
        [ 0.0402,  0.0437,  0.0067,  ...,  0.0019,  0.0508,  0.0039],
        [ 0.0417, -0.0071, -0.0366,  ..., -0.0530,  0.0445,  0.0182]],
       device='cuda:0', requires_grad=True)

name linear2.bias 
shape:
 torch.Size([2350554]) 
grad:
 True 
date:
 tensor([ 0.0327, -0.0466,  0.0602,  ..., -0.0451,  0.0440,  0.0170],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([ 0.0327, -0.0466,  0.0602,  ..., -0.0451,  0.0440,  0.0170],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0781,  0.0994, -0.1074,  ..., -0.0846,  0.0046,  0.0766],
        [-0.0804,  0.0158, -0.0839,  ..., -0.0718, -0.0450,  0.1148],
        [-0.0517, -0.0728,  0.0039,  ..., -0.1177, -0.0202, -0.1111],
        ...,
        [-0.0124, -0.0082, -0.0101,  ..., -0.0212, -0.1248,  0.0347],
        [ 0.0268, -0.0961,  0.0287,  ...,  0.0525,  0.0461, -0.0240],
        [ 0.0379,  0.0154, -0.0683,  ..., -0.0483, -0.0770,  0.1142]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0781,  0.0994, -0.1074,  ..., -0.0846,  0.0046,  0.0766],
        [-0.0804,  0.0158, -0.0839,  ..., -0.0718, -0.0450,  0.1148],
        [-0.0517, -0.0728,  0.0039,  ..., -0.1177, -0.0202, -0.1111],
        ...,
        [-0.0124, -0.0082, -0.0101,  ..., -0.0212, -0.1248,  0.0347],
        [ 0.0268, -0.0961,  0.0287,  ...,  0.0525,  0.0461, -0.0240],
        [ 0.0379,  0.0154, -0.0683,  ..., -0.0483, -0.0770,  0.1142]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.1472,  0.1063, -0.0974,  ..., -0.0055, -0.0935, -0.1742],
        [-0.0860, -0.0152, -0.1579,  ...,  0.1034, -0.0267,  0.1136],
        [ 0.0766, -0.1674,  0.0172,  ..., -0.1106, -0.1731,  0.0261],
        ...,
        [-0.1332,  0.0002, -0.0163,  ..., -0.1203,  0.1053, -0.1099],
        [-0.1238, -0.0548,  0.1093,  ...,  0.0037, -0.1142,  0.1066],
        [-0.0269, -0.1165,  0.1654,  ..., -0.1417,  0.0921,  0.1536]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1472,  0.1063, -0.0974,  ..., -0.0055, -0.0935, -0.1742],
        [-0.0860, -0.0152, -0.1579,  ...,  0.1034, -0.0267,  0.1136],
        [ 0.0766, -0.1674,  0.0172,  ..., -0.1106, -0.1731,  0.0261],
        ...,
        [-0.1332,  0.0002, -0.0163,  ..., -0.1203,  0.1053, -0.1099],
        [-0.1238, -0.0548,  0.1093,  ...,  0.0037, -0.1142,  0.1066],
        [-0.0269, -0.1165,  0.1654,  ..., -0.1417,  0.0921,  0.1536]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-0.1885, -0.1217, -0.1802,  ..., -0.2248, -0.0787,  0.1850],
        [ 0.2327, -0.2431,  0.1847,  ..., -0.1449,  0.1207, -0.0436],
        [ 0.2112, -0.1003, -0.1300,  ...,  0.0349,  0.0016,  0.2419],
        ...,
        [-0.1126,  0.1824,  0.1062,  ...,  0.1143,  0.1543, -0.1242],
        [-0.2045,  0.0562, -0.2244,  ...,  0.2229, -0.1677,  0.2250],
        [ 0.1608,  0.0169, -0.2289,  ..., -0.0894, -0.0905,  0.0155]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1885, -0.1217, -0.1802,  ..., -0.2248, -0.0787,  0.1850],
        [ 0.2327, -0.2431,  0.1847,  ..., -0.1449,  0.1207, -0.0436],
        [ 0.2112, -0.1003, -0.1300,  ...,  0.0349,  0.0016,  0.2419],
        ...,
        [-0.1126,  0.1824,  0.1062,  ...,  0.1143,  0.1543, -0.1242],
        [-0.2045,  0.0562, -0.2244,  ...,  0.2229, -0.1677,  0.2250],
        [ 0.1608,  0.0169, -0.2289,  ..., -0.0894, -0.0905,  0.0155]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.0430],
        [ 0.0663],
        [-0.4149],
        [ 0.1362],
        [ 0.3275],
        [-0.3425],
        [-0.3649],
        [ 0.0199],
        [ 0.3000],
        [-0.2989],
        [ 0.0692],
        [-0.0587],
        [ 0.0408],
        [-0.1652],
        [-0.2618],
        [-0.0847],
        [ 0.2638],
        [-0.4086],
        [-0.1834],
        [-0.2634],
        [ 0.1269],
        [-0.1305],
        [ 0.1545],
        [ 0.1673],
        [ 0.3493],
        [ 0.0384],
        [ 0.2820],
        [-0.2959],
        [-0.0966],
        [-0.3964],
        [ 0.1168],
        [-0.3126]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0430],
        [ 0.0663],
        [-0.4149],
        [ 0.1362],
        [ 0.3275],
        [-0.3425],
        [-0.3649],
        [ 0.0199],
        [ 0.3000],
        [-0.2989],
        [ 0.0692],
        [-0.0587],
        [ 0.0408],
        [-0.1652],
        [-0.2618],
        [-0.0847],
        [ 0.2638],
        [-0.4086],
        [-0.1834],
        [-0.2634],
        [ 0.1269],
        [-0.1305],
        [ 0.1545],
        [ 0.1673],
        [ 0.3493],
        [ 0.0384],
        [ 0.2820],
        [-0.2959],
        [-0.0966],
        [-0.3964],
        [ 0.1168],
        [-0.3126]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)





 shepe: torch.Size([2350554, 1]) 






Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndneiefet.py", line 5, in <module>
    from ModelBha2ndneiefet import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 165, in <module>
    result1 = net(dglgraph.to(device), TraTen[1007].reshape(6796, 1).to(device))
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 65, in forward
    he = self.linear1(he)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (2350554x1 and 2350554x256)

real	0m36.380s
user	0m27.445s
sys	0m6.788s
