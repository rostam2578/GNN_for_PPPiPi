0: gpu035.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-31f0faa6-490d-b385-7cf1-6dd798b1dcea)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        70:B2:A7:DF:ED:82:78:26:9F:D8:28:A0:1D:52:CD:B5:3B:DF:C3:17
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Jan  9 16:29:23 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   45C    P0    44W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2ba7bd1f1880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m29.981s
user	0m1.886s
sys	0m1.198s




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[-1.1439],
        [-1.2183],
        [ 0.1376],
        ...,
        [ 1.7180],
        [-1.8753],
        [-0.1632]], device='cuda:0', requires_grad=True) 
node features sum: tensor(42.5320, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (linear1): Linear(in_features=2350554, out_features=256, bias=True)
  (linear2): Linear(in_features=256, out_features=2350554, bias=True)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 1205878235

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.1463,  0.0401, -0.0313, -0.0061,  0.0969, -0.1103, -0.0862, -0.0905,
         -0.0056, -0.0938,  0.1151, -0.1106, -0.0906,  0.0060, -0.0446,  0.0032,
         -0.0269,  0.1408, -0.0493,  0.0585, -0.0087,  0.0782,  0.1446,  0.0742,
         -0.0708,  0.0985, -0.1061, -0.1292, -0.1097, -0.0739, -0.0743, -0.1104,
          0.0808, -0.0024,  0.0850,  0.0537, -0.1368, -0.0676,  0.0123,  0.1449,
          0.0727,  0.0041,  0.0164,  0.0658, -0.0480,  0.0921, -0.1372,  0.1180,
          0.1061,  0.0474,  0.0695,  0.1293,  0.1308, -0.0910,  0.0522, -0.0855,
         -0.0764, -0.0155,  0.1066, -0.0338,  0.0019,  0.0916,  0.0891, -0.0054,
         -0.0514,  0.0928,  0.0207, -0.0649, -0.1501, -0.0735, -0.0140, -0.1289,
         -0.0309, -0.0426, -0.1224, -0.0428, -0.1145,  0.1032, -0.1479, -0.0808,
         -0.0898,  0.1269,  0.1196, -0.0745, -0.0282, -0.1037,  0.1270, -0.1288,
         -0.0516,  0.0751, -0.1426, -0.0368, -0.0025, -0.0109, -0.0214,  0.0852,
          0.1106,  0.0078, -0.1192, -0.0591,  0.1486, -0.0111,  0.0909,  0.0459,
         -0.1061,  0.1246, -0.1058, -0.1198,  0.1301,  0.0481, -0.0541,  0.0779,
         -0.1420, -0.0666,  0.0565,  0.0599,  0.0352, -0.1165, -0.0943,  0.1220,
          0.0851, -0.1067, -0.0372, -0.0717,  0.1294, -0.0030,  0.0153, -0.0522,
         -0.0889,  0.1329, -0.1523, -0.1364, -0.0358, -0.0250,  0.0155,  0.0313,
         -0.1020,  0.1280, -0.0323, -0.0542, -0.1210,  0.1140, -0.1226, -0.0501,
          0.1277, -0.1286, -0.1205,  0.0381, -0.0131, -0.0462, -0.1065, -0.0191,
          0.0363, -0.0587,  0.1420, -0.1172,  0.1392,  0.0253,  0.0025, -0.1495,
         -0.0087, -0.1230, -0.1081, -0.0150, -0.1334, -0.1463,  0.0344,  0.0716,
         -0.0897, -0.1122,  0.0027,  0.0367,  0.0018,  0.1444, -0.0652,  0.0870,
         -0.0053,  0.0390,  0.0098,  0.0773,  0.0500, -0.1195,  0.1096, -0.0131,
          0.0633, -0.0331,  0.0675,  0.0805, -0.0428,  0.0012, -0.1029,  0.0565,
         -0.0902, -0.0963,  0.0540, -0.0736, -0.0895,  0.1323,  0.1292,  0.0697,
          0.0555, -0.0183, -0.1261, -0.0648,  0.0040,  0.0178, -0.0458, -0.0592,
          0.0943,  0.0551,  0.0477, -0.1189, -0.0695,  0.0128, -0.0453, -0.0402,
          0.0874, -0.1188, -0.1363, -0.0918,  0.1291,  0.0773,  0.0335,  0.0838,
          0.1069,  0.0525,  0.0328, -0.0091,  0.1289, -0.0796, -0.1420, -0.0822,
         -0.0971,  0.0785,  0.0381,  0.0120, -0.0517,  0.0552,  0.0368,  0.1233,
          0.1137, -0.1444, -0.0065, -0.1324,  0.0841,  0.0196,  0.1359,  0.0030,
          0.0392,  0.1524, -0.1022,  0.1065, -0.0125, -0.0077,  0.0877,  0.1509]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1463,  0.0401, -0.0313, -0.0061,  0.0969, -0.1103, -0.0862, -0.0905,
         -0.0056, -0.0938,  0.1151, -0.1106, -0.0906,  0.0060, -0.0446,  0.0032,
         -0.0269,  0.1408, -0.0493,  0.0585, -0.0087,  0.0782,  0.1446,  0.0742,
         -0.0708,  0.0985, -0.1061, -0.1292, -0.1097, -0.0739, -0.0743, -0.1104,
          0.0808, -0.0024,  0.0850,  0.0537, -0.1368, -0.0676,  0.0123,  0.1449,
          0.0727,  0.0041,  0.0164,  0.0658, -0.0480,  0.0921, -0.1372,  0.1180,
          0.1061,  0.0474,  0.0695,  0.1293,  0.1308, -0.0910,  0.0522, -0.0855,
         -0.0764, -0.0155,  0.1066, -0.0338,  0.0019,  0.0916,  0.0891, -0.0054,
         -0.0514,  0.0928,  0.0207, -0.0649, -0.1501, -0.0735, -0.0140, -0.1289,
         -0.0309, -0.0426, -0.1224, -0.0428, -0.1145,  0.1032, -0.1479, -0.0808,
         -0.0898,  0.1269,  0.1196, -0.0745, -0.0282, -0.1037,  0.1270, -0.1288,
         -0.0516,  0.0751, -0.1426, -0.0368, -0.0025, -0.0109, -0.0214,  0.0852,
          0.1106,  0.0078, -0.1192, -0.0591,  0.1486, -0.0111,  0.0909,  0.0459,
         -0.1061,  0.1246, -0.1058, -0.1198,  0.1301,  0.0481, -0.0541,  0.0779,
         -0.1420, -0.0666,  0.0565,  0.0599,  0.0352, -0.1165, -0.0943,  0.1220,
          0.0851, -0.1067, -0.0372, -0.0717,  0.1294, -0.0030,  0.0153, -0.0522,
         -0.0889,  0.1329, -0.1523, -0.1364, -0.0358, -0.0250,  0.0155,  0.0313,
         -0.1020,  0.1280, -0.0323, -0.0542, -0.1210,  0.1140, -0.1226, -0.0501,
          0.1277, -0.1286, -0.1205,  0.0381, -0.0131, -0.0462, -0.1065, -0.0191,
          0.0363, -0.0587,  0.1420, -0.1172,  0.1392,  0.0253,  0.0025, -0.1495,
         -0.0087, -0.1230, -0.1081, -0.0150, -0.1334, -0.1463,  0.0344,  0.0716,
         -0.0897, -0.1122,  0.0027,  0.0367,  0.0018,  0.1444, -0.0652,  0.0870,
         -0.0053,  0.0390,  0.0098,  0.0773,  0.0500, -0.1195,  0.1096, -0.0131,
          0.0633, -0.0331,  0.0675,  0.0805, -0.0428,  0.0012, -0.1029,  0.0565,
         -0.0902, -0.0963,  0.0540, -0.0736, -0.0895,  0.1323,  0.1292,  0.0697,
          0.0555, -0.0183, -0.1261, -0.0648,  0.0040,  0.0178, -0.0458, -0.0592,
          0.0943,  0.0551,  0.0477, -0.1189, -0.0695,  0.0128, -0.0453, -0.0402,
          0.0874, -0.1188, -0.1363, -0.0918,  0.1291,  0.0773,  0.0335,  0.0838,
          0.1069,  0.0525,  0.0328, -0.0091,  0.1289, -0.0796, -0.1420, -0.0822,
         -0.0971,  0.0785,  0.0381,  0.0120, -0.0517,  0.0552,  0.0368,  0.1233,
          0.1137, -0.1444, -0.0065, -0.1324,  0.0841,  0.0196,  0.1359,  0.0030,
          0.0392,  0.1524, -0.1022,  0.1065, -0.0125, -0.0077,  0.0877,  0.1509]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name linear1.weight 
shape:
 torch.Size([256, 2350554]) 
grad:
 True 
date:
 tensor([[-5.8526e-04,  5.5213e-05, -2.6779e-04,  ..., -3.9702e-04,
         -5.9889e-04,  5.0768e-04],
        [-3.1556e-04,  1.5709e-04,  5.0237e-04,  ..., -1.4340e-04,
         -6.2030e-04,  5.3065e-04],
        [-1.4283e-04, -3.2809e-04, -1.7745e-04,  ..., -4.8093e-04,
         -1.7937e-04,  2.4356e-04],
        ...,
        [-3.8264e-04, -5.8434e-04, -3.8702e-04,  ..., -4.6888e-04,
         -2.3416e-04, -1.9480e-04],
        [-3.7207e-04, -2.8399e-04,  2.2021e-05,  ..., -4.2811e-04,
          6.8516e-05, -3.9643e-04],
        [-3.5244e-05, -3.2194e-04,  3.3912e-04,  ..., -4.2328e-04,
          3.6227e-04, -4.1840e-04]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-5.8526e-04,  5.5213e-05, -2.6779e-04,  ..., -3.9702e-04,
         -5.9889e-04,  5.0768e-04],
        [-3.1556e-04,  1.5709e-04,  5.0237e-04,  ..., -1.4340e-04,
         -6.2030e-04,  5.3065e-04],
        [-1.4283e-04, -3.2809e-04, -1.7745e-04,  ..., -4.8093e-04,
         -1.7937e-04,  2.4356e-04],
        ...,
        [-3.8264e-04, -5.8434e-04, -3.8702e-04,  ..., -4.6888e-04,
         -2.3416e-04, -1.9480e-04],
        [-3.7207e-04, -2.8399e-04,  2.2021e-05,  ..., -4.2811e-04,
          6.8516e-05, -3.9643e-04],
        [-3.5244e-05, -3.2194e-04,  3.3912e-04,  ..., -4.2328e-04,
          3.6227e-04, -4.1840e-04]], device='cuda:0', requires_grad=True)

name linear1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([ 4.2133e-04,  1.7906e-04, -2.7690e-04, -3.1517e-05,  5.0982e-04,
        -2.4001e-05,  4.1097e-04, -5.6480e-04, -1.3726e-04,  2.3258e-05,
        -2.0095e-04, -4.9509e-05, -4.8932e-04, -4.1847e-04,  1.1435e-04,
        -3.9974e-04, -2.6787e-05, -5.5772e-04, -2.2773e-04, -1.8909e-04,
         1.4039e-04,  5.8241e-04, -5.7950e-04,  6.4424e-04,  4.0016e-04,
         7.4587e-05,  6.5089e-04,  5.7062e-06,  1.3099e-04,  6.4658e-04,
         6.2504e-04, -3.9144e-04, -1.4316e-04, -4.9653e-04, -4.7602e-04,
        -4.8003e-04, -3.7220e-04, -9.3370e-05,  8.0522e-05,  3.6003e-04,
         2.5434e-04, -4.0318e-04, -5.8161e-04, -6.6856e-05, -4.7889e-04,
        -7.9312e-05, -6.0675e-04, -3.6186e-04,  1.5905e-04,  4.1393e-04,
        -1.8560e-04,  3.0891e-05, -8.4750e-05, -1.5097e-04,  3.3675e-04,
         1.9167e-04,  4.2242e-04,  9.0219e-05, -4.8357e-04, -1.5135e-04,
         5.2051e-04,  2.1317e-04,  4.5702e-04, -4.1806e-04,  2.5018e-04,
        -3.8827e-04,  5.7180e-04, -3.8015e-04, -5.7170e-04,  6.3470e-04,
        -4.0859e-04,  2.6452e-04,  3.1556e-04, -1.3601e-04,  5.4739e-05,
         4.1035e-04,  1.8685e-04,  5.6059e-04,  8.0356e-06, -6.1437e-04,
         3.6500e-04,  4.8121e-04, -5.3637e-04,  3.5821e-04,  4.6380e-04,
         3.1492e-04,  8.4988e-05, -4.5378e-04, -3.7900e-04, -8.2175e-05,
         3.9760e-04, -4.4298e-04, -2.0022e-04,  1.1706e-04, -6.5058e-04,
         1.8681e-04, -2.4550e-05,  3.3927e-04, -5.0579e-04, -1.2231e-04,
        -3.8606e-04,  2.3863e-04,  3.3711e-04,  3.8043e-04, -1.2338e-04,
        -4.3529e-04, -1.7497e-04,  2.6051e-04, -5.1557e-04,  5.3635e-04,
        -5.1987e-05,  2.3986e-05,  6.3246e-04,  5.0273e-04,  4.6994e-04,
        -4.9093e-04, -3.6095e-04,  2.5232e-04, -2.5196e-04, -1.8995e-05,
        -4.1433e-04, -1.7047e-04,  6.7675e-06, -6.0016e-04, -2.0568e-04,
        -5.7120e-04, -3.1092e-04,  5.9921e-04, -5.4576e-04, -4.5801e-04,
        -2.6513e-04, -5.7233e-04,  5.6959e-04,  9.3943e-05,  4.9861e-04,
         5.6747e-04,  1.1459e-04,  9.4003e-05,  5.4648e-04, -1.3165e-04,
         5.1780e-04,  3.4074e-04, -1.8105e-04, -2.0366e-04, -3.3945e-04,
        -5.8204e-04,  9.0971e-05,  5.3861e-04,  6.5997e-05,  2.6593e-04,
         5.2050e-04, -1.0504e-04,  4.8914e-04, -4.6005e-04,  6.1314e-04,
         3.7625e-04, -3.3313e-04,  3.1730e-04,  3.8758e-05, -3.7782e-05,
         2.2065e-04, -5.0127e-04,  9.7086e-05, -2.2285e-05,  1.6029e-04,
        -5.3641e-05,  3.0211e-04, -3.2214e-04,  4.8225e-04,  1.7878e-04,
        -5.8274e-04, -6.2694e-04, -1.4522e-04, -6.1706e-04,  4.0049e-04,
         5.8757e-04, -5.6992e-04, -4.1944e-05, -8.2522e-05, -5.0656e-04,
         3.0926e-04, -5.2188e-04, -3.8160e-04,  5.6130e-04,  7.0197e-05,
         3.3139e-04,  1.7264e-04,  4.3137e-05, -4.7993e-04,  3.7857e-04,
         2.1293e-04, -4.6349e-04, -2.6580e-04,  5.4238e-04,  2.2240e-04,
         5.3861e-04,  1.2496e-04, -3.0795e-04,  5.5767e-04,  5.7695e-04,
        -4.1152e-04, -1.4331e-04,  3.1156e-06,  4.4589e-04, -5.6390e-04,
        -5.3947e-04,  5.0402e-04,  1.1702e-07,  2.9117e-04,  6.5638e-06,
         3.2148e-05, -6.1242e-04,  4.4744e-04,  1.5228e-04, -3.8800e-04,
         6.2189e-04,  2.7692e-04,  3.8360e-04, -3.2007e-04,  1.9566e-04,
         8.2099e-05,  2.4850e-04, -1.5261e-04,  2.0153e-04,  5.3163e-05,
        -4.0571e-04, -2.6491e-04,  6.0232e-04, -2.4630e-04,  3.0302e-05,
         7.0577e-05,  4.9334e-04,  7.0888e-06,  5.3421e-04, -5.7987e-04,
        -1.1146e-04,  1.4504e-04,  1.2578e-04,  1.3634e-04,  3.5086e-04,
         1.2939e-04,  6.3802e-04, -3.8450e-07,  4.8549e-04,  1.4027e-04,
        -2.5592e-04, -2.3056e-04,  6.2824e-04, -3.4592e-04,  3.9558e-04,
         6.9244e-05,  3.5914e-05, -6.2147e-04, -1.4026e-04,  4.0391e-04,
         6.3826e-04], device='cuda:0') 
parameter:
 Parameter containing:
tensor([ 4.2133e-04,  1.7906e-04, -2.7690e-04, -3.1517e-05,  5.0982e-04,
        -2.4001e-05,  4.1097e-04, -5.6480e-04, -1.3726e-04,  2.3258e-05,
        -2.0095e-04, -4.9509e-05, -4.8932e-04, -4.1847e-04,  1.1435e-04,
        -3.9974e-04, -2.6787e-05, -5.5772e-04, -2.2773e-04, -1.8909e-04,
         1.4039e-04,  5.8241e-04, -5.7950e-04,  6.4424e-04,  4.0016e-04,
         7.4587e-05,  6.5089e-04,  5.7062e-06,  1.3099e-04,  6.4658e-04,
         6.2504e-04, -3.9144e-04, -1.4316e-04, -4.9653e-04, -4.7602e-04,
        -4.8003e-04, -3.7220e-04, -9.3370e-05,  8.0522e-05,  3.6003e-04,
         2.5434e-04, -4.0318e-04, -5.8161e-04, -6.6856e-05, -4.7889e-04,
        -7.9312e-05, -6.0675e-04, -3.6186e-04,  1.5905e-04,  4.1393e-04,
        -1.8560e-04,  3.0891e-05, -8.4750e-05, -1.5097e-04,  3.3675e-04,
         1.9167e-04,  4.2242e-04,  9.0219e-05, -4.8357e-04, -1.5135e-04,
         5.2051e-04,  2.1317e-04,  4.5702e-04, -4.1806e-04,  2.5018e-04,
        -3.8827e-04,  5.7180e-04, -3.8015e-04, -5.7170e-04,  6.3470e-04,
        -4.0859e-04,  2.6452e-04,  3.1556e-04, -1.3601e-04,  5.4739e-05,
         4.1035e-04,  1.8685e-04,  5.6059e-04,  8.0356e-06, -6.1437e-04,
         3.6500e-04,  4.8121e-04, -5.3637e-04,  3.5821e-04,  4.6380e-04,
         3.1492e-04,  8.4988e-05, -4.5378e-04, -3.7900e-04, -8.2175e-05,
         3.9760e-04, -4.4298e-04, -2.0022e-04,  1.1706e-04, -6.5058e-04,
         1.8681e-04, -2.4550e-05,  3.3927e-04, -5.0579e-04, -1.2231e-04,
        -3.8606e-04,  2.3863e-04,  3.3711e-04,  3.8043e-04, -1.2338e-04,
        -4.3529e-04, -1.7497e-04,  2.6051e-04, -5.1557e-04,  5.3635e-04,
        -5.1987e-05,  2.3986e-05,  6.3246e-04,  5.0273e-04,  4.6994e-04,
        -4.9093e-04, -3.6095e-04,  2.5232e-04, -2.5196e-04, -1.8995e-05,
        -4.1433e-04, -1.7047e-04,  6.7675e-06, -6.0016e-04, -2.0568e-04,
        -5.7120e-04, -3.1092e-04,  5.9921e-04, -5.4576e-04, -4.5801e-04,
        -2.6513e-04, -5.7233e-04,  5.6959e-04,  9.3943e-05,  4.9861e-04,
         5.6747e-04,  1.1459e-04,  9.4003e-05,  5.4648e-04, -1.3165e-04,
         5.1780e-04,  3.4074e-04, -1.8105e-04, -2.0366e-04, -3.3945e-04,
        -5.8204e-04,  9.0971e-05,  5.3861e-04,  6.5997e-05,  2.6593e-04,
         5.2050e-04, -1.0504e-04,  4.8914e-04, -4.6005e-04,  6.1314e-04,
         3.7625e-04, -3.3313e-04,  3.1730e-04,  3.8758e-05, -3.7782e-05,
         2.2065e-04, -5.0127e-04,  9.7086e-05, -2.2285e-05,  1.6029e-04,
        -5.3641e-05,  3.0211e-04, -3.2214e-04,  4.8225e-04,  1.7878e-04,
        -5.8274e-04, -6.2694e-04, -1.4522e-04, -6.1706e-04,  4.0049e-04,
         5.8757e-04, -5.6992e-04, -4.1944e-05, -8.2522e-05, -5.0656e-04,
         3.0926e-04, -5.2188e-04, -3.8160e-04,  5.6130e-04,  7.0197e-05,
         3.3139e-04,  1.7264e-04,  4.3137e-05, -4.7993e-04,  3.7857e-04,
         2.1293e-04, -4.6349e-04, -2.6580e-04,  5.4238e-04,  2.2240e-04,
         5.3861e-04,  1.2496e-04, -3.0795e-04,  5.5767e-04,  5.7695e-04,
        -4.1152e-04, -1.4331e-04,  3.1156e-06,  4.4589e-04, -5.6390e-04,
        -5.3947e-04,  5.0402e-04,  1.1702e-07,  2.9117e-04,  6.5638e-06,
         3.2148e-05, -6.1242e-04,  4.4744e-04,  1.5228e-04, -3.8800e-04,
         6.2189e-04,  2.7692e-04,  3.8360e-04, -3.2007e-04,  1.9566e-04,
         8.2099e-05,  2.4850e-04, -1.5261e-04,  2.0153e-04,  5.3163e-05,
        -4.0571e-04, -2.6491e-04,  6.0232e-04, -2.4630e-04,  3.0302e-05,
         7.0577e-05,  4.9334e-04,  7.0888e-06,  5.3421e-04, -5.7987e-04,
        -1.1146e-04,  1.4504e-04,  1.2578e-04,  1.3634e-04,  3.5086e-04,
         1.2939e-04,  6.3802e-04, -3.8450e-07,  4.8549e-04,  1.4027e-04,
        -2.5592e-04, -2.3056e-04,  6.2824e-04, -3.4592e-04,  3.9558e-04,
         6.9244e-05,  3.5914e-05, -6.2147e-04, -1.4026e-04,  4.0391e-04,
         6.3826e-04], device='cuda:0', requires_grad=True)

name linear2.weight 
shape:
 torch.Size([2350554, 256]) 
grad:
 True 
date:
 tensor([[ 0.0358,  0.0384,  0.0002,  ...,  0.0060, -0.0352,  0.0224],
        [ 0.0208,  0.0591,  0.0333,  ...,  0.0428, -0.0580,  0.0220],
        [ 0.0402, -0.0183, -0.0485,  ..., -0.0420, -0.0518,  0.0149],
        ...,
        [ 0.0046, -0.0082, -0.0227,  ..., -0.0332, -0.0202, -0.0606],
        [ 0.0141,  0.0163,  0.0243,  ..., -0.0188, -0.0427, -0.0160],
        [-0.0226,  0.0545,  0.0161,  ...,  0.0191, -0.0612, -0.0101]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0358,  0.0384,  0.0002,  ...,  0.0060, -0.0352,  0.0224],
        [ 0.0208,  0.0591,  0.0333,  ...,  0.0428, -0.0580,  0.0220],
        [ 0.0402, -0.0183, -0.0485,  ..., -0.0420, -0.0518,  0.0149],
        ...,
        [ 0.0046, -0.0082, -0.0227,  ..., -0.0332, -0.0202, -0.0606],
        [ 0.0141,  0.0163,  0.0243,  ..., -0.0188, -0.0427, -0.0160],
        [-0.0226,  0.0545,  0.0161,  ...,  0.0191, -0.0612, -0.0101]],
       device='cuda:0', requires_grad=True)

name linear2.bias 
shape:
 torch.Size([2350554]) 
grad:
 True 
date:
 tensor([-0.0356, -0.0089,  0.0386,  ...,  0.0194,  0.0599, -0.0598],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([-0.0356, -0.0089,  0.0386,  ...,  0.0194,  0.0599, -0.0598],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0844,  0.0870,  0.0435,  ...,  0.1222, -0.0010, -0.0366],
        [-0.0448,  0.1083, -0.1076,  ...,  0.0211, -0.0825, -0.1174],
        [-0.0788,  0.0052, -0.0689,  ...,  0.0544,  0.0657,  0.0533],
        ...,
        [ 0.0029,  0.1241, -0.0191,  ...,  0.0340,  0.0530,  0.0634],
        [ 0.1188,  0.0293, -0.0028,  ...,  0.0880, -0.0899, -0.1008],
        [-0.0222,  0.0845,  0.0690,  ..., -0.0763,  0.0683,  0.0330]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0844,  0.0870,  0.0435,  ...,  0.1222, -0.0010, -0.0366],
        [-0.0448,  0.1083, -0.1076,  ...,  0.0211, -0.0825, -0.1174],
        [-0.0788,  0.0052, -0.0689,  ...,  0.0544,  0.0657,  0.0533],
        ...,
        [ 0.0029,  0.1241, -0.0191,  ...,  0.0340,  0.0530,  0.0634],
        [ 0.1188,  0.0293, -0.0028,  ...,  0.0880, -0.0899, -0.1008],
        [-0.0222,  0.0845,  0.0690,  ..., -0.0763,  0.0683,  0.0330]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0812,  0.1733, -0.0955,  ...,  0.0772,  0.1572, -0.0468],
        [-0.0259,  0.1555, -0.1286,  ..., -0.1227,  0.0510,  0.1147],
        [-0.1666,  0.0459,  0.1401,  ...,  0.1102, -0.1491, -0.1285],
        ...,
        [-0.1363, -0.0012,  0.0866,  ..., -0.0787, -0.0698, -0.0149],
        [-0.0557, -0.0961,  0.1002,  ...,  0.1162,  0.0236,  0.1720],
        [ 0.1476, -0.1589,  0.0323,  ..., -0.0619,  0.1029, -0.0235]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0812,  0.1733, -0.0955,  ...,  0.0772,  0.1572, -0.0468],
        [-0.0259,  0.1555, -0.1286,  ..., -0.1227,  0.0510,  0.1147],
        [-0.1666,  0.0459,  0.1401,  ...,  0.1102, -0.1491, -0.1285],
        ...,
        [-0.1363, -0.0012,  0.0866,  ..., -0.0787, -0.0698, -0.0149],
        [-0.0557, -0.0961,  0.1002,  ...,  0.1162,  0.0236,  0.1720],
        [ 0.1476, -0.1589,  0.0323,  ..., -0.0619,  0.1029, -0.0235]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[-0.2194, -0.0582, -0.2255,  ...,  0.0620,  0.0148,  0.0141],
        [ 0.2316, -0.1753,  0.1516,  ...,  0.2467,  0.0912, -0.1766],
        [ 0.2329,  0.1374, -0.1877,  ..., -0.1011, -0.2471, -0.1904],
        ...,
        [-0.0229,  0.1799,  0.0445,  ...,  0.1924, -0.2303, -0.1398],
        [-0.0600,  0.0569, -0.0014,  ...,  0.1573,  0.2446, -0.0279],
        [-0.0943, -0.1236,  0.1450,  ...,  0.0151,  0.2041,  0.0481]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.2194, -0.0582, -0.2255,  ...,  0.0620,  0.0148,  0.0141],
        [ 0.2316, -0.1753,  0.1516,  ...,  0.2467,  0.0912, -0.1766],
        [ 0.2329,  0.1374, -0.1877,  ..., -0.1011, -0.2471, -0.1904],
        ...,
        [-0.0229,  0.1799,  0.0445,  ...,  0.1924, -0.2303, -0.1398],
        [-0.0600,  0.0569, -0.0014,  ...,  0.1573,  0.2446, -0.0279],
        [-0.0943, -0.1236,  0.1450,  ...,  0.0151,  0.2041,  0.0481]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[ 0.2843],
        [-0.2469],
        [-0.1415],
        [-0.3647],
        [-0.0105],
        [-0.0051],
        [ 0.3779],
        [-0.0439],
        [ 0.4220],
        [ 0.1517],
        [-0.0848],
        [-0.0231],
        [ 0.1695],
        [-0.3684],
        [ 0.0266],
        [ 0.0240],
        [-0.3587],
        [-0.1705],
        [-0.0651],
        [ 0.3035],
        [-0.2359],
        [-0.1819],
        [-0.1436],
        [ 0.0108],
        [ 0.1898],
        [ 0.1784],
        [-0.3658],
        [-0.1652],
        [-0.2030],
        [-0.1296],
        [-0.1190],
        [ 0.1056]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.2843],
        [-0.2469],
        [-0.1415],
        [-0.3647],
        [-0.0105],
        [-0.0051],
        [ 0.3779],
        [-0.0439],
        [ 0.4220],
        [ 0.1517],
        [-0.0848],
        [-0.0231],
        [ 0.1695],
        [-0.3684],
        [ 0.0266],
        [ 0.0240],
        [-0.3587],
        [-0.1705],
        [-0.0651],
        [ 0.3035],
        [-0.2359],
        [-0.1819],
        [-0.1436],
        [ 0.0108],
        [ 0.1898],
        [ 0.1784],
        [-0.3658],
        [-0.1652],
        [-0.2030],
        [-0.1296],
        [-0.1190],
        [ 0.1056]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet] tensor([[0.2513],
        [0.0000],
        [0.0000],
        ...,
        [0.0000],
        [0.1922],
        [0.0000]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(208734.5156, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(-85.7943, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(10.7032, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(11.4509, device='cuda:0')



h[100].sum tensor(0.9134, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(0.9772, device='cuda:0')



h[200].sum tensor(-6.1337, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-6.5622, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(29150.9688, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2183e-02, 0.0000e+00,
         1.4448e-04],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.0964e-03, 0.0000e+00,
         4.8579e-05],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.5367e-03, 0.0000e+00,
         1.8223e-05],
        ...,
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00]], device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(673514.1875, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-242.2854, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-149.9448, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-293.4578, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[0.1432],
        [0.1135],
        [0.0832],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(48205.6016, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.2513],
        [0.0000],
        [0.0000],
        ...,
        [0.0000],
        [0.1922],
        [0.0000]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet].sum tensor(208734.5156, device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[0.1432],
        [0.1135],
        [0.0832],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndneiefet.py", line 5, in <module>
    from ModelBha2ndneiefet import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 208, in <module>
    result2 = net(batcheddglgraph, batten)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 63, in forward
    he = self.linear1(g.edata['efet'].reshape(1, 2350554))
RuntimeError: shape '[1, 2350554]' is invalid for input of size 47011080

real	1m15.017s
user	0m35.541s
sys	0m9.666s
