0: cmsgpu001.ihep.ac.cn
GPU 0: NVIDIA A100-PCIE-40GB (UUID: GPU-83673d1f-01b2-490d-5bc6-a84aaf3ddc65)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.80.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.80.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        9B:9E:55:A9:86:D9:50:0B:6D:2D:9F:BA:A7:E6:45:39:D4:DD:5F:C6
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Jan  9 17:16:21 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   28C    P0    33W / 250W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: NVIDIA A100-PCIE-40GB

 CUDA Device Total Memory [GB]: 42.358472704

 Device capability: (8, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b8ac2572880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m5.048s
user	0m2.674s
sys	0m0.997s




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[ 0.7332],
        [ 0.8347],
        [ 0.1584],
        ...,
        [ 0.6470],
        [-1.9437],
        [ 1.2442]], device='cuda:0', requires_grad=True) 
node features sum: tensor(26.7562, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (linear1): Linear(in_features=2350554, out_features=32, bias=True)
  (linear2): Linear(in_features=32, out_features=2350554, bias=True)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 152829819

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.1244,  0.0297,  0.0507, -0.1140,  0.0821,  0.0044, -0.0086,  0.1081,
          0.0613, -0.0687,  0.1389, -0.1130, -0.0207, -0.0715,  0.0662, -0.1193,
         -0.0717, -0.1367,  0.1357,  0.0892, -0.0080, -0.0187,  0.0232,  0.1341,
          0.0156,  0.0803,  0.0797, -0.0488,  0.0245, -0.0590,  0.0736,  0.1093,
         -0.0437, -0.0999,  0.1382,  0.1204,  0.0350,  0.1049, -0.0567,  0.0109,
         -0.1192,  0.1112, -0.0175,  0.0455,  0.1418, -0.0848, -0.0239,  0.0137,
         -0.0448,  0.0499,  0.1415, -0.1265, -0.0075, -0.1122, -0.0207,  0.0070,
          0.1300,  0.0389,  0.0413,  0.0250,  0.0977, -0.0342,  0.1242, -0.0566,
         -0.1167, -0.1352,  0.0550,  0.0989,  0.0622, -0.1226,  0.1207, -0.0016,
         -0.0744, -0.0626, -0.1197,  0.1384, -0.0466,  0.0616,  0.0678, -0.0960,
          0.0223, -0.0996,  0.1257, -0.0015,  0.0451, -0.0352,  0.0083,  0.0998,
          0.0701,  0.0915, -0.0466, -0.1063,  0.1134,  0.0522, -0.0365,  0.0184,
          0.0563,  0.0804,  0.0077, -0.0263,  0.0229,  0.0944,  0.0036, -0.0560,
          0.0095,  0.1403, -0.1149,  0.1141, -0.1112,  0.0146, -0.1356, -0.0081,
          0.1148,  0.0781, -0.0020, -0.1100,  0.0144, -0.1495, -0.0479,  0.0629,
         -0.0286,  0.1382,  0.0614, -0.0750,  0.1475, -0.0495, -0.0157, -0.1008,
         -0.0723,  0.0123,  0.1491, -0.1075, -0.1100, -0.0529,  0.1228, -0.0915,
          0.1403, -0.0903,  0.1209, -0.0464, -0.0212, -0.0458,  0.0078,  0.0800,
          0.1519, -0.0005,  0.0494,  0.0444, -0.0092,  0.0471, -0.0508, -0.1110,
         -0.0605,  0.0641,  0.0592, -0.1258,  0.0962, -0.0798, -0.0238, -0.0915,
          0.0285, -0.1250, -0.1032,  0.0579, -0.0293, -0.0723, -0.0536, -0.0509,
          0.0574, -0.0951,  0.1209, -0.1243,  0.0210, -0.0787, -0.0850, -0.0349,
         -0.0993, -0.1497, -0.0117, -0.0995, -0.0541,  0.0808, -0.0817, -0.0798,
         -0.1418,  0.0180,  0.0438, -0.1375, -0.1124,  0.1196, -0.1321, -0.0980,
          0.0512, -0.0069, -0.0815, -0.1359,  0.1238,  0.1171, -0.0254, -0.0012,
          0.1388,  0.1471, -0.0719, -0.0035,  0.0490, -0.1265, -0.0404, -0.1311,
          0.0235, -0.0989,  0.0671, -0.0514,  0.0415, -0.1149,  0.1307, -0.1287,
          0.0781, -0.0960,  0.1488,  0.1447, -0.0753,  0.0994, -0.0241,  0.0191,
         -0.0218,  0.0629, -0.0213, -0.0236,  0.0867, -0.0110,  0.1286,  0.1004,
         -0.0140,  0.0422, -0.0927, -0.0155, -0.0692, -0.1106,  0.1398,  0.1483,
          0.1134,  0.0141,  0.0079, -0.0671, -0.1343,  0.1052, -0.0914,  0.1502,
          0.1172,  0.0148, -0.0703,  0.0238,  0.0220,  0.0810, -0.0961,  0.0292]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1244,  0.0297,  0.0507, -0.1140,  0.0821,  0.0044, -0.0086,  0.1081,
          0.0613, -0.0687,  0.1389, -0.1130, -0.0207, -0.0715,  0.0662, -0.1193,
         -0.0717, -0.1367,  0.1357,  0.0892, -0.0080, -0.0187,  0.0232,  0.1341,
          0.0156,  0.0803,  0.0797, -0.0488,  0.0245, -0.0590,  0.0736,  0.1093,
         -0.0437, -0.0999,  0.1382,  0.1204,  0.0350,  0.1049, -0.0567,  0.0109,
         -0.1192,  0.1112, -0.0175,  0.0455,  0.1418, -0.0848, -0.0239,  0.0137,
         -0.0448,  0.0499,  0.1415, -0.1265, -0.0075, -0.1122, -0.0207,  0.0070,
          0.1300,  0.0389,  0.0413,  0.0250,  0.0977, -0.0342,  0.1242, -0.0566,
         -0.1167, -0.1352,  0.0550,  0.0989,  0.0622, -0.1226,  0.1207, -0.0016,
         -0.0744, -0.0626, -0.1197,  0.1384, -0.0466,  0.0616,  0.0678, -0.0960,
          0.0223, -0.0996,  0.1257, -0.0015,  0.0451, -0.0352,  0.0083,  0.0998,
          0.0701,  0.0915, -0.0466, -0.1063,  0.1134,  0.0522, -0.0365,  0.0184,
          0.0563,  0.0804,  0.0077, -0.0263,  0.0229,  0.0944,  0.0036, -0.0560,
          0.0095,  0.1403, -0.1149,  0.1141, -0.1112,  0.0146, -0.1356, -0.0081,
          0.1148,  0.0781, -0.0020, -0.1100,  0.0144, -0.1495, -0.0479,  0.0629,
         -0.0286,  0.1382,  0.0614, -0.0750,  0.1475, -0.0495, -0.0157, -0.1008,
         -0.0723,  0.0123,  0.1491, -0.1075, -0.1100, -0.0529,  0.1228, -0.0915,
          0.1403, -0.0903,  0.1209, -0.0464, -0.0212, -0.0458,  0.0078,  0.0800,
          0.1519, -0.0005,  0.0494,  0.0444, -0.0092,  0.0471, -0.0508, -0.1110,
         -0.0605,  0.0641,  0.0592, -0.1258,  0.0962, -0.0798, -0.0238, -0.0915,
          0.0285, -0.1250, -0.1032,  0.0579, -0.0293, -0.0723, -0.0536, -0.0509,
          0.0574, -0.0951,  0.1209, -0.1243,  0.0210, -0.0787, -0.0850, -0.0349,
         -0.0993, -0.1497, -0.0117, -0.0995, -0.0541,  0.0808, -0.0817, -0.0798,
         -0.1418,  0.0180,  0.0438, -0.1375, -0.1124,  0.1196, -0.1321, -0.0980,
          0.0512, -0.0069, -0.0815, -0.1359,  0.1238,  0.1171, -0.0254, -0.0012,
          0.1388,  0.1471, -0.0719, -0.0035,  0.0490, -0.1265, -0.0404, -0.1311,
          0.0235, -0.0989,  0.0671, -0.0514,  0.0415, -0.1149,  0.1307, -0.1287,
          0.0781, -0.0960,  0.1488,  0.1447, -0.0753,  0.0994, -0.0241,  0.0191,
         -0.0218,  0.0629, -0.0213, -0.0236,  0.0867, -0.0110,  0.1286,  0.1004,
         -0.0140,  0.0422, -0.0927, -0.0155, -0.0692, -0.1106,  0.1398,  0.1483,
          0.1134,  0.0141,  0.0079, -0.0671, -0.1343,  0.1052, -0.0914,  0.1502,
          0.1172,  0.0148, -0.0703,  0.0238,  0.0220,  0.0810, -0.0961,  0.0292]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name linear1.weight 
shape:
 torch.Size([32, 2350554]) 
grad:
 True 
date:
 tensor([[-2.7594e-04, -3.9545e-04, -5.2932e-04,  ...,  2.2638e-04,
         -1.5009e-05, -3.6572e-05],
        [-2.3752e-05,  6.0006e-05,  1.8203e-04,  ..., -4.1192e-04,
          2.8880e-04,  3.9790e-04],
        [ 5.1967e-05, -4.3888e-04, -5.9186e-04,  ..., -3.1970e-04,
          2.3225e-04,  2.1156e-04],
        ...,
        [ 4.9937e-04,  6.3718e-04,  5.9751e-04,  ...,  1.7410e-04,
          3.0796e-04, -8.3050e-05],
        [ 4.5436e-04, -5.2169e-04, -2.4289e-04,  ...,  9.3846e-06,
          4.7821e-04,  3.6121e-04],
        [-4.7358e-04, -4.8927e-04, -1.1067e-04,  ..., -5.2911e-05,
          5.6585e-04, -3.5768e-04]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-2.7594e-04, -3.9545e-04, -5.2932e-04,  ...,  2.2638e-04,
         -1.5009e-05, -3.6572e-05],
        [-2.3752e-05,  6.0006e-05,  1.8203e-04,  ..., -4.1192e-04,
          2.8880e-04,  3.9790e-04],
        [ 5.1967e-05, -4.3888e-04, -5.9186e-04,  ..., -3.1970e-04,
          2.3225e-04,  2.1156e-04],
        ...,
        [ 4.9937e-04,  6.3718e-04,  5.9751e-04,  ...,  1.7410e-04,
          3.0796e-04, -8.3050e-05],
        [ 4.5436e-04, -5.2169e-04, -2.4289e-04,  ...,  9.3846e-06,
          4.7821e-04,  3.6121e-04],
        [-4.7358e-04, -4.8927e-04, -1.1067e-04,  ..., -5.2911e-05,
          5.6585e-04, -3.5768e-04]], device='cuda:0', requires_grad=True)

name linear1.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([-5.0970e-05, -1.0267e-04,  2.5414e-04, -3.3427e-04, -4.9486e-05,
        -2.9141e-04, -2.1358e-04,  5.1894e-04,  4.2506e-04, -6.3566e-04,
         7.0879e-05,  5.1654e-04, -8.3856e-05,  4.1887e-04, -3.9800e-04,
        -5.5026e-04,  2.8897e-04, -1.0576e-04,  6.1289e-04, -2.4039e-04,
        -3.0098e-04, -2.2026e-04, -5.9815e-04,  4.8917e-04,  4.9068e-04,
         5.3212e-04, -5.6349e-04,  1.8284e-04,  9.7458e-06,  4.5544e-04,
         9.1917e-06,  5.2769e-04], device='cuda:0') 
parameter:
 Parameter containing:
tensor([-5.0970e-05, -1.0267e-04,  2.5414e-04, -3.3427e-04, -4.9486e-05,
        -2.9141e-04, -2.1358e-04,  5.1894e-04,  4.2506e-04, -6.3566e-04,
         7.0879e-05,  5.1654e-04, -8.3856e-05,  4.1887e-04, -3.9800e-04,
        -5.5026e-04,  2.8897e-04, -1.0576e-04,  6.1289e-04, -2.4039e-04,
        -3.0098e-04, -2.2026e-04, -5.9815e-04,  4.8917e-04,  4.9068e-04,
         5.3212e-04, -5.6349e-04,  1.8284e-04,  9.7458e-06,  4.5544e-04,
         9.1917e-06,  5.2769e-04], device='cuda:0', requires_grad=True)

name linear2.weight 
shape:
 torch.Size([2350554, 32]) 
grad:
 True 
date:
 tensor([[ 0.1045, -0.0982, -0.0170,  ..., -0.1407, -0.1281, -0.0968],
        [-0.1191, -0.1028, -0.1061,  ..., -0.1099,  0.0483, -0.0026],
        [-0.1720,  0.0716,  0.0503,  ...,  0.0679,  0.0145,  0.0442],
        ...,
        [-0.0878,  0.0598,  0.0140,  ..., -0.1585,  0.0507,  0.1666],
        [-0.0827, -0.0169, -0.1530,  ..., -0.0895, -0.1221,  0.1140],
        [ 0.1279, -0.1060, -0.1730,  ..., -0.0028,  0.0726,  0.1607]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1045, -0.0982, -0.0170,  ..., -0.1407, -0.1281, -0.0968],
        [-0.1191, -0.1028, -0.1061,  ..., -0.1099,  0.0483, -0.0026],
        [-0.1720,  0.0716,  0.0503,  ...,  0.0679,  0.0145,  0.0442],
        ...,
        [-0.0878,  0.0598,  0.0140,  ..., -0.1585,  0.0507,  0.1666],
        [-0.0827, -0.0169, -0.1530,  ..., -0.0895, -0.1221,  0.1140],
        [ 0.1279, -0.1060, -0.1730,  ..., -0.0028,  0.0726,  0.1607]],
       device='cuda:0', requires_grad=True)

name linear2.bias 
shape:
 torch.Size([2350554]) 
grad:
 True 
date:
 tensor([-0.0143, -0.0894, -0.1361,  ..., -0.0167,  0.0435, -0.0205],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([-0.0143, -0.0894, -0.1361,  ..., -0.0167,  0.0435, -0.0205],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0218,  0.0949,  0.0513,  ...,  0.0676,  0.0152, -0.0315],
        [-0.0529, -0.0807, -0.0052,  ...,  0.0223,  0.0036,  0.1162],
        [ 0.1136,  0.1022,  0.0938,  ...,  0.0559, -0.0303, -0.0045],
        ...,
        [ 0.1033,  0.0201, -0.0309,  ...,  0.0044,  0.0288,  0.0877],
        [-0.0930, -0.0083,  0.0353,  ...,  0.0187, -0.0896,  0.1112],
        [ 0.1223, -0.0500, -0.0026,  ..., -0.0669,  0.0766, -0.0841]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0218,  0.0949,  0.0513,  ...,  0.0676,  0.0152, -0.0315],
        [-0.0529, -0.0807, -0.0052,  ...,  0.0223,  0.0036,  0.1162],
        [ 0.1136,  0.1022,  0.0938,  ...,  0.0559, -0.0303, -0.0045],
        ...,
        [ 0.1033,  0.0201, -0.0309,  ...,  0.0044,  0.0288,  0.0877],
        [-0.0930, -0.0083,  0.0353,  ...,  0.0187, -0.0896,  0.1112],
        [ 0.1223, -0.0500, -0.0026,  ..., -0.0669,  0.0766, -0.0841]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[ 0.0370, -0.0947,  0.0639,  ..., -0.0418, -0.0632,  0.1118],
        [-0.1262, -0.1417,  0.0954,  ...,  0.1475, -0.1189, -0.1718],
        [ 0.1292,  0.1635, -0.0031,  ...,  0.0730,  0.0684,  0.0714],
        ...,
        [-0.0719, -0.0776,  0.0637,  ...,  0.0574,  0.0993,  0.0612],
        [-0.0717,  0.0992,  0.1137,  ..., -0.0884,  0.0383, -0.1726],
        [-0.1259,  0.1236, -0.1310,  ...,  0.1727, -0.1730, -0.1155]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0370, -0.0947,  0.0639,  ..., -0.0418, -0.0632,  0.1118],
        [-0.1262, -0.1417,  0.0954,  ...,  0.1475, -0.1189, -0.1718],
        [ 0.1292,  0.1635, -0.0031,  ...,  0.0730,  0.0684,  0.0714],
        ...,
        [-0.0719, -0.0776,  0.0637,  ...,  0.0574,  0.0993,  0.0612],
        [-0.0717,  0.0992,  0.1137,  ..., -0.0884,  0.0383, -0.1726],
        [-0.1259,  0.1236, -0.1310,  ...,  0.1727, -0.1730, -0.1155]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.2414, -0.1507,  0.1713,  ..., -0.1859,  0.0883, -0.2055],
        [ 0.1986,  0.2445, -0.1363,  ..., -0.2374,  0.1313, -0.1330],
        [ 0.1674, -0.0241, -0.0416,  ...,  0.0506, -0.0395, -0.0484],
        ...,
        [-0.2098, -0.1200, -0.0157,  ..., -0.0865,  0.1343,  0.0813],
        [ 0.1126, -0.0049, -0.0177,  ..., -0.2218, -0.1649,  0.2402],
        [-0.1018,  0.0366,  0.0633,  ...,  0.2498, -0.0912,  0.1085]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.2414, -0.1507,  0.1713,  ..., -0.1859,  0.0883, -0.2055],
        [ 0.1986,  0.2445, -0.1363,  ..., -0.2374,  0.1313, -0.1330],
        [ 0.1674, -0.0241, -0.0416,  ...,  0.0506, -0.0395, -0.0484],
        ...,
        [-0.2098, -0.1200, -0.0157,  ..., -0.0865,  0.1343,  0.0813],
        [ 0.1126, -0.0049, -0.0177,  ..., -0.2218, -0.1649,  0.2402],
        [-0.1018,  0.0366,  0.0633,  ...,  0.2498, -0.0912,  0.1085]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[ 0.3341],
        [ 0.1775],
        [ 0.4248],
        [ 0.1011],
        [ 0.0505],
        [-0.3283],
        [-0.0151],
        [ 0.0949],
        [-0.3223],
        [-0.1716],
        [-0.0992],
        [-0.1008],
        [-0.2169],
        [-0.3606],
        [-0.1074],
        [ 0.3923],
        [-0.2978],
        [ 0.2822],
        [-0.3313],
        [-0.4193],
        [-0.0908],
        [ 0.2094],
        [ 0.2251],
        [ 0.3914],
        [-0.3677],
        [-0.2440],
        [-0.0445],
        [-0.1285],
        [-0.0413],
        [-0.3860],
        [ 0.3474],
        [-0.1979]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.3341],
        [ 0.1775],
        [ 0.4248],
        [ 0.1011],
        [ 0.0505],
        [-0.3283],
        [-0.0151],
        [ 0.0949],
        [-0.3223],
        [-0.1716],
        [-0.0992],
        [-0.1008],
        [-0.2169],
        [-0.3606],
        [-0.1074],
        [ 0.3923],
        [-0.2978],
        [ 0.2822],
        [-0.3313],
        [-0.4193],
        [-0.0908],
        [ 0.2094],
        [ 0.2251],
        [ 0.3914],
        [-0.3677],
        [-0.2440],
        [-0.0445],
        [-0.1285],
        [-0.0413],
        [-0.3860],
        [ 0.3474],
        [-0.1979]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)





 shepe: torch.Size([2350554, 1]) 









input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet] tensor([[0.4633],
        [0.0000],
        [0.1840],
        ...,
        [0.0000],
        [0.1210],
        [0.0000]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(254590.5625, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(140.3542, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(4.6122, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(4.9344, device='cuda:0')



h[100].sum tensor(4.6481, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(4.9728, device='cuda:0')



h[200].sum tensor(1.3852, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(1.4820, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(39693.5547, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[3.3242e-03, 1.6435e-04, 0.0000e+00,  ..., 0.0000e+00, 2.1107e-02,
         1.4820e-02],
        [3.9290e-03, 1.9436e-04, 0.0000e+00,  ..., 0.0000e+00, 2.4968e-02,
         1.7525e-02],
        [1.4674e-03, 7.3693e-05, 0.0000e+00,  ..., 0.0000e+00, 9.3358e-03,
         6.5511e-03],
        ...,
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00],
        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,
         0.0000e+00]], device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(1175707.1250, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(4050.6001, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(54.3800, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[7.6350],
        [5.9914],
        [4.2690],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(2343175.7500, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.4633],
        [0.0000],
        [0.1840],
        ...,
        [0.0000],
        [0.1210],
        [0.0000]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet].sum tensor(254590.5625, device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[7.6350],
        [5.9914],
        [4.2690],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])





 shepe: torch.Size([47011080, 1]) 









input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet] tensor([[0.0125],
        [0.0612],
        [0.0568],
        ...,
        [0.0000],
        [0.2034],
        [0.0753]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(4052530., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0199,  0.0014,  0.0200,  ..., -0.0159, -0.0148,  0.0049],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(940.3631, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-138.4350, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-148.6874, device='cuda:0')



h[100].sum tensor(60.4820, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(64.9613, device='cuda:0')



h[200].sum tensor(125.3371, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(134.6196, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0057, 0.0817,  ..., 0.0000, 0.0000, 0.0200],
        [0.0000, 0.0038, 0.0545,  ..., 0.0000, 0.0000, 0.0133],
        [0.0000, 0.0009, 0.0128,  ..., 0.0000, 0.0000, 0.0031],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(281185.1250, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0918, 0.2249, 0.0000,  ..., 0.3393, 0.0000, 0.0000],
        [0.0623, 0.1527, 0.0000,  ..., 0.2304, 0.0000, 0.0000],
        [0.0407, 0.0998, 0.0000,  ..., 0.1505, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(5969600., device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(41132.4023, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(728.4272, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-1.6937e+01],
        [-1.8563e+01],
        [-2.2630e+01],
        ...,
        [-4.7809e-04],
        [-6.8742e-04],
        [-6.9532e-04]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(-10008708., device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.0125],
        [0.0612],
        [0.0568],
        ...,
        [0.0000],
        [0.2034],
        [0.0753]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet].sum tensor(4052530., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[7.6350],
        [5.9914],
        [4.2690],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')



load_model False 
TraEvN 201 
BatchSize 15 
EpochNum 10 
epoch_save 5 
LrVal 0.0001 
weight_decay 5e-05 
startmesh 164 
endmesh 165 






optimizer.param_groups
 [{'params': [Parameter containing:
tensor([[-0.1503,  0.0106,  0.1515,  0.0929,  0.0887,  0.1306, -0.1227, -0.0925,
          0.0322, -0.0525,  0.1236, -0.0251, -0.0814, -0.1155,  0.1407, -0.1308,
          0.0697, -0.1487,  0.1067, -0.0486,  0.1366,  0.0954,  0.0765, -0.0588,
         -0.0247,  0.1389, -0.1444, -0.1278,  0.0555,  0.0101,  0.1450, -0.0283,
         -0.1085, -0.0707,  0.0390,  0.0042,  0.1346, -0.0956,  0.0785,  0.1519,
         -0.1109, -0.1464,  0.0033,  0.0115,  0.0638, -0.0593,  0.1197, -0.0084,
          0.1512, -0.1447,  0.1141,  0.0887, -0.0220, -0.0387,  0.0358,  0.1361,
          0.0464,  0.1059,  0.1235, -0.1099, -0.0475,  0.1211,  0.0719, -0.0319,
          0.1142, -0.0998,  0.0381, -0.0247,  0.1483,  0.0923, -0.0229, -0.0157,
         -0.0163,  0.0267,  0.0268, -0.1257,  0.0247,  0.1198, -0.0023, -0.0079,
         -0.1197,  0.0459,  0.0741, -0.0996,  0.1298,  0.0628,  0.1287, -0.1476,
          0.0420,  0.1514,  0.1121, -0.0451, -0.0176,  0.0837,  0.1431,  0.0151,
          0.0495, -0.0405,  0.0022,  0.0605,  0.0657, -0.0137, -0.1255, -0.0188,
          0.0335,  0.1272,  0.0074, -0.0407, -0.0460, -0.0807,  0.1255,  0.0682,
         -0.0187, -0.0685,  0.1467, -0.1423,  0.0458,  0.0710, -0.0051,  0.0617,
          0.0641, -0.0701,  0.0234,  0.0326,  0.0083, -0.1395,  0.0021,  0.0563,
          0.0854,  0.0813, -0.1077,  0.0813,  0.0129,  0.0506,  0.0458, -0.0441,
         -0.1092, -0.1442,  0.0592,  0.1267,  0.1443, -0.0243,  0.0676,  0.1251,
         -0.1483, -0.1021, -0.1040, -0.1203, -0.1154,  0.0326, -0.0588, -0.0072,
         -0.0276, -0.0266,  0.0895,  0.0611,  0.0206,  0.0686,  0.0539,  0.1423,
         -0.0944, -0.0232,  0.1386, -0.1114,  0.1161, -0.1457,  0.0474,  0.0852,
         -0.0151,  0.1108, -0.1044, -0.0420,  0.0897, -0.0958, -0.0776, -0.0638,
         -0.0753,  0.1371,  0.0511,  0.1438,  0.0082,  0.0649,  0.1153, -0.0225,
          0.0426,  0.0732,  0.1209, -0.1519,  0.0124, -0.1016,  0.0278, -0.0869,
          0.0042, -0.1254, -0.0040, -0.1229,  0.0406, -0.1112,  0.0204, -0.0616,
          0.1361, -0.0998, -0.0455, -0.1270, -0.1146,  0.0356,  0.0542, -0.0912,
         -0.1054,  0.0467, -0.0334,  0.0828,  0.1218, -0.1303, -0.1220, -0.0020,
         -0.0060, -0.0062, -0.0993,  0.0451, -0.0087,  0.0270, -0.1106,  0.1423,
          0.0722,  0.0580, -0.1215,  0.0618,  0.0068,  0.0370, -0.0364, -0.1234,
          0.1288,  0.0307, -0.0379, -0.0964,  0.0716, -0.0714,  0.0654, -0.0246,
         -0.0292,  0.0444,  0.0431, -0.0947, -0.1205, -0.0646, -0.1273, -0.0751,
         -0.1459,  0.1517,  0.0649,  0.0580, -0.0575, -0.1202, -0.1120,  0.0371]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-5.0347e-05,  3.0203e-04, -1.3198e-04,  ...,  4.2273e-04,
          4.8291e-04,  2.9479e-04],
        [-5.9748e-04,  4.7767e-04,  4.4157e-04,  ...,  2.4269e-05,
          3.2128e-04,  4.0467e-04],
        [ 3.1290e-04,  2.6237e-04, -2.3680e-04,  ..., -3.8173e-04,
         -5.9815e-04,  3.4600e-04],
        ...,
        [-1.0070e-04, -3.7234e-04, -3.3382e-04,  ...,  4.7578e-04,
          1.5636e-04,  2.3876e-04],
        [ 6.3726e-04, -6.0955e-04,  5.4707e-04,  ...,  1.5129e-04,
         -1.2063e-05, -3.6808e-04],
        [-3.1445e-04, -2.0817e-04,  3.2159e-04,  ...,  5.2171e-04,
         -2.2029e-04,  4.8916e-05]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-5.5539e-04, -6.0131e-04,  4.6256e-04,  6.1140e-04, -2.7160e-04,
         3.0583e-04,  8.4011e-05,  2.8077e-04,  4.2732e-04, -4.6375e-04,
        -3.3113e-05, -3.5210e-05, -5.1634e-04, -3.1572e-04, -2.1485e-04,
        -1.6585e-04,  5.0857e-04,  1.8823e-04, -3.2573e-05, -5.4343e-04,
        -1.9328e-04,  9.8320e-07,  3.2989e-04,  1.8393e-04,  5.2632e-04,
        -2.5219e-04, -4.0095e-04,  5.6030e-04, -5.7938e-04,  6.3645e-04,
         5.0339e-04, -1.0295e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1371,  0.0602, -0.0607,  ...,  0.0158, -0.1559,  0.1608],
        [-0.1490,  0.0522,  0.0815,  ..., -0.0525,  0.0595, -0.0468],
        [-0.0064, -0.0158,  0.0693,  ...,  0.0336, -0.0199, -0.0269],
        ...,
        [ 0.1403,  0.1223,  0.0241,  ...,  0.0891, -0.0720,  0.1542],
        [-0.1296, -0.0547, -0.1598,  ...,  0.0640,  0.0514, -0.0251],
        [-0.1173, -0.0424,  0.1311,  ...,  0.1651,  0.1646, -0.1065]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0663,  0.0741,  0.1037,  ..., -0.1103,  0.0482,  0.1574],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0496, -0.0248,  0.1150,  ...,  0.0297, -0.0031,  0.0781],
        [-0.1091, -0.0889,  0.0359,  ...,  0.0017, -0.0281, -0.1146],
        [-0.0120, -0.0571, -0.0169,  ..., -0.1079, -0.1070, -0.0749],
        ...,
        [-0.0239, -0.0245,  0.0741,  ...,  0.0096,  0.1011, -0.0839],
        [ 0.0230,  0.0590, -0.0907,  ...,  0.1035,  0.0293,  0.0540],
        [ 0.0786,  0.1196, -0.0959,  ..., -0.0137, -0.0843, -0.0435]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0144,  0.1009, -0.0625,  ...,  0.1267, -0.0831, -0.1129],
        [ 0.1168,  0.0862,  0.0006,  ..., -0.0059,  0.0619, -0.0611],
        [-0.1535, -0.1713, -0.1252,  ..., -0.1711,  0.0173, -0.1174],
        ...,
        [ 0.0368, -0.1282,  0.0609,  ..., -0.0168, -0.0602,  0.1309],
        [-0.0518, -0.0574,  0.1629,  ...,  0.1064,  0.1334,  0.0209],
        [ 0.1523,  0.0770, -0.0681,  ..., -0.1619,  0.0587, -0.0064]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0698, -0.0547,  0.2265,  ..., -0.0827, -0.0947,  0.2413],
        [-0.0522, -0.2239,  0.0468,  ..., -0.1992,  0.2246,  0.0786],
        [ 0.0768, -0.1641, -0.1247,  ..., -0.1830,  0.0494,  0.2370],
        ...,
        [ 0.1652,  0.0955, -0.2066,  ..., -0.0985,  0.0130,  0.2342],
        [-0.0495,  0.0509,  0.2460,  ...,  0.1789, -0.0009, -0.2247],
        [ 0.0124,  0.2133,  0.0767,  ...,  0.1127,  0.1602,  0.0868]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.2159],
        [ 0.3116],
        [-0.2938],
        [-0.1707],
        [ 0.0044],
        [-0.0481],
        [-0.2443],
        [-0.1874],
        [-0.3154],
        [ 0.1261],
        [ 0.3538],
        [ 0.2730],
        [-0.4242],
        [-0.2399],
        [-0.1299],
        [-0.1438],
        [-0.3686],
        [-0.3730],
        [-0.2935],
        [-0.1684],
        [ 0.0129],
        [ 0.3476],
        [-0.3038],
        [-0.2430],
        [-0.3073],
        [ 0.0798],
        [-0.1392],
        [ 0.2112],
        [ 0.2943],
        [-0.0249],
        [-0.0566],
        [ 0.4045]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]



optimizer.param_groups after adding efet as parameters
 [{'params': [Parameter containing:
tensor([[-0.1503,  0.0106,  0.1515,  0.0929,  0.0887,  0.1306, -0.1227, -0.0925,
          0.0322, -0.0525,  0.1236, -0.0251, -0.0814, -0.1155,  0.1407, -0.1308,
          0.0697, -0.1487,  0.1067, -0.0486,  0.1366,  0.0954,  0.0765, -0.0588,
         -0.0247,  0.1389, -0.1444, -0.1278,  0.0555,  0.0101,  0.1450, -0.0283,
         -0.1085, -0.0707,  0.0390,  0.0042,  0.1346, -0.0956,  0.0785,  0.1519,
         -0.1109, -0.1464,  0.0033,  0.0115,  0.0638, -0.0593,  0.1197, -0.0084,
          0.1512, -0.1447,  0.1141,  0.0887, -0.0220, -0.0387,  0.0358,  0.1361,
          0.0464,  0.1059,  0.1235, -0.1099, -0.0475,  0.1211,  0.0719, -0.0319,
          0.1142, -0.0998,  0.0381, -0.0247,  0.1483,  0.0923, -0.0229, -0.0157,
         -0.0163,  0.0267,  0.0268, -0.1257,  0.0247,  0.1198, -0.0023, -0.0079,
         -0.1197,  0.0459,  0.0741, -0.0996,  0.1298,  0.0628,  0.1287, -0.1476,
          0.0420,  0.1514,  0.1121, -0.0451, -0.0176,  0.0837,  0.1431,  0.0151,
          0.0495, -0.0405,  0.0022,  0.0605,  0.0657, -0.0137, -0.1255, -0.0188,
          0.0335,  0.1272,  0.0074, -0.0407, -0.0460, -0.0807,  0.1255,  0.0682,
         -0.0187, -0.0685,  0.1467, -0.1423,  0.0458,  0.0710, -0.0051,  0.0617,
          0.0641, -0.0701,  0.0234,  0.0326,  0.0083, -0.1395,  0.0021,  0.0563,
          0.0854,  0.0813, -0.1077,  0.0813,  0.0129,  0.0506,  0.0458, -0.0441,
         -0.1092, -0.1442,  0.0592,  0.1267,  0.1443, -0.0243,  0.0676,  0.1251,
         -0.1483, -0.1021, -0.1040, -0.1203, -0.1154,  0.0326, -0.0588, -0.0072,
         -0.0276, -0.0266,  0.0895,  0.0611,  0.0206,  0.0686,  0.0539,  0.1423,
         -0.0944, -0.0232,  0.1386, -0.1114,  0.1161, -0.1457,  0.0474,  0.0852,
         -0.0151,  0.1108, -0.1044, -0.0420,  0.0897, -0.0958, -0.0776, -0.0638,
         -0.0753,  0.1371,  0.0511,  0.1438,  0.0082,  0.0649,  0.1153, -0.0225,
          0.0426,  0.0732,  0.1209, -0.1519,  0.0124, -0.1016,  0.0278, -0.0869,
          0.0042, -0.1254, -0.0040, -0.1229,  0.0406, -0.1112,  0.0204, -0.0616,
          0.1361, -0.0998, -0.0455, -0.1270, -0.1146,  0.0356,  0.0542, -0.0912,
         -0.1054,  0.0467, -0.0334,  0.0828,  0.1218, -0.1303, -0.1220, -0.0020,
         -0.0060, -0.0062, -0.0993,  0.0451, -0.0087,  0.0270, -0.1106,  0.1423,
          0.0722,  0.0580, -0.1215,  0.0618,  0.0068,  0.0370, -0.0364, -0.1234,
          0.1288,  0.0307, -0.0379, -0.0964,  0.0716, -0.0714,  0.0654, -0.0246,
         -0.0292,  0.0444,  0.0431, -0.0947, -0.1205, -0.0646, -0.1273, -0.0751,
         -0.1459,  0.1517,  0.0649,  0.0580, -0.0575, -0.1202, -0.1120,  0.0371]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-5.0347e-05,  3.0203e-04, -1.3198e-04,  ...,  4.2273e-04,
          4.8291e-04,  2.9479e-04],
        [-5.9748e-04,  4.7767e-04,  4.4157e-04,  ...,  2.4269e-05,
          3.2128e-04,  4.0467e-04],
        [ 3.1290e-04,  2.6237e-04, -2.3680e-04,  ..., -3.8173e-04,
         -5.9815e-04,  3.4600e-04],
        ...,
        [-1.0070e-04, -3.7234e-04, -3.3382e-04,  ...,  4.7578e-04,
          1.5636e-04,  2.3876e-04],
        [ 6.3726e-04, -6.0955e-04,  5.4707e-04,  ...,  1.5129e-04,
         -1.2063e-05, -3.6808e-04],
        [-3.1445e-04, -2.0817e-04,  3.2159e-04,  ...,  5.2171e-04,
         -2.2029e-04,  4.8916e-05]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([-5.5539e-04, -6.0131e-04,  4.6256e-04,  6.1140e-04, -2.7160e-04,
         3.0583e-04,  8.4011e-05,  2.8077e-04,  4.2732e-04, -4.6375e-04,
        -3.3113e-05, -3.5210e-05, -5.1634e-04, -3.1572e-04, -2.1485e-04,
        -1.6585e-04,  5.0857e-04,  1.8823e-04, -3.2573e-05, -5.4343e-04,
        -1.9328e-04,  9.8320e-07,  3.2989e-04,  1.8393e-04,  5.2632e-04,
        -2.5219e-04, -4.0095e-04,  5.6030e-04, -5.7938e-04,  6.3645e-04,
         5.0339e-04, -1.0295e-04], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1371,  0.0602, -0.0607,  ...,  0.0158, -0.1559,  0.1608],
        [-0.1490,  0.0522,  0.0815,  ..., -0.0525,  0.0595, -0.0468],
        [-0.0064, -0.0158,  0.0693,  ...,  0.0336, -0.0199, -0.0269],
        ...,
        [ 0.1403,  0.1223,  0.0241,  ...,  0.0891, -0.0720,  0.1542],
        [-0.1296, -0.0547, -0.1598,  ...,  0.0640,  0.0514, -0.0251],
        [-0.1173, -0.0424,  0.1311,  ...,  0.1651,  0.1646, -0.1065]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0663,  0.0741,  0.1037,  ..., -0.1103,  0.0482,  0.1574],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0496, -0.0248,  0.1150,  ...,  0.0297, -0.0031,  0.0781],
        [-0.1091, -0.0889,  0.0359,  ...,  0.0017, -0.0281, -0.1146],
        [-0.0120, -0.0571, -0.0169,  ..., -0.1079, -0.1070, -0.0749],
        ...,
        [-0.0239, -0.0245,  0.0741,  ...,  0.0096,  0.1011, -0.0839],
        [ 0.0230,  0.0590, -0.0907,  ...,  0.1035,  0.0293,  0.0540],
        [ 0.0786,  0.1196, -0.0959,  ..., -0.0137, -0.0843, -0.0435]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.0144,  0.1009, -0.0625,  ...,  0.1267, -0.0831, -0.1129],
        [ 0.1168,  0.0862,  0.0006,  ..., -0.0059,  0.0619, -0.0611],
        [-0.1535, -0.1713, -0.1252,  ..., -0.1711,  0.0173, -0.1174],
        ...,
        [ 0.0368, -0.1282,  0.0609,  ..., -0.0168, -0.0602,  0.1309],
        [-0.0518, -0.0574,  0.1629,  ...,  0.1064,  0.1334,  0.0209],
        [ 0.1523,  0.0770, -0.0681,  ..., -0.1619,  0.0587, -0.0064]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.0698, -0.0547,  0.2265,  ..., -0.0827, -0.0947,  0.2413],
        [-0.0522, -0.2239,  0.0468,  ..., -0.1992,  0.2246,  0.0786],
        [ 0.0768, -0.1641, -0.1247,  ..., -0.1830,  0.0494,  0.2370],
        ...,
        [ 0.1652,  0.0955, -0.2066,  ..., -0.0985,  0.0130,  0.2342],
        [-0.0495,  0.0509,  0.2460,  ...,  0.1789, -0.0009, -0.2247],
        [ 0.0124,  0.2133,  0.0767,  ...,  0.1127,  0.1602,  0.0868]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.2159],
        [ 0.3116],
        [-0.2938],
        [-0.1707],
        [ 0.0044],
        [-0.0481],
        [-0.2443],
        [-0.1874],
        [-0.3154],
        [ 0.1261],
        [ 0.3538],
        [ 0.2730],
        [-0.4242],
        [-0.2399],
        [-0.1299],
        [-0.1438],
        [-0.3686],
        [-0.3730],
        [-0.2935],
        [-0.1684],
        [ 0.0129],
        [ 0.3476],
        [-0.3038],
        [-0.2430],
        [-0.3073],
        [ 0.0798],
        [-0.1392],
        [ 0.2112],
        [ 0.2943],
        [-0.0249],
        [-0.0566],
        [ 0.4045]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}, {'params': [tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True)], 'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 5e-05, 'amsgrad': False}]





 shepe: torch.Size([35258310, 1]) 









input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([101940, 1]) 
g.ndata[nfet].sum tensor(893.2103, device='cuda:0')



input graph: 
g Graph(num_nodes=101940, num_edges=35258310,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([35258310, 1]) 
g.edata[efet] tensor([[0.0125],
        [0.0612],
        [0.0568],
        ...,
        [0.0000],
        [0.2034],
        [0.0753]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(3039397.5000, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([101940, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(893.2103, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0086,  0.0006,  0.0087,  ..., -0.0069, -0.0064,  0.0021],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([101940, 256]) 
h.sum tensor(851.5820, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-125.3651, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-134.2802, device='cuda:0')



h[100].sum tensor(54.7718, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(58.6667, device='cuda:0')



h[200].sum tensor(113.5039, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(121.5754, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0008, 0.0110,  ..., 0.0000, 0.0000, 0.0027],
        [0.0000, 0.0003, 0.0041,  ..., 0.0000, 0.0000, 0.0010],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([101940, 256]) 
h.sum tensor(267370.2500, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.0086, 0.0212, 0.0000,  ..., 0.0319, 0.0000, 0.0000],
        [0.0036, 0.0087, 0.0000,  ..., 0.0132, 0.0000, 0.0000],
        [0.0015, 0.0036, 0.0000,  ..., 0.0055, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([101940, 128]) 
h2.sum tensor(5851812.5000, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(40320.8320, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(692.6392, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=101940, num_edges=35258310,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-3.2736e-01],
        [-5.2711e-01],
        [-9.1699e-01],
        ...,
        [-5.5683e-06],
        [-2.5749e-05],
        [-9.4424e-05]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([101940, 1]) 
h5.sum tensor(-9919992., device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.0125],
        [0.0612],
        [0.0568],
        ...,
        [0.0000],
        [0.2034],
        [0.0753]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([35258310, 1]) 
g.edata[efet].sum tensor(3039397.5000, device='cuda:0', grad_fn=<SumBackward0>)





 shepe: torch.Size([35258310, 1]) 









input node feature: 
g.ndata[nfet] tensor([[0.3496],
        [0.4070],
        [0.0000],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([101940, 1]) 
g.ndata[nfet].sum tensor(818.1088, device='cuda:0')



input graph: 
g Graph(num_nodes=101940, num_edges=35258310,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([35258310, 1]) 
g.edata[efet] tensor([[0.0000],
        [0.0814],
        [0.0922],
        ...,
        [0.0000],
        [0.0547],
        [0.1566]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(1557496.7500, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([101940, 1]) 
g.ndata[nfet] tensor([[0.3496],
        [0.4070],
        [0.0000],
        ...,
        [0.0000],
        [0.0000],
        [0.0000]], device='cuda:0') 
g.ndata[nfet].sum tensor(818.1088, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-3.6999e-02,  2.4841e-03,  3.7186e-02,  ..., -2.9580e-02,
         -2.7548e-02,  9.0001e-03],
        [-2.3184e-02,  1.5192e-03,  2.3264e-02,  ..., -1.8535e-02,
         -1.7262e-02,  5.6022e-03],
        [-1.3757e-02,  8.6085e-04,  1.3764e-02,  ..., -1.0998e-02,
         -1.0243e-02,  3.2837e-03],
        ...,
        [ 0.0000e+00, -1.0000e-04, -1.0000e-04,  ...,  0.0000e+00,
          0.0000e+00, -1.0000e-04],
        [ 0.0000e+00, -1.0000e-04, -1.0000e-04,  ...,  0.0000e+00,
          0.0000e+00, -1.0000e-04],
        [ 0.0000e+00, -1.0000e-04, -1.0000e-04,  ...,  0.0000e+00,
          0.0000e+00, -1.0000e-04]], device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([101940, 256]) 
h.sum tensor(639.1664, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-113.8553, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-122.9081, device='cuda:0')



h[100].sum tensor(39.5064, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(53.6522, device='cuda:0')



h[200].sum tensor(113.4213, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(111.4351, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0032, 0.0475,  ..., 0.0000, 0.0000, 0.0115],
        [0.0000, 0.0034, 0.0521,  ..., 0.0000, 0.0000, 0.0126],
        [0.0000, 0.0011, 0.0164,  ..., 0.0000, 0.0000, 0.0040],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([101940, 256]) 
h.sum tensor(130633.8047, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[2.1030e-02, 4.7661e-02, 0.0000e+00,  ..., 7.2332e-02, 0.0000e+00,
         0.0000e+00],
        [2.0908e-02, 4.7137e-02, 0.0000e+00,  ..., 7.1625e-02, 0.0000e+00,
         0.0000e+00],
        [6.7478e-03, 1.4960e-02, 0.0000e+00,  ..., 2.2827e-02, 0.0000e+00,
         0.0000e+00],
        ...,
        [4.9237e-04, 0.0000e+00, 0.0000e+00,  ..., 2.2462e-04, 0.0000e+00,
         0.0000e+00],
        [2.7920e-04, 0.0000e+00, 0.0000e+00,  ..., 1.0429e-04, 0.0000e+00,
         0.0000e+00],
        [2.0738e-04, 0.0000e+00, 0.0000e+00,  ..., 6.8907e-05, 0.0000e+00,
         0.0000e+00]], device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([101940, 128]) 
h2.sum tensor(1481266., device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(11984.7129, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(387.9546, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=101940, num_edges=35258310,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-9.4738e-01],
        [-7.9903e-01],
        [-6.4138e-01],
        ...,
        [ 1.8019e-04],
        [ 1.6017e-04],
        [ 1.6196e-04]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([101940, 1]) 
h5.sum tensor(-885734.1875, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[0.0000],
        [0.0814],
        [0.0922],
        ...,
        [0.0000],
        [0.0547],
        [0.1566]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].shape torch.Size([35258310, 1]) 
g.edata[efet].sum tensor(1557496.7500, device='cuda:0', grad_fn=<SumBackward0>)
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndneiefet.py", line 84, in <module>
    loss.backward()#(retain_graph=True)   # Derive gradients.
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/_tensor.py", line 307, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/autograd/__init__.py", line 154, in backward
    Variable._execution_engine.run_backward(
RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.

real	0m27.944s
user	0m21.970s
sys	0m5.582s
