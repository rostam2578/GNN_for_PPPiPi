0: gpu035.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-8ac19b97-e996-d56f-26ed-caea68e1fcfc)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        70:B2:A7:DF:ED:82:78:26:9F:D8:28:A0:1D:52:CD:B5:3B:DF:C3:17
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Jan  9 16:57:20 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:16:00.0 Off |                    0 |
| N/A   43C    P0    40W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b1769212880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m3.061s
user	0m1.762s
sys	0m0.551s




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[-1.9672],
        [ 0.8357],
        [-1.1079],
        ...,
        [-0.5614],
        [ 0.3739],
        [ 0.9282]], device='cuda:0', requires_grad=True) 
node features sum: tensor(130.3594, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (linear1): Linear(in_features=2350554, out_features=256, bias=True)
  (linear2): Linear(in_features=256, out_features=2350554, bias=True)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 1205878235

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.0727,  0.1181, -0.0943, -0.1441,  0.1292,  0.1170,  0.0455, -0.0935,
          0.0785,  0.1526,  0.0940, -0.1040,  0.0859, -0.0634,  0.0436,  0.0828,
          0.0572,  0.1467,  0.0035, -0.1356,  0.0422, -0.0522, -0.0277, -0.0528,
          0.0284,  0.0773, -0.1071,  0.0385,  0.0532,  0.0991,  0.0996, -0.0154,
          0.0969, -0.0827,  0.0352, -0.0128,  0.1105,  0.0427, -0.0348,  0.0165,
         -0.0304, -0.1343, -0.0138, -0.1335, -0.0792,  0.1124, -0.0647, -0.0438,
          0.0312, -0.1335, -0.1247, -0.1442,  0.0611,  0.1414, -0.0996,  0.0386,
          0.1223,  0.1344, -0.1460,  0.0476, -0.0511, -0.0291, -0.0168,  0.1448,
          0.1434, -0.1214,  0.0584, -0.0152, -0.1037, -0.0860,  0.0292,  0.1326,
         -0.0804, -0.0786,  0.1489, -0.1287,  0.0573, -0.0131,  0.0494,  0.0161,
          0.1453, -0.0866,  0.1020,  0.0310, -0.1006, -0.1466,  0.0725,  0.1024,
         -0.1502, -0.1246, -0.1358,  0.0027,  0.1462, -0.1312, -0.0392,  0.0773,
         -0.0295,  0.1506,  0.0136,  0.0757,  0.0069,  0.0162, -0.0877,  0.0650,
         -0.0598,  0.1452, -0.1167,  0.0820, -0.0469, -0.0756, -0.0389,  0.0015,
          0.0697, -0.0446,  0.1039, -0.0166,  0.1099,  0.0882,  0.1473,  0.1368,
          0.0311, -0.1192,  0.0158,  0.0559, -0.0452,  0.1413, -0.0641,  0.0005,
          0.1115,  0.0390, -0.0755, -0.0135,  0.1196,  0.0455,  0.0177,  0.0542,
         -0.0552, -0.0257, -0.0492, -0.0852, -0.1149, -0.1195,  0.1338,  0.1514,
          0.0611, -0.1346,  0.1155,  0.1125, -0.1107, -0.1263,  0.0668,  0.0111,
         -0.0641,  0.0192,  0.0987, -0.0798,  0.1256,  0.1175, -0.0950, -0.0818,
          0.0908,  0.0997, -0.0759,  0.0650, -0.1221, -0.1115,  0.0021,  0.0674,
         -0.0580, -0.0873,  0.0814,  0.0079, -0.0308, -0.0311,  0.1301, -0.1439,
          0.0863, -0.0722,  0.0907, -0.0561,  0.1212,  0.1436,  0.0455,  0.0292,
          0.1368, -0.1473,  0.1379,  0.0788,  0.0890,  0.0315,  0.1035, -0.0670,
          0.1474, -0.0209,  0.1088, -0.0724,  0.0759,  0.1143, -0.0064, -0.0264,
         -0.1254, -0.1417, -0.1296, -0.0352, -0.1354,  0.1515, -0.1020, -0.0350,
          0.0572,  0.1322, -0.0446,  0.0101,  0.0892,  0.0845,  0.0168,  0.0108,
         -0.0685, -0.0781, -0.1251,  0.0632, -0.0807, -0.0932,  0.1253, -0.0666,
         -0.1467,  0.1257, -0.0764, -0.0744,  0.0535, -0.1315,  0.0848, -0.1262,
         -0.0664, -0.1001, -0.1320,  0.1291,  0.0803,  0.0937,  0.0697, -0.1173,
          0.0980, -0.0147, -0.0573,  0.1146, -0.0953,  0.0602, -0.0927, -0.0545,
         -0.0731, -0.0890, -0.0455,  0.1188,  0.1213, -0.0365,  0.0118, -0.0084]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0727,  0.1181, -0.0943, -0.1441,  0.1292,  0.1170,  0.0455, -0.0935,
          0.0785,  0.1526,  0.0940, -0.1040,  0.0859, -0.0634,  0.0436,  0.0828,
          0.0572,  0.1467,  0.0035, -0.1356,  0.0422, -0.0522, -0.0277, -0.0528,
          0.0284,  0.0773, -0.1071,  0.0385,  0.0532,  0.0991,  0.0996, -0.0154,
          0.0969, -0.0827,  0.0352, -0.0128,  0.1105,  0.0427, -0.0348,  0.0165,
         -0.0304, -0.1343, -0.0138, -0.1335, -0.0792,  0.1124, -0.0647, -0.0438,
          0.0312, -0.1335, -0.1247, -0.1442,  0.0611,  0.1414, -0.0996,  0.0386,
          0.1223,  0.1344, -0.1460,  0.0476, -0.0511, -0.0291, -0.0168,  0.1448,
          0.1434, -0.1214,  0.0584, -0.0152, -0.1037, -0.0860,  0.0292,  0.1326,
         -0.0804, -0.0786,  0.1489, -0.1287,  0.0573, -0.0131,  0.0494,  0.0161,
          0.1453, -0.0866,  0.1020,  0.0310, -0.1006, -0.1466,  0.0725,  0.1024,
         -0.1502, -0.1246, -0.1358,  0.0027,  0.1462, -0.1312, -0.0392,  0.0773,
         -0.0295,  0.1506,  0.0136,  0.0757,  0.0069,  0.0162, -0.0877,  0.0650,
         -0.0598,  0.1452, -0.1167,  0.0820, -0.0469, -0.0756, -0.0389,  0.0015,
          0.0697, -0.0446,  0.1039, -0.0166,  0.1099,  0.0882,  0.1473,  0.1368,
          0.0311, -0.1192,  0.0158,  0.0559, -0.0452,  0.1413, -0.0641,  0.0005,
          0.1115,  0.0390, -0.0755, -0.0135,  0.1196,  0.0455,  0.0177,  0.0542,
         -0.0552, -0.0257, -0.0492, -0.0852, -0.1149, -0.1195,  0.1338,  0.1514,
          0.0611, -0.1346,  0.1155,  0.1125, -0.1107, -0.1263,  0.0668,  0.0111,
         -0.0641,  0.0192,  0.0987, -0.0798,  0.1256,  0.1175, -0.0950, -0.0818,
          0.0908,  0.0997, -0.0759,  0.0650, -0.1221, -0.1115,  0.0021,  0.0674,
         -0.0580, -0.0873,  0.0814,  0.0079, -0.0308, -0.0311,  0.1301, -0.1439,
          0.0863, -0.0722,  0.0907, -0.0561,  0.1212,  0.1436,  0.0455,  0.0292,
          0.1368, -0.1473,  0.1379,  0.0788,  0.0890,  0.0315,  0.1035, -0.0670,
          0.1474, -0.0209,  0.1088, -0.0724,  0.0759,  0.1143, -0.0064, -0.0264,
         -0.1254, -0.1417, -0.1296, -0.0352, -0.1354,  0.1515, -0.1020, -0.0350,
          0.0572,  0.1322, -0.0446,  0.0101,  0.0892,  0.0845,  0.0168,  0.0108,
         -0.0685, -0.0781, -0.1251,  0.0632, -0.0807, -0.0932,  0.1253, -0.0666,
         -0.1467,  0.1257, -0.0764, -0.0744,  0.0535, -0.1315,  0.0848, -0.1262,
         -0.0664, -0.1001, -0.1320,  0.1291,  0.0803,  0.0937,  0.0697, -0.1173,
          0.0980, -0.0147, -0.0573,  0.1146, -0.0953,  0.0602, -0.0927, -0.0545,
         -0.0731, -0.0890, -0.0455,  0.1188,  0.1213, -0.0365,  0.0118, -0.0084]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name linear1.weight 
shape:
 torch.Size([256, 2350554]) 
grad:
 True 
date:
 tensor([[ 6.3103e-04,  6.8545e-05, -5.4767e-04,  ...,  3.6114e-05,
         -2.0144e-04,  4.2304e-04],
        [-4.9005e-04, -2.1193e-04,  3.2835e-04,  ...,  7.0469e-05,
         -9.4728e-05, -4.6095e-04],
        [ 8.4081e-05, -4.3783e-04,  8.1564e-05,  ...,  7.0617e-05,
          2.1986e-04, -4.4306e-04],
        ...,
        [-2.7046e-04,  2.8602e-04,  4.1424e-04,  ...,  3.8146e-04,
          1.3933e-05,  4.5204e-04],
        [-5.0024e-04, -4.2507e-05,  5.4238e-04,  ..., -4.8273e-04,
         -1.9988e-04, -4.5730e-04],
        [ 1.4454e-04,  2.2960e-04,  1.4838e-04,  ..., -2.9466e-04,
         -2.4095e-04,  2.6467e-04]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 6.3103e-04,  6.8545e-05, -5.4767e-04,  ...,  3.6114e-05,
         -2.0144e-04,  4.2304e-04],
        [-4.9005e-04, -2.1193e-04,  3.2835e-04,  ...,  7.0469e-05,
         -9.4728e-05, -4.6095e-04],
        [ 8.4081e-05, -4.3783e-04,  8.1564e-05,  ...,  7.0617e-05,
          2.1986e-04, -4.4306e-04],
        ...,
        [-2.7046e-04,  2.8602e-04,  4.1424e-04,  ...,  3.8146e-04,
          1.3933e-05,  4.5204e-04],
        [-5.0024e-04, -4.2507e-05,  5.4238e-04,  ..., -4.8273e-04,
         -1.9988e-04, -4.5730e-04],
        [ 1.4454e-04,  2.2960e-04,  1.4838e-04,  ..., -2.9466e-04,
         -2.4095e-04,  2.6467e-04]], device='cuda:0', requires_grad=True)

name linear1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([-6.6740e-06,  3.8350e-04, -1.3759e-04,  1.8083e-04, -4.2499e-05,
         1.2651e-04,  3.1715e-04,  2.3466e-06, -1.5322e-04,  3.5985e-04,
        -2.9364e-04, -2.7633e-05,  4.3820e-04, -3.5396e-04, -1.8026e-05,
        -1.3845e-04, -1.7043e-04, -5.3143e-04,  4.2170e-04,  6.0016e-04,
        -4.5644e-04,  2.6871e-04,  5.3495e-04,  4.1193e-04,  4.4737e-04,
        -5.9997e-04,  6.0963e-04, -2.3999e-04, -6.2421e-04, -8.3438e-05,
        -1.5302e-04, -5.9287e-04, -2.8120e-04, -1.5704e-04,  1.4136e-04,
         3.9683e-04, -3.9963e-04,  4.9320e-04,  3.1412e-04,  7.7242e-05,
        -5.2368e-04, -4.7180e-05, -5.8978e-04, -4.2325e-05,  6.2846e-04,
         6.4333e-04, -1.3041e-04,  3.3605e-04,  4.9011e-04,  2.2574e-06,
        -1.9941e-04, -1.3830e-04, -5.4729e-04,  8.4858e-05,  2.9388e-04,
         2.0324e-05,  2.8736e-04, -4.0015e-04,  3.8345e-04,  3.1796e-04,
        -3.8989e-04, -6.0969e-04, -6.3616e-04, -5.1168e-05,  2.2547e-04,
         5.5639e-04,  8.1824e-05,  4.5789e-04, -2.9274e-04, -7.5495e-05,
         4.8417e-04, -5.1948e-04,  2.1439e-04, -4.5123e-04, -1.1805e-04,
        -9.3345e-05, -3.6839e-04,  5.5615e-04, -4.3303e-04,  4.3677e-05,
         5.0892e-04, -6.2514e-04,  1.4141e-04,  5.0372e-04,  1.7150e-04,
        -2.6510e-04, -1.1849e-04, -4.2542e-04,  5.3049e-04,  2.8228e-04,
         1.2672e-04,  6.1954e-04,  6.3686e-04,  2.3750e-04, -5.2762e-04,
        -4.8612e-04, -4.8020e-04, -9.3499e-05, -1.6402e-04,  4.9663e-04,
        -6.0871e-04, -4.9082e-04, -1.1131e-04, -4.2368e-04, -2.6041e-04,
         5.0796e-04,  5.6513e-04, -1.9384e-04,  3.2961e-04,  6.8591e-05,
        -2.9936e-04, -1.5790e-04, -1.4497e-05,  4.5415e-04, -3.7622e-04,
        -4.6522e-04,  2.2749e-04, -7.6419e-05,  5.3121e-04, -7.4886e-05,
         2.6698e-05, -1.5769e-04,  6.0125e-04, -5.7525e-04,  3.5001e-04,
         1.1505e-04,  2.8601e-04, -4.5476e-04, -4.1636e-04, -2.4254e-04,
         5.2278e-04, -4.4719e-04, -2.2232e-04, -5.8691e-04,  5.3275e-04,
        -1.7932e-04,  3.6698e-04, -2.3540e-04,  1.2484e-04, -2.2142e-04,
        -5.4289e-04, -5.2458e-05, -1.4009e-04, -6.4695e-04,  5.7944e-04,
         4.8511e-04,  2.0820e-04,  3.9328e-04, -7.8762e-06,  5.2806e-04,
        -2.1679e-04,  1.2438e-05, -2.3839e-04,  3.3417e-04,  6.2494e-04,
        -1.2083e-04, -3.6285e-04, -5.6491e-04, -3.2010e-04, -1.2041e-04,
        -1.2097e-05, -2.1453e-04,  7.4581e-05, -6.4674e-04,  6.4242e-04,
         7.3576e-05, -3.6830e-04, -1.1250e-04,  3.5436e-04,  3.1860e-04,
        -4.9645e-04, -2.9774e-04,  2.9831e-04,  1.2668e-04,  4.1107e-05,
        -1.3524e-04, -5.6751e-04,  1.5899e-04,  4.6865e-04,  3.0119e-05,
        -5.2859e-04,  9.2802e-05,  3.4917e-04, -2.8525e-05,  5.7014e-04,
         3.2716e-04, -2.8054e-04, -1.8214e-04,  5.7059e-04, -3.6847e-04,
        -6.3170e-04,  2.8437e-04, -2.6768e-04, -3.4077e-04, -1.1699e-04,
         1.5322e-04, -4.0616e-05,  5.4776e-04, -4.0565e-04,  1.9620e-04,
        -3.8091e-04,  4.5954e-04, -1.7339e-04,  3.7165e-04,  2.2100e-04,
        -6.2305e-04,  5.6170e-04,  1.2035e-04,  6.3815e-04, -5.8797e-05,
         1.9809e-04, -2.8097e-04,  3.0673e-04, -1.7119e-04, -6.5208e-04,
        -5.1502e-04, -2.4243e-04,  9.3747e-05, -1.6770e-04,  3.5393e-04,
         7.6640e-05,  5.9045e-04, -2.5683e-04,  1.4511e-04, -4.4819e-04,
         4.5469e-04, -4.4396e-04, -5.6864e-04,  3.7642e-04, -5.2351e-04,
         5.8133e-04, -2.6606e-04,  2.1971e-04,  1.8108e-04,  2.2070e-04,
         2.2852e-04, -9.1355e-05, -4.2604e-04,  1.8634e-04,  1.7293e-04,
         2.6550e-04, -5.5006e-04,  3.6259e-04, -4.1763e-04,  1.2379e-04,
        -2.0764e-04,  1.6609e-04, -6.1496e-04,  2.0564e-04,  5.3329e-04,
         2.4322e-04, -3.6742e-04, -4.6759e-04, -3.1884e-04, -6.3451e-04,
         2.9279e-04], device='cuda:0') 
parameter:
 Parameter containing:
tensor([-6.6740e-06,  3.8350e-04, -1.3759e-04,  1.8083e-04, -4.2499e-05,
         1.2651e-04,  3.1715e-04,  2.3466e-06, -1.5322e-04,  3.5985e-04,
        -2.9364e-04, -2.7633e-05,  4.3820e-04, -3.5396e-04, -1.8026e-05,
        -1.3845e-04, -1.7043e-04, -5.3143e-04,  4.2170e-04,  6.0016e-04,
        -4.5644e-04,  2.6871e-04,  5.3495e-04,  4.1193e-04,  4.4737e-04,
        -5.9997e-04,  6.0963e-04, -2.3999e-04, -6.2421e-04, -8.3438e-05,
        -1.5302e-04, -5.9287e-04, -2.8120e-04, -1.5704e-04,  1.4136e-04,
         3.9683e-04, -3.9963e-04,  4.9320e-04,  3.1412e-04,  7.7242e-05,
        -5.2368e-04, -4.7180e-05, -5.8978e-04, -4.2325e-05,  6.2846e-04,
         6.4333e-04, -1.3041e-04,  3.3605e-04,  4.9011e-04,  2.2574e-06,
        -1.9941e-04, -1.3830e-04, -5.4729e-04,  8.4858e-05,  2.9388e-04,
         2.0324e-05,  2.8736e-04, -4.0015e-04,  3.8345e-04,  3.1796e-04,
        -3.8989e-04, -6.0969e-04, -6.3616e-04, -5.1168e-05,  2.2547e-04,
         5.5639e-04,  8.1824e-05,  4.5789e-04, -2.9274e-04, -7.5495e-05,
         4.8417e-04, -5.1948e-04,  2.1439e-04, -4.5123e-04, -1.1805e-04,
        -9.3345e-05, -3.6839e-04,  5.5615e-04, -4.3303e-04,  4.3677e-05,
         5.0892e-04, -6.2514e-04,  1.4141e-04,  5.0372e-04,  1.7150e-04,
        -2.6510e-04, -1.1849e-04, -4.2542e-04,  5.3049e-04,  2.8228e-04,
         1.2672e-04,  6.1954e-04,  6.3686e-04,  2.3750e-04, -5.2762e-04,
        -4.8612e-04, -4.8020e-04, -9.3499e-05, -1.6402e-04,  4.9663e-04,
        -6.0871e-04, -4.9082e-04, -1.1131e-04, -4.2368e-04, -2.6041e-04,
         5.0796e-04,  5.6513e-04, -1.9384e-04,  3.2961e-04,  6.8591e-05,
        -2.9936e-04, -1.5790e-04, -1.4497e-05,  4.5415e-04, -3.7622e-04,
        -4.6522e-04,  2.2749e-04, -7.6419e-05,  5.3121e-04, -7.4886e-05,
         2.6698e-05, -1.5769e-04,  6.0125e-04, -5.7525e-04,  3.5001e-04,
         1.1505e-04,  2.8601e-04, -4.5476e-04, -4.1636e-04, -2.4254e-04,
         5.2278e-04, -4.4719e-04, -2.2232e-04, -5.8691e-04,  5.3275e-04,
        -1.7932e-04,  3.6698e-04, -2.3540e-04,  1.2484e-04, -2.2142e-04,
        -5.4289e-04, -5.2458e-05, -1.4009e-04, -6.4695e-04,  5.7944e-04,
         4.8511e-04,  2.0820e-04,  3.9328e-04, -7.8762e-06,  5.2806e-04,
        -2.1679e-04,  1.2438e-05, -2.3839e-04,  3.3417e-04,  6.2494e-04,
        -1.2083e-04, -3.6285e-04, -5.6491e-04, -3.2010e-04, -1.2041e-04,
        -1.2097e-05, -2.1453e-04,  7.4581e-05, -6.4674e-04,  6.4242e-04,
         7.3576e-05, -3.6830e-04, -1.1250e-04,  3.5436e-04,  3.1860e-04,
        -4.9645e-04, -2.9774e-04,  2.9831e-04,  1.2668e-04,  4.1107e-05,
        -1.3524e-04, -5.6751e-04,  1.5899e-04,  4.6865e-04,  3.0119e-05,
        -5.2859e-04,  9.2802e-05,  3.4917e-04, -2.8525e-05,  5.7014e-04,
         3.2716e-04, -2.8054e-04, -1.8214e-04,  5.7059e-04, -3.6847e-04,
        -6.3170e-04,  2.8437e-04, -2.6768e-04, -3.4077e-04, -1.1699e-04,
         1.5322e-04, -4.0616e-05,  5.4776e-04, -4.0565e-04,  1.9620e-04,
        -3.8091e-04,  4.5954e-04, -1.7339e-04,  3.7165e-04,  2.2100e-04,
        -6.2305e-04,  5.6170e-04,  1.2035e-04,  6.3815e-04, -5.8797e-05,
         1.9809e-04, -2.8097e-04,  3.0673e-04, -1.7119e-04, -6.5208e-04,
        -5.1502e-04, -2.4243e-04,  9.3747e-05, -1.6770e-04,  3.5393e-04,
         7.6640e-05,  5.9045e-04, -2.5683e-04,  1.4511e-04, -4.4819e-04,
         4.5469e-04, -4.4396e-04, -5.6864e-04,  3.7642e-04, -5.2351e-04,
         5.8133e-04, -2.6606e-04,  2.1971e-04,  1.8108e-04,  2.2070e-04,
         2.2852e-04, -9.1355e-05, -4.2604e-04,  1.8634e-04,  1.7293e-04,
         2.6550e-04, -5.5006e-04,  3.6259e-04, -4.1763e-04,  1.2379e-04,
        -2.0764e-04,  1.6609e-04, -6.1496e-04,  2.0564e-04,  5.3329e-04,
         2.4322e-04, -3.6742e-04, -4.6759e-04, -3.1884e-04, -6.3451e-04,
         2.9279e-04], device='cuda:0', requires_grad=True)

name linear2.weight 
shape:
 torch.Size([2350554, 256]) 
grad:
 True 
date:
 tensor([[ 0.0301, -0.0465,  0.0070,  ..., -0.0446, -0.0402, -0.0432],
        [-0.0332,  0.0301,  0.0513,  ..., -0.0406, -0.0442, -0.0006],
        [ 0.0325,  0.0178, -0.0203,  ..., -0.0051, -0.0167,  0.0267],
        ...,
        [-0.0049,  0.0328, -0.0115,  ...,  0.0541,  0.0429,  0.0079],
        [ 0.0489,  0.0495, -0.0462,  ..., -0.0339,  0.0444,  0.0579],
        [-0.0299, -0.0356, -0.0417,  ...,  0.0528, -0.0383, -0.0310]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0301, -0.0465,  0.0070,  ..., -0.0446, -0.0402, -0.0432],
        [-0.0332,  0.0301,  0.0513,  ..., -0.0406, -0.0442, -0.0006],
        [ 0.0325,  0.0178, -0.0203,  ..., -0.0051, -0.0167,  0.0267],
        ...,
        [-0.0049,  0.0328, -0.0115,  ...,  0.0541,  0.0429,  0.0079],
        [ 0.0489,  0.0495, -0.0462,  ..., -0.0339,  0.0444,  0.0579],
        [-0.0299, -0.0356, -0.0417,  ...,  0.0528, -0.0383, -0.0310]],
       device='cuda:0', requires_grad=True)

name linear2.bias 
shape:
 torch.Size([2350554]) 
grad:
 True 
date:
 tensor([-0.0520,  0.0215,  0.0499,  ..., -0.0385, -0.0365,  0.0328],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([-0.0520,  0.0215,  0.0499,  ..., -0.0385, -0.0365,  0.0328],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[ 0.0871,  0.0214, -0.1137,  ..., -0.0505,  0.1106,  0.0577],
        [ 0.1198,  0.1091, -0.0865,  ...,  0.0091, -0.0591,  0.1047],
        [-0.0865, -0.0301, -0.0924,  ..., -0.1080,  0.1073,  0.0732],
        ...,
        [ 0.0349,  0.1055, -0.0678,  ...,  0.0631, -0.1066,  0.0372],
        [ 0.0988,  0.0170,  0.0146,  ..., -0.0060, -0.0791, -0.0485],
        [-0.1043,  0.1200, -0.0645,  ..., -0.1241, -0.0782, -0.0060]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0871,  0.0214, -0.1137,  ..., -0.0505,  0.1106,  0.0577],
        [ 0.1198,  0.1091, -0.0865,  ...,  0.0091, -0.0591,  0.1047],
        [-0.0865, -0.0301, -0.0924,  ..., -0.1080,  0.1073,  0.0732],
        ...,
        [ 0.0349,  0.1055, -0.0678,  ...,  0.0631, -0.1066,  0.0372],
        [ 0.0988,  0.0170,  0.0146,  ..., -0.0060, -0.0791, -0.0485],
        [-0.1043,  0.1200, -0.0645,  ..., -0.1241, -0.0782, -0.0060]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0615,  0.1144, -0.1595,  ...,  0.1547,  0.0656, -0.0533],
        [ 0.0569,  0.0370, -0.1732,  ...,  0.1145, -0.0086,  0.1122],
        [ 0.0130,  0.1098, -0.0623,  ...,  0.1233, -0.0140, -0.0975],
        ...,
        [ 0.0135,  0.0655,  0.0837,  ..., -0.0472, -0.0279, -0.0562],
        [-0.0883, -0.1407,  0.1417,  ..., -0.1748,  0.1526,  0.0929],
        [ 0.1114,  0.0222, -0.0599,  ...,  0.0758, -0.1340, -0.0487]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0615,  0.1144, -0.1595,  ...,  0.1547,  0.0656, -0.0533],
        [ 0.0569,  0.0370, -0.1732,  ...,  0.1145, -0.0086,  0.1122],
        [ 0.0130,  0.1098, -0.0623,  ...,  0.1233, -0.0140, -0.0975],
        ...,
        [ 0.0135,  0.0655,  0.0837,  ..., -0.0472, -0.0279, -0.0562],
        [-0.0883, -0.1407,  0.1417,  ..., -0.1748,  0.1526,  0.0929],
        [ 0.1114,  0.0222, -0.0599,  ...,  0.0758, -0.1340, -0.0487]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.1562,  0.2136, -0.0364,  ..., -0.1864,  0.2088, -0.0112],
        [-0.0785,  0.2283,  0.2301,  ...,  0.1651,  0.1378,  0.1665],
        [-0.1818,  0.2342, -0.1052,  ...,  0.1222,  0.0237, -0.1632],
        ...,
        [ 0.2223, -0.0506, -0.1024,  ...,  0.2203, -0.1967, -0.0847],
        [-0.0379,  0.2243,  0.0962,  ..., -0.0078, -0.1468, -0.1912],
        [ 0.1642,  0.2470, -0.2191,  ..., -0.2487,  0.1404,  0.0561]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1562,  0.2136, -0.0364,  ..., -0.1864,  0.2088, -0.0112],
        [-0.0785,  0.2283,  0.2301,  ...,  0.1651,  0.1378,  0.1665],
        [-0.1818,  0.2342, -0.1052,  ...,  0.1222,  0.0237, -0.1632],
        ...,
        [ 0.2223, -0.0506, -0.1024,  ...,  0.2203, -0.1967, -0.0847],
        [-0.0379,  0.2243,  0.0962,  ..., -0.0078, -0.1468, -0.1912],
        [ 0.1642,  0.2470, -0.2191,  ..., -0.2487,  0.1404,  0.0561]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[ 0.2613],
        [ 0.1549],
        [-0.1743],
        [-0.1806],
        [-0.0081],
        [ 0.2906],
        [-0.4255],
        [-0.1605],
        [ 0.2878],
        [-0.0711],
        [-0.1677],
        [ 0.2692],
        [-0.0199],
        [ 0.1194],
        [ 0.0871],
        [-0.0099],
        [-0.1658],
        [ 0.1411],
        [ 0.0274],
        [-0.1164],
        [ 0.3442],
        [-0.4026],
        [-0.3072],
        [-0.1851],
        [-0.4038],
        [ 0.0259],
        [ 0.3207],
        [ 0.2422],
        [ 0.0885],
        [-0.0750],
        [ 0.2174],
        [ 0.1782]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.2613],
        [ 0.1549],
        [-0.1743],
        [-0.1806],
        [-0.0081],
        [ 0.2906],
        [-0.4255],
        [-0.1605],
        [ 0.2878],
        [-0.0711],
        [-0.1677],
        [ 0.2692],
        [-0.0199],
        [ 0.1194],
        [ 0.0871],
        [-0.0099],
        [-0.1658],
        [ 0.1411],
        [ 0.0274],
        [-0.1164],
        [ 0.3442],
        [-0.4026],
        [-0.3072],
        [-0.1851],
        [-0.4038],
        [ 0.0259],
        [ 0.3207],
        [ 0.2422],
        [ 0.0885],
        [-0.0750],
        [ 0.2174],
        [ 0.1782]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)





 shepe: torch.Size([2350554, 1]) 









input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(1, 256), dtype=torch.float32), 'h2': Scheme(shape=(1, 128), dtype=torch.float32), 'h3': Scheme(shape=(1, 64), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1, 1), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1, 1]) 
g.edata[efet] tensor([[[0.0000]],

        [[0.1538]],

        [[0.0000]],

        ...,

        [[0.0000]],

        [[0.0960]],

        [[0.0000]]], device='cuda:0', grad_fn=<ReshapeAliasBackward0>) 
g.edata[efet].sum tensor(223505.2656, device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(36.1753, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-7.4596, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-7.9807, device='cuda:0')



h[100].sum tensor(10.5022, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(11.2359, device='cuda:0')



h[200].sum tensor(-0.0886, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(-0.0948, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 1, 256]) 
h.sum tensor(30141.6738, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[[0.0000, 0.0254, 0.0000,  ..., 0.0000, 0.0034, 0.0000]],

        [[0.0000, 0.0144, 0.0000,  ..., 0.0000, 0.0019, 0.0000]],

        [[0.0000, 0.0048, 0.0000,  ..., 0.0000, 0.0006, 0.0000]],

        ...,

        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 1, 128]) 
h2.sum tensor(558380.8750, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(558380.8750, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(-167.2047, device='cuda:0', grad_fn=<AddBackward0>)
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndneiefet.py", line 5, in <module>
    from ModelBha2ndneiefet import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 165, in <module>
    result1 = net(dglgraph.to(device), TraTen[1007].reshape(6796, 1).to(device))
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 139, in forward
    print('\n\n\nh2[100].sum', h2[:, 50].sum())
IndexError: index 50 is out of bounds for dimension 1 with size 1

real	0m33.602s
user	0m27.798s
sys	0m5.931s
