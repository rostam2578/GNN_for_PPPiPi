0: gpu013.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-ca856528-66d0-b6f4-a298-d0e4b337129a)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        93:21:1B:18:EF:A7:C8:57:82:69:24:2E:8F:A1:6F:B1:C8:1C:13:C2
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Mon Jan  9 16:39:56 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1C:00.0 Off |                    0 |
| N/A   32C    P0    42W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2ae8bf6b7880> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m4.341s
user	0m2.412s
sys	0m0.779s




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[-0.4861],
        [ 0.8060],
        [ 0.2491],
        ...,
        [ 0.6804],
        [-1.4318],
        [ 0.1344]], device='cuda:0', requires_grad=True) 
node features sum: tensor(54.4957, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (linear1): Linear(in_features=2350554, out_features=256, bias=True)
  (linear2): Linear(in_features=256, out_features=2350554, bias=True)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 1205878235

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[ 0.1161, -0.1362, -0.1437, -0.0539,  0.0245, -0.0504, -0.0648, -0.1463,
         -0.0383, -0.1029,  0.0361,  0.0399, -0.1332, -0.1154, -0.0152, -0.1045,
          0.0491,  0.1187,  0.1009, -0.1018,  0.0428, -0.1138,  0.0158, -0.0307,
         -0.0548, -0.0170, -0.0394, -0.0801,  0.0556,  0.1492, -0.1457,  0.0395,
          0.0332,  0.0835,  0.0657,  0.0712, -0.0610,  0.0634, -0.1157, -0.0457,
          0.1505, -0.1143, -0.1214, -0.0247,  0.0901, -0.0601,  0.0267, -0.1456,
          0.0057,  0.1475,  0.1023, -0.1059, -0.1490, -0.0256, -0.0350, -0.1350,
          0.0881,  0.0134,  0.0514,  0.1436,  0.0162, -0.0118, -0.1081,  0.0935,
         -0.0489,  0.0556, -0.1244,  0.0636, -0.0320,  0.1405, -0.0395,  0.1495,
          0.1408,  0.1248, -0.0757,  0.0146,  0.0482,  0.0537, -0.0734,  0.1391,
         -0.0684, -0.0273, -0.0602,  0.1477,  0.0831, -0.0284, -0.0497,  0.1090,
         -0.0815,  0.0835, -0.0816,  0.0044, -0.0109,  0.0197,  0.0562, -0.0319,
         -0.0269,  0.0729,  0.0184,  0.0580,  0.1488, -0.0201,  0.0126,  0.1192,
         -0.1333, -0.1208,  0.0426, -0.0527,  0.0522,  0.0724,  0.0462, -0.0141,
          0.0093, -0.0833, -0.0519,  0.0021, -0.0076,  0.0996,  0.0084, -0.1087,
          0.0911, -0.0185,  0.0896,  0.1188, -0.0782,  0.0501, -0.0730,  0.0954,
          0.1154, -0.0214,  0.0915, -0.0675,  0.0190, -0.0782, -0.1191, -0.0543,
          0.0647,  0.1138,  0.1502, -0.1252,  0.1276, -0.1131, -0.1132,  0.1429,
         -0.1200, -0.1510, -0.1490, -0.0415,  0.1513, -0.0695,  0.0603, -0.0897,
         -0.0984,  0.0011, -0.0791,  0.0770, -0.0948,  0.0327, -0.1113,  0.1060,
          0.1381, -0.0641,  0.0417,  0.1477, -0.0488,  0.0401,  0.0376,  0.1077,
          0.0488,  0.1403,  0.0074,  0.0781, -0.0098,  0.0455,  0.1051,  0.1338,
          0.1003, -0.1415, -0.1039,  0.0662,  0.0276, -0.1287, -0.0800,  0.0528,
         -0.0323,  0.1019,  0.0197, -0.1100,  0.1330,  0.0309,  0.0150, -0.0535,
          0.0530, -0.1181,  0.0704, -0.1312, -0.1501, -0.0531,  0.0641,  0.0153,
         -0.0384,  0.0493,  0.1399,  0.0224,  0.0764,  0.0028, -0.1163,  0.0259,
          0.0540,  0.0589,  0.0486, -0.1271,  0.0133,  0.1446,  0.1271,  0.0617,
         -0.1453, -0.0685, -0.0012, -0.0355, -0.1374, -0.1182,  0.0124, -0.1150,
         -0.1136, -0.1377,  0.0988,  0.0126,  0.0669,  0.0700,  0.1269, -0.1156,
         -0.0881,  0.1259, -0.1032,  0.0144,  0.0143,  0.1374, -0.1183, -0.0854,
          0.0532, -0.1083, -0.0484, -0.1189,  0.1183,  0.0935,  0.1251, -0.0020,
         -0.0456, -0.1486, -0.0497, -0.0902, -0.0774,  0.0485,  0.0868, -0.1023]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.1161, -0.1362, -0.1437, -0.0539,  0.0245, -0.0504, -0.0648, -0.1463,
         -0.0383, -0.1029,  0.0361,  0.0399, -0.1332, -0.1154, -0.0152, -0.1045,
          0.0491,  0.1187,  0.1009, -0.1018,  0.0428, -0.1138,  0.0158, -0.0307,
         -0.0548, -0.0170, -0.0394, -0.0801,  0.0556,  0.1492, -0.1457,  0.0395,
          0.0332,  0.0835,  0.0657,  0.0712, -0.0610,  0.0634, -0.1157, -0.0457,
          0.1505, -0.1143, -0.1214, -0.0247,  0.0901, -0.0601,  0.0267, -0.1456,
          0.0057,  0.1475,  0.1023, -0.1059, -0.1490, -0.0256, -0.0350, -0.1350,
          0.0881,  0.0134,  0.0514,  0.1436,  0.0162, -0.0118, -0.1081,  0.0935,
         -0.0489,  0.0556, -0.1244,  0.0636, -0.0320,  0.1405, -0.0395,  0.1495,
          0.1408,  0.1248, -0.0757,  0.0146,  0.0482,  0.0537, -0.0734,  0.1391,
         -0.0684, -0.0273, -0.0602,  0.1477,  0.0831, -0.0284, -0.0497,  0.1090,
         -0.0815,  0.0835, -0.0816,  0.0044, -0.0109,  0.0197,  0.0562, -0.0319,
         -0.0269,  0.0729,  0.0184,  0.0580,  0.1488, -0.0201,  0.0126,  0.1192,
         -0.1333, -0.1208,  0.0426, -0.0527,  0.0522,  0.0724,  0.0462, -0.0141,
          0.0093, -0.0833, -0.0519,  0.0021, -0.0076,  0.0996,  0.0084, -0.1087,
          0.0911, -0.0185,  0.0896,  0.1188, -0.0782,  0.0501, -0.0730,  0.0954,
          0.1154, -0.0214,  0.0915, -0.0675,  0.0190, -0.0782, -0.1191, -0.0543,
          0.0647,  0.1138,  0.1502, -0.1252,  0.1276, -0.1131, -0.1132,  0.1429,
         -0.1200, -0.1510, -0.1490, -0.0415,  0.1513, -0.0695,  0.0603, -0.0897,
         -0.0984,  0.0011, -0.0791,  0.0770, -0.0948,  0.0327, -0.1113,  0.1060,
          0.1381, -0.0641,  0.0417,  0.1477, -0.0488,  0.0401,  0.0376,  0.1077,
          0.0488,  0.1403,  0.0074,  0.0781, -0.0098,  0.0455,  0.1051,  0.1338,
          0.1003, -0.1415, -0.1039,  0.0662,  0.0276, -0.1287, -0.0800,  0.0528,
         -0.0323,  0.1019,  0.0197, -0.1100,  0.1330,  0.0309,  0.0150, -0.0535,
          0.0530, -0.1181,  0.0704, -0.1312, -0.1501, -0.0531,  0.0641,  0.0153,
         -0.0384,  0.0493,  0.1399,  0.0224,  0.0764,  0.0028, -0.1163,  0.0259,
          0.0540,  0.0589,  0.0486, -0.1271,  0.0133,  0.1446,  0.1271,  0.0617,
         -0.1453, -0.0685, -0.0012, -0.0355, -0.1374, -0.1182,  0.0124, -0.1150,
         -0.1136, -0.1377,  0.0988,  0.0126,  0.0669,  0.0700,  0.1269, -0.1156,
         -0.0881,  0.1259, -0.1032,  0.0144,  0.0143,  0.1374, -0.1183, -0.0854,
          0.0532, -0.1083, -0.0484, -0.1189,  0.1183,  0.0935,  0.1251, -0.0020,
         -0.0456, -0.1486, -0.0497, -0.0902, -0.0774,  0.0485,  0.0868, -0.1023]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name linear1.weight 
shape:
 torch.Size([256, 2350554]) 
grad:
 True 
date:
 tensor([[ 4.3435e-04, -1.3754e-04, -7.0986e-06,  ...,  3.8000e-04,
          2.0297e-04, -4.0992e-04],
        [-2.2542e-04,  1.8957e-04, -4.3652e-04,  ...,  3.7432e-04,
          5.4243e-04, -2.8335e-04],
        [-4.1334e-04,  4.6829e-04, -4.4573e-04,  ...,  6.0866e-04,
          9.2363e-05, -6.4485e-04],
        ...,
        [-5.7217e-05, -3.2763e-04, -2.4464e-04,  ...,  1.9981e-06,
          2.3653e-04,  3.9230e-04],
        [ 3.8039e-04, -6.0810e-04,  3.6083e-04,  ...,  6.4060e-04,
         -4.1330e-04, -5.6839e-04],
        [-3.6320e-04,  4.0342e-04,  6.4571e-04,  ...,  4.9299e-04,
          3.9100e-04,  1.1451e-04]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 4.3435e-04, -1.3754e-04, -7.0986e-06,  ...,  3.8000e-04,
          2.0297e-04, -4.0992e-04],
        [-2.2542e-04,  1.8957e-04, -4.3652e-04,  ...,  3.7432e-04,
          5.4243e-04, -2.8335e-04],
        [-4.1334e-04,  4.6829e-04, -4.4573e-04,  ...,  6.0866e-04,
          9.2363e-05, -6.4485e-04],
        ...,
        [-5.7217e-05, -3.2763e-04, -2.4464e-04,  ...,  1.9981e-06,
          2.3653e-04,  3.9230e-04],
        [ 3.8039e-04, -6.0810e-04,  3.6083e-04,  ...,  6.4060e-04,
         -4.1330e-04, -5.6839e-04],
        [-3.6320e-04,  4.0342e-04,  6.4571e-04,  ...,  4.9299e-04,
          3.9100e-04,  1.1451e-04]], device='cuda:0', requires_grad=True)

name linear1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([ 9.0707e-05,  3.6762e-04, -4.6982e-04,  4.1273e-04, -5.3955e-04,
         3.0792e-04,  6.3392e-04, -3.9575e-04, -3.0977e-04, -5.1598e-04,
         1.5609e-04, -1.5974e-04, -1.4355e-04, -2.4804e-04,  2.8005e-04,
         5.3109e-04, -2.0879e-04,  1.0601e-04,  4.3799e-04,  6.4442e-04,
         4.1852e-04,  3.0861e-04, -3.8244e-04, -8.7078e-05, -4.0592e-04,
        -6.4116e-04,  6.9949e-05, -5.3446e-04,  2.0679e-04,  3.7989e-05,
        -5.9580e-04, -6.1381e-04, -4.6708e-04, -4.0734e-04, -3.1201e-04,
        -3.4231e-04,  4.6952e-04, -5.0929e-05, -3.2484e-04, -3.5061e-04,
        -4.1886e-04, -3.2387e-04,  5.6832e-04, -1.2531e-04, -3.2040e-04,
        -2.2810e-04, -4.8328e-05, -6.7490e-05, -4.4950e-04,  1.6182e-04,
        -4.9629e-04, -4.7559e-04,  4.1098e-04,  5.3546e-04, -3.1781e-05,
         2.7149e-04, -5.6698e-04, -5.9047e-04, -4.4169e-05, -2.8250e-04,
         1.7215e-04, -2.5390e-04,  2.9831e-04, -3.6660e-04, -1.7146e-06,
         6.4043e-04,  4.2390e-05,  6.1022e-04, -2.4997e-05, -3.4389e-04,
         2.0918e-04, -1.0954e-04,  3.8146e-04, -3.4772e-04, -5.2133e-04,
        -3.4389e-04, -4.3958e-04, -2.1213e-04,  5.8333e-04,  6.2028e-04,
        -3.1175e-04, -8.9977e-05,  3.3287e-04, -1.5541e-05,  3.2605e-05,
         4.3774e-04,  1.2777e-04,  6.8893e-05,  6.1727e-04, -1.3017e-05,
        -9.0057e-05,  1.9513e-04,  5.4915e-04,  2.3501e-04,  5.4075e-04,
         6.4657e-04, -2.2786e-04,  3.1988e-04,  2.7701e-04, -3.0425e-04,
        -4.1223e-04, -3.1694e-04,  4.8257e-04, -5.6158e-04,  5.3788e-04,
         5.2168e-04,  6.1919e-04,  4.8614e-04,  3.0743e-04,  3.2090e-04,
         6.4884e-04,  1.4573e-04, -1.6635e-04, -2.3965e-04, -4.7229e-04,
         6.3118e-04,  4.5314e-04,  1.5694e-04, -3.3385e-04, -5.2706e-04,
        -4.7696e-04, -8.5098e-05, -2.7216e-04, -5.5512e-04,  3.3906e-04,
         1.2234e-04,  6.1018e-04, -2.6892e-04, -3.5405e-04,  1.5562e-04,
         2.8327e-04, -2.8149e-04, -3.4766e-04, -4.0213e-04, -3.9806e-04,
        -4.8453e-04,  4.6089e-04, -3.1611e-04, -5.9219e-04,  5.4545e-04,
         3.8963e-04, -6.0175e-04,  4.0283e-05,  3.8740e-04, -1.6322e-04,
        -4.0511e-04,  5.0922e-04, -4.9688e-04,  3.4337e-04, -1.2947e-04,
         5.3724e-04, -2.9421e-04, -3.3462e-04,  8.7770e-05, -6.1137e-04,
        -9.5475e-05, -4.1323e-04, -2.1648e-04,  4.0947e-04, -3.5139e-04,
         4.7951e-04, -4.6162e-04, -9.8581e-05, -9.9815e-05, -4.0348e-04,
         3.2025e-04,  4.0659e-05,  2.0700e-04,  4.3450e-04, -1.6256e-04,
        -3.6039e-04,  5.1815e-04, -5.7373e-04, -1.5344e-04,  1.8632e-04,
         1.1911e-04,  1.3981e-04, -2.7712e-04, -4.3470e-04,  4.8084e-04,
         4.5113e-04, -2.3173e-04, -6.1680e-04, -4.1960e-04, -2.2214e-04,
         3.5179e-04, -1.9703e-04, -5.8068e-04, -6.2408e-04, -6.2487e-04,
        -5.1312e-04, -3.7908e-04,  1.4043e-04, -2.3516e-05,  6.3243e-04,
         6.0876e-05, -3.0836e-04, -3.3447e-04,  5.8144e-04,  2.7294e-05,
        -2.7084e-04,  5.4067e-04, -2.4589e-04, -4.6273e-04, -1.3395e-04,
        -4.2620e-04, -6.5217e-04,  5.8865e-04,  6.4409e-04,  5.5571e-04,
        -4.7393e-04, -3.0354e-04, -5.5876e-04,  5.0122e-04, -5.0843e-04,
        -4.1974e-05, -8.4494e-05,  2.6479e-04, -6.0610e-04, -6.3950e-04,
        -2.9669e-04,  5.1598e-04,  2.6708e-04, -7.6822e-05, -2.6249e-04,
        -2.4842e-04,  2.3393e-04,  4.1599e-04,  5.7011e-05,  3.6217e-04,
        -1.8812e-04, -4.9456e-04, -5.3743e-04, -3.4573e-04, -4.4856e-04,
        -1.8921e-04, -4.8308e-04, -3.6333e-04, -2.6096e-04,  5.1324e-05,
         4.3078e-04,  2.6702e-04,  6.0380e-04,  6.0571e-04,  2.6016e-04,
         3.3361e-04, -1.4046e-04, -6.4134e-04, -1.2191e-04,  6.4193e-05,
        -4.9878e-04,  3.1595e-04, -6.1534e-04, -2.1842e-04, -4.8023e-05,
        -5.8476e-04], device='cuda:0') 
parameter:
 Parameter containing:
tensor([ 9.0707e-05,  3.6762e-04, -4.6982e-04,  4.1273e-04, -5.3955e-04,
         3.0792e-04,  6.3392e-04, -3.9575e-04, -3.0977e-04, -5.1598e-04,
         1.5609e-04, -1.5974e-04, -1.4355e-04, -2.4804e-04,  2.8005e-04,
         5.3109e-04, -2.0879e-04,  1.0601e-04,  4.3799e-04,  6.4442e-04,
         4.1852e-04,  3.0861e-04, -3.8244e-04, -8.7078e-05, -4.0592e-04,
        -6.4116e-04,  6.9949e-05, -5.3446e-04,  2.0679e-04,  3.7989e-05,
        -5.9580e-04, -6.1381e-04, -4.6708e-04, -4.0734e-04, -3.1201e-04,
        -3.4231e-04,  4.6952e-04, -5.0929e-05, -3.2484e-04, -3.5061e-04,
        -4.1886e-04, -3.2387e-04,  5.6832e-04, -1.2531e-04, -3.2040e-04,
        -2.2810e-04, -4.8328e-05, -6.7490e-05, -4.4950e-04,  1.6182e-04,
        -4.9629e-04, -4.7559e-04,  4.1098e-04,  5.3546e-04, -3.1781e-05,
         2.7149e-04, -5.6698e-04, -5.9047e-04, -4.4169e-05, -2.8250e-04,
         1.7215e-04, -2.5390e-04,  2.9831e-04, -3.6660e-04, -1.7146e-06,
         6.4043e-04,  4.2390e-05,  6.1022e-04, -2.4997e-05, -3.4389e-04,
         2.0918e-04, -1.0954e-04,  3.8146e-04, -3.4772e-04, -5.2133e-04,
        -3.4389e-04, -4.3958e-04, -2.1213e-04,  5.8333e-04,  6.2028e-04,
        -3.1175e-04, -8.9977e-05,  3.3287e-04, -1.5541e-05,  3.2605e-05,
         4.3774e-04,  1.2777e-04,  6.8893e-05,  6.1727e-04, -1.3017e-05,
        -9.0057e-05,  1.9513e-04,  5.4915e-04,  2.3501e-04,  5.4075e-04,
         6.4657e-04, -2.2786e-04,  3.1988e-04,  2.7701e-04, -3.0425e-04,
        -4.1223e-04, -3.1694e-04,  4.8257e-04, -5.6158e-04,  5.3788e-04,
         5.2168e-04,  6.1919e-04,  4.8614e-04,  3.0743e-04,  3.2090e-04,
         6.4884e-04,  1.4573e-04, -1.6635e-04, -2.3965e-04, -4.7229e-04,
         6.3118e-04,  4.5314e-04,  1.5694e-04, -3.3385e-04, -5.2706e-04,
        -4.7696e-04, -8.5098e-05, -2.7216e-04, -5.5512e-04,  3.3906e-04,
         1.2234e-04,  6.1018e-04, -2.6892e-04, -3.5405e-04,  1.5562e-04,
         2.8327e-04, -2.8149e-04, -3.4766e-04, -4.0213e-04, -3.9806e-04,
        -4.8453e-04,  4.6089e-04, -3.1611e-04, -5.9219e-04,  5.4545e-04,
         3.8963e-04, -6.0175e-04,  4.0283e-05,  3.8740e-04, -1.6322e-04,
        -4.0511e-04,  5.0922e-04, -4.9688e-04,  3.4337e-04, -1.2947e-04,
         5.3724e-04, -2.9421e-04, -3.3462e-04,  8.7770e-05, -6.1137e-04,
        -9.5475e-05, -4.1323e-04, -2.1648e-04,  4.0947e-04, -3.5139e-04,
         4.7951e-04, -4.6162e-04, -9.8581e-05, -9.9815e-05, -4.0348e-04,
         3.2025e-04,  4.0659e-05,  2.0700e-04,  4.3450e-04, -1.6256e-04,
        -3.6039e-04,  5.1815e-04, -5.7373e-04, -1.5344e-04,  1.8632e-04,
         1.1911e-04,  1.3981e-04, -2.7712e-04, -4.3470e-04,  4.8084e-04,
         4.5113e-04, -2.3173e-04, -6.1680e-04, -4.1960e-04, -2.2214e-04,
         3.5179e-04, -1.9703e-04, -5.8068e-04, -6.2408e-04, -6.2487e-04,
        -5.1312e-04, -3.7908e-04,  1.4043e-04, -2.3516e-05,  6.3243e-04,
         6.0876e-05, -3.0836e-04, -3.3447e-04,  5.8144e-04,  2.7294e-05,
        -2.7084e-04,  5.4067e-04, -2.4589e-04, -4.6273e-04, -1.3395e-04,
        -4.2620e-04, -6.5217e-04,  5.8865e-04,  6.4409e-04,  5.5571e-04,
        -4.7393e-04, -3.0354e-04, -5.5876e-04,  5.0122e-04, -5.0843e-04,
        -4.1974e-05, -8.4494e-05,  2.6479e-04, -6.0610e-04, -6.3950e-04,
        -2.9669e-04,  5.1598e-04,  2.6708e-04, -7.6822e-05, -2.6249e-04,
        -2.4842e-04,  2.3393e-04,  4.1599e-04,  5.7011e-05,  3.6217e-04,
        -1.8812e-04, -4.9456e-04, -5.3743e-04, -3.4573e-04, -4.4856e-04,
        -1.8921e-04, -4.8308e-04, -3.6333e-04, -2.6096e-04,  5.1324e-05,
         4.3078e-04,  2.6702e-04,  6.0380e-04,  6.0571e-04,  2.6016e-04,
         3.3361e-04, -1.4046e-04, -6.4134e-04, -1.2191e-04,  6.4193e-05,
        -4.9878e-04,  3.1595e-04, -6.1534e-04, -2.1842e-04, -4.8023e-05,
        -5.8476e-04], device='cuda:0', requires_grad=True)

name linear2.weight 
shape:
 torch.Size([2350554, 256]) 
grad:
 True 
date:
 tensor([[-0.0221, -0.0332, -0.0574,  ..., -0.0159,  0.0063, -0.0592],
        [-0.0466, -0.0611, -0.0221,  ..., -0.0390, -0.0262,  0.0579],
        [ 0.0205,  0.0212, -0.0102,  ..., -0.0378,  0.0594,  0.0150],
        ...,
        [-0.0359,  0.0360,  0.0154,  ..., -0.0255, -0.0213,  0.0131],
        [-0.0080,  0.0316, -0.0451,  ...,  0.0178,  0.0028, -0.0281],
        [-0.0201, -0.0175,  0.0131,  ...,  0.0149,  0.0100, -0.0209]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0221, -0.0332, -0.0574,  ..., -0.0159,  0.0063, -0.0592],
        [-0.0466, -0.0611, -0.0221,  ..., -0.0390, -0.0262,  0.0579],
        [ 0.0205,  0.0212, -0.0102,  ..., -0.0378,  0.0594,  0.0150],
        ...,
        [-0.0359,  0.0360,  0.0154,  ..., -0.0255, -0.0213,  0.0131],
        [-0.0080,  0.0316, -0.0451,  ...,  0.0178,  0.0028, -0.0281],
        [-0.0201, -0.0175,  0.0131,  ...,  0.0149,  0.0100, -0.0209]],
       device='cuda:0', requires_grad=True)

name linear2.bias 
shape:
 torch.Size([2350554]) 
grad:
 True 
date:
 tensor([ 0.0084,  0.0199, -0.0589,  ..., -0.0173, -0.0056, -0.0288],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([ 0.0084,  0.0199, -0.0589,  ..., -0.0173, -0.0056, -0.0288],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.1245, -0.0902, -0.1058,  ...,  0.0292, -0.0506,  0.0884],
        [-0.0448, -0.0311, -0.1001,  ..., -0.0806, -0.0032, -0.1044],
        [-0.0265, -0.0729,  0.0842,  ..., -0.0365, -0.0947,  0.0778],
        ...,
        [ 0.1014,  0.1148, -0.0914,  ..., -0.0842, -0.0097, -0.0181],
        [ 0.0784,  0.0137,  0.0108,  ...,  0.0332,  0.0002, -0.1193],
        [ 0.1176,  0.1024,  0.0690,  ..., -0.0895,  0.0502,  0.0781]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1245, -0.0902, -0.1058,  ...,  0.0292, -0.0506,  0.0884],
        [-0.0448, -0.0311, -0.1001,  ..., -0.0806, -0.0032, -0.1044],
        [-0.0265, -0.0729,  0.0842,  ..., -0.0365, -0.0947,  0.0778],
        ...,
        [ 0.1014,  0.1148, -0.0914,  ..., -0.0842, -0.0097, -0.0181],
        [ 0.0784,  0.0137,  0.0108,  ...,  0.0332,  0.0002, -0.1193],
        [ 0.1176,  0.1024,  0.0690,  ..., -0.0895,  0.0502,  0.0781]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0989,  0.1171,  0.0986,  ..., -0.1737, -0.0455,  0.0421],
        [ 0.0168, -0.1028,  0.1563,  ..., -0.1202,  0.0049,  0.0164],
        [ 0.0329, -0.1706, -0.1640,  ...,  0.1404, -0.1086, -0.1188],
        ...,
        [ 0.1265, -0.0699,  0.1225,  ..., -0.1022,  0.1180, -0.0297],
        [-0.0422, -0.0875, -0.0782,  ..., -0.1642,  0.1449, -0.1629],
        [-0.0757,  0.0629, -0.1608,  ..., -0.0227,  0.0156, -0.0099]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0989,  0.1171,  0.0986,  ..., -0.1737, -0.0455,  0.0421],
        [ 0.0168, -0.1028,  0.1563,  ..., -0.1202,  0.0049,  0.0164],
        [ 0.0329, -0.1706, -0.1640,  ...,  0.1404, -0.1086, -0.1188],
        ...,
        [ 0.1265, -0.0699,  0.1225,  ..., -0.1022,  0.1180, -0.0297],
        [-0.0422, -0.0875, -0.0782,  ..., -0.1642,  0.1449, -0.1629],
        [-0.0757,  0.0629, -0.1608,  ..., -0.0227,  0.0156, -0.0099]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.2250, -0.2410, -0.2135,  ..., -0.2393,  0.0080, -0.2303],
        [ 0.1721,  0.0689,  0.0425,  ..., -0.0281,  0.1324, -0.1048],
        [-0.0300, -0.0205, -0.0165,  ..., -0.0093, -0.1784,  0.1273],
        ...,
        [ 0.0123,  0.1134,  0.0285,  ..., -0.0533, -0.0061, -0.0208],
        [-0.0585, -0.1017, -0.0199,  ..., -0.1770,  0.0650,  0.1502],
        [ 0.0201, -0.1124,  0.0904,  ...,  0.1756,  0.0907,  0.2425]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.2250, -0.2410, -0.2135,  ..., -0.2393,  0.0080, -0.2303],
        [ 0.1721,  0.0689,  0.0425,  ..., -0.0281,  0.1324, -0.1048],
        [-0.0300, -0.0205, -0.0165,  ..., -0.0093, -0.1784,  0.1273],
        ...,
        [ 0.0123,  0.1134,  0.0285,  ..., -0.0533, -0.0061, -0.0208],
        [-0.0585, -0.1017, -0.0199,  ..., -0.1770,  0.0650,  0.1502],
        [ 0.0201, -0.1124,  0.0904,  ...,  0.1756,  0.0907,  0.2425]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.1287],
        [-0.3138],
        [ 0.3625],
        [ 0.3748],
        [ 0.3195],
        [ 0.1879],
        [-0.4165],
        [-0.0007],
        [ 0.2812],
        [ 0.1795],
        [-0.3296],
        [ 0.0315],
        [ 0.1183],
        [ 0.3243],
        [ 0.0336],
        [-0.2574],
        [ 0.1047],
        [ 0.1091],
        [ 0.3137],
        [ 0.3219],
        [ 0.2383],
        [ 0.1361],
        [ 0.3159],
        [-0.0771],
        [-0.0346],
        [ 0.0189],
        [-0.1111],
        [-0.1530],
        [-0.3580],
        [-0.1814],
        [ 0.1081],
        [ 0.0509]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.1287],
        [-0.3138],
        [ 0.3625],
        [ 0.3748],
        [ 0.3195],
        [ 0.1879],
        [-0.4165],
        [-0.0007],
        [ 0.2812],
        [ 0.1795],
        [-0.3296],
        [ 0.0315],
        [ 0.1183],
        [ 0.3243],
        [ 0.0336],
        [-0.2574],
        [ 0.1047],
        [ 0.1091],
        [ 0.3137],
        [ 0.3219],
        [ 0.2383],
        [ 0.1361],
        [ 0.3159],
        [-0.0771],
        [-0.0346],
        [ 0.0189],
        [-0.1111],
        [-0.1530],
        [-0.3580],
        [-0.1814],
        [ 0.1081],
        [ 0.0509]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndneiefet.py", line 5, in <module>
    from ModelBha2ndneiefet import *
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 164, in <module>
    result1 = net(dglgraph.to(device), TraTen[1007].reshape(6796, 1).to(device))
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/ModelBha2ndneiefet.py", line 63, in forward
    print('\n\n\n\n\n shepe:', self.linear1(g.edata['efet']), '\n\n\n\n\n\n' )
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (2350554x1 and 2350554x256)

real	0m36.717s
user	0m29.868s
sys	0m6.229s
