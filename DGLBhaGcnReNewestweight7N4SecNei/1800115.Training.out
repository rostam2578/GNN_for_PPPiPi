0: gpu012.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-78c5b384-4986-bbf2-2ed8-8a0c200db7e7)
Allocate GPU cards : 0

modinfo:
filename:       /lib/modules/3.10.0-1160.71.1.el7.x86_64/extra/nvidia.ko.xz
firmware:       nvidia/515.65.01/gsp.bin
alias:          char-major-195-*
version:        515.65.01
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.9
srcversion:     8049D44E2C1B08F41E1B8A6
alias:          pci:v000010DEd*sv*sd*bc06sc80i00*
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        drm
vermagic:       3.10.0-1160.71.1.el7.x86_64 SMP mod_unload modversions 
signer:         DKMS module signing key
sig_key:        EF:0E:98:3F:91:41:E3:86:F6:3E:64:3A:6E:A0:AF:13:10:A2:28:23
sig_hashalgo:   sha512
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_EnableS0ixPowerManagement:int
parm:           NVreg_S0ixPowerManagementVideoMemoryThreshold:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableGpuFirmware:int
parm:           NVreg_EnableGpuFirmwareLogs:int
parm:           NVreg_OpenRmEnableUnsupportedGpus:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_EnableDbgBreakpoint:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_ExcludedGpus:charp
parm:           NVreg_DmaRemapPeerMmio:int
parm:           rm_firmware_active:charp

nvidia-smi:
Wed Oct 12 13:07:36 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |
| N/A   35C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Sun_Mar_21_19:15:46_PDT_2021
Cuda compilation tools, release 11.3, V11.3.58
Build cuda_11.3.r11.3/compiler.29745058_0

 torch version: 1.10.2

 cuda version: 11.3

 is cuda available: True

 CUDNN VERSION: 8200

 Number CUDA Devices: 1

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089926656

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b8c9e15c940> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1

real	0m38.204s
user	0m3.561s
sys	0m2.215s
/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/cupy/_environment.py:438: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda110

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''




 Training ... 






 The Network ... 






 The graph ... 



edge_index
 tensor([[   0,    1,    2,  ..., 6507, 6507, 6507],
        [   1,    2,    3,  ..., 6219, 6794, 6795]]) 

edge_index shape
 torch.Size([2, 1175277])
graph: Graph(num_nodes=6796, num_edges=1175277,
      ndata_schemes={}
      edata_schemes={}) 
nodes: tensor([   0,    1,    2,  ..., 6793, 6794, 6795], device='cuda:0') 
nodes shape: torch.Size([6796]) 
edges: (tensor([   0,    1,    2,  ..., 6507, 6507, 6507], device='cuda:0'), tensor([   1,    2,    3,  ..., 6219, 6794, 6795], device='cuda:0'))

number of nodes: 6796

number of edges: 2350554

node features (random input): tensor([[ 1.4461],
        [ 0.3860],
        [-0.9702],
        ...,
        [ 1.9284],
        [ 0.2196],
        [ 0.2861]], device='cuda:0', requires_grad=True) 
node features sum: tensor(20.8434, device='cuda:0', grad_fn=<SumBackward0>)

edges features: tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
edges features sum: tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

example: 
Out degrees of node 234: 399

In degrees of node 234: 399





 Loading data ... 



training set shape (80000, 6796) 
sum 8401300

target set shape (80000, 6796) 
sum 5574226

TraTen and TrvTen shape:
 torch.Size([80000, 6796]) torch.Size([80000, 6796])
Model name: DGLBhaGcnReNewestweight7N4SecNei

net GCN(
  (conv1): GraphConv(in=1, out=256, normalization=both, activation=None)
  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)
  (conv3): GraphConv(in=128, out=64, normalization=both, activation=None)
  (conv4): GraphConv(in=64, out=32, normalization=both, activation=None)
  (conv5): GraphConv(in=32, out=1, normalization=both, activation=None)
) 
number of the free learnable parameters: 43777

parameters of the network:

name conv1.weight 
shape:
 torch.Size([1, 256]) 
grad:
 True 
date:
 tensor([[-0.0534,  0.0374, -0.1469,  0.0875, -0.0320,  0.0026, -0.1119, -0.0763,
          0.0013,  0.1052,  0.1493,  0.0080,  0.0867, -0.0873, -0.0348,  0.0885,
          0.0195, -0.0642,  0.1244,  0.0899,  0.0632,  0.0259, -0.0468, -0.1315,
          0.0914, -0.0190, -0.1387,  0.1267,  0.1127, -0.0153,  0.0681, -0.0941,
          0.1374,  0.1397,  0.0769,  0.0579,  0.0518,  0.0924, -0.0077,  0.0404,
         -0.0195, -0.1375,  0.1274, -0.0026,  0.0144, -0.1481,  0.0638,  0.0950,
         -0.0530, -0.0967, -0.0617,  0.0669,  0.0573,  0.0211, -0.1278,  0.1123,
          0.0175, -0.1314,  0.0751,  0.1359,  0.0286, -0.0072,  0.0768,  0.1287,
          0.0738,  0.0076,  0.0637, -0.0276, -0.1520,  0.0693, -0.0329, -0.1182,
         -0.1457, -0.1493,  0.1320, -0.1027,  0.0758,  0.0349, -0.0938,  0.1209,
          0.0634,  0.1514, -0.1446, -0.0597,  0.1288,  0.0454,  0.1140,  0.1288,
         -0.1508, -0.0458, -0.0374,  0.0720, -0.1160, -0.1415,  0.0329,  0.0966,
         -0.0972, -0.1272,  0.1099,  0.1394,  0.1126,  0.1085, -0.0887,  0.1042,
          0.1441, -0.1380, -0.1088, -0.0364, -0.0363, -0.0432,  0.1124,  0.0124,
         -0.0299, -0.1405,  0.0971, -0.0777,  0.0960, -0.1330, -0.0873,  0.1170,
         -0.0871,  0.0375,  0.0261,  0.1502, -0.1290,  0.0566, -0.0288, -0.1061,
          0.1303,  0.0330,  0.0467, -0.0293,  0.0056,  0.1133, -0.1509, -0.0368,
         -0.0637, -0.0738, -0.0432, -0.0470, -0.0024,  0.0920,  0.0911, -0.1506,
         -0.1120, -0.1410,  0.0939,  0.0064, -0.0399, -0.1034, -0.1083, -0.0607,
         -0.1324,  0.0813, -0.0973,  0.0227, -0.1297, -0.0418, -0.0699,  0.0975,
          0.1235,  0.0925, -0.0555,  0.0477,  0.0405,  0.1425,  0.0095,  0.0574,
          0.1376,  0.0199, -0.1521, -0.0104,  0.0181, -0.0975, -0.0915,  0.0184,
          0.0680,  0.0369,  0.1002, -0.0062,  0.0655, -0.0234, -0.1313,  0.0428,
         -0.1522, -0.0920,  0.0907, -0.1187, -0.0697, -0.0805,  0.1494, -0.0206,
          0.1259, -0.1367,  0.0348,  0.1232,  0.0374,  0.0918, -0.0730,  0.0299,
         -0.0364, -0.0606, -0.0152,  0.0094, -0.0711,  0.0006,  0.0356,  0.0772,
         -0.0767, -0.0224,  0.0902,  0.1373, -0.1199,  0.1299, -0.0676, -0.1274,
         -0.0648,  0.1401,  0.0556, -0.0012,  0.1381, -0.1470, -0.0996, -0.1019,
         -0.0706,  0.0604,  0.1245, -0.0626, -0.0847, -0.0361, -0.0378,  0.0584,
          0.0596,  0.1289,  0.1161,  0.0822, -0.0916, -0.1070,  0.0766, -0.1219,
         -0.0089, -0.1198,  0.1058, -0.1258,  0.1230,  0.0612, -0.0065,  0.1030,
          0.0822,  0.0857, -0.1363, -0.0977, -0.0595, -0.0969,  0.0990, -0.0427]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0534,  0.0374, -0.1469,  0.0875, -0.0320,  0.0026, -0.1119, -0.0763,
          0.0013,  0.1052,  0.1493,  0.0080,  0.0867, -0.0873, -0.0348,  0.0885,
          0.0195, -0.0642,  0.1244,  0.0899,  0.0632,  0.0259, -0.0468, -0.1315,
          0.0914, -0.0190, -0.1387,  0.1267,  0.1127, -0.0153,  0.0681, -0.0941,
          0.1374,  0.1397,  0.0769,  0.0579,  0.0518,  0.0924, -0.0077,  0.0404,
         -0.0195, -0.1375,  0.1274, -0.0026,  0.0144, -0.1481,  0.0638,  0.0950,
         -0.0530, -0.0967, -0.0617,  0.0669,  0.0573,  0.0211, -0.1278,  0.1123,
          0.0175, -0.1314,  0.0751,  0.1359,  0.0286, -0.0072,  0.0768,  0.1287,
          0.0738,  0.0076,  0.0637, -0.0276, -0.1520,  0.0693, -0.0329, -0.1182,
         -0.1457, -0.1493,  0.1320, -0.1027,  0.0758,  0.0349, -0.0938,  0.1209,
          0.0634,  0.1514, -0.1446, -0.0597,  0.1288,  0.0454,  0.1140,  0.1288,
         -0.1508, -0.0458, -0.0374,  0.0720, -0.1160, -0.1415,  0.0329,  0.0966,
         -0.0972, -0.1272,  0.1099,  0.1394,  0.1126,  0.1085, -0.0887,  0.1042,
          0.1441, -0.1380, -0.1088, -0.0364, -0.0363, -0.0432,  0.1124,  0.0124,
         -0.0299, -0.1405,  0.0971, -0.0777,  0.0960, -0.1330, -0.0873,  0.1170,
         -0.0871,  0.0375,  0.0261,  0.1502, -0.1290,  0.0566, -0.0288, -0.1061,
          0.1303,  0.0330,  0.0467, -0.0293,  0.0056,  0.1133, -0.1509, -0.0368,
         -0.0637, -0.0738, -0.0432, -0.0470, -0.0024,  0.0920,  0.0911, -0.1506,
         -0.1120, -0.1410,  0.0939,  0.0064, -0.0399, -0.1034, -0.1083, -0.0607,
         -0.1324,  0.0813, -0.0973,  0.0227, -0.1297, -0.0418, -0.0699,  0.0975,
          0.1235,  0.0925, -0.0555,  0.0477,  0.0405,  0.1425,  0.0095,  0.0574,
          0.1376,  0.0199, -0.1521, -0.0104,  0.0181, -0.0975, -0.0915,  0.0184,
          0.0680,  0.0369,  0.1002, -0.0062,  0.0655, -0.0234, -0.1313,  0.0428,
         -0.1522, -0.0920,  0.0907, -0.1187, -0.0697, -0.0805,  0.1494, -0.0206,
          0.1259, -0.1367,  0.0348,  0.1232,  0.0374,  0.0918, -0.0730,  0.0299,
         -0.0364, -0.0606, -0.0152,  0.0094, -0.0711,  0.0006,  0.0356,  0.0772,
         -0.0767, -0.0224,  0.0902,  0.1373, -0.1199,  0.1299, -0.0676, -0.1274,
         -0.0648,  0.1401,  0.0556, -0.0012,  0.1381, -0.1470, -0.0996, -0.1019,
         -0.0706,  0.0604,  0.1245, -0.0626, -0.0847, -0.0361, -0.0378,  0.0584,
          0.0596,  0.1289,  0.1161,  0.0822, -0.0916, -0.1070,  0.0766, -0.1219,
         -0.0089, -0.1198,  0.1058, -0.1258,  0.1230,  0.0612, -0.0065,  0.1030,
          0.0822,  0.0857, -0.1363, -0.0977, -0.0595, -0.0969,  0.0990, -0.0427]],
       device='cuda:0', requires_grad=True)

name conv1.bias 
shape:
 torch.Size([256]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv2.weight 
shape:
 torch.Size([256, 128]) 
grad:
 True 
date:
 tensor([[-0.0871,  0.1146,  0.0494,  ..., -0.0207,  0.1040, -0.0734],
        [ 0.0837, -0.0118,  0.0559,  ...,  0.1112,  0.1168,  0.0363],
        [-0.0099, -0.0950, -0.0687,  ..., -0.1232,  0.1121, -0.0918],
        ...,
        [ 0.0927,  0.0558,  0.1086,  ..., -0.0899,  0.0604,  0.0203],
        [-0.0675,  0.1000, -0.0057,  ...,  0.1246, -0.0137, -0.0792],
        [-0.0785, -0.0229, -0.1064,  ..., -0.1180, -0.0654, -0.0487]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0871,  0.1146,  0.0494,  ..., -0.0207,  0.1040, -0.0734],
        [ 0.0837, -0.0118,  0.0559,  ...,  0.1112,  0.1168,  0.0363],
        [-0.0099, -0.0950, -0.0687,  ..., -0.1232,  0.1121, -0.0918],
        ...,
        [ 0.0927,  0.0558,  0.1086,  ..., -0.0899,  0.0604,  0.0203],
        [-0.0675,  0.1000, -0.0057,  ...,  0.1246, -0.0137, -0.0792],
        [-0.0785, -0.0229, -0.1064,  ..., -0.1180, -0.0654, -0.0487]],
       device='cuda:0', requires_grad=True)

name conv2.bias 
shape:
 torch.Size([128]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv3.weight 
shape:
 torch.Size([128, 64]) 
grad:
 True 
date:
 tensor([[-0.0693,  0.1103, -0.1094,  ..., -0.1519, -0.1327,  0.0676],
        [ 0.0110,  0.1590, -0.1094,  ...,  0.1737,  0.0962,  0.1399],
        [-0.0244, -0.0922, -0.0230,  ..., -0.0293,  0.0188, -0.0052],
        ...,
        [-0.0345,  0.1458,  0.0071,  ...,  0.0245,  0.1586, -0.0133],
        [ 0.0582,  0.0149,  0.0809,  ..., -0.0399,  0.1701,  0.0654],
        [-0.0355, -0.1387,  0.1379,  ...,  0.0196,  0.0383,  0.0225]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0693,  0.1103, -0.1094,  ..., -0.1519, -0.1327,  0.0676],
        [ 0.0110,  0.1590, -0.1094,  ...,  0.1737,  0.0962,  0.1399],
        [-0.0244, -0.0922, -0.0230,  ..., -0.0293,  0.0188, -0.0052],
        ...,
        [-0.0345,  0.1458,  0.0071,  ...,  0.0245,  0.1586, -0.0133],
        [ 0.0582,  0.0149,  0.0809,  ..., -0.0399,  0.1701,  0.0654],
        [-0.0355, -0.1387,  0.1379,  ...,  0.0196,  0.0383,  0.0225]],
       device='cuda:0', requires_grad=True)

name conv3.bias 
shape:
 torch.Size([64]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       device='cuda:0', requires_grad=True)

name conv4.weight 
shape:
 torch.Size([64, 32]) 
grad:
 True 
date:
 tensor([[ 0.0649, -0.2249, -0.0472,  ..., -0.0207,  0.0611,  0.2275],
        [-0.0799,  0.0937,  0.1001,  ..., -0.0932, -0.0148,  0.2487],
        [-0.0825,  0.0679, -0.0064,  ...,  0.0656,  0.0434, -0.0704],
        ...,
        [-0.0853,  0.0915, -0.2253,  ..., -0.0306, -0.0102,  0.1712],
        [-0.0659, -0.2177,  0.2360,  ..., -0.2045, -0.1305, -0.0276],
        [-0.2439, -0.1449,  0.0599,  ...,  0.0879,  0.1982,  0.0757]],
       device='cuda:0') 
parameter:
 Parameter containing:
tensor([[ 0.0649, -0.2249, -0.0472,  ..., -0.0207,  0.0611,  0.2275],
        [-0.0799,  0.0937,  0.1001,  ..., -0.0932, -0.0148,  0.2487],
        [-0.0825,  0.0679, -0.0064,  ...,  0.0656,  0.0434, -0.0704],
        ...,
        [-0.0853,  0.0915, -0.2253,  ..., -0.0306, -0.0102,  0.1712],
        [-0.0659, -0.2177,  0.2360,  ..., -0.2045, -0.1305, -0.0276],
        [-0.2439, -0.1449,  0.0599,  ...,  0.0879,  0.1982,  0.0757]],
       device='cuda:0', requires_grad=True)

name conv4.bias 
shape:
 torch.Size([32]) 
grad:
 True 
date:
 tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

name conv5.weight 
shape:
 torch.Size([32, 1]) 
grad:
 True 
date:
 tensor([[-0.0370],
        [-0.1967],
        [-0.3639],
        [ 0.0040],
        [ 0.2057],
        [ 0.1360],
        [-0.2662],
        [ 0.2403],
        [-0.3400],
        [-0.1788],
        [-0.3299],
        [ 0.4021],
        [ 0.0761],
        [ 0.1877],
        [-0.1717],
        [ 0.0612],
        [-0.0866],
        [ 0.0385],
        [ 0.4223],
        [-0.1664],
        [-0.0931],
        [ 0.2918],
        [-0.3000],
        [ 0.1433],
        [ 0.2323],
        [ 0.3223],
        [ 0.0774],
        [ 0.1774],
        [-0.2010],
        [-0.2686],
        [-0.1249],
        [-0.2593]], device='cuda:0') 
parameter:
 Parameter containing:
tensor([[-0.0370],
        [-0.1967],
        [-0.3639],
        [ 0.0040],
        [ 0.2057],
        [ 0.1360],
        [-0.2662],
        [ 0.2403],
        [-0.3400],
        [-0.1788],
        [-0.3299],
        [ 0.4021],
        [ 0.0761],
        [ 0.1877],
        [-0.1717],
        [ 0.0612],
        [-0.0866],
        [ 0.0385],
        [ 0.4223],
        [-0.1664],
        [-0.0931],
        [ 0.2918],
        [-0.3000],
        [ 0.1433],
        [ 0.2323],
        [ 0.3223],
        [ 0.0774],
        [ 0.1774],
        [-0.2010],
        [-0.2686],
        [-0.1249],
        [-0.2593]], device='cuda:0', requires_grad=True)

name conv5.bias 
shape:
 torch.Size([1]) 
grad:
 True 
date:
 tensor([0.], device='cuda:0') 
parameter:
 Parameter containing:
tensor([0.], device='cuda:0', requires_grad=True)



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')



input graph: 
g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].sum tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([6796, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(82.4738, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<AddBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(98.3449, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(10.5710, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(11.3094, device='cuda:0')



h[100].sum tensor(-2.0709, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(-2.2155, device='cuda:0')



h[200].sum tensor(10.0138, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(10.7133, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<ReluBackward0>) 
h.shape torch.Size([6796, 256]) 
h.sum tensor(395785.5000, device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[0.4586, 2.8200, 0.0000,  ..., 0.0000, 1.2742, 0.0000],
        [0.2397, 1.4740, 0.0000,  ..., 0.0000, 0.6660, 0.0000],
        [0.1045, 0.6428, 0.0000,  ..., 0.0000, 0.2904, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([6796, 128]) 
h2.sum tensor(96855568., device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(517869.1250, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(752.3051, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(-4368.1123, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-1321.5150, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=6796, num_edges=2350554,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[-1971.7389],
        [-1428.3789],
        [-1004.5702],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([6796, 1]) 
h5.sum tensor(-6.0315e+08, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', requires_grad=True) 
g.edata[efet].shape torch.Size([2350554, 1]) 
g.edata[efet].sum tensor(2350554., device='cuda:0', grad_fn=<SumBackward0>)

Passing event 1007 from the network before training input tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0') 
result1: tensor([[-1971.7389],
        [-1428.3789],
        [-1004.5702],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1])



input node feature: 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')



input graph: 
g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)}) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].sum tensor(47011080., device='cuda:0', grad_fn=<SumBackward0>) 
g.ndata[nfet].shape torch.Size([135920, 1]) 
g.ndata[nfet] tensor([[0.],
        [0.],
        [0.],
        ...,
        [0.],
        [0.],
        [0.]], device='cuda:0') 
g.ndata[nfet].sum tensor(989.0452, device='cuda:0')
param0_0.shape torch.Size([256])
param.data[:, 0].shape torch.Size([256])



h after the first convolutional layer: 
 tensor([[-0.0087, -0.0142, -0.0134,  ...,  0.0040, -0.0186, -0.0028],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<AddBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(-140.5056, device='cuda:0', grad_fn=<SumBackward0>)



h[:, 0].sum tensor(-60.5669, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[0] tensor(-65.0524, device='cuda:0')



h[100].sum tensor(129.0060, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[100] tensor(138.5602, device='cuda:0')



h[200].sum tensor(117.9659, device='cuda:0', grad_fn=<SumBackward0>)

g.ndata[nfet].sum() * conv1.weight[200] tensor(126.7024, device='cuda:0')



h1 after relu, the first updating, and another relu: 
 tensor([[0.0000, 0.0000, 0.0000,  ..., 0.1672, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.1329, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0331, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h.shape torch.Size([135920, 256]) 
h.sum tensor(3315915., device='cuda:0', grad_fn=<SumBackward0>)



h2 after the second convolutional layer: 
 tensor([[10.1513,  0.0000,  0.0000,  ...,  4.0404,  0.0000,  0.0000],
        [ 9.0137,  0.0000,  0.0000,  ...,  3.5876,  0.0000,  0.0000],
        [ 7.8827,  0.0000,  0.0000,  ...,  3.1375,  0.0000,  0.0000],
        ...,
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],
       device='cuda:0', grad_fn=<ReluBackward0>) 
h2.shape torch.Size([135920, 128]) 
h2.sum tensor(7.3806e+08, device='cuda:0', grad_fn=<SumBackward0>)



h2[0].sum tensor(5477582.5000, device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param0_2).sum() + bias0 tensor(8361.1299, device='cuda:0', grad_fn=<AddBackward0>)



h2[100].sum tensor(8518768., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param50_2).sum() + bias50 tensor(13003.2773, device='cuda:0', grad_fn=<AddBackward0>)



h2[200].sum tensor(0., device='cuda:0', grad_fn=<SumBackward0>)

(h1.sum(axis=0) * param100_2).sum() + bias100 tensor(-6560.0635, device='cuda:0', grad_fn=<AddBackward0>)



g Graph(num_nodes=135920, num_edges=47011080,
      ndata_schemes={'nfet': Scheme(shape=(1,), dtype=torch.float32), 'h1': Scheme(shape=(256,), dtype=torch.float32), 'h2': Scheme(shape=(128,), dtype=torch.float32), 'h3': Scheme(shape=(64,), dtype=torch.float32)}
      edata_schemes={'efet': Scheme(shape=(1,), dtype=torch.float32)})



 output, 
h5 tensor([[7.4727e+02],
        [8.2565e+02],
        [9.5761e+02],
        ...,
        [1.0729e-02],
        [1.7616e-02],
        [2.4463e-02]], device='cuda:0', grad_fn=<AddBackward0>) 
h5.shape torch.Size([135920, 1]) 
h5.sum tensor(4.2318e+08, device='cuda:0', grad_fn=<SumBackward0>) 
g.edata[efet] tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]], device='cuda:0', grad_fn=<CatBackward0>) 
g.edata[efet].shape torch.Size([47011080, 1]) 
g.edata[efet].sum tensor(47011080., device='cuda:0', grad_fn=<SumBackward0>)

Passing two random events from the network before training 
result1: tensor([[-1971.7389],
        [-1428.3789],
        [-1004.5702],
        ...,
        [    0.0000],
        [    0.0000],
        [    0.0000]], device='cuda:0', grad_fn=<AddBackward0>) 
result1.shape: torch.Size([6796, 1]) 
input: tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')
Traceback (most recent call last):
  File "/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/./TrainingBha2ndnei.py", line 52, in <module>
    checkpoint_load(torch.load(F"{checkpoint_dir_path}/checkpoint_dir/{TraEvN}{6}{startmesh}saved_checkpoint.tar"))
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/hpcfs/bes/mlgpu/hoseinkk/Miniconda3/envs/dgl1/lib/python3.9/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/hpcfs/bes/mlgpu/hoseinkk/MLTracking/otherparticles/pppipi/DGLBhaGcnReNewestweight7N4SecNei/checkpoint_dir/90016284saved_checkpoint.tar'

real	1m17.769s
user	0m23.807s
sys	0m9.557s
